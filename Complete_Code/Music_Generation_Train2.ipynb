{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T06:26:52.842093Z",
     "start_time": "2020-05-06T06:26:52.785104Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dropout, TimeDistributed, Dense, Activation, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T06:26:53.829897Z",
     "start_time": "2020-05-06T06:26:53.822904Z"
    }
   },
   "outputs": [],
   "source": [
    "data_directory = \"../Data2/\"\n",
    "data_file = \"Data_Tunes.txt\"  ## contains 744 Tunes Sample\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "model_weights_directory = '../Data2/Model_Weights/'\n",
    "BATCH_SIZE = 32\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T06:26:55.786152Z",
     "start_time": "2020-05-06T06:26:55.770161Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_batches(all_chars, unique_chars):\n",
    "    length = all_chars.shape[0]\n",
    "    batch_chars = int(length / BATCH_SIZE) #155222/16 = 9701\n",
    "    \n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, 64):  #(0, 9637, 64)  #it denotes number of batches. It runs everytime when\n",
    "        #new batch is created. We have a total of 151 batches.\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))    #(32, 64)\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))   #(32, 64, 87)\n",
    "        for batch_index in range(0, 32):  #it denotes each row in a batch.  \n",
    "            for i in range(0, 64):  #it denotes each column in a batch. Each column represents each character means \n",
    "                #each time-step character in a sequence.\n",
    "                X[batch_index, i] = all_chars[batch_index * batch_chars + start + i]\n",
    "                Y[batch_index, i, all_chars[batch_index * batch_chars + start + i + 1]] = 1 #here we have added '1' because the\n",
    "                #correct label will be the next character in the sequence. So, the next character will be denoted by\n",
    "                #all_chars[batch_index * batch_chars + start + i] + 1. \n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T06:26:57.180013Z",
     "start_time": "2020-05-06T06:26:57.164024Z"
    }
   },
   "outputs": [],
   "source": [
    "def built_model(batch_size, seq_length, unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (batch_size, seq_length), name = \"embd_1\")) \n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True, name = \"lstm_first\"))\n",
    "    model.add(Dropout(0.2, name = \"drp_1\"))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    model.load_weights(\"../Data/Model_Weights/Weights_80.h5\", by_name = True)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-06T06:26:58.193556Z",
     "start_time": "2020-05-06T06:26:58.167548Z"
    }
   },
   "outputs": [],
   "source": [
    "def training_model(data, epochs = 200):\n",
    "    #mapping character to index\n",
    "    char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(data))))}\n",
    "    print(\"Number of unique characters in our whole tunes database = {}\".format(len(char_to_index))) #87\n",
    "    \n",
    "    with open(os.path.join(data_directory, charIndex_json), mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "    unique_chars = len(char_to_index)\n",
    "    \n",
    "    model = built_model(BATCH_SIZE, SEQ_LENGTH, unique_chars)\n",
    "    model.summary()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"Adamax\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    all_characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    print(\"Total number of characters = \"+str(all_characters.shape[0])) #155222\n",
    "    \n",
    "    epoch_number, loss, accuracy = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        final_epoch_loss, final_epoch_accuracy = 0, 0\n",
    "        epoch_number.append(epoch+1)\n",
    "        \n",
    "        for i, (x, y) in enumerate(read_batches(all_characters, unique_chars)):\n",
    "            final_epoch_loss, final_epoch_accuracy = model.train_on_batch(x, y) #check documentation of train_on_batch here: https://keras.io/models/sequential/\n",
    "            print(\"Batch: {}, Loss: {}, Accuracy: {}\".format(i+1, final_epoch_loss, final_epoch_accuracy))\n",
    "            #here, above we are reading the batches one-by-one and train our model on each batch one-by-one.\n",
    "        loss.append(final_epoch_loss)\n",
    "        accuracy.append(final_epoch_accuracy)\n",
    "        \n",
    "        #saving weights after every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(model_weights_directory):\n",
    "                os.makedirs(model_weights_directory)\n",
    "            model.save_weights(os.path.join(model_weights_directory, \"Weights_{}.h5\".format(epoch+1)))\n",
    "            print('Saved Weights at epoch {} to file Weights_{}.h5'.format(epoch+1, epoch+1))\n",
    "    \n",
    "    #creating dataframe and record all the losses and accuracies at each epoch\n",
    "    log_frame = pd.DataFrame(columns = [\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "    log_frame[\"Epoch\"] = epoch_number\n",
    "    log_frame[\"Loss\"] = loss\n",
    "    log_frame[\"Accuracy\"] = accuracy\n",
    "    log_frame.to_csv(\"../Data2/log.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-06T06:26:59.148Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 92\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embd_1 (Embedding)           (32, 64, 512)             47104     \n",
      "_________________________________________________________________\n",
      "lstm_first (LSTM)            (32, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "drp_1 (Dropout)              (32, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (32, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (32, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (32, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (32, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (32, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (32, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (32, 64, 92)              23644     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (32, 64, 92)              0         \n",
      "=================================================================\n",
      "Total params: 2,434,140\n",
      "Trainable params: 2,434,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Total number of characters = 368948\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SACHIN\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Loss: 4.521768569946289, Accuracy: 0.0146484375\n",
      "Batch: 2, Loss: 4.500132083892822, Accuracy: 0.125\n",
      "Batch: 3, Loss: 4.397945404052734, Accuracy: 0.123046875\n",
      "Batch: 4, Loss: 3.98176908493042, Accuracy: 0.130859375\n",
      "Batch: 5, Loss: 3.7812066078186035, Accuracy: 0.12548828125\n",
      "Batch: 6, Loss: 3.590672016143799, Accuracy: 0.1259765625\n",
      "Batch: 7, Loss: 3.573263168334961, Accuracy: 0.10791015625\n",
      "Batch: 8, Loss: 3.520186424255371, Accuracy: 0.08837890625\n",
      "Batch: 9, Loss: 3.7517571449279785, Accuracy: 0.0791015625\n",
      "Batch: 10, Loss: 3.6481857299804688, Accuracy: 0.07958984375\n",
      "Batch: 11, Loss: 3.5272161960601807, Accuracy: 0.09521484375\n",
      "Batch: 12, Loss: 3.4136385917663574, Accuracy: 0.1171875\n",
      "Batch: 13, Loss: 3.3235745429992676, Accuracy: 0.13037109375\n",
      "Batch: 14, Loss: 3.515815019607544, Accuracy: 0.10888671875\n",
      "Batch: 15, Loss: 3.4710474014282227, Accuracy: 0.10009765625\n",
      "Batch: 16, Loss: 3.6054911613464355, Accuracy: 0.09716796875\n",
      "Batch: 17, Loss: 3.572608232498169, Accuracy: 0.095703125\n",
      "Batch: 18, Loss: 3.3391919136047363, Accuracy: 0.10693359375\n",
      "Batch: 19, Loss: 3.4491686820983887, Accuracy: 0.1025390625\n",
      "Batch: 20, Loss: 3.485572338104248, Accuracy: 0.10498046875\n",
      "Batch: 21, Loss: 3.3307206630706787, Accuracy: 0.10693359375\n",
      "Batch: 22, Loss: 3.429873466491699, Accuracy: 0.1064453125\n",
      "Batch: 23, Loss: 3.5596940517425537, Accuracy: 0.08642578125\n",
      "Batch: 24, Loss: 3.4147820472717285, Accuracy: 0.1123046875\n",
      "Batch: 25, Loss: 3.58074688911438, Accuracy: 0.09619140625\n",
      "Batch: 26, Loss: 3.549433469772339, Accuracy: 0.1123046875\n",
      "Batch: 27, Loss: 3.414498805999756, Accuracy: 0.1201171875\n",
      "Batch: 28, Loss: 3.4044265747070312, Accuracy: 0.11962890625\n",
      "Batch: 29, Loss: 3.449281692504883, Accuracy: 0.1103515625\n",
      "Batch: 30, Loss: 3.5465972423553467, Accuracy: 0.09765625\n",
      "Batch: 31, Loss: 3.3938779830932617, Accuracy: 0.119140625\n",
      "Batch: 32, Loss: 3.4503488540649414, Accuracy: 0.1083984375\n",
      "Batch: 33, Loss: 3.3823628425598145, Accuracy: 0.1123046875\n",
      "Batch: 34, Loss: 3.4128036499023438, Accuracy: 0.1171875\n",
      "Batch: 35, Loss: 3.4249134063720703, Accuracy: 0.109375\n",
      "Batch: 36, Loss: 3.5511207580566406, Accuracy: 0.0908203125\n",
      "Batch: 37, Loss: 3.4825172424316406, Accuracy: 0.10009765625\n",
      "Batch: 38, Loss: 3.4994280338287354, Accuracy: 0.10791015625\n",
      "Batch: 39, Loss: 3.581045150756836, Accuracy: 0.0986328125\n",
      "Batch: 40, Loss: 3.444550037384033, Accuracy: 0.11181640625\n",
      "Batch: 41, Loss: 3.326289176940918, Accuracy: 0.11572265625\n",
      "Batch: 42, Loss: 3.324864625930786, Accuracy: 0.1201171875\n",
      "Batch: 43, Loss: 3.5050156116485596, Accuracy: 0.10009765625\n",
      "Batch: 44, Loss: 3.5831689834594727, Accuracy: 0.0966796875\n",
      "Batch: 45, Loss: 3.469789505004883, Accuracy: 0.10888671875\n",
      "Batch: 46, Loss: 3.32045841217041, Accuracy: 0.14013671875\n",
      "Batch: 47, Loss: 3.289888858795166, Accuracy: 0.1259765625\n",
      "Batch: 48, Loss: 3.353908061981201, Accuracy: 0.12060546875\n",
      "Batch: 49, Loss: 3.3625881671905518, Accuracy: 0.12158203125\n",
      "Batch: 50, Loss: 3.4881086349487305, Accuracy: 0.11572265625\n",
      "Batch: 51, Loss: 3.505702495574951, Accuracy: 0.103515625\n",
      "Batch: 52, Loss: 3.3972883224487305, Accuracy: 0.1162109375\n",
      "Batch: 53, Loss: 3.2493181228637695, Accuracy: 0.126953125\n",
      "Batch: 54, Loss: 3.2772064208984375, Accuracy: 0.14111328125\n",
      "Batch: 55, Loss: 3.6127777099609375, Accuracy: 0.1025390625\n",
      "Batch: 56, Loss: 3.4769766330718994, Accuracy: 0.119140625\n",
      "Batch: 57, Loss: 3.3798136711120605, Accuracy: 0.13671875\n",
      "Batch: 58, Loss: 3.290787935256958, Accuracy: 0.1259765625\n",
      "Batch: 59, Loss: 3.373358964920044, Accuracy: 0.1455078125\n",
      "Batch: 60, Loss: 3.370260000228882, Accuracy: 0.13330078125\n",
      "Batch: 61, Loss: 3.4500021934509277, Accuracy: 0.1123046875\n",
      "Batch: 62, Loss: 3.408958673477173, Accuracy: 0.11181640625\n",
      "Batch: 63, Loss: 3.225216865539551, Accuracy: 0.12451171875\n",
      "Batch: 64, Loss: 3.1829795837402344, Accuracy: 0.1376953125\n",
      "Batch: 65, Loss: 3.3410348892211914, Accuracy: 0.11767578125\n",
      "Batch: 66, Loss: 3.281933546066284, Accuracy: 0.1220703125\n",
      "Batch: 67, Loss: 3.315702438354492, Accuracy: 0.12646484375\n",
      "Batch: 68, Loss: 3.3047149181365967, Accuracy: 0.1201171875\n",
      "Batch: 69, Loss: 3.275371789932251, Accuracy: 0.1064453125\n",
      "Batch: 70, Loss: 3.2620952129364014, Accuracy: 0.107421875\n",
      "Batch: 71, Loss: 3.3589863777160645, Accuracy: 0.10595703125\n",
      "Batch: 72, Loss: 3.305173397064209, Accuracy: 0.10400390625\n",
      "Batch: 73, Loss: 3.2598876953125, Accuracy: 0.10400390625\n",
      "Batch: 74, Loss: 3.277139663696289, Accuracy: 0.11328125\n",
      "Batch: 75, Loss: 3.239380359649658, Accuracy: 0.11767578125\n",
      "Batch: 76, Loss: 3.238821506500244, Accuracy: 0.12841796875\n",
      "Batch: 77, Loss: 3.2621164321899414, Accuracy: 0.12939453125\n",
      "Batch: 78, Loss: 3.2734556198120117, Accuracy: 0.12841796875\n",
      "Batch: 79, Loss: 3.179049015045166, Accuracy: 0.12646484375\n",
      "Batch: 80, Loss: 3.202950954437256, Accuracy: 0.1318359375\n",
      "Batch: 81, Loss: 3.259716033935547, Accuracy: 0.12451171875\n",
      "Batch: 82, Loss: 3.2788562774658203, Accuracy: 0.12890625\n",
      "Batch: 83, Loss: 3.250572919845581, Accuracy: 0.13671875\n",
      "Batch: 84, Loss: 3.208387851715088, Accuracy: 0.138671875\n",
      "Batch: 85, Loss: 3.1875243186950684, Accuracy: 0.1279296875\n",
      "Batch: 86, Loss: 3.2410080432891846, Accuracy: 0.12451171875\n",
      "Batch: 87, Loss: 3.2176966667175293, Accuracy: 0.1328125\n",
      "Batch: 88, Loss: 3.2108752727508545, Accuracy: 0.12744140625\n",
      "Batch: 89, Loss: 3.234060287475586, Accuracy: 0.12841796875\n",
      "Batch: 90, Loss: 3.171926975250244, Accuracy: 0.13525390625\n",
      "Batch: 91, Loss: 3.2012875080108643, Accuracy: 0.13427734375\n",
      "Batch: 92, Loss: 3.109116554260254, Accuracy: 0.14404296875\n",
      "Batch: 93, Loss: 3.1157784461975098, Accuracy: 0.1416015625\n",
      "Batch: 94, Loss: 3.155679702758789, Accuracy: 0.1513671875\n",
      "Batch: 95, Loss: 3.085059881210327, Accuracy: 0.15771484375\n",
      "Batch: 96, Loss: 3.176255226135254, Accuracy: 0.15283203125\n",
      "Batch: 97, Loss: 3.1815550327301025, Accuracy: 0.15283203125\n",
      "Batch: 98, Loss: 3.169755458831787, Accuracy: 0.15673828125\n",
      "Batch: 99, Loss: 3.16750431060791, Accuracy: 0.14453125\n",
      "Batch: 100, Loss: 3.1726603507995605, Accuracy: 0.1513671875\n",
      "Batch: 101, Loss: 3.153963565826416, Accuracy: 0.14599609375\n",
      "Batch: 102, Loss: 3.1354734897613525, Accuracy: 0.15771484375\n",
      "Batch: 103, Loss: 3.169125556945801, Accuracy: 0.15234375\n",
      "Batch: 104, Loss: 3.167149066925049, Accuracy: 0.17138671875\n",
      "Batch: 105, Loss: 3.1325693130493164, Accuracy: 0.181640625\n",
      "Batch: 106, Loss: 3.1279349327087402, Accuracy: 0.1748046875\n",
      "Batch: 107, Loss: 3.159576177597046, Accuracy: 0.17919921875\n",
      "Batch: 108, Loss: 3.1409716606140137, Accuracy: 0.17578125\n",
      "Batch: 109, Loss: 3.1790337562561035, Accuracy: 0.171875\n",
      "Batch: 110, Loss: 3.1042799949645996, Accuracy: 0.166015625\n",
      "Batch: 111, Loss: 3.156332492828369, Accuracy: 0.1669921875\n",
      "Batch: 112, Loss: 3.1719272136688232, Accuracy: 0.16943359375\n",
      "Batch: 113, Loss: 3.085899829864502, Accuracy: 0.16259765625\n",
      "Batch: 114, Loss: 3.070704698562622, Accuracy: 0.17041015625\n",
      "Batch: 115, Loss: 3.16459321975708, Accuracy: 0.16162109375\n",
      "Batch: 116, Loss: 3.128375768661499, Accuracy: 0.162109375\n",
      "Batch: 117, Loss: 3.056732654571533, Accuracy: 0.1689453125\n",
      "Batch: 118, Loss: 3.065980911254883, Accuracy: 0.177734375\n",
      "Batch: 119, Loss: 3.035139799118042, Accuracy: 0.17822265625\n",
      "Batch: 120, Loss: 3.066995143890381, Accuracy: 0.18798828125\n",
      "Batch: 121, Loss: 3.04687762260437, Accuracy: 0.16748046875\n",
      "Batch: 122, Loss: 3.067575216293335, Accuracy: 0.17626953125\n",
      "Batch: 123, Loss: 3.129302501678467, Accuracy: 0.16650390625\n",
      "Batch: 124, Loss: 3.08548641204834, Accuracy: 0.17578125\n",
      "Batch: 125, Loss: 3.0555145740509033, Accuracy: 0.18115234375\n",
      "Batch: 126, Loss: 3.108490467071533, Accuracy: 0.1533203125\n",
      "Batch: 127, Loss: 3.092318058013916, Accuracy: 0.16552734375\n",
      "Batch: 128, Loss: 3.1664679050445557, Accuracy: 0.15673828125\n",
      "Batch: 129, Loss: 3.1133546829223633, Accuracy: 0.17626953125\n",
      "Batch: 130, Loss: 3.1121249198913574, Accuracy: 0.17431640625\n",
      "Batch: 131, Loss: 3.167886734008789, Accuracy: 0.16650390625\n",
      "Batch: 132, Loss: 3.066506862640381, Accuracy: 0.169921875\n",
      "Batch: 133, Loss: 3.026792049407959, Accuracy: 0.1748046875\n",
      "Batch: 134, Loss: 3.0195155143737793, Accuracy: 0.19482421875\n",
      "Batch: 135, Loss: 3.0071187019348145, Accuracy: 0.1923828125\n",
      "Batch: 136, Loss: 3.0483949184417725, Accuracy: 0.19287109375\n",
      "Batch: 137, Loss: 3.0770585536956787, Accuracy: 0.17138671875\n",
      "Batch: 138, Loss: 3.069821834564209, Accuracy: 0.17431640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 139, Loss: 3.022627830505371, Accuracy: 0.18212890625\n",
      "Batch: 140, Loss: 2.9675331115722656, Accuracy: 0.20166015625\n",
      "Batch: 141, Loss: 2.926487684249878, Accuracy: 0.20751953125\n",
      "Batch: 142, Loss: 2.98268985748291, Accuracy: 0.19873046875\n",
      "Batch: 143, Loss: 3.01859712600708, Accuracy: 0.1806640625\n",
      "Batch: 144, Loss: 3.0294322967529297, Accuracy: 0.1884765625\n",
      "Batch: 145, Loss: 2.9960551261901855, Accuracy: 0.19580078125\n",
      "Batch: 146, Loss: 2.888007402420044, Accuracy: 0.212890625\n",
      "Batch: 147, Loss: 2.943621873855591, Accuracy: 0.212890625\n",
      "Batch: 148, Loss: 2.9333136081695557, Accuracy: 0.22802734375\n",
      "Batch: 149, Loss: 2.9116742610931396, Accuracy: 0.212890625\n",
      "Batch: 150, Loss: 2.9598922729492188, Accuracy: 0.21826171875\n",
      "Batch: 151, Loss: 2.859642744064331, Accuracy: 0.22216796875\n",
      "Batch: 152, Loss: 2.8918113708496094, Accuracy: 0.2255859375\n",
      "Batch: 153, Loss: 2.873473882675171, Accuracy: 0.220703125\n",
      "Batch: 154, Loss: 2.871687412261963, Accuracy: 0.21875\n",
      "Batch: 155, Loss: 2.870089530944824, Accuracy: 0.224609375\n",
      "Batch: 156, Loss: 2.8303616046905518, Accuracy: 0.23876953125\n",
      "Batch: 157, Loss: 2.8615221977233887, Accuracy: 0.228515625\n",
      "Batch: 158, Loss: 2.849395275115967, Accuracy: 0.21728515625\n",
      "Batch: 159, Loss: 2.8456108570098877, Accuracy: 0.22705078125\n",
      "Batch: 160, Loss: 2.8148465156555176, Accuracy: 0.2314453125\n",
      "Batch: 161, Loss: 2.8637516498565674, Accuracy: 0.22021484375\n",
      "Batch: 162, Loss: 2.9049153327941895, Accuracy: 0.23828125\n",
      "Batch: 163, Loss: 2.796952247619629, Accuracy: 0.2568359375\n",
      "Batch: 164, Loss: 2.814826488494873, Accuracy: 0.244140625\n",
      "Batch: 165, Loss: 2.819978713989258, Accuracy: 0.2509765625\n",
      "Batch: 166, Loss: 2.8195302486419678, Accuracy: 0.244140625\n",
      "Batch: 167, Loss: 2.852217197418213, Accuracy: 0.24169921875\n",
      "Batch: 168, Loss: 2.7694764137268066, Accuracy: 0.28369140625\n",
      "Batch: 169, Loss: 2.722135066986084, Accuracy: 0.27392578125\n",
      "Batch: 170, Loss: 2.8100075721740723, Accuracy: 0.26171875\n",
      "Batch: 171, Loss: 2.7591605186462402, Accuracy: 0.2529296875\n",
      "Batch: 172, Loss: 2.760284900665283, Accuracy: 0.27099609375\n",
      "Batch: 173, Loss: 2.8662185668945312, Accuracy: 0.25146484375\n",
      "Batch: 174, Loss: 2.7694380283355713, Accuracy: 0.2861328125\n",
      "Batch: 175, Loss: 2.7112069129943848, Accuracy: 0.30078125\n",
      "Batch: 176, Loss: 2.806403875350952, Accuracy: 0.28369140625\n",
      "Batch: 177, Loss: 2.738644599914551, Accuracy: 0.29638671875\n",
      "Batch: 178, Loss: 2.7348899841308594, Accuracy: 0.28515625\n",
      "Batch: 179, Loss: 2.7614681720733643, Accuracy: 0.287109375\n",
      "Batch: 180, Loss: 2.76076602935791, Accuracy: 0.30078125\n",
      "Epoch 2/200\n",
      "Batch: 1, Loss: 2.983048677444458, Accuracy: 0.25390625\n",
      "Batch: 2, Loss: 2.7264342308044434, Accuracy: 0.294921875\n",
      "Batch: 3, Loss: 2.7576093673706055, Accuracy: 0.27587890625\n",
      "Batch: 4, Loss: 2.7011401653289795, Accuracy: 0.28466796875\n",
      "Batch: 5, Loss: 2.7123124599456787, Accuracy: 0.296875\n",
      "Batch: 6, Loss: 2.6543192863464355, Accuracy: 0.3115234375\n",
      "Batch: 7, Loss: 2.6782639026641846, Accuracy: 0.30615234375\n",
      "Batch: 8, Loss: 2.6365058422088623, Accuracy: 0.3115234375\n",
      "Batch: 9, Loss: 2.7832489013671875, Accuracy: 0.27978515625\n",
      "Batch: 10, Loss: 2.726046085357666, Accuracy: 0.27685546875\n",
      "Batch: 11, Loss: 2.622093915939331, Accuracy: 0.318359375\n",
      "Batch: 12, Loss: 2.536968946456909, Accuracy: 0.35400390625\n",
      "Batch: 13, Loss: 2.5319323539733887, Accuracy: 0.357421875\n",
      "Batch: 14, Loss: 2.6354458332061768, Accuracy: 0.32373046875\n",
      "Batch: 15, Loss: 2.6338558197021484, Accuracy: 0.3212890625\n",
      "Batch: 16, Loss: 2.690735340118408, Accuracy: 0.30029296875\n",
      "Batch: 17, Loss: 2.619626522064209, Accuracy: 0.3193359375\n",
      "Batch: 18, Loss: 2.5510976314544678, Accuracy: 0.33935546875\n",
      "Batch: 19, Loss: 2.632761001586914, Accuracy: 0.3251953125\n",
      "Batch: 20, Loss: 2.61232590675354, Accuracy: 0.32861328125\n",
      "Batch: 21, Loss: 2.57914137840271, Accuracy: 0.341796875\n",
      "Batch: 22, Loss: 2.5887250900268555, Accuracy: 0.33984375\n",
      "Batch: 23, Loss: 2.690427303314209, Accuracy: 0.3125\n",
      "Batch: 24, Loss: 2.55035400390625, Accuracy: 0.34326171875\n",
      "Batch: 25, Loss: 2.6593832969665527, Accuracy: 0.30908203125\n",
      "Batch: 26, Loss: 2.669203996658325, Accuracy: 0.314453125\n",
      "Batch: 27, Loss: 2.524928569793701, Accuracy: 0.34912109375\n",
      "Batch: 28, Loss: 2.4574410915374756, Accuracy: 0.36181640625\n",
      "Batch: 29, Loss: 2.5198237895965576, Accuracy: 0.35400390625\n",
      "Batch: 30, Loss: 2.5871896743774414, Accuracy: 0.3115234375\n",
      "Batch: 31, Loss: 2.4747402667999268, Accuracy: 0.37744140625\n",
      "Batch: 32, Loss: 2.5225205421447754, Accuracy: 0.35498046875\n",
      "Batch: 33, Loss: 2.494126319885254, Accuracy: 0.3583984375\n",
      "Batch: 34, Loss: 2.5143063068389893, Accuracy: 0.36376953125\n",
      "Batch: 35, Loss: 2.5732460021972656, Accuracy: 0.34375\n",
      "Batch: 36, Loss: 2.5758557319641113, Accuracy: 0.33056640625\n",
      "Batch: 37, Loss: 2.5175113677978516, Accuracy: 0.3486328125\n",
      "Batch: 38, Loss: 2.528930187225342, Accuracy: 0.33740234375\n",
      "Batch: 39, Loss: 2.61875057220459, Accuracy: 0.33154296875\n",
      "Batch: 40, Loss: 2.550393581390381, Accuracy: 0.3505859375\n",
      "Batch: 41, Loss: 2.4283647537231445, Accuracy: 0.37353515625\n",
      "Batch: 42, Loss: 2.3641247749328613, Accuracy: 0.37841796875\n",
      "Batch: 43, Loss: 2.5143957138061523, Accuracy: 0.33984375\n",
      "Batch: 44, Loss: 2.509305000305176, Accuracy: 0.32958984375\n",
      "Batch: 45, Loss: 2.4781017303466797, Accuracy: 0.35009765625\n",
      "Batch: 46, Loss: 2.3636739253997803, Accuracy: 0.36767578125\n",
      "Batch: 47, Loss: 2.346207618713379, Accuracy: 0.37646484375\n",
      "Batch: 48, Loss: 2.345471143722534, Accuracy: 0.37353515625\n",
      "Batch: 49, Loss: 2.378018379211426, Accuracy: 0.38134765625\n",
      "Batch: 50, Loss: 2.463507652282715, Accuracy: 0.35498046875\n",
      "Batch: 51, Loss: 2.4899234771728516, Accuracy: 0.3583984375\n",
      "Batch: 52, Loss: 2.387300968170166, Accuracy: 0.3505859375\n",
      "Batch: 53, Loss: 2.2663676738739014, Accuracy: 0.39453125\n",
      "Batch: 54, Loss: 2.305448532104492, Accuracy: 0.3720703125\n",
      "Batch: 55, Loss: 2.5472941398620605, Accuracy: 0.31689453125\n",
      "Batch: 56, Loss: 2.4616761207580566, Accuracy: 0.34521484375\n",
      "Batch: 57, Loss: 2.4525294303894043, Accuracy: 0.3486328125\n",
      "Batch: 58, Loss: 2.394595146179199, Accuracy: 0.3701171875\n",
      "Batch: 59, Loss: 2.468855857849121, Accuracy: 0.35693359375\n",
      "Batch: 60, Loss: 2.4367752075195312, Accuracy: 0.36376953125\n",
      "Batch: 61, Loss: 2.4096922874450684, Accuracy: 0.34619140625\n",
      "Batch: 62, Loss: 2.358880043029785, Accuracy: 0.3671875\n",
      "Batch: 63, Loss: 2.232527256011963, Accuracy: 0.39599609375\n",
      "Batch: 64, Loss: 2.1879897117614746, Accuracy: 0.423828125\n",
      "Batch: 65, Loss: 2.4116315841674805, Accuracy: 0.35888671875\n",
      "Batch: 66, Loss: 2.3347325325012207, Accuracy: 0.38232421875\n",
      "Batch: 67, Loss: 2.3856582641601562, Accuracy: 0.357421875\n",
      "Batch: 68, Loss: 2.3973379135131836, Accuracy: 0.3642578125\n",
      "Batch: 69, Loss: 2.386960506439209, Accuracy: 0.3818359375\n",
      "Batch: 70, Loss: 2.4004275798797607, Accuracy: 0.39306640625\n",
      "Batch: 71, Loss: 2.4433398246765137, Accuracy: 0.3740234375\n",
      "Batch: 72, Loss: 2.3963398933410645, Accuracy: 0.38134765625\n",
      "Batch: 73, Loss: 2.329901695251465, Accuracy: 0.40234375\n",
      "Batch: 74, Loss: 2.409210205078125, Accuracy: 0.3837890625\n",
      "Batch: 75, Loss: 2.3408994674682617, Accuracy: 0.3759765625\n",
      "Batch: 76, Loss: 2.294126510620117, Accuracy: 0.4033203125\n",
      "Batch: 77, Loss: 2.336160659790039, Accuracy: 0.361328125\n",
      "Batch: 78, Loss: 2.3635356426239014, Accuracy: 0.376953125\n",
      "Batch: 79, Loss: 2.2546210289001465, Accuracy: 0.40673828125\n",
      "Batch: 80, Loss: 2.287212371826172, Accuracy: 0.3916015625\n",
      "Batch: 81, Loss: 2.373584747314453, Accuracy: 0.38525390625\n",
      "Batch: 82, Loss: 2.3761940002441406, Accuracy: 0.365234375\n",
      "Batch: 83, Loss: 2.3449463844299316, Accuracy: 0.37109375\n",
      "Batch: 84, Loss: 2.286557197570801, Accuracy: 0.380859375\n",
      "Batch: 85, Loss: 2.2425549030303955, Accuracy: 0.392578125\n",
      "Batch: 86, Loss: 2.347165584564209, Accuracy: 0.3818359375\n",
      "Batch: 87, Loss: 2.3050146102905273, Accuracy: 0.37841796875\n",
      "Batch: 88, Loss: 2.3472485542297363, Accuracy: 0.37939453125\n",
      "Batch: 89, Loss: 2.3444559574127197, Accuracy: 0.38671875\n",
      "Batch: 90, Loss: 2.3116884231567383, Accuracy: 0.3759765625\n",
      "Batch: 91, Loss: 2.2621665000915527, Accuracy: 0.37548828125\n",
      "Batch: 92, Loss: 2.2432072162628174, Accuracy: 0.4111328125\n",
      "Batch: 93, Loss: 2.215534210205078, Accuracy: 0.40869140625\n",
      "Batch: 94, Loss: 2.3515610694885254, Accuracy: 0.38427734375\n",
      "Batch: 95, Loss: 2.2168335914611816, Accuracy: 0.41064453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 96, Loss: 2.337177276611328, Accuracy: 0.3818359375\n",
      "Batch: 97, Loss: 2.282219409942627, Accuracy: 0.40869140625\n",
      "Batch: 98, Loss: 2.3455958366394043, Accuracy: 0.3984375\n",
      "Batch: 99, Loss: 2.2546539306640625, Accuracy: 0.38818359375\n",
      "Batch: 100, Loss: 2.324881076812744, Accuracy: 0.384765625\n",
      "Batch: 101, Loss: 2.296651840209961, Accuracy: 0.39404296875\n",
      "Batch: 102, Loss: 2.2353978157043457, Accuracy: 0.4013671875\n",
      "Batch: 103, Loss: 2.2952094078063965, Accuracy: 0.3876953125\n",
      "Batch: 104, Loss: 2.3384246826171875, Accuracy: 0.388671875\n",
      "Batch: 105, Loss: 2.2880301475524902, Accuracy: 0.39453125\n",
      "Batch: 106, Loss: 2.2699694633483887, Accuracy: 0.39599609375\n",
      "Batch: 107, Loss: 2.2874441146850586, Accuracy: 0.3935546875\n",
      "Batch: 108, Loss: 2.249988079071045, Accuracy: 0.41650390625\n",
      "Batch: 109, Loss: 2.2782764434814453, Accuracy: 0.3916015625\n",
      "Batch: 110, Loss: 2.234407901763916, Accuracy: 0.40185546875\n",
      "Batch: 111, Loss: 2.227210521697998, Accuracy: 0.40625\n",
      "Batch: 112, Loss: 2.2532477378845215, Accuracy: 0.40625\n",
      "Batch: 113, Loss: 2.1775336265563965, Accuracy: 0.41796875\n",
      "Batch: 114, Loss: 2.1108663082122803, Accuracy: 0.42578125\n",
      "Batch: 115, Loss: 2.2403922080993652, Accuracy: 0.3955078125\n",
      "Batch: 116, Loss: 2.197831153869629, Accuracy: 0.41064453125\n",
      "Batch: 117, Loss: 2.114210605621338, Accuracy: 0.43115234375\n",
      "Batch: 118, Loss: 2.1326913833618164, Accuracy: 0.43505859375\n",
      "Batch: 119, Loss: 2.081313133239746, Accuracy: 0.44189453125\n",
      "Batch: 120, Loss: 2.175020694732666, Accuracy: 0.4072265625\n",
      "Batch: 121, Loss: 2.078042984008789, Accuracy: 0.439453125\n",
      "Batch: 122, Loss: 2.1220054626464844, Accuracy: 0.43310546875\n",
      "Batch: 123, Loss: 2.2162227630615234, Accuracy: 0.40380859375\n",
      "Batch: 124, Loss: 2.165463924407959, Accuracy: 0.4130859375\n",
      "Batch: 125, Loss: 2.1454577445983887, Accuracy: 0.4130859375\n",
      "Batch: 126, Loss: 2.1650938987731934, Accuracy: 0.42236328125\n",
      "Batch: 127, Loss: 2.186795711517334, Accuracy: 0.40966796875\n",
      "Batch: 128, Loss: 2.345062732696533, Accuracy: 0.3974609375\n",
      "Batch: 129, Loss: 2.236419677734375, Accuracy: 0.41259765625\n",
      "Batch: 130, Loss: 2.334451675415039, Accuracy: 0.39013671875\n",
      "Batch: 131, Loss: 2.3051743507385254, Accuracy: 0.38916015625\n",
      "Batch: 132, Loss: 2.0976622104644775, Accuracy: 0.4228515625\n",
      "Batch: 133, Loss: 2.1201720237731934, Accuracy: 0.42138671875\n",
      "Batch: 134, Loss: 2.0767221450805664, Accuracy: 0.43701171875\n",
      "Batch: 135, Loss: 2.0906176567077637, Accuracy: 0.4365234375\n",
      "Batch: 136, Loss: 2.098562717437744, Accuracy: 0.4130859375\n",
      "Batch: 137, Loss: 2.1638946533203125, Accuracy: 0.41064453125\n",
      "Batch: 138, Loss: 2.1381211280822754, Accuracy: 0.3974609375\n",
      "Batch: 139, Loss: 2.1006288528442383, Accuracy: 0.41796875\n",
      "Batch: 140, Loss: 2.020794630050659, Accuracy: 0.4453125\n",
      "Batch: 141, Loss: 2.0560989379882812, Accuracy: 0.43310546875\n",
      "Batch: 142, Loss: 1.993450403213501, Accuracy: 0.4658203125\n",
      "Batch: 143, Loss: 2.150771141052246, Accuracy: 0.40283203125\n",
      "Batch: 144, Loss: 2.1676530838012695, Accuracy: 0.4130859375\n",
      "Batch: 145, Loss: 2.108595609664917, Accuracy: 0.43310546875\n",
      "Batch: 146, Loss: 2.0345041751861572, Accuracy: 0.453125\n",
      "Batch: 147, Loss: 2.048664093017578, Accuracy: 0.43212890625\n",
      "Batch: 148, Loss: 1.9982444047927856, Accuracy: 0.45849609375\n",
      "Batch: 149, Loss: 1.9672801494598389, Accuracy: 0.46875\n",
      "Batch: 150, Loss: 2.0447301864624023, Accuracy: 0.4482421875\n",
      "Batch: 151, Loss: 1.9627529382705688, Accuracy: 0.4599609375\n",
      "Batch: 152, Loss: 1.964586853981018, Accuracy: 0.46875\n",
      "Batch: 153, Loss: 2.0018348693847656, Accuracy: 0.46435546875\n",
      "Batch: 154, Loss: 1.972901463508606, Accuracy: 0.45849609375\n",
      "Batch: 155, Loss: 2.054448127746582, Accuracy: 0.4443359375\n",
      "Batch: 156, Loss: 1.9499962329864502, Accuracy: 0.4775390625\n",
      "Batch: 157, Loss: 1.9533329010009766, Accuracy: 0.45654296875\n",
      "Batch: 158, Loss: 1.9122285842895508, Accuracy: 0.46875\n",
      "Batch: 159, Loss: 1.958691120147705, Accuracy: 0.4599609375\n",
      "Batch: 160, Loss: 1.901230812072754, Accuracy: 0.4736328125\n",
      "Batch: 161, Loss: 2.0134224891662598, Accuracy: 0.45751953125\n",
      "Batch: 162, Loss: 2.0787525177001953, Accuracy: 0.4462890625\n",
      "Batch: 163, Loss: 1.9180556535720825, Accuracy: 0.4814453125\n",
      "Batch: 164, Loss: 1.9831721782684326, Accuracy: 0.46435546875\n",
      "Batch: 165, Loss: 1.9749178886413574, Accuracy: 0.46484375\n",
      "Batch: 166, Loss: 2.010434150695801, Accuracy: 0.447265625\n",
      "Batch: 167, Loss: 2.0086112022399902, Accuracy: 0.43310546875\n",
      "Batch: 168, Loss: 1.9006255865097046, Accuracy: 0.4814453125\n",
      "Batch: 169, Loss: 1.8592092990875244, Accuracy: 0.48876953125\n",
      "Batch: 170, Loss: 2.031074047088623, Accuracy: 0.4423828125\n",
      "Batch: 171, Loss: 1.9378149509429932, Accuracy: 0.4619140625\n",
      "Batch: 172, Loss: 1.954183578491211, Accuracy: 0.46826171875\n",
      "Batch: 173, Loss: 2.1056013107299805, Accuracy: 0.42529296875\n",
      "Batch: 174, Loss: 1.9450386762619019, Accuracy: 0.46630859375\n",
      "Batch: 175, Loss: 1.9358571767807007, Accuracy: 0.47216796875\n",
      "Batch: 176, Loss: 2.1039786338806152, Accuracy: 0.43212890625\n",
      "Batch: 177, Loss: 2.0073752403259277, Accuracy: 0.44287109375\n",
      "Batch: 178, Loss: 2.0060150623321533, Accuracy: 0.43896484375\n",
      "Batch: 179, Loss: 2.0261058807373047, Accuracy: 0.43505859375\n",
      "Batch: 180, Loss: 2.0677900314331055, Accuracy: 0.4462890625\n",
      "Epoch 3/200\n",
      "Batch: 1, Loss: 2.575383186340332, Accuracy: 0.359375\n",
      "Batch: 2, Loss: 2.0604124069213867, Accuracy: 0.4326171875\n",
      "Batch: 3, Loss: 2.0314555168151855, Accuracy: 0.4423828125\n",
      "Batch: 4, Loss: 2.0188093185424805, Accuracy: 0.4501953125\n",
      "Batch: 5, Loss: 2.0441579818725586, Accuracy: 0.44140625\n",
      "Batch: 6, Loss: 1.9732667207717896, Accuracy: 0.4609375\n",
      "Batch: 7, Loss: 1.9830045700073242, Accuracy: 0.45263671875\n",
      "Batch: 8, Loss: 1.9979486465454102, Accuracy: 0.45361328125\n",
      "Batch: 9, Loss: 2.1413445472717285, Accuracy: 0.416015625\n",
      "Batch: 10, Loss: 2.0834367275238037, Accuracy: 0.4482421875\n",
      "Batch: 11, Loss: 2.0091371536254883, Accuracy: 0.46240234375\n",
      "Batch: 12, Loss: 1.825385570526123, Accuracy: 0.49267578125\n",
      "Batch: 13, Loss: 1.8494576215744019, Accuracy: 0.4921875\n",
      "Batch: 14, Loss: 2.0054984092712402, Accuracy: 0.45849609375\n",
      "Batch: 15, Loss: 1.958126425743103, Accuracy: 0.453125\n",
      "Batch: 16, Loss: 2.0592777729034424, Accuracy: 0.44580078125\n",
      "Batch: 17, Loss: 1.9950416088104248, Accuracy: 0.45849609375\n",
      "Batch: 18, Loss: 1.912123203277588, Accuracy: 0.47705078125\n",
      "Batch: 19, Loss: 2.006955623626709, Accuracy: 0.4541015625\n",
      "Batch: 20, Loss: 1.9469225406646729, Accuracy: 0.47900390625\n",
      "Batch: 21, Loss: 2.042125701904297, Accuracy: 0.4462890625\n",
      "Batch: 22, Loss: 2.0117716789245605, Accuracy: 0.45947265625\n",
      "Batch: 23, Loss: 2.0120346546173096, Accuracy: 0.44384765625\n",
      "Batch: 24, Loss: 1.9157794713974, Accuracy: 0.47119140625\n",
      "Batch: 25, Loss: 2.05330753326416, Accuracy: 0.44384765625\n",
      "Batch: 26, Loss: 2.115022659301758, Accuracy: 0.435546875\n",
      "Batch: 27, Loss: 1.9479708671569824, Accuracy: 0.46142578125\n",
      "Batch: 28, Loss: 1.86557936668396, Accuracy: 0.47705078125\n",
      "Batch: 29, Loss: 1.9607912302017212, Accuracy: 0.45654296875\n",
      "Batch: 30, Loss: 1.9793212413787842, Accuracy: 0.4462890625\n",
      "Batch: 31, Loss: 1.9717652797698975, Accuracy: 0.46484375\n",
      "Batch: 32, Loss: 2.0293869972229004, Accuracy: 0.447265625\n",
      "Batch: 33, Loss: 1.9729763269424438, Accuracy: 0.45849609375\n",
      "Batch: 34, Loss: 1.9823459386825562, Accuracy: 0.4599609375\n",
      "Batch: 35, Loss: 2.0631065368652344, Accuracy: 0.43310546875\n",
      "Batch: 36, Loss: 2.0458455085754395, Accuracy: 0.43701171875\n",
      "Batch: 37, Loss: 1.9884765148162842, Accuracy: 0.451171875\n",
      "Batch: 38, Loss: 1.9932994842529297, Accuracy: 0.45458984375\n",
      "Batch: 39, Loss: 2.0736398696899414, Accuracy: 0.4453125\n",
      "Batch: 40, Loss: 1.999365210533142, Accuracy: 0.45947265625\n",
      "Batch: 41, Loss: 1.9388432502746582, Accuracy: 0.45751953125\n",
      "Batch: 42, Loss: 1.8735990524291992, Accuracy: 0.46142578125\n",
      "Batch: 43, Loss: 1.9650981426239014, Accuracy: 0.4580078125\n",
      "Batch: 44, Loss: 1.9316754341125488, Accuracy: 0.45703125\n",
      "Batch: 45, Loss: 1.9702284336090088, Accuracy: 0.4609375\n",
      "Batch: 46, Loss: 1.8270899057388306, Accuracy: 0.47802734375\n",
      "Batch: 47, Loss: 1.8403595685958862, Accuracy: 0.478515625\n",
      "Batch: 48, Loss: 1.8599730730056763, Accuracy: 0.478515625\n",
      "Batch: 49, Loss: 1.8859872817993164, Accuracy: 0.4775390625\n",
      "Batch: 50, Loss: 1.9965956211090088, Accuracy: 0.44091796875\n",
      "Batch: 51, Loss: 2.0317177772521973, Accuracy: 0.4521484375\n",
      "Batch: 52, Loss: 1.8983893394470215, Accuracy: 0.48681640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 53, Loss: 1.7965424060821533, Accuracy: 0.49365234375\n",
      "Batch: 54, Loss: 1.8510417938232422, Accuracy: 0.4658203125\n",
      "Batch: 55, Loss: 2.0210280418395996, Accuracy: 0.44140625\n",
      "Batch: 56, Loss: 1.9369453191757202, Accuracy: 0.46728515625\n",
      "Batch: 57, Loss: 1.9962308406829834, Accuracy: 0.43896484375\n",
      "Batch: 58, Loss: 1.920936107635498, Accuracy: 0.4677734375\n",
      "Batch: 59, Loss: 2.0403518676757812, Accuracy: 0.43896484375\n",
      "Batch: 60, Loss: 1.9544304609298706, Accuracy: 0.4619140625\n",
      "Batch: 61, Loss: 1.8850622177124023, Accuracy: 0.4609375\n",
      "Batch: 62, Loss: 1.9081244468688965, Accuracy: 0.46533203125\n",
      "Batch: 63, Loss: 1.8137482404708862, Accuracy: 0.48583984375\n",
      "Batch: 64, Loss: 1.8108738660812378, Accuracy: 0.486328125\n",
      "Batch: 65, Loss: 1.9643608331680298, Accuracy: 0.44970703125\n",
      "Batch: 66, Loss: 1.9013227224349976, Accuracy: 0.47021484375\n",
      "Batch: 67, Loss: 1.934730052947998, Accuracy: 0.45068359375\n",
      "Batch: 68, Loss: 1.8691672086715698, Accuracy: 0.47021484375\n",
      "Batch: 69, Loss: 1.9529087543487549, Accuracy: 0.45751953125\n",
      "Batch: 70, Loss: 2.0020720958709717, Accuracy: 0.45263671875\n",
      "Batch: 71, Loss: 2.0089712142944336, Accuracy: 0.45166015625\n",
      "Batch: 72, Loss: 1.9588125944137573, Accuracy: 0.455078125\n",
      "Batch: 73, Loss: 1.9407761096954346, Accuracy: 0.470703125\n",
      "Batch: 74, Loss: 2.017477512359619, Accuracy: 0.45849609375\n",
      "Batch: 75, Loss: 1.9041270017623901, Accuracy: 0.47705078125\n",
      "Batch: 76, Loss: 1.8910818099975586, Accuracy: 0.48974609375\n",
      "Batch: 77, Loss: 1.8896846771240234, Accuracy: 0.47412109375\n",
      "Batch: 78, Loss: 1.943633794784546, Accuracy: 0.4599609375\n",
      "Batch: 79, Loss: 1.8456730842590332, Accuracy: 0.48681640625\n",
      "Batch: 80, Loss: 1.8929859399795532, Accuracy: 0.46435546875\n",
      "Batch: 81, Loss: 1.9803693294525146, Accuracy: 0.4697265625\n",
      "Batch: 82, Loss: 1.9129027128219604, Accuracy: 0.470703125\n",
      "Batch: 83, Loss: 1.9225764274597168, Accuracy: 0.45703125\n",
      "Batch: 84, Loss: 1.8641271591186523, Accuracy: 0.46923828125\n",
      "Batch: 85, Loss: 1.827028751373291, Accuracy: 0.47802734375\n",
      "Batch: 86, Loss: 1.9805282354354858, Accuracy: 0.44970703125\n",
      "Batch: 87, Loss: 1.9002766609191895, Accuracy: 0.47021484375\n",
      "Batch: 88, Loss: 1.9608283042907715, Accuracy: 0.44873046875\n",
      "Batch: 89, Loss: 1.9352829456329346, Accuracy: 0.46435546875\n",
      "Batch: 90, Loss: 1.9563169479370117, Accuracy: 0.43798828125\n",
      "Batch: 91, Loss: 1.850839614868164, Accuracy: 0.4775390625\n",
      "Batch: 92, Loss: 1.9135286808013916, Accuracy: 0.46875\n",
      "Batch: 93, Loss: 1.881736159324646, Accuracy: 0.466796875\n",
      "Batch: 94, Loss: 2.0032079219818115, Accuracy: 0.451171875\n",
      "Batch: 95, Loss: 1.8993961811065674, Accuracy: 0.47705078125\n",
      "Batch: 96, Loss: 1.976885437965393, Accuracy: 0.4619140625\n",
      "Batch: 97, Loss: 1.9301421642303467, Accuracy: 0.47021484375\n",
      "Batch: 98, Loss: 2.01536226272583, Accuracy: 0.45556640625\n",
      "Batch: 99, Loss: 1.9017001390457153, Accuracy: 0.47412109375\n",
      "Batch: 100, Loss: 1.976189374923706, Accuracy: 0.458984375\n",
      "Batch: 101, Loss: 1.9358413219451904, Accuracy: 0.4716796875\n",
      "Batch: 102, Loss: 1.870972990989685, Accuracy: 0.482421875\n",
      "Batch: 103, Loss: 1.948756217956543, Accuracy: 0.46337890625\n",
      "Batch: 104, Loss: 1.964229702949524, Accuracy: 0.45849609375\n",
      "Batch: 105, Loss: 1.9825513362884521, Accuracy: 0.46044921875\n",
      "Batch: 106, Loss: 1.9608122110366821, Accuracy: 0.46240234375\n",
      "Batch: 107, Loss: 1.971402883529663, Accuracy: 0.46337890625\n",
      "Batch: 108, Loss: 1.948811650276184, Accuracy: 0.46923828125\n",
      "Batch: 109, Loss: 1.9384379386901855, Accuracy: 0.45751953125\n",
      "Batch: 110, Loss: 1.849391222000122, Accuracy: 0.4794921875\n",
      "Batch: 111, Loss: 1.8599059581756592, Accuracy: 0.4765625\n",
      "Batch: 112, Loss: 1.9211769104003906, Accuracy: 0.48291015625\n",
      "Batch: 113, Loss: 1.8735146522521973, Accuracy: 0.48828125\n",
      "Batch: 114, Loss: 1.810070514678955, Accuracy: 0.48486328125\n",
      "Batch: 115, Loss: 1.8846632242202759, Accuracy: 0.46923828125\n",
      "Batch: 116, Loss: 1.8848192691802979, Accuracy: 0.470703125\n",
      "Batch: 117, Loss: 1.7769112586975098, Accuracy: 0.490234375\n",
      "Batch: 118, Loss: 1.8015484809875488, Accuracy: 0.49609375\n",
      "Batch: 119, Loss: 1.7837406396865845, Accuracy: 0.48583984375\n",
      "Batch: 120, Loss: 1.8412644863128662, Accuracy: 0.4833984375\n",
      "Batch: 121, Loss: 1.7475048303604126, Accuracy: 0.5126953125\n",
      "Batch: 122, Loss: 1.813286542892456, Accuracy: 0.4931640625\n",
      "Batch: 123, Loss: 1.9208455085754395, Accuracy: 0.47412109375\n",
      "Batch: 124, Loss: 1.816589593887329, Accuracy: 0.484375\n",
      "Batch: 125, Loss: 1.8569514751434326, Accuracy: 0.4765625\n",
      "Batch: 126, Loss: 1.8298680782318115, Accuracy: 0.4853515625\n",
      "Batch: 127, Loss: 1.8299403190612793, Accuracy: 0.4892578125\n",
      "Batch: 128, Loss: 2.0195248126983643, Accuracy: 0.4541015625\n",
      "Batch: 129, Loss: 1.9603402614593506, Accuracy: 0.45556640625\n",
      "Batch: 130, Loss: 2.020418643951416, Accuracy: 0.44873046875\n",
      "Batch: 131, Loss: 1.9686336517333984, Accuracy: 0.46240234375\n",
      "Batch: 132, Loss: 1.7543950080871582, Accuracy: 0.5048828125\n",
      "Batch: 133, Loss: 1.806469440460205, Accuracy: 0.49462890625\n",
      "Batch: 134, Loss: 1.8330200910568237, Accuracy: 0.48486328125\n",
      "Batch: 135, Loss: 1.8424017429351807, Accuracy: 0.4794921875\n",
      "Batch: 136, Loss: 1.7971179485321045, Accuracy: 0.47216796875\n",
      "Batch: 137, Loss: 1.8807151317596436, Accuracy: 0.47705078125\n",
      "Batch: 138, Loss: 1.7829893827438354, Accuracy: 0.49560546875\n",
      "Batch: 139, Loss: 1.8150616884231567, Accuracy: 0.4892578125\n",
      "Batch: 140, Loss: 1.7449984550476074, Accuracy: 0.50537109375\n",
      "Batch: 141, Loss: 1.7734109163284302, Accuracy: 0.486328125\n",
      "Batch: 142, Loss: 1.723984956741333, Accuracy: 0.50390625\n",
      "Batch: 143, Loss: 1.8571431636810303, Accuracy: 0.4765625\n",
      "Batch: 144, Loss: 1.8655472993850708, Accuracy: 0.48291015625\n",
      "Batch: 145, Loss: 1.825791597366333, Accuracy: 0.4931640625\n",
      "Batch: 146, Loss: 1.7691786289215088, Accuracy: 0.49462890625\n",
      "Batch: 147, Loss: 1.7775719165802002, Accuracy: 0.49853515625\n",
      "Batch: 148, Loss: 1.7060036659240723, Accuracy: 0.51513671875\n",
      "Batch: 149, Loss: 1.6968584060668945, Accuracy: 0.52490234375\n",
      "Batch: 150, Loss: 1.7347941398620605, Accuracy: 0.515625\n",
      "Batch: 151, Loss: 1.658155918121338, Accuracy: 0.52392578125\n",
      "Batch: 152, Loss: 1.6736105680465698, Accuracy: 0.5185546875\n",
      "Batch: 153, Loss: 1.7135775089263916, Accuracy: 0.52294921875\n",
      "Batch: 154, Loss: 1.7186939716339111, Accuracy: 0.50830078125\n",
      "Batch: 155, Loss: 1.7509520053863525, Accuracy: 0.51611328125\n",
      "Batch: 156, Loss: 1.685097575187683, Accuracy: 0.51611328125\n",
      "Batch: 157, Loss: 1.6952159404754639, Accuracy: 0.51123046875\n",
      "Batch: 158, Loss: 1.6598520278930664, Accuracy: 0.5224609375\n",
      "Batch: 159, Loss: 1.654853105545044, Accuracy: 0.53759765625\n",
      "Batch: 160, Loss: 1.6482689380645752, Accuracy: 0.51806640625\n",
      "Batch: 161, Loss: 1.7169065475463867, Accuracy: 0.5234375\n",
      "Batch: 162, Loss: 1.7815186977386475, Accuracy: 0.51416015625\n",
      "Batch: 163, Loss: 1.6596379280090332, Accuracy: 0.53271484375\n",
      "Batch: 164, Loss: 1.7574248313903809, Accuracy: 0.5009765625\n",
      "Batch: 165, Loss: 1.7130811214447021, Accuracy: 0.52587890625\n",
      "Batch: 166, Loss: 1.7591850757598877, Accuracy: 0.5068359375\n",
      "Batch: 167, Loss: 1.7169768810272217, Accuracy: 0.50830078125\n",
      "Batch: 168, Loss: 1.6254898309707642, Accuracy: 0.5400390625\n",
      "Batch: 169, Loss: 1.6288042068481445, Accuracy: 0.52734375\n",
      "Batch: 170, Loss: 1.7777342796325684, Accuracy: 0.50146484375\n",
      "Batch: 171, Loss: 1.6966993808746338, Accuracy: 0.525390625\n",
      "Batch: 172, Loss: 1.7243914604187012, Accuracy: 0.51318359375\n",
      "Batch: 173, Loss: 1.8524456024169922, Accuracy: 0.4716796875\n",
      "Batch: 174, Loss: 1.6653988361358643, Accuracy: 0.53173828125\n",
      "Batch: 175, Loss: 1.7388291358947754, Accuracy: 0.50927734375\n",
      "Batch: 176, Loss: 1.8814404010772705, Accuracy: 0.46630859375\n",
      "Batch: 177, Loss: 1.7358088493347168, Accuracy: 0.5078125\n",
      "Batch: 178, Loss: 1.7318564653396606, Accuracy: 0.4951171875\n",
      "Batch: 179, Loss: 1.7914066314697266, Accuracy: 0.4892578125\n",
      "Batch: 180, Loss: 1.8159031867980957, Accuracy: 0.494140625\n",
      "Epoch 4/200\n",
      "Batch: 1, Loss: 2.432032585144043, Accuracy: 0.3935546875\n",
      "Batch: 2, Loss: 1.7855732440948486, Accuracy: 0.4873046875\n",
      "Batch: 3, Loss: 1.7818539142608643, Accuracy: 0.49658203125\n",
      "Batch: 4, Loss: 1.7556008100509644, Accuracy: 0.48291015625\n",
      "Batch: 5, Loss: 1.8190605640411377, Accuracy: 0.48779296875\n",
      "Batch: 6, Loss: 1.7697150707244873, Accuracy: 0.49169921875\n",
      "Batch: 7, Loss: 1.7616901397705078, Accuracy: 0.4912109375\n",
      "Batch: 8, Loss: 1.7624285221099854, Accuracy: 0.49072265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 9, Loss: 1.8981443643569946, Accuracy: 0.47705078125\n",
      "Batch: 10, Loss: 1.8074734210968018, Accuracy: 0.51025390625\n",
      "Batch: 11, Loss: 1.8239598274230957, Accuracy: 0.4931640625\n",
      "Batch: 12, Loss: 1.6223387718200684, Accuracy: 0.54248046875\n",
      "Batch: 13, Loss: 1.6715538501739502, Accuracy: 0.521484375\n",
      "Batch: 14, Loss: 1.795705795288086, Accuracy: 0.49267578125\n",
      "Batch: 15, Loss: 1.724344253540039, Accuracy: 0.515625\n",
      "Batch: 16, Loss: 1.8769185543060303, Accuracy: 0.48779296875\n",
      "Batch: 17, Loss: 1.734459638595581, Accuracy: 0.52294921875\n",
      "Batch: 18, Loss: 1.725933313369751, Accuracy: 0.50830078125\n",
      "Batch: 19, Loss: 1.7953357696533203, Accuracy: 0.486328125\n",
      "Batch: 20, Loss: 1.7224349975585938, Accuracy: 0.52392578125\n",
      "Batch: 21, Loss: 1.8819425106048584, Accuracy: 0.48193359375\n",
      "Batch: 22, Loss: 1.8079538345336914, Accuracy: 0.48046875\n",
      "Batch: 23, Loss: 1.7696658372879028, Accuracy: 0.49853515625\n",
      "Batch: 24, Loss: 1.7059683799743652, Accuracy: 0.50927734375\n",
      "Batch: 25, Loss: 1.8167541027069092, Accuracy: 0.48828125\n",
      "Batch: 26, Loss: 1.8738725185394287, Accuracy: 0.4892578125\n",
      "Batch: 27, Loss: 1.762349009513855, Accuracy: 0.4892578125\n",
      "Batch: 28, Loss: 1.6756582260131836, Accuracy: 0.52587890625\n",
      "Batch: 29, Loss: 1.780128002166748, Accuracy: 0.490234375\n",
      "Batch: 30, Loss: 1.740143895149231, Accuracy: 0.50439453125\n",
      "Batch: 31, Loss: 1.8260829448699951, Accuracy: 0.48681640625\n",
      "Batch: 32, Loss: 1.8340593576431274, Accuracy: 0.48046875\n",
      "Batch: 33, Loss: 1.7903668880462646, Accuracy: 0.4970703125\n",
      "Batch: 34, Loss: 1.822969675064087, Accuracy: 0.50048828125\n",
      "Batch: 35, Loss: 1.8840036392211914, Accuracy: 0.47509765625\n",
      "Batch: 36, Loss: 1.8631575107574463, Accuracy: 0.4765625\n",
      "Batch: 37, Loss: 1.7690337896347046, Accuracy: 0.4951171875\n",
      "Batch: 38, Loss: 1.8018574714660645, Accuracy: 0.48583984375\n",
      "Batch: 39, Loss: 1.8401877880096436, Accuracy: 0.49755859375\n",
      "Batch: 40, Loss: 1.8131754398345947, Accuracy: 0.501953125\n",
      "Batch: 41, Loss: 1.7603029012680054, Accuracy: 0.4912109375\n",
      "Batch: 42, Loss: 1.7083206176757812, Accuracy: 0.49755859375\n",
      "Batch: 43, Loss: 1.7558176517486572, Accuracy: 0.51220703125\n",
      "Batch: 44, Loss: 1.69124174118042, Accuracy: 0.51513671875\n",
      "Batch: 45, Loss: 1.7293384075164795, Accuracy: 0.513671875\n",
      "Batch: 46, Loss: 1.6430950164794922, Accuracy: 0.51904296875\n",
      "Batch: 47, Loss: 1.7007114887237549, Accuracy: 0.49609375\n",
      "Batch: 48, Loss: 1.6481261253356934, Accuracy: 0.513671875\n",
      "Batch: 49, Loss: 1.6993030309677124, Accuracy: 0.51220703125\n",
      "Batch: 50, Loss: 1.7836267948150635, Accuracy: 0.49462890625\n",
      "Batch: 51, Loss: 1.818050503730774, Accuracy: 0.50146484375\n",
      "Batch: 52, Loss: 1.70497727394104, Accuracy: 0.50830078125\n",
      "Batch: 53, Loss: 1.6016230583190918, Accuracy: 0.53125\n",
      "Batch: 54, Loss: 1.6538617610931396, Accuracy: 0.501953125\n",
      "Batch: 55, Loss: 1.7760233879089355, Accuracy: 0.4921875\n",
      "Batch: 56, Loss: 1.7319365739822388, Accuracy: 0.49951171875\n",
      "Batch: 57, Loss: 1.782177209854126, Accuracy: 0.48583984375\n",
      "Batch: 58, Loss: 1.7159605026245117, Accuracy: 0.49609375\n",
      "Batch: 59, Loss: 1.8479225635528564, Accuracy: 0.48193359375\n",
      "Batch: 60, Loss: 1.7696459293365479, Accuracy: 0.5048828125\n",
      "Batch: 61, Loss: 1.6585482358932495, Accuracy: 0.52197265625\n",
      "Batch: 62, Loss: 1.6968462467193604, Accuracy: 0.52001953125\n",
      "Batch: 63, Loss: 1.671953797340393, Accuracy: 0.50830078125\n",
      "Batch: 64, Loss: 1.6669833660125732, Accuracy: 0.52197265625\n",
      "Batch: 65, Loss: 1.8012499809265137, Accuracy: 0.49169921875\n",
      "Batch: 66, Loss: 1.7287676334381104, Accuracy: 0.5087890625\n",
      "Batch: 67, Loss: 1.7511985301971436, Accuracy: 0.5\n",
      "Batch: 68, Loss: 1.684260368347168, Accuracy: 0.51806640625\n",
      "Batch: 69, Loss: 1.7882611751556396, Accuracy: 0.4921875\n",
      "Batch: 70, Loss: 1.834914207458496, Accuracy: 0.48486328125\n",
      "Batch: 71, Loss: 1.8061728477478027, Accuracy: 0.501953125\n",
      "Batch: 72, Loss: 1.8007690906524658, Accuracy: 0.48681640625\n",
      "Batch: 73, Loss: 1.8019306659698486, Accuracy: 0.4951171875\n",
      "Batch: 74, Loss: 1.8357326984405518, Accuracy: 0.49951171875\n",
      "Batch: 75, Loss: 1.7295138835906982, Accuracy: 0.5087890625\n",
      "Batch: 76, Loss: 1.746728777885437, Accuracy: 0.5126953125\n",
      "Batch: 77, Loss: 1.7136887311935425, Accuracy: 0.5029296875\n",
      "Batch: 78, Loss: 1.74306321144104, Accuracy: 0.515625\n",
      "Batch: 79, Loss: 1.6799201965332031, Accuracy: 0.52490234375\n",
      "Batch: 80, Loss: 1.7424745559692383, Accuracy: 0.48046875\n",
      "Batch: 81, Loss: 1.8023220300674438, Accuracy: 0.49951171875\n",
      "Batch: 82, Loss: 1.7088623046875, Accuracy: 0.50830078125\n",
      "Batch: 83, Loss: 1.7495977878570557, Accuracy: 0.49609375\n",
      "Batch: 84, Loss: 1.67330002784729, Accuracy: 0.51513671875\n",
      "Batch: 85, Loss: 1.6406093835830688, Accuracy: 0.5166015625\n",
      "Batch: 86, Loss: 1.8067400455474854, Accuracy: 0.47265625\n",
      "Batch: 87, Loss: 1.7435369491577148, Accuracy: 0.49853515625\n",
      "Batch: 88, Loss: 1.7759811878204346, Accuracy: 0.49462890625\n",
      "Batch: 89, Loss: 1.7556560039520264, Accuracy: 0.513671875\n",
      "Batch: 90, Loss: 1.8035415410995483, Accuracy: 0.4765625\n",
      "Batch: 91, Loss: 1.629192590713501, Accuracy: 0.53515625\n",
      "Batch: 92, Loss: 1.7619895935058594, Accuracy: 0.50634765625\n",
      "Batch: 93, Loss: 1.7239751815795898, Accuracy: 0.501953125\n",
      "Batch: 94, Loss: 1.8206725120544434, Accuracy: 0.4990234375\n",
      "Batch: 95, Loss: 1.7609827518463135, Accuracy: 0.4990234375\n",
      "Batch: 96, Loss: 1.7837371826171875, Accuracy: 0.49462890625\n",
      "Batch: 97, Loss: 1.7360856533050537, Accuracy: 0.5126953125\n",
      "Batch: 98, Loss: 1.8467116355895996, Accuracy: 0.48291015625\n",
      "Batch: 99, Loss: 1.700564980506897, Accuracy: 0.509765625\n",
      "Batch: 100, Loss: 1.7935998439788818, Accuracy: 0.4931640625\n",
      "Batch: 101, Loss: 1.7806745767593384, Accuracy: 0.49951171875\n",
      "Batch: 102, Loss: 1.6827552318572998, Accuracy: 0.5205078125\n",
      "Batch: 103, Loss: 1.7479650974273682, Accuracy: 0.50048828125\n",
      "Batch: 104, Loss: 1.7517826557159424, Accuracy: 0.5146484375\n",
      "Batch: 105, Loss: 1.798591136932373, Accuracy: 0.490234375\n",
      "Batch: 106, Loss: 1.8105764389038086, Accuracy: 0.48974609375\n",
      "Batch: 107, Loss: 1.7833340167999268, Accuracy: 0.505859375\n",
      "Batch: 108, Loss: 1.7823824882507324, Accuracy: 0.5009765625\n",
      "Batch: 109, Loss: 1.7494789361953735, Accuracy: 0.5068359375\n",
      "Batch: 110, Loss: 1.6898643970489502, Accuracy: 0.5205078125\n",
      "Batch: 111, Loss: 1.6966867446899414, Accuracy: 0.51416015625\n",
      "Batch: 112, Loss: 1.7551369667053223, Accuracy: 0.525390625\n",
      "Batch: 113, Loss: 1.7190431356430054, Accuracy: 0.52490234375\n",
      "Batch: 114, Loss: 1.6563355922698975, Accuracy: 0.52880859375\n",
      "Batch: 115, Loss: 1.73691987991333, Accuracy: 0.49951171875\n",
      "Batch: 116, Loss: 1.707014799118042, Accuracy: 0.51123046875\n",
      "Batch: 117, Loss: 1.6457716226577759, Accuracy: 0.51513671875\n",
      "Batch: 118, Loss: 1.661620855331421, Accuracy: 0.52685546875\n",
      "Batch: 119, Loss: 1.6407688856124878, Accuracy: 0.51513671875\n",
      "Batch: 120, Loss: 1.6736640930175781, Accuracy: 0.51416015625\n",
      "Batch: 121, Loss: 1.6143016815185547, Accuracy: 0.541015625\n",
      "Batch: 122, Loss: 1.664681077003479, Accuracy: 0.5302734375\n",
      "Batch: 123, Loss: 1.7715258598327637, Accuracy: 0.5048828125\n",
      "Batch: 124, Loss: 1.6556391716003418, Accuracy: 0.521484375\n",
      "Batch: 125, Loss: 1.7204842567443848, Accuracy: 0.5068359375\n",
      "Batch: 126, Loss: 1.6531277894973755, Accuracy: 0.53662109375\n",
      "Batch: 127, Loss: 1.6722800731658936, Accuracy: 0.533203125\n",
      "Batch: 128, Loss: 1.9086852073669434, Accuracy: 0.48046875\n",
      "Batch: 129, Loss: 1.854322075843811, Accuracy: 0.48876953125\n",
      "Batch: 130, Loss: 1.8649272918701172, Accuracy: 0.4873046875\n",
      "Batch: 131, Loss: 1.8051310777664185, Accuracy: 0.5029296875\n",
      "Batch: 132, Loss: 1.6043459177017212, Accuracy: 0.53076171875\n",
      "Batch: 133, Loss: 1.6434221267700195, Accuracy: 0.5283203125\n",
      "Batch: 134, Loss: 1.7070448398590088, Accuracy: 0.505859375\n",
      "Batch: 135, Loss: 1.7399581670761108, Accuracy: 0.49609375\n",
      "Batch: 136, Loss: 1.6710978746414185, Accuracy: 0.5087890625\n",
      "Batch: 137, Loss: 1.7595369815826416, Accuracy: 0.509765625\n",
      "Batch: 138, Loss: 1.611482858657837, Accuracy: 0.544921875\n",
      "Batch: 139, Loss: 1.6919684410095215, Accuracy: 0.51123046875\n",
      "Batch: 140, Loss: 1.6136894226074219, Accuracy: 0.525390625\n",
      "Batch: 141, Loss: 1.6742184162139893, Accuracy: 0.5009765625\n",
      "Batch: 142, Loss: 1.6345564126968384, Accuracy: 0.53076171875\n",
      "Batch: 143, Loss: 1.7067586183547974, Accuracy: 0.51611328125\n",
      "Batch: 144, Loss: 1.7002499103546143, Accuracy: 0.5234375\n",
      "Batch: 145, Loss: 1.6740009784698486, Accuracy: 0.53173828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 146, Loss: 1.664355754852295, Accuracy: 0.5244140625\n",
      "Batch: 147, Loss: 1.6401039361953735, Accuracy: 0.53759765625\n",
      "Batch: 148, Loss: 1.6192336082458496, Accuracy: 0.53466796875\n",
      "Batch: 149, Loss: 1.5890114307403564, Accuracy: 0.55419921875\n",
      "Batch: 150, Loss: 1.5637401342391968, Accuracy: 0.55908203125\n",
      "Batch: 151, Loss: 1.4829058647155762, Accuracy: 0.56005859375\n",
      "Batch: 152, Loss: 1.5451321601867676, Accuracy: 0.548828125\n",
      "Batch: 153, Loss: 1.5699005126953125, Accuracy: 0.56103515625\n",
      "Batch: 154, Loss: 1.5736267566680908, Accuracy: 0.552734375\n",
      "Batch: 155, Loss: 1.6343121528625488, Accuracy: 0.54150390625\n",
      "Batch: 156, Loss: 1.5402121543884277, Accuracy: 0.56103515625\n",
      "Batch: 157, Loss: 1.5795140266418457, Accuracy: 0.54345703125\n",
      "Batch: 158, Loss: 1.543021559715271, Accuracy: 0.55322265625\n",
      "Batch: 159, Loss: 1.4922144412994385, Accuracy: 0.5693359375\n",
      "Batch: 160, Loss: 1.5473450422286987, Accuracy: 0.5458984375\n",
      "Batch: 161, Loss: 1.5965871810913086, Accuracy: 0.53271484375\n",
      "Batch: 162, Loss: 1.6433340311050415, Accuracy: 0.54296875\n",
      "Batch: 163, Loss: 1.5657572746276855, Accuracy: 0.5556640625\n",
      "Batch: 164, Loss: 1.6279423236846924, Accuracy: 0.53857421875\n",
      "Batch: 165, Loss: 1.5907135009765625, Accuracy: 0.55078125\n",
      "Batch: 166, Loss: 1.6251659393310547, Accuracy: 0.52978515625\n",
      "Batch: 167, Loss: 1.5626379251480103, Accuracy: 0.5478515625\n",
      "Batch: 168, Loss: 1.5027213096618652, Accuracy: 0.56787109375\n",
      "Batch: 169, Loss: 1.5177874565124512, Accuracy: 0.55126953125\n",
      "Batch: 170, Loss: 1.642562747001648, Accuracy: 0.53369140625\n",
      "Batch: 171, Loss: 1.5662215948104858, Accuracy: 0.55615234375\n",
      "Batch: 172, Loss: 1.5868291854858398, Accuracy: 0.5439453125\n",
      "Batch: 173, Loss: 1.6831884384155273, Accuracy: 0.5234375\n",
      "Batch: 174, Loss: 1.504506230354309, Accuracy: 0.576171875\n",
      "Batch: 175, Loss: 1.6405469179153442, Accuracy: 0.52001953125\n",
      "Batch: 176, Loss: 1.7495555877685547, Accuracy: 0.50732421875\n",
      "Batch: 177, Loss: 1.5876299142837524, Accuracy: 0.53857421875\n",
      "Batch: 178, Loss: 1.585933804512024, Accuracy: 0.533203125\n",
      "Batch: 179, Loss: 1.6404800415039062, Accuracy: 0.5185546875\n",
      "Batch: 180, Loss: 1.6847710609436035, Accuracy: 0.52001953125\n",
      "Epoch 5/200\n",
      "Batch: 1, Loss: 2.2924249172210693, Accuracy: 0.4267578125\n",
      "Batch: 2, Loss: 1.6328790187835693, Accuracy: 0.5322265625\n",
      "Batch: 3, Loss: 1.6394658088684082, Accuracy: 0.53515625\n",
      "Batch: 4, Loss: 1.6527440547943115, Accuracy: 0.517578125\n",
      "Batch: 5, Loss: 1.7123680114746094, Accuracy: 0.505859375\n",
      "Batch: 6, Loss: 1.6244049072265625, Accuracy: 0.53076171875\n",
      "Batch: 7, Loss: 1.6227328777313232, Accuracy: 0.5146484375\n",
      "Batch: 8, Loss: 1.6379326581954956, Accuracy: 0.513671875\n",
      "Batch: 9, Loss: 1.7552433013916016, Accuracy: 0.49951171875\n",
      "Batch: 10, Loss: 1.6589524745941162, Accuracy: 0.54248046875\n",
      "Batch: 11, Loss: 1.6978106498718262, Accuracy: 0.52783203125\n",
      "Batch: 12, Loss: 1.4824570417404175, Accuracy: 0.5703125\n",
      "Batch: 13, Loss: 1.5805656909942627, Accuracy: 0.53564453125\n",
      "Batch: 14, Loss: 1.6759898662567139, Accuracy: 0.51953125\n",
      "Batch: 15, Loss: 1.6164517402648926, Accuracy: 0.54248046875\n",
      "Batch: 16, Loss: 1.745689034461975, Accuracy: 0.51904296875\n",
      "Batch: 17, Loss: 1.6055891513824463, Accuracy: 0.55810546875\n",
      "Batch: 18, Loss: 1.6336376667022705, Accuracy: 0.52783203125\n",
      "Batch: 19, Loss: 1.678154706954956, Accuracy: 0.52490234375\n",
      "Batch: 20, Loss: 1.5712735652923584, Accuracy: 0.5615234375\n",
      "Batch: 21, Loss: 1.7819664478302002, Accuracy: 0.5009765625\n",
      "Batch: 22, Loss: 1.6757631301879883, Accuracy: 0.5126953125\n",
      "Batch: 23, Loss: 1.624178409576416, Accuracy: 0.5341796875\n",
      "Batch: 24, Loss: 1.606492280960083, Accuracy: 0.529296875\n",
      "Batch: 25, Loss: 1.6712411642074585, Accuracy: 0.517578125\n",
      "Batch: 26, Loss: 1.7263890504837036, Accuracy: 0.52587890625\n",
      "Batch: 27, Loss: 1.6589536666870117, Accuracy: 0.50732421875\n",
      "Batch: 28, Loss: 1.570481300354004, Accuracy: 0.5498046875\n",
      "Batch: 29, Loss: 1.6849122047424316, Accuracy: 0.51611328125\n",
      "Batch: 30, Loss: 1.609191656112671, Accuracy: 0.544921875\n",
      "Batch: 31, Loss: 1.7002524137496948, Accuracy: 0.51416015625\n",
      "Batch: 32, Loss: 1.7278428077697754, Accuracy: 0.5107421875\n",
      "Batch: 33, Loss: 1.7136383056640625, Accuracy: 0.515625\n",
      "Batch: 34, Loss: 1.7406905889511108, Accuracy: 0.521484375\n",
      "Batch: 35, Loss: 1.7750893831253052, Accuracy: 0.4931640625\n",
      "Batch: 36, Loss: 1.7144744396209717, Accuracy: 0.51806640625\n",
      "Batch: 37, Loss: 1.6500141620635986, Accuracy: 0.53271484375\n",
      "Batch: 38, Loss: 1.688398838043213, Accuracy: 0.51806640625\n",
      "Batch: 39, Loss: 1.7037798166275024, Accuracy: 0.52978515625\n",
      "Batch: 40, Loss: 1.7035703659057617, Accuracy: 0.5205078125\n",
      "Batch: 41, Loss: 1.6679012775421143, Accuracy: 0.509765625\n",
      "Batch: 42, Loss: 1.6277228593826294, Accuracy: 0.5185546875\n",
      "Batch: 43, Loss: 1.6364524364471436, Accuracy: 0.54296875\n",
      "Batch: 44, Loss: 1.5467805862426758, Accuracy: 0.5576171875\n",
      "Batch: 45, Loss: 1.5830246210098267, Accuracy: 0.546875\n",
      "Batch: 46, Loss: 1.499450445175171, Accuracy: 0.53955078125\n",
      "Batch: 47, Loss: 1.5887534618377686, Accuracy: 0.52490234375\n",
      "Batch: 48, Loss: 1.5448265075683594, Accuracy: 0.544921875\n",
      "Batch: 49, Loss: 1.584808588027954, Accuracy: 0.533203125\n",
      "Batch: 50, Loss: 1.657205581665039, Accuracy: 0.5224609375\n",
      "Batch: 51, Loss: 1.6906721591949463, Accuracy: 0.5283203125\n",
      "Batch: 52, Loss: 1.5660358667373657, Accuracy: 0.55126953125\n",
      "Batch: 53, Loss: 1.4587733745574951, Accuracy: 0.5595703125\n",
      "Batch: 54, Loss: 1.5657066106796265, Accuracy: 0.517578125\n",
      "Batch: 55, Loss: 1.6453988552093506, Accuracy: 0.53369140625\n",
      "Batch: 56, Loss: 1.5771620273590088, Accuracy: 0.54833984375\n",
      "Batch: 57, Loss: 1.639373540878296, Accuracy: 0.51953125\n",
      "Batch: 58, Loss: 1.622591495513916, Accuracy: 0.5263671875\n",
      "Batch: 59, Loss: 1.7309315204620361, Accuracy: 0.51416015625\n",
      "Batch: 60, Loss: 1.6240001916885376, Accuracy: 0.52685546875\n",
      "Batch: 61, Loss: 1.514614224433899, Accuracy: 0.57080078125\n",
      "Batch: 62, Loss: 1.576453447341919, Accuracy: 0.55810546875\n",
      "Batch: 63, Loss: 1.575058937072754, Accuracy: 0.53662109375\n",
      "Batch: 64, Loss: 1.5670015811920166, Accuracy: 0.53515625\n",
      "Batch: 65, Loss: 1.6878955364227295, Accuracy: 0.51220703125\n",
      "Batch: 66, Loss: 1.6076045036315918, Accuracy: 0.5263671875\n",
      "Batch: 67, Loss: 1.6437920331954956, Accuracy: 0.52685546875\n",
      "Batch: 68, Loss: 1.536264419555664, Accuracy: 0.5625\n",
      "Batch: 69, Loss: 1.6481690406799316, Accuracy: 0.51953125\n",
      "Batch: 70, Loss: 1.7329225540161133, Accuracy: 0.49853515625\n",
      "Batch: 71, Loss: 1.6476929187774658, Accuracy: 0.525390625\n",
      "Batch: 72, Loss: 1.6532845497131348, Accuracy: 0.5302734375\n",
      "Batch: 73, Loss: 1.7098194360733032, Accuracy: 0.51220703125\n",
      "Batch: 74, Loss: 1.748915672302246, Accuracy: 0.51904296875\n",
      "Batch: 75, Loss: 1.6202497482299805, Accuracy: 0.5341796875\n",
      "Batch: 76, Loss: 1.638221263885498, Accuracy: 0.53076171875\n",
      "Batch: 77, Loss: 1.5808268785476685, Accuracy: 0.54736328125\n",
      "Batch: 78, Loss: 1.624098300933838, Accuracy: 0.53515625\n",
      "Batch: 79, Loss: 1.5917248725891113, Accuracy: 0.54443359375\n",
      "Batch: 80, Loss: 1.6184558868408203, Accuracy: 0.51611328125\n",
      "Batch: 81, Loss: 1.6753101348876953, Accuracy: 0.5361328125\n",
      "Batch: 82, Loss: 1.5363712310791016, Accuracy: 0.54296875\n",
      "Batch: 83, Loss: 1.5991154909133911, Accuracy: 0.53173828125\n",
      "Batch: 84, Loss: 1.534956693649292, Accuracy: 0.54150390625\n",
      "Batch: 85, Loss: 1.5032249689102173, Accuracy: 0.5458984375\n",
      "Batch: 86, Loss: 1.7167978286743164, Accuracy: 0.5126953125\n",
      "Batch: 87, Loss: 1.6131290197372437, Accuracy: 0.53662109375\n",
      "Batch: 88, Loss: 1.6631615161895752, Accuracy: 0.525390625\n",
      "Batch: 89, Loss: 1.6685811281204224, Accuracy: 0.51953125\n",
      "Batch: 90, Loss: 1.7180018424987793, Accuracy: 0.5078125\n",
      "Batch: 91, Loss: 1.521742582321167, Accuracy: 0.56689453125\n",
      "Batch: 92, Loss: 1.6839470863342285, Accuracy: 0.51806640625\n",
      "Batch: 93, Loss: 1.6170815229415894, Accuracy: 0.52783203125\n",
      "Batch: 94, Loss: 1.6946159601211548, Accuracy: 0.52392578125\n",
      "Batch: 95, Loss: 1.6625277996063232, Accuracy: 0.52685546875\n",
      "Batch: 96, Loss: 1.6647791862487793, Accuracy: 0.5400390625\n",
      "Batch: 97, Loss: 1.6342532634735107, Accuracy: 0.54248046875\n",
      "Batch: 98, Loss: 1.7373991012573242, Accuracy: 0.50732421875\n",
      "Batch: 99, Loss: 1.5730056762695312, Accuracy: 0.5478515625\n",
      "Batch: 100, Loss: 1.6960465908050537, Accuracy: 0.521484375\n",
      "Batch: 101, Loss: 1.662693738937378, Accuracy: 0.5205078125\n",
      "Batch: 102, Loss: 1.5608553886413574, Accuracy: 0.55126953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 103, Loss: 1.6249074935913086, Accuracy: 0.53076171875\n",
      "Batch: 104, Loss: 1.617876410484314, Accuracy: 0.53955078125\n",
      "Batch: 105, Loss: 1.6900619268417358, Accuracy: 0.5126953125\n",
      "Batch: 106, Loss: 1.698310136795044, Accuracy: 0.50537109375\n",
      "Batch: 107, Loss: 1.6939655542373657, Accuracy: 0.53076171875\n",
      "Batch: 108, Loss: 1.6787132024765015, Accuracy: 0.52880859375\n",
      "Batch: 109, Loss: 1.6433109045028687, Accuracy: 0.52880859375\n",
      "Batch: 110, Loss: 1.5833946466445923, Accuracy: 0.52880859375\n",
      "Batch: 111, Loss: 1.5747263431549072, Accuracy: 0.54638671875\n",
      "Batch: 112, Loss: 1.6150522232055664, Accuracy: 0.5498046875\n",
      "Batch: 113, Loss: 1.638187289237976, Accuracy: 0.53271484375\n",
      "Batch: 114, Loss: 1.5673141479492188, Accuracy: 0.544921875\n",
      "Batch: 115, Loss: 1.6223886013031006, Accuracy: 0.5302734375\n",
      "Batch: 116, Loss: 1.5890278816223145, Accuracy: 0.5419921875\n",
      "Batch: 117, Loss: 1.5210013389587402, Accuracy: 0.5478515625\n",
      "Batch: 118, Loss: 1.5524553060531616, Accuracy: 0.54150390625\n",
      "Batch: 119, Loss: 1.5431842803955078, Accuracy: 0.52978515625\n",
      "Batch: 120, Loss: 1.5772886276245117, Accuracy: 0.546875\n",
      "Batch: 121, Loss: 1.509272813796997, Accuracy: 0.5615234375\n",
      "Batch: 122, Loss: 1.5619456768035889, Accuracy: 0.544921875\n",
      "Batch: 123, Loss: 1.6459894180297852, Accuracy: 0.53955078125\n",
      "Batch: 124, Loss: 1.5248035192489624, Accuracy: 0.560546875\n",
      "Batch: 125, Loss: 1.617980718612671, Accuracy: 0.5224609375\n",
      "Batch: 126, Loss: 1.5524861812591553, Accuracy: 0.56201171875\n",
      "Batch: 127, Loss: 1.5457615852355957, Accuracy: 0.55615234375\n",
      "Batch: 128, Loss: 1.785643458366394, Accuracy: 0.501953125\n",
      "Batch: 129, Loss: 1.755431056022644, Accuracy: 0.509765625\n",
      "Batch: 130, Loss: 1.7584967613220215, Accuracy: 0.50244140625\n",
      "Batch: 131, Loss: 1.6791633367538452, Accuracy: 0.5234375\n",
      "Batch: 132, Loss: 1.504236102104187, Accuracy: 0.5615234375\n",
      "Batch: 133, Loss: 1.5194306373596191, Accuracy: 0.57421875\n",
      "Batch: 134, Loss: 1.620546817779541, Accuracy: 0.51806640625\n",
      "Batch: 135, Loss: 1.6484041213989258, Accuracy: 0.5126953125\n",
      "Batch: 136, Loss: 1.5713590383529663, Accuracy: 0.53515625\n",
      "Batch: 137, Loss: 1.630016565322876, Accuracy: 0.52490234375\n",
      "Batch: 138, Loss: 1.4892503023147583, Accuracy: 0.57080078125\n",
      "Batch: 139, Loss: 1.5934360027313232, Accuracy: 0.5341796875\n",
      "Batch: 140, Loss: 1.5223000049591064, Accuracy: 0.54443359375\n",
      "Batch: 141, Loss: 1.5982567071914673, Accuracy: 0.517578125\n",
      "Batch: 142, Loss: 1.5071299076080322, Accuracy: 0.55908203125\n",
      "Batch: 143, Loss: 1.5794771909713745, Accuracy: 0.54052734375\n",
      "Batch: 144, Loss: 1.5914568901062012, Accuracy: 0.548828125\n",
      "Batch: 145, Loss: 1.590226173400879, Accuracy: 0.53955078125\n",
      "Batch: 146, Loss: 1.5925811529159546, Accuracy: 0.53759765625\n",
      "Batch: 147, Loss: 1.5666148662567139, Accuracy: 0.5517578125\n",
      "Batch: 148, Loss: 1.5396132469177246, Accuracy: 0.548828125\n",
      "Batch: 149, Loss: 1.517881155014038, Accuracy: 0.56103515625\n",
      "Batch: 150, Loss: 1.4613306522369385, Accuracy: 0.5830078125\n",
      "Batch: 151, Loss: 1.3933203220367432, Accuracy: 0.57666015625\n",
      "Batch: 152, Loss: 1.4483009576797485, Accuracy: 0.58349609375\n",
      "Batch: 153, Loss: 1.4565309286117554, Accuracy: 0.5849609375\n",
      "Batch: 154, Loss: 1.475953459739685, Accuracy: 0.5693359375\n",
      "Batch: 155, Loss: 1.5278431177139282, Accuracy: 0.5615234375\n",
      "Batch: 156, Loss: 1.4545738697052002, Accuracy: 0.580078125\n",
      "Batch: 157, Loss: 1.4815857410430908, Accuracy: 0.57421875\n",
      "Batch: 158, Loss: 1.4560787677764893, Accuracy: 0.5771484375\n",
      "Batch: 159, Loss: 1.4185608625411987, Accuracy: 0.58349609375\n",
      "Batch: 160, Loss: 1.4696593284606934, Accuracy: 0.57275390625\n",
      "Batch: 161, Loss: 1.4871511459350586, Accuracy: 0.56787109375\n",
      "Batch: 162, Loss: 1.5287244319915771, Accuracy: 0.576171875\n",
      "Batch: 163, Loss: 1.4792590141296387, Accuracy: 0.56787109375\n",
      "Batch: 164, Loss: 1.5586662292480469, Accuracy: 0.5498046875\n",
      "Batch: 165, Loss: 1.4773222208023071, Accuracy: 0.58154296875\n",
      "Batch: 166, Loss: 1.5349223613739014, Accuracy: 0.55322265625\n",
      "Batch: 167, Loss: 1.4366763830184937, Accuracy: 0.587890625\n",
      "Batch: 168, Loss: 1.4036164283752441, Accuracy: 0.5869140625\n",
      "Batch: 169, Loss: 1.446081280708313, Accuracy: 0.57470703125\n",
      "Batch: 170, Loss: 1.5661673545837402, Accuracy: 0.5517578125\n",
      "Batch: 171, Loss: 1.4902021884918213, Accuracy: 0.5654296875\n",
      "Batch: 172, Loss: 1.512858271598816, Accuracy: 0.55908203125\n",
      "Batch: 173, Loss: 1.5805749893188477, Accuracy: 0.5478515625\n",
      "Batch: 174, Loss: 1.3814774751663208, Accuracy: 0.6025390625\n",
      "Batch: 175, Loss: 1.5362420082092285, Accuracy: 0.544921875\n",
      "Batch: 176, Loss: 1.6458030939102173, Accuracy: 0.525390625\n",
      "Batch: 177, Loss: 1.4876019954681396, Accuracy: 0.5703125\n",
      "Batch: 178, Loss: 1.4870721101760864, Accuracy: 0.5693359375\n",
      "Batch: 179, Loss: 1.5319374799728394, Accuracy: 0.55322265625\n",
      "Batch: 180, Loss: 1.6249024868011475, Accuracy: 0.53466796875\n",
      "Epoch 6/200\n",
      "Batch: 1, Loss: 2.2722089290618896, Accuracy: 0.44287109375\n",
      "Batch: 2, Loss: 1.548769474029541, Accuracy: 0.55126953125\n",
      "Batch: 3, Loss: 1.550097942352295, Accuracy: 0.55419921875\n",
      "Batch: 4, Loss: 1.5637130737304688, Accuracy: 0.54150390625\n",
      "Batch: 5, Loss: 1.639514684677124, Accuracy: 0.515625\n",
      "Batch: 6, Loss: 1.5571298599243164, Accuracy: 0.5380859375\n",
      "Batch: 7, Loss: 1.5206058025360107, Accuracy: 0.5419921875\n",
      "Batch: 8, Loss: 1.5552928447723389, Accuracy: 0.529296875\n",
      "Batch: 9, Loss: 1.6538853645324707, Accuracy: 0.521484375\n",
      "Batch: 10, Loss: 1.5619043111801147, Accuracy: 0.55517578125\n",
      "Batch: 11, Loss: 1.6288220882415771, Accuracy: 0.537109375\n",
      "Batch: 12, Loss: 1.4221833944320679, Accuracy: 0.5830078125\n",
      "Batch: 13, Loss: 1.5322604179382324, Accuracy: 0.5458984375\n",
      "Batch: 14, Loss: 1.5972089767456055, Accuracy: 0.53466796875\n",
      "Batch: 15, Loss: 1.5297248363494873, Accuracy: 0.55322265625\n",
      "Batch: 16, Loss: 1.6228522062301636, Accuracy: 0.544921875\n",
      "Batch: 17, Loss: 1.4997482299804688, Accuracy: 0.583984375\n",
      "Batch: 18, Loss: 1.5502424240112305, Accuracy: 0.5380859375\n",
      "Batch: 19, Loss: 1.58564293384552, Accuracy: 0.5380859375\n",
      "Batch: 20, Loss: 1.4878121614456177, Accuracy: 0.576171875\n",
      "Batch: 21, Loss: 1.7063472270965576, Accuracy: 0.5087890625\n",
      "Batch: 22, Loss: 1.5998125076293945, Accuracy: 0.53466796875\n",
      "Batch: 23, Loss: 1.5230917930603027, Accuracy: 0.56298828125\n",
      "Batch: 24, Loss: 1.5122164487838745, Accuracy: 0.55615234375\n",
      "Batch: 25, Loss: 1.5495400428771973, Accuracy: 0.55810546875\n",
      "Batch: 26, Loss: 1.6262139081954956, Accuracy: 0.53662109375\n",
      "Batch: 27, Loss: 1.5793429613113403, Accuracy: 0.52783203125\n",
      "Batch: 28, Loss: 1.4866468906402588, Accuracy: 0.55908203125\n",
      "Batch: 29, Loss: 1.5957579612731934, Accuracy: 0.525390625\n",
      "Batch: 30, Loss: 1.527153730392456, Accuracy: 0.5693359375\n",
      "Batch: 31, Loss: 1.6631978750228882, Accuracy: 0.51708984375\n",
      "Batch: 32, Loss: 1.666273832321167, Accuracy: 0.51416015625\n",
      "Batch: 33, Loss: 1.6426551342010498, Accuracy: 0.52490234375\n",
      "Batch: 34, Loss: 1.6379660367965698, Accuracy: 0.54833984375\n",
      "Batch: 35, Loss: 1.730785608291626, Accuracy: 0.51318359375\n",
      "Batch: 36, Loss: 1.6305344104766846, Accuracy: 0.53759765625\n",
      "Batch: 37, Loss: 1.5712668895721436, Accuracy: 0.55419921875\n",
      "Batch: 38, Loss: 1.6327195167541504, Accuracy: 0.52978515625\n",
      "Batch: 39, Loss: 1.597712516784668, Accuracy: 0.54638671875\n",
      "Batch: 40, Loss: 1.604416847229004, Accuracy: 0.53271484375\n",
      "Batch: 41, Loss: 1.5853239297866821, Accuracy: 0.53076171875\n",
      "Batch: 42, Loss: 1.540124535560608, Accuracy: 0.53857421875\n",
      "Batch: 43, Loss: 1.563944935798645, Accuracy: 0.55810546875\n",
      "Batch: 44, Loss: 1.4474818706512451, Accuracy: 0.58740234375\n",
      "Batch: 45, Loss: 1.4852594137191772, Accuracy: 0.56005859375\n",
      "Batch: 46, Loss: 1.4441591501235962, Accuracy: 0.55224609375\n",
      "Batch: 47, Loss: 1.525718092918396, Accuracy: 0.54931640625\n",
      "Batch: 48, Loss: 1.4612476825714111, Accuracy: 0.560546875\n",
      "Batch: 49, Loss: 1.4952329397201538, Accuracy: 0.5576171875\n",
      "Batch: 50, Loss: 1.58121657371521, Accuracy: 0.548828125\n",
      "Batch: 51, Loss: 1.5385018587112427, Accuracy: 0.55810546875\n",
      "Batch: 52, Loss: 1.4862271547317505, Accuracy: 0.5625\n",
      "Batch: 53, Loss: 1.4049687385559082, Accuracy: 0.56640625\n",
      "Batch: 54, Loss: 1.4953023195266724, Accuracy: 0.54248046875\n",
      "Batch: 55, Loss: 1.5249680280685425, Accuracy: 0.5625\n",
      "Batch: 56, Loss: 1.4845026731491089, Accuracy: 0.56787109375\n",
      "Batch: 57, Loss: 1.5580344200134277, Accuracy: 0.54345703125\n",
      "Batch: 58, Loss: 1.5431101322174072, Accuracy: 0.54345703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 59, Loss: 1.6355533599853516, Accuracy: 0.5341796875\n",
      "Batch: 60, Loss: 1.552878975868225, Accuracy: 0.5439453125\n",
      "Batch: 61, Loss: 1.4359089136123657, Accuracy: 0.58203125\n",
      "Batch: 62, Loss: 1.4659717082977295, Accuracy: 0.57080078125\n",
      "Batch: 63, Loss: 1.4946513175964355, Accuracy: 0.5458984375\n",
      "Batch: 64, Loss: 1.4798802137374878, Accuracy: 0.556640625\n",
      "Batch: 65, Loss: 1.5688855648040771, Accuracy: 0.5302734375\n",
      "Batch: 66, Loss: 1.5032415390014648, Accuracy: 0.5546875\n",
      "Batch: 67, Loss: 1.5466492176055908, Accuracy: 0.55029296875\n",
      "Batch: 68, Loss: 1.4400571584701538, Accuracy: 0.57861328125\n",
      "Batch: 69, Loss: 1.557244062423706, Accuracy: 0.5302734375\n",
      "Batch: 70, Loss: 1.6159454584121704, Accuracy: 0.52587890625\n",
      "Batch: 71, Loss: 1.558664083480835, Accuracy: 0.54345703125\n",
      "Batch: 72, Loss: 1.5802865028381348, Accuracy: 0.53466796875\n",
      "Batch: 73, Loss: 1.6368134021759033, Accuracy: 0.5283203125\n",
      "Batch: 74, Loss: 1.6474111080169678, Accuracy: 0.5380859375\n",
      "Batch: 75, Loss: 1.5377134084701538, Accuracy: 0.5576171875\n",
      "Batch: 76, Loss: 1.5264105796813965, Accuracy: 0.55517578125\n",
      "Batch: 77, Loss: 1.4477198123931885, Accuracy: 0.57568359375\n",
      "Batch: 78, Loss: 1.5092555284500122, Accuracy: 0.5634765625\n",
      "Batch: 79, Loss: 1.5071561336517334, Accuracy: 0.56591796875\n",
      "Batch: 80, Loss: 1.5292909145355225, Accuracy: 0.541015625\n",
      "Batch: 81, Loss: 1.5981214046478271, Accuracy: 0.55712890625\n",
      "Batch: 82, Loss: 1.4369754791259766, Accuracy: 0.5673828125\n",
      "Batch: 83, Loss: 1.4870266914367676, Accuracy: 0.5576171875\n",
      "Batch: 84, Loss: 1.4567797183990479, Accuracy: 0.560546875\n",
      "Batch: 85, Loss: 1.4007489681243896, Accuracy: 0.5751953125\n",
      "Batch: 86, Loss: 1.655524730682373, Accuracy: 0.51953125\n",
      "Batch: 87, Loss: 1.5248980522155762, Accuracy: 0.55419921875\n",
      "Batch: 88, Loss: 1.5779743194580078, Accuracy: 0.53173828125\n",
      "Batch: 89, Loss: 1.561110019683838, Accuracy: 0.55126953125\n",
      "Batch: 90, Loss: 1.6205450296401978, Accuracy: 0.5234375\n",
      "Batch: 91, Loss: 1.418380618095398, Accuracy: 0.5908203125\n",
      "Batch: 92, Loss: 1.6161305904388428, Accuracy: 0.5244140625\n",
      "Batch: 93, Loss: 1.5188316106796265, Accuracy: 0.54931640625\n",
      "Batch: 94, Loss: 1.6012847423553467, Accuracy: 0.5390625\n",
      "Batch: 95, Loss: 1.5800855159759521, Accuracy: 0.53955078125\n",
      "Batch: 96, Loss: 1.5646142959594727, Accuracy: 0.56201171875\n",
      "Batch: 97, Loss: 1.5351123809814453, Accuracy: 0.5625\n",
      "Batch: 98, Loss: 1.66053307056427, Accuracy: 0.53271484375\n",
      "Batch: 99, Loss: 1.45667564868927, Accuracy: 0.57470703125\n",
      "Batch: 100, Loss: 1.5926693677902222, Accuracy: 0.55615234375\n",
      "Batch: 101, Loss: 1.6076971292495728, Accuracy: 0.53857421875\n",
      "Batch: 102, Loss: 1.454775094985962, Accuracy: 0.5732421875\n",
      "Batch: 103, Loss: 1.5141710042953491, Accuracy: 0.560546875\n",
      "Batch: 104, Loss: 1.508266806602478, Accuracy: 0.55419921875\n",
      "Batch: 105, Loss: 1.5975639820098877, Accuracy: 0.53125\n",
      "Batch: 106, Loss: 1.5921621322631836, Accuracy: 0.53369140625\n",
      "Batch: 107, Loss: 1.6160764694213867, Accuracy: 0.54296875\n",
      "Batch: 108, Loss: 1.5690220594406128, Accuracy: 0.5537109375\n",
      "Batch: 109, Loss: 1.5607495307922363, Accuracy: 0.548828125\n",
      "Batch: 110, Loss: 1.480250358581543, Accuracy: 0.57080078125\n",
      "Batch: 111, Loss: 1.4684455394744873, Accuracy: 0.57177734375\n",
      "Batch: 112, Loss: 1.5318388938903809, Accuracy: 0.5712890625\n",
      "Batch: 113, Loss: 1.5419921875, Accuracy: 0.54931640625\n",
      "Batch: 114, Loss: 1.487760066986084, Accuracy: 0.5634765625\n",
      "Batch: 115, Loss: 1.5054736137390137, Accuracy: 0.55419921875\n",
      "Batch: 116, Loss: 1.4890391826629639, Accuracy: 0.5615234375\n",
      "Batch: 117, Loss: 1.4516819715499878, Accuracy: 0.56494140625\n",
      "Batch: 118, Loss: 1.4496511220932007, Accuracy: 0.568359375\n",
      "Batch: 119, Loss: 1.45479154586792, Accuracy: 0.55712890625\n",
      "Batch: 120, Loss: 1.4902080297470093, Accuracy: 0.55078125\n",
      "Batch: 121, Loss: 1.4340968132019043, Accuracy: 0.56689453125\n",
      "Batch: 122, Loss: 1.4596936702728271, Accuracy: 0.56689453125\n",
      "Batch: 123, Loss: 1.5396809577941895, Accuracy: 0.55859375\n",
      "Batch: 124, Loss: 1.414584755897522, Accuracy: 0.58349609375\n",
      "Batch: 125, Loss: 1.5202860832214355, Accuracy: 0.541015625\n",
      "Batch: 126, Loss: 1.4265034198760986, Accuracy: 0.5869140625\n",
      "Batch: 127, Loss: 1.4406028985977173, Accuracy: 0.57763671875\n",
      "Batch: 128, Loss: 1.6829382181167603, Accuracy: 0.53125\n",
      "Batch: 129, Loss: 1.6713050603866577, Accuracy: 0.52880859375\n",
      "Batch: 130, Loss: 1.6608326435089111, Accuracy: 0.52587890625\n",
      "Batch: 131, Loss: 1.5580694675445557, Accuracy: 0.5517578125\n",
      "Batch: 132, Loss: 1.3896920680999756, Accuracy: 0.5859375\n",
      "Batch: 133, Loss: 1.4176048040390015, Accuracy: 0.578125\n",
      "Batch: 134, Loss: 1.5283421277999878, Accuracy: 0.546875\n",
      "Batch: 135, Loss: 1.5782275199890137, Accuracy: 0.53515625\n",
      "Batch: 136, Loss: 1.4435763359069824, Accuracy: 0.5732421875\n",
      "Batch: 137, Loss: 1.5124835968017578, Accuracy: 0.564453125\n",
      "Batch: 138, Loss: 1.3787413835525513, Accuracy: 0.60400390625\n",
      "Batch: 139, Loss: 1.4829792976379395, Accuracy: 0.55810546875\n",
      "Batch: 140, Loss: 1.4362406730651855, Accuracy: 0.56201171875\n",
      "Batch: 141, Loss: 1.500678539276123, Accuracy: 0.5439453125\n",
      "Batch: 142, Loss: 1.4202423095703125, Accuracy: 0.57421875\n",
      "Batch: 143, Loss: 1.479501724243164, Accuracy: 0.56494140625\n",
      "Batch: 144, Loss: 1.4972383975982666, Accuracy: 0.56494140625\n",
      "Batch: 145, Loss: 1.4828572273254395, Accuracy: 0.57177734375\n",
      "Batch: 146, Loss: 1.5234194993972778, Accuracy: 0.5458984375\n",
      "Batch: 147, Loss: 1.4800572395324707, Accuracy: 0.57421875\n",
      "Batch: 148, Loss: 1.4439113140106201, Accuracy: 0.57275390625\n",
      "Batch: 149, Loss: 1.410388708114624, Accuracy: 0.5859375\n",
      "Batch: 150, Loss: 1.361368179321289, Accuracy: 0.6064453125\n",
      "Batch: 151, Loss: 1.2884024381637573, Accuracy: 0.61083984375\n",
      "Batch: 152, Loss: 1.3497722148895264, Accuracy: 0.61279296875\n",
      "Batch: 153, Loss: 1.3647534847259521, Accuracy: 0.603515625\n",
      "Batch: 154, Loss: 1.3857264518737793, Accuracy: 0.5732421875\n",
      "Batch: 155, Loss: 1.4239249229431152, Accuracy: 0.57666015625\n",
      "Batch: 156, Loss: 1.3578290939331055, Accuracy: 0.59130859375\n",
      "Batch: 157, Loss: 1.371159553527832, Accuracy: 0.58740234375\n",
      "Batch: 158, Loss: 1.353865623474121, Accuracy: 0.59716796875\n",
      "Batch: 159, Loss: 1.3015077114105225, Accuracy: 0.61669921875\n",
      "Batch: 160, Loss: 1.3943781852722168, Accuracy: 0.587890625\n",
      "Batch: 161, Loss: 1.4098665714263916, Accuracy: 0.58544921875\n",
      "Batch: 162, Loss: 1.4125216007232666, Accuracy: 0.59765625\n",
      "Batch: 163, Loss: 1.4021683931350708, Accuracy: 0.58837890625\n",
      "Batch: 164, Loss: 1.4568482637405396, Accuracy: 0.5615234375\n",
      "Batch: 165, Loss: 1.3926477432250977, Accuracy: 0.59228515625\n",
      "Batch: 166, Loss: 1.4548779726028442, Accuracy: 0.56494140625\n",
      "Batch: 167, Loss: 1.3457434177398682, Accuracy: 0.59619140625\n",
      "Batch: 168, Loss: 1.3147666454315186, Accuracy: 0.6025390625\n",
      "Batch: 169, Loss: 1.3561303615570068, Accuracy: 0.58154296875\n",
      "Batch: 170, Loss: 1.4425512552261353, Accuracy: 0.56396484375\n",
      "Batch: 171, Loss: 1.3803812265396118, Accuracy: 0.591796875\n",
      "Batch: 172, Loss: 1.4080028533935547, Accuracy: 0.58203125\n",
      "Batch: 173, Loss: 1.462675929069519, Accuracy: 0.57763671875\n",
      "Batch: 174, Loss: 1.2705211639404297, Accuracy: 0.63330078125\n",
      "Batch: 175, Loss: 1.4679348468780518, Accuracy: 0.5595703125\n",
      "Batch: 176, Loss: 1.547330617904663, Accuracy: 0.55078125\n",
      "Batch: 177, Loss: 1.3986804485321045, Accuracy: 0.5869140625\n",
      "Batch: 178, Loss: 1.3898530006408691, Accuracy: 0.57421875\n",
      "Batch: 179, Loss: 1.425207495689392, Accuracy: 0.5732421875\n",
      "Batch: 180, Loss: 1.5344688892364502, Accuracy: 0.560546875\n",
      "Epoch 7/200\n",
      "Batch: 1, Loss: 2.146284580230713, Accuracy: 0.4677734375\n",
      "Batch: 2, Loss: 1.4440245628356934, Accuracy: 0.568359375\n",
      "Batch: 3, Loss: 1.4664990901947021, Accuracy: 0.5751953125\n",
      "Batch: 4, Loss: 1.4641797542572021, Accuracy: 0.5634765625\n",
      "Batch: 5, Loss: 1.5379884243011475, Accuracy: 0.5419921875\n",
      "Batch: 6, Loss: 1.4925134181976318, Accuracy: 0.5537109375\n",
      "Batch: 7, Loss: 1.4264835119247437, Accuracy: 0.56591796875\n",
      "Batch: 8, Loss: 1.4603559970855713, Accuracy: 0.5546875\n",
      "Batch: 9, Loss: 1.549405574798584, Accuracy: 0.55322265625\n",
      "Batch: 10, Loss: 1.4882346391677856, Accuracy: 0.5732421875\n",
      "Batch: 11, Loss: 1.5188827514648438, Accuracy: 0.55126953125\n",
      "Batch: 12, Loss: 1.3373876810073853, Accuracy: 0.6044921875\n",
      "Batch: 13, Loss: 1.4417986869812012, Accuracy: 0.5625\n",
      "Batch: 14, Loss: 1.5100276470184326, Accuracy: 0.5634765625\n",
      "Batch: 15, Loss: 1.445397138595581, Accuracy: 0.5712890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 16, Loss: 1.5087378025054932, Accuracy: 0.55712890625\n",
      "Batch: 17, Loss: 1.423551321029663, Accuracy: 0.59326171875\n",
      "Batch: 18, Loss: 1.4660916328430176, Accuracy: 0.552734375\n",
      "Batch: 19, Loss: 1.4985461235046387, Accuracy: 0.552734375\n",
      "Batch: 20, Loss: 1.3991403579711914, Accuracy: 0.5947265625\n",
      "Batch: 21, Loss: 1.6297398805618286, Accuracy: 0.5205078125\n",
      "Batch: 22, Loss: 1.5155138969421387, Accuracy: 0.55029296875\n",
      "Batch: 23, Loss: 1.4320926666259766, Accuracy: 0.578125\n",
      "Batch: 24, Loss: 1.4171230792999268, Accuracy: 0.572265625\n",
      "Batch: 25, Loss: 1.4646680355072021, Accuracy: 0.57275390625\n",
      "Batch: 26, Loss: 1.496302604675293, Accuracy: 0.56982421875\n",
      "Batch: 27, Loss: 1.4662772417068481, Accuracy: 0.55615234375\n",
      "Batch: 28, Loss: 1.382455825805664, Accuracy: 0.57958984375\n",
      "Batch: 29, Loss: 1.502213954925537, Accuracy: 0.55322265625\n",
      "Batch: 30, Loss: 1.4323712587356567, Accuracy: 0.5908203125\n",
      "Batch: 31, Loss: 1.5705006122589111, Accuracy: 0.54833984375\n",
      "Batch: 32, Loss: 1.5372225046157837, Accuracy: 0.55419921875\n",
      "Batch: 33, Loss: 1.5316007137298584, Accuracy: 0.54736328125\n",
      "Batch: 34, Loss: 1.5372776985168457, Accuracy: 0.55615234375\n",
      "Batch: 35, Loss: 1.5981497764587402, Accuracy: 0.5263671875\n",
      "Batch: 36, Loss: 1.4967846870422363, Accuracy: 0.5546875\n",
      "Batch: 37, Loss: 1.4572741985321045, Accuracy: 0.5703125\n",
      "Batch: 38, Loss: 1.5002946853637695, Accuracy: 0.5595703125\n",
      "Batch: 39, Loss: 1.482756495475769, Accuracy: 0.5654296875\n",
      "Batch: 40, Loss: 1.498584270477295, Accuracy: 0.5712890625\n",
      "Batch: 41, Loss: 1.502151608467102, Accuracy: 0.55908203125\n",
      "Batch: 42, Loss: 1.4403650760650635, Accuracy: 0.564453125\n",
      "Batch: 43, Loss: 1.443931221961975, Accuracy: 0.58837890625\n",
      "Batch: 44, Loss: 1.32139253616333, Accuracy: 0.6123046875\n",
      "Batch: 45, Loss: 1.3650076389312744, Accuracy: 0.58642578125\n",
      "Batch: 46, Loss: 1.335119605064392, Accuracy: 0.583984375\n",
      "Batch: 47, Loss: 1.4306066036224365, Accuracy: 0.5615234375\n",
      "Batch: 48, Loss: 1.3530999422073364, Accuracy: 0.59521484375\n",
      "Batch: 49, Loss: 1.4026635885238647, Accuracy: 0.583984375\n",
      "Batch: 50, Loss: 1.459604263305664, Accuracy: 0.5673828125\n",
      "Batch: 51, Loss: 1.4431395530700684, Accuracy: 0.5703125\n",
      "Batch: 52, Loss: 1.3675804138183594, Accuracy: 0.587890625\n",
      "Batch: 53, Loss: 1.3084065914154053, Accuracy: 0.603515625\n",
      "Batch: 54, Loss: 1.3855856657028198, Accuracy: 0.5595703125\n",
      "Batch: 55, Loss: 1.4036586284637451, Accuracy: 0.58447265625\n",
      "Batch: 56, Loss: 1.378456711769104, Accuracy: 0.60400390625\n",
      "Batch: 57, Loss: 1.450843334197998, Accuracy: 0.56689453125\n",
      "Batch: 58, Loss: 1.4269602298736572, Accuracy: 0.564453125\n",
      "Batch: 59, Loss: 1.5495015382766724, Accuracy: 0.5283203125\n",
      "Batch: 60, Loss: 1.4514689445495605, Accuracy: 0.5703125\n",
      "Batch: 61, Loss: 1.3354822397232056, Accuracy: 0.60498046875\n",
      "Batch: 62, Loss: 1.3539128303527832, Accuracy: 0.60595703125\n",
      "Batch: 63, Loss: 1.407871127128601, Accuracy: 0.560546875\n",
      "Batch: 64, Loss: 1.4108742475509644, Accuracy: 0.5771484375\n",
      "Batch: 65, Loss: 1.5002202987670898, Accuracy: 0.5439453125\n",
      "Batch: 66, Loss: 1.4468798637390137, Accuracy: 0.5625\n",
      "Batch: 67, Loss: 1.478918194770813, Accuracy: 0.56103515625\n",
      "Batch: 68, Loss: 1.332836627960205, Accuracy: 0.60107421875\n",
      "Batch: 69, Loss: 1.4456396102905273, Accuracy: 0.552734375\n",
      "Batch: 70, Loss: 1.52960205078125, Accuracy: 0.53369140625\n",
      "Batch: 71, Loss: 1.4655117988586426, Accuracy: 0.5537109375\n",
      "Batch: 72, Loss: 1.47983717918396, Accuracy: 0.54248046875\n",
      "Batch: 73, Loss: 1.5355570316314697, Accuracy: 0.53125\n",
      "Batch: 74, Loss: 1.5317697525024414, Accuracy: 0.564453125\n",
      "Batch: 75, Loss: 1.4364715814590454, Accuracy: 0.583984375\n",
      "Batch: 76, Loss: 1.434791922569275, Accuracy: 0.57470703125\n",
      "Batch: 77, Loss: 1.3596982955932617, Accuracy: 0.59912109375\n",
      "Batch: 78, Loss: 1.4100520610809326, Accuracy: 0.583984375\n",
      "Batch: 79, Loss: 1.4251196384429932, Accuracy: 0.58544921875\n",
      "Batch: 80, Loss: 1.4201884269714355, Accuracy: 0.56103515625\n",
      "Batch: 81, Loss: 1.4880073070526123, Accuracy: 0.57421875\n",
      "Batch: 82, Loss: 1.319441795349121, Accuracy: 0.59521484375\n",
      "Batch: 83, Loss: 1.3766614198684692, Accuracy: 0.58642578125\n",
      "Batch: 84, Loss: 1.3553614616394043, Accuracy: 0.5908203125\n",
      "Batch: 85, Loss: 1.3030078411102295, Accuracy: 0.59228515625\n",
      "Batch: 86, Loss: 1.5627338886260986, Accuracy: 0.5361328125\n",
      "Batch: 87, Loss: 1.4381797313690186, Accuracy: 0.576171875\n",
      "Batch: 88, Loss: 1.4640952348709106, Accuracy: 0.5654296875\n",
      "Batch: 89, Loss: 1.476235270500183, Accuracy: 0.576171875\n",
      "Batch: 90, Loss: 1.5204713344573975, Accuracy: 0.54736328125\n",
      "Batch: 91, Loss: 1.314543604850769, Accuracy: 0.607421875\n",
      "Batch: 92, Loss: 1.4999995231628418, Accuracy: 0.5537109375\n",
      "Batch: 93, Loss: 1.4296880960464478, Accuracy: 0.56884765625\n",
      "Batch: 94, Loss: 1.5058921575546265, Accuracy: 0.55908203125\n",
      "Batch: 95, Loss: 1.4962860345840454, Accuracy: 0.55615234375\n",
      "Batch: 96, Loss: 1.453071117401123, Accuracy: 0.58984375\n",
      "Batch: 97, Loss: 1.4169833660125732, Accuracy: 0.58642578125\n",
      "Batch: 98, Loss: 1.554495096206665, Accuracy: 0.5546875\n",
      "Batch: 99, Loss: 1.3825160264968872, Accuracy: 0.59033203125\n",
      "Batch: 100, Loss: 1.5130369663238525, Accuracy: 0.5693359375\n",
      "Batch: 101, Loss: 1.5077687501907349, Accuracy: 0.556640625\n",
      "Batch: 102, Loss: 1.3709713220596313, Accuracy: 0.59228515625\n",
      "Batch: 103, Loss: 1.39739191532135, Accuracy: 0.5869140625\n",
      "Batch: 104, Loss: 1.4202079772949219, Accuracy: 0.5771484375\n",
      "Batch: 105, Loss: 1.5247704982757568, Accuracy: 0.53076171875\n",
      "Batch: 106, Loss: 1.4938515424728394, Accuracy: 0.54541015625\n",
      "Batch: 107, Loss: 1.5303899049758911, Accuracy: 0.56640625\n",
      "Batch: 108, Loss: 1.4582912921905518, Accuracy: 0.5712890625\n",
      "Batch: 109, Loss: 1.4638731479644775, Accuracy: 0.55615234375\n",
      "Batch: 110, Loss: 1.3725699186325073, Accuracy: 0.580078125\n",
      "Batch: 111, Loss: 1.345668911933899, Accuracy: 0.59130859375\n",
      "Batch: 112, Loss: 1.4505765438079834, Accuracy: 0.5947265625\n",
      "Batch: 113, Loss: 1.4571442604064941, Accuracy: 0.5791015625\n",
      "Batch: 114, Loss: 1.3927065134048462, Accuracy: 0.5751953125\n",
      "Batch: 115, Loss: 1.4078813791275024, Accuracy: 0.56982421875\n",
      "Batch: 116, Loss: 1.4068964719772339, Accuracy: 0.58349609375\n",
      "Batch: 117, Loss: 1.366444706916809, Accuracy: 0.578125\n",
      "Batch: 118, Loss: 1.3819760084152222, Accuracy: 0.57373046875\n",
      "Batch: 119, Loss: 1.3726928234100342, Accuracy: 0.57666015625\n",
      "Batch: 120, Loss: 1.399267315864563, Accuracy: 0.56884765625\n",
      "Batch: 121, Loss: 1.3301067352294922, Accuracy: 0.59228515625\n",
      "Batch: 122, Loss: 1.3604397773742676, Accuracy: 0.58837890625\n",
      "Batch: 123, Loss: 1.4438936710357666, Accuracy: 0.57470703125\n",
      "Batch: 124, Loss: 1.3328070640563965, Accuracy: 0.59423828125\n",
      "Batch: 125, Loss: 1.431199073791504, Accuracy: 0.560546875\n",
      "Batch: 126, Loss: 1.348988652229309, Accuracy: 0.603515625\n",
      "Batch: 127, Loss: 1.3658370971679688, Accuracy: 0.59716796875\n",
      "Batch: 128, Loss: 1.6027908325195312, Accuracy: 0.54296875\n",
      "Batch: 129, Loss: 1.5984833240509033, Accuracy: 0.53857421875\n",
      "Batch: 130, Loss: 1.5682337284088135, Accuracy: 0.5439453125\n",
      "Batch: 131, Loss: 1.4867371320724487, Accuracy: 0.568359375\n",
      "Batch: 132, Loss: 1.305626630783081, Accuracy: 0.60107421875\n",
      "Batch: 133, Loss: 1.3393012285232544, Accuracy: 0.61181640625\n",
      "Batch: 134, Loss: 1.4447693824768066, Accuracy: 0.564453125\n",
      "Batch: 135, Loss: 1.4858169555664062, Accuracy: 0.54736328125\n",
      "Batch: 136, Loss: 1.36484694480896, Accuracy: 0.58203125\n",
      "Batch: 137, Loss: 1.4382706880569458, Accuracy: 0.57421875\n",
      "Batch: 138, Loss: 1.2867463827133179, Accuracy: 0.61767578125\n",
      "Batch: 139, Loss: 1.3945848941802979, Accuracy: 0.57373046875\n",
      "Batch: 140, Loss: 1.3420684337615967, Accuracy: 0.58642578125\n",
      "Batch: 141, Loss: 1.4148752689361572, Accuracy: 0.56494140625\n",
      "Batch: 142, Loss: 1.3288675546646118, Accuracy: 0.583984375\n",
      "Batch: 143, Loss: 1.4064412117004395, Accuracy: 0.5869140625\n",
      "Batch: 144, Loss: 1.4160834550857544, Accuracy: 0.5888671875\n",
      "Batch: 145, Loss: 1.3942391872406006, Accuracy: 0.5849609375\n",
      "Batch: 146, Loss: 1.421311616897583, Accuracy: 0.57177734375\n",
      "Batch: 147, Loss: 1.400069236755371, Accuracy: 0.58349609375\n",
      "Batch: 148, Loss: 1.3499213457107544, Accuracy: 0.58544921875\n",
      "Batch: 149, Loss: 1.3172180652618408, Accuracy: 0.5986328125\n",
      "Batch: 150, Loss: 1.2289977073669434, Accuracy: 0.62744140625\n",
      "Batch: 151, Loss: 1.2188358306884766, Accuracy: 0.62060546875\n",
      "Batch: 152, Loss: 1.2799046039581299, Accuracy: 0.6201171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 153, Loss: 1.26774001121521, Accuracy: 0.62255859375\n",
      "Batch: 154, Loss: 1.2940013408660889, Accuracy: 0.6015625\n",
      "Batch: 155, Loss: 1.3269269466400146, Accuracy: 0.60888671875\n",
      "Batch: 156, Loss: 1.2833061218261719, Accuracy: 0.6123046875\n",
      "Batch: 157, Loss: 1.2776732444763184, Accuracy: 0.60009765625\n",
      "Batch: 158, Loss: 1.272979974746704, Accuracy: 0.61474609375\n",
      "Batch: 159, Loss: 1.2268450260162354, Accuracy: 0.6337890625\n",
      "Batch: 160, Loss: 1.3110036849975586, Accuracy: 0.60205078125\n",
      "Batch: 161, Loss: 1.301766037940979, Accuracy: 0.60302734375\n",
      "Batch: 162, Loss: 1.340134859085083, Accuracy: 0.60693359375\n",
      "Batch: 163, Loss: 1.3440055847167969, Accuracy: 0.59521484375\n",
      "Batch: 164, Loss: 1.3761675357818604, Accuracy: 0.5732421875\n",
      "Batch: 165, Loss: 1.2972849607467651, Accuracy: 0.61083984375\n",
      "Batch: 166, Loss: 1.3617074489593506, Accuracy: 0.591796875\n",
      "Batch: 167, Loss: 1.2685502767562866, Accuracy: 0.619140625\n",
      "Batch: 168, Loss: 1.2362875938415527, Accuracy: 0.6240234375\n",
      "Batch: 169, Loss: 1.2735941410064697, Accuracy: 0.61181640625\n",
      "Batch: 170, Loss: 1.38287353515625, Accuracy: 0.57080078125\n",
      "Batch: 171, Loss: 1.296501874923706, Accuracy: 0.6005859375\n",
      "Batch: 172, Loss: 1.3111231327056885, Accuracy: 0.6044921875\n",
      "Batch: 173, Loss: 1.3723797798156738, Accuracy: 0.591796875\n",
      "Batch: 174, Loss: 1.1836192607879639, Accuracy: 0.64453125\n",
      "Batch: 175, Loss: 1.3708157539367676, Accuracy: 0.5771484375\n",
      "Batch: 176, Loss: 1.459128975868225, Accuracy: 0.56396484375\n",
      "Batch: 177, Loss: 1.3320965766906738, Accuracy: 0.59423828125\n",
      "Batch: 178, Loss: 1.299245834350586, Accuracy: 0.60546875\n",
      "Batch: 179, Loss: 1.3442587852478027, Accuracy: 0.5810546875\n",
      "Batch: 180, Loss: 1.4405248165130615, Accuracy: 0.56884765625\n",
      "Epoch 8/200\n",
      "Batch: 1, Loss: 2.0821571350097656, Accuracy: 0.48291015625\n",
      "Batch: 2, Loss: 1.3431034088134766, Accuracy: 0.59814453125\n",
      "Batch: 3, Loss: 1.3436728715896606, Accuracy: 0.59619140625\n",
      "Batch: 4, Loss: 1.389878273010254, Accuracy: 0.5751953125\n",
      "Batch: 5, Loss: 1.4374299049377441, Accuracy: 0.56982421875\n",
      "Batch: 6, Loss: 1.3964945077896118, Accuracy: 0.56884765625\n",
      "Batch: 7, Loss: 1.324691653251648, Accuracy: 0.5888671875\n",
      "Batch: 8, Loss: 1.3896218538284302, Accuracy: 0.572265625\n",
      "Batch: 9, Loss: 1.4460238218307495, Accuracy: 0.58349609375\n",
      "Batch: 10, Loss: 1.3795645236968994, Accuracy: 0.59765625\n",
      "Batch: 11, Loss: 1.429168939590454, Accuracy: 0.57861328125\n",
      "Batch: 12, Loss: 1.2664904594421387, Accuracy: 0.6103515625\n",
      "Batch: 13, Loss: 1.3728978633880615, Accuracy: 0.57275390625\n",
      "Batch: 14, Loss: 1.4064698219299316, Accuracy: 0.58544921875\n",
      "Batch: 15, Loss: 1.3828375339508057, Accuracy: 0.59228515625\n",
      "Batch: 16, Loss: 1.4270875453948975, Accuracy: 0.59228515625\n",
      "Batch: 17, Loss: 1.3252031803131104, Accuracy: 0.61083984375\n",
      "Batch: 18, Loss: 1.4024343490600586, Accuracy: 0.56494140625\n",
      "Batch: 19, Loss: 1.408564567565918, Accuracy: 0.58251953125\n",
      "Batch: 20, Loss: 1.3097176551818848, Accuracy: 0.61328125\n",
      "Batch: 21, Loss: 1.548001766204834, Accuracy: 0.54541015625\n",
      "Batch: 22, Loss: 1.4073559045791626, Accuracy: 0.58203125\n",
      "Batch: 23, Loss: 1.3333326578140259, Accuracy: 0.5966796875\n",
      "Batch: 24, Loss: 1.3496005535125732, Accuracy: 0.58837890625\n",
      "Batch: 25, Loss: 1.3656139373779297, Accuracy: 0.60107421875\n",
      "Batch: 26, Loss: 1.3841137886047363, Accuracy: 0.5888671875\n",
      "Batch: 27, Loss: 1.3813281059265137, Accuracy: 0.576171875\n",
      "Batch: 28, Loss: 1.306364893913269, Accuracy: 0.599609375\n",
      "Batch: 29, Loss: 1.4091328382492065, Accuracy: 0.568359375\n",
      "Batch: 30, Loss: 1.3228366374969482, Accuracy: 0.60302734375\n",
      "Batch: 31, Loss: 1.4899265766143799, Accuracy: 0.56689453125\n",
      "Batch: 32, Loss: 1.4535577297210693, Accuracy: 0.56494140625\n",
      "Batch: 33, Loss: 1.4504811763763428, Accuracy: 0.5615234375\n",
      "Batch: 34, Loss: 1.4536716938018799, Accuracy: 0.56591796875\n",
      "Batch: 35, Loss: 1.5133763551712036, Accuracy: 0.552734375\n",
      "Batch: 36, Loss: 1.4465911388397217, Accuracy: 0.57470703125\n",
      "Batch: 37, Loss: 1.386322021484375, Accuracy: 0.58837890625\n",
      "Batch: 38, Loss: 1.4334845542907715, Accuracy: 0.560546875\n",
      "Batch: 39, Loss: 1.405232310295105, Accuracy: 0.58837890625\n",
      "Batch: 40, Loss: 1.4416139125823975, Accuracy: 0.57470703125\n",
      "Batch: 41, Loss: 1.4109073877334595, Accuracy: 0.57080078125\n",
      "Batch: 42, Loss: 1.3731818199157715, Accuracy: 0.57421875\n",
      "Batch: 43, Loss: 1.382584571838379, Accuracy: 0.59130859375\n",
      "Batch: 44, Loss: 1.2441349029541016, Accuracy: 0.62451171875\n",
      "Batch: 45, Loss: 1.2900400161743164, Accuracy: 0.6123046875\n",
      "Batch: 46, Loss: 1.2467055320739746, Accuracy: 0.60107421875\n",
      "Batch: 47, Loss: 1.3395575284957886, Accuracy: 0.59033203125\n",
      "Batch: 48, Loss: 1.2920989990234375, Accuracy: 0.6123046875\n",
      "Batch: 49, Loss: 1.3339155912399292, Accuracy: 0.5966796875\n",
      "Batch: 50, Loss: 1.3598357439041138, Accuracy: 0.59765625\n",
      "Batch: 51, Loss: 1.344226598739624, Accuracy: 0.59814453125\n",
      "Batch: 52, Loss: 1.2848148345947266, Accuracy: 0.6083984375\n",
      "Batch: 53, Loss: 1.2576364278793335, Accuracy: 0.60107421875\n",
      "Batch: 54, Loss: 1.3193155527114868, Accuracy: 0.57666015625\n",
      "Batch: 55, Loss: 1.3055269718170166, Accuracy: 0.60302734375\n",
      "Batch: 56, Loss: 1.3051830530166626, Accuracy: 0.607421875\n",
      "Batch: 57, Loss: 1.39972984790802, Accuracy: 0.59423828125\n",
      "Batch: 58, Loss: 1.3751518726348877, Accuracy: 0.57861328125\n",
      "Batch: 59, Loss: 1.4849623441696167, Accuracy: 0.55126953125\n",
      "Batch: 60, Loss: 1.3742735385894775, Accuracy: 0.57470703125\n",
      "Batch: 61, Loss: 1.2313201427459717, Accuracy: 0.625\n",
      "Batch: 62, Loss: 1.2771916389465332, Accuracy: 0.61279296875\n",
      "Batch: 63, Loss: 1.3400945663452148, Accuracy: 0.58349609375\n",
      "Batch: 64, Loss: 1.3309234380722046, Accuracy: 0.59716796875\n",
      "Batch: 65, Loss: 1.4366036653518677, Accuracy: 0.56787109375\n",
      "Batch: 66, Loss: 1.3455817699432373, Accuracy: 0.5908203125\n",
      "Batch: 67, Loss: 1.3854045867919922, Accuracy: 0.5869140625\n",
      "Batch: 68, Loss: 1.2628473043441772, Accuracy: 0.6162109375\n",
      "Batch: 69, Loss: 1.395395278930664, Accuracy: 0.5703125\n",
      "Batch: 70, Loss: 1.4366166591644287, Accuracy: 0.55908203125\n",
      "Batch: 71, Loss: 1.351576566696167, Accuracy: 0.59033203125\n",
      "Batch: 72, Loss: 1.3868441581726074, Accuracy: 0.56298828125\n",
      "Batch: 73, Loss: 1.4442522525787354, Accuracy: 0.55810546875\n",
      "Batch: 74, Loss: 1.434840440750122, Accuracy: 0.57958984375\n",
      "Batch: 75, Loss: 1.339191198348999, Accuracy: 0.5908203125\n",
      "Batch: 76, Loss: 1.3459572792053223, Accuracy: 0.5947265625\n",
      "Batch: 77, Loss: 1.2914998531341553, Accuracy: 0.61572265625\n",
      "Batch: 78, Loss: 1.3105138540267944, Accuracy: 0.61181640625\n",
      "Batch: 79, Loss: 1.3537318706512451, Accuracy: 0.60302734375\n",
      "Batch: 80, Loss: 1.337155818939209, Accuracy: 0.57421875\n",
      "Batch: 81, Loss: 1.4040470123291016, Accuracy: 0.591796875\n",
      "Batch: 82, Loss: 1.2535669803619385, Accuracy: 0.603515625\n",
      "Batch: 83, Loss: 1.2894359827041626, Accuracy: 0.5966796875\n",
      "Batch: 84, Loss: 1.2723702192306519, Accuracy: 0.609375\n",
      "Batch: 85, Loss: 1.2339484691619873, Accuracy: 0.61669921875\n",
      "Batch: 86, Loss: 1.4830877780914307, Accuracy: 0.55859375\n",
      "Batch: 87, Loss: 1.3416903018951416, Accuracy: 0.5830078125\n",
      "Batch: 88, Loss: 1.3834421634674072, Accuracy: 0.583984375\n",
      "Batch: 89, Loss: 1.3861722946166992, Accuracy: 0.5830078125\n",
      "Batch: 90, Loss: 1.450290560722351, Accuracy: 0.55517578125\n",
      "Batch: 91, Loss: 1.241346836090088, Accuracy: 0.61962890625\n",
      "Batch: 92, Loss: 1.4386389255523682, Accuracy: 0.57373046875\n",
      "Batch: 93, Loss: 1.3444856405258179, Accuracy: 0.5869140625\n",
      "Batch: 94, Loss: 1.4460748434066772, Accuracy: 0.57373046875\n",
      "Batch: 95, Loss: 1.430062174797058, Accuracy: 0.5625\n",
      "Batch: 96, Loss: 1.3607637882232666, Accuracy: 0.6015625\n",
      "Batch: 97, Loss: 1.3681004047393799, Accuracy: 0.587890625\n",
      "Batch: 98, Loss: 1.4734957218170166, Accuracy: 0.5576171875\n",
      "Batch: 99, Loss: 1.3032740354537964, Accuracy: 0.60498046875\n",
      "Batch: 100, Loss: 1.4266453981399536, Accuracy: 0.58984375\n",
      "Batch: 101, Loss: 1.4294919967651367, Accuracy: 0.580078125\n",
      "Batch: 102, Loss: 1.3031361103057861, Accuracy: 0.59423828125\n",
      "Batch: 103, Loss: 1.321821928024292, Accuracy: 0.60595703125\n",
      "Batch: 104, Loss: 1.3570525646209717, Accuracy: 0.5888671875\n",
      "Batch: 105, Loss: 1.4413201808929443, Accuracy: 0.5615234375\n",
      "Batch: 106, Loss: 1.4329942464828491, Accuracy: 0.56884765625\n",
      "Batch: 107, Loss: 1.4661974906921387, Accuracy: 0.58203125\n",
      "Batch: 108, Loss: 1.4025843143463135, Accuracy: 0.58154296875\n",
      "Batch: 109, Loss: 1.364159107208252, Accuracy: 0.5849609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 110, Loss: 1.2999296188354492, Accuracy: 0.6015625\n",
      "Batch: 111, Loss: 1.2571372985839844, Accuracy: 0.599609375\n",
      "Batch: 112, Loss: 1.3884408473968506, Accuracy: 0.60009765625\n",
      "Batch: 113, Loss: 1.3839950561523438, Accuracy: 0.583984375\n",
      "Batch: 114, Loss: 1.3229796886444092, Accuracy: 0.59619140625\n",
      "Batch: 115, Loss: 1.3617467880249023, Accuracy: 0.5869140625\n",
      "Batch: 116, Loss: 1.3379604816436768, Accuracy: 0.591796875\n",
      "Batch: 117, Loss: 1.295945405960083, Accuracy: 0.59228515625\n",
      "Batch: 118, Loss: 1.3227813243865967, Accuracy: 0.59375\n",
      "Batch: 119, Loss: 1.293700933456421, Accuracy: 0.59326171875\n",
      "Batch: 120, Loss: 1.3372869491577148, Accuracy: 0.58251953125\n",
      "Batch: 121, Loss: 1.286277413368225, Accuracy: 0.591796875\n",
      "Batch: 122, Loss: 1.3068468570709229, Accuracy: 0.611328125\n",
      "Batch: 123, Loss: 1.3509637117385864, Accuracy: 0.60107421875\n",
      "Batch: 124, Loss: 1.2783989906311035, Accuracy: 0.61669921875\n",
      "Batch: 125, Loss: 1.368931531906128, Accuracy: 0.57421875\n",
      "Batch: 126, Loss: 1.286426305770874, Accuracy: 0.62060546875\n",
      "Batch: 127, Loss: 1.2932618856430054, Accuracy: 0.60498046875\n",
      "Batch: 128, Loss: 1.516439437866211, Accuracy: 0.56103515625\n",
      "Batch: 129, Loss: 1.5367006063461304, Accuracy: 0.544921875\n",
      "Batch: 130, Loss: 1.5167869329452515, Accuracy: 0.54833984375\n",
      "Batch: 131, Loss: 1.4279608726501465, Accuracy: 0.583984375\n",
      "Batch: 132, Loss: 1.2448461055755615, Accuracy: 0.6201171875\n",
      "Batch: 133, Loss: 1.2612282037734985, Accuracy: 0.62548828125\n",
      "Batch: 134, Loss: 1.390075922012329, Accuracy: 0.56884765625\n",
      "Batch: 135, Loss: 1.4227104187011719, Accuracy: 0.5615234375\n",
      "Batch: 136, Loss: 1.2980310916900635, Accuracy: 0.5859375\n",
      "Batch: 137, Loss: 1.3681817054748535, Accuracy: 0.58935546875\n",
      "Batch: 138, Loss: 1.2199019193649292, Accuracy: 0.62890625\n",
      "Batch: 139, Loss: 1.3364503383636475, Accuracy: 0.58837890625\n",
      "Batch: 140, Loss: 1.2694919109344482, Accuracy: 0.603515625\n",
      "Batch: 141, Loss: 1.3571903705596924, Accuracy: 0.5849609375\n",
      "Batch: 142, Loss: 1.2531534433364868, Accuracy: 0.6162109375\n",
      "Batch: 143, Loss: 1.3338390588760376, Accuracy: 0.595703125\n",
      "Batch: 144, Loss: 1.3392112255096436, Accuracy: 0.60986328125\n",
      "Batch: 145, Loss: 1.3324626684188843, Accuracy: 0.59326171875\n",
      "Batch: 146, Loss: 1.3570845127105713, Accuracy: 0.5732421875\n",
      "Batch: 147, Loss: 1.3220423460006714, Accuracy: 0.5966796875\n",
      "Batch: 148, Loss: 1.2913625240325928, Accuracy: 0.60302734375\n",
      "Batch: 149, Loss: 1.260179877281189, Accuracy: 0.615234375\n",
      "Batch: 150, Loss: 1.1568999290466309, Accuracy: 0.64501953125\n",
      "Batch: 151, Loss: 1.164015531539917, Accuracy: 0.63232421875\n",
      "Batch: 152, Loss: 1.2236292362213135, Accuracy: 0.61572265625\n",
      "Batch: 153, Loss: 1.2071774005889893, Accuracy: 0.6220703125\n",
      "Batch: 154, Loss: 1.227165699005127, Accuracy: 0.61767578125\n",
      "Batch: 155, Loss: 1.2678747177124023, Accuracy: 0.62451171875\n",
      "Batch: 156, Loss: 1.2195162773132324, Accuracy: 0.6240234375\n",
      "Batch: 157, Loss: 1.2258014678955078, Accuracy: 0.6171875\n",
      "Batch: 158, Loss: 1.2265002727508545, Accuracy: 0.62890625\n",
      "Batch: 159, Loss: 1.171704649925232, Accuracy: 0.6416015625\n",
      "Batch: 160, Loss: 1.2539557218551636, Accuracy: 0.6025390625\n",
      "Batch: 161, Loss: 1.2461028099060059, Accuracy: 0.6181640625\n",
      "Batch: 162, Loss: 1.2662677764892578, Accuracy: 0.61474609375\n",
      "Batch: 163, Loss: 1.2790608406066895, Accuracy: 0.6103515625\n",
      "Batch: 164, Loss: 1.3086519241333008, Accuracy: 0.59912109375\n",
      "Batch: 165, Loss: 1.246606707572937, Accuracy: 0.6181640625\n",
      "Batch: 166, Loss: 1.3154010772705078, Accuracy: 0.603515625\n",
      "Batch: 167, Loss: 1.2088115215301514, Accuracy: 0.62548828125\n",
      "Batch: 168, Loss: 1.1793642044067383, Accuracy: 0.62939453125\n",
      "Batch: 169, Loss: 1.2259798049926758, Accuracy: 0.607421875\n",
      "Batch: 170, Loss: 1.321691632270813, Accuracy: 0.59716796875\n",
      "Batch: 171, Loss: 1.2352522611618042, Accuracy: 0.60693359375\n",
      "Batch: 172, Loss: 1.239768385887146, Accuracy: 0.61328125\n",
      "Batch: 173, Loss: 1.3140842914581299, Accuracy: 0.60888671875\n",
      "Batch: 174, Loss: 1.1373990774154663, Accuracy: 0.65771484375\n",
      "Batch: 175, Loss: 1.2975189685821533, Accuracy: 0.5986328125\n",
      "Batch: 176, Loss: 1.3845927715301514, Accuracy: 0.57666015625\n",
      "Batch: 177, Loss: 1.2877100706100464, Accuracy: 0.6025390625\n",
      "Batch: 178, Loss: 1.2324706315994263, Accuracy: 0.61279296875\n",
      "Batch: 179, Loss: 1.269538402557373, Accuracy: 0.607421875\n",
      "Batch: 180, Loss: 1.362982988357544, Accuracy: 0.58203125\n",
      "Epoch 9/200\n",
      "Batch: 1, Loss: 1.9952839612960815, Accuracy: 0.4931640625\n",
      "Batch: 2, Loss: 1.2826545238494873, Accuracy: 0.60888671875\n",
      "Batch: 3, Loss: 1.2760196924209595, Accuracy: 0.60498046875\n",
      "Batch: 4, Loss: 1.3288297653198242, Accuracy: 0.5859375\n",
      "Batch: 5, Loss: 1.3660662174224854, Accuracy: 0.57177734375\n",
      "Batch: 6, Loss: 1.3442413806915283, Accuracy: 0.58740234375\n",
      "Batch: 7, Loss: 1.254214882850647, Accuracy: 0.6064453125\n",
      "Batch: 8, Loss: 1.3166431188583374, Accuracy: 0.59130859375\n",
      "Batch: 9, Loss: 1.3844879865646362, Accuracy: 0.58740234375\n",
      "Batch: 10, Loss: 1.335463523864746, Accuracy: 0.6103515625\n",
      "Batch: 11, Loss: 1.3764088153839111, Accuracy: 0.58642578125\n",
      "Batch: 12, Loss: 1.2220797538757324, Accuracy: 0.62451171875\n",
      "Batch: 13, Loss: 1.307065725326538, Accuracy: 0.5849609375\n",
      "Batch: 14, Loss: 1.3345955610275269, Accuracy: 0.59375\n",
      "Batch: 15, Loss: 1.2980077266693115, Accuracy: 0.60498046875\n",
      "Batch: 16, Loss: 1.3581998348236084, Accuracy: 0.59423828125\n",
      "Batch: 17, Loss: 1.2668571472167969, Accuracy: 0.62548828125\n",
      "Batch: 18, Loss: 1.344330072402954, Accuracy: 0.58349609375\n",
      "Batch: 19, Loss: 1.350264310836792, Accuracy: 0.595703125\n",
      "Batch: 20, Loss: 1.2495733499526978, Accuracy: 0.63232421875\n",
      "Batch: 21, Loss: 1.473808765411377, Accuracy: 0.5517578125\n",
      "Batch: 22, Loss: 1.3471990823745728, Accuracy: 0.5927734375\n",
      "Batch: 23, Loss: 1.285864233970642, Accuracy: 0.60791015625\n",
      "Batch: 24, Loss: 1.277099370956421, Accuracy: 0.6083984375\n",
      "Batch: 25, Loss: 1.2934658527374268, Accuracy: 0.6005859375\n",
      "Batch: 26, Loss: 1.3384997844696045, Accuracy: 0.603515625\n",
      "Batch: 27, Loss: 1.329064130783081, Accuracy: 0.58349609375\n",
      "Batch: 28, Loss: 1.2285172939300537, Accuracy: 0.623046875\n",
      "Batch: 29, Loss: 1.354589581489563, Accuracy: 0.5830078125\n",
      "Batch: 30, Loss: 1.267532229423523, Accuracy: 0.61962890625\n",
      "Batch: 31, Loss: 1.4240334033966064, Accuracy: 0.5791015625\n",
      "Batch: 32, Loss: 1.3844761848449707, Accuracy: 0.578125\n",
      "Batch: 33, Loss: 1.3829553127288818, Accuracy: 0.58154296875\n",
      "Batch: 34, Loss: 1.3938645124435425, Accuracy: 0.58447265625\n",
      "Batch: 35, Loss: 1.4511981010437012, Accuracy: 0.56396484375\n",
      "Batch: 36, Loss: 1.3751121759414673, Accuracy: 0.58349609375\n",
      "Batch: 37, Loss: 1.3167848587036133, Accuracy: 0.59375\n",
      "Batch: 38, Loss: 1.3744754791259766, Accuracy: 0.57958984375\n",
      "Batch: 39, Loss: 1.319528341293335, Accuracy: 0.6103515625\n",
      "Batch: 40, Loss: 1.3680113554000854, Accuracy: 0.59423828125\n",
      "Batch: 41, Loss: 1.351541519165039, Accuracy: 0.591796875\n",
      "Batch: 42, Loss: 1.2987608909606934, Accuracy: 0.58642578125\n",
      "Batch: 43, Loss: 1.2845768928527832, Accuracy: 0.6220703125\n",
      "Batch: 44, Loss: 1.1732861995697021, Accuracy: 0.63427734375\n",
      "Batch: 45, Loss: 1.2498245239257812, Accuracy: 0.61279296875\n",
      "Batch: 46, Loss: 1.1979739665985107, Accuracy: 0.61376953125\n",
      "Batch: 47, Loss: 1.279183030128479, Accuracy: 0.58984375\n",
      "Batch: 48, Loss: 1.2252607345581055, Accuracy: 0.6181640625\n",
      "Batch: 49, Loss: 1.275062084197998, Accuracy: 0.60009765625\n",
      "Batch: 50, Loss: 1.3018933534622192, Accuracy: 0.6005859375\n",
      "Batch: 51, Loss: 1.2886826992034912, Accuracy: 0.60888671875\n",
      "Batch: 52, Loss: 1.2261748313903809, Accuracy: 0.6142578125\n",
      "Batch: 53, Loss: 1.200400948524475, Accuracy: 0.61376953125\n",
      "Batch: 54, Loss: 1.2524573802947998, Accuracy: 0.595703125\n",
      "Batch: 55, Loss: 1.2463915348052979, Accuracy: 0.6123046875\n",
      "Batch: 56, Loss: 1.2405028343200684, Accuracy: 0.6181640625\n",
      "Batch: 57, Loss: 1.3312203884124756, Accuracy: 0.60693359375\n",
      "Batch: 58, Loss: 1.3080134391784668, Accuracy: 0.5927734375\n",
      "Batch: 59, Loss: 1.4208705425262451, Accuracy: 0.56396484375\n",
      "Batch: 60, Loss: 1.311232089996338, Accuracy: 0.5888671875\n",
      "Batch: 61, Loss: 1.1876792907714844, Accuracy: 0.63232421875\n",
      "Batch: 62, Loss: 1.2162806987762451, Accuracy: 0.62939453125\n",
      "Batch: 63, Loss: 1.26688814163208, Accuracy: 0.603515625\n",
      "Batch: 64, Loss: 1.2774877548217773, Accuracy: 0.6044921875\n",
      "Batch: 65, Loss: 1.3462111949920654, Accuracy: 0.580078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 66, Loss: 1.315807819366455, Accuracy: 0.5908203125\n",
      "Batch: 67, Loss: 1.3411033153533936, Accuracy: 0.58740234375\n",
      "Batch: 68, Loss: 1.2042720317840576, Accuracy: 0.6279296875\n",
      "Batch: 69, Loss: 1.3422701358795166, Accuracy: 0.578125\n",
      "Batch: 70, Loss: 1.3683977127075195, Accuracy: 0.583984375\n",
      "Batch: 71, Loss: 1.3227856159210205, Accuracy: 0.5986328125\n",
      "Batch: 72, Loss: 1.3273159265518188, Accuracy: 0.5966796875\n",
      "Batch: 73, Loss: 1.3868000507354736, Accuracy: 0.578125\n",
      "Batch: 74, Loss: 1.3824737071990967, Accuracy: 0.59130859375\n",
      "Batch: 75, Loss: 1.302520751953125, Accuracy: 0.60595703125\n",
      "Batch: 76, Loss: 1.2986433506011963, Accuracy: 0.6083984375\n",
      "Batch: 77, Loss: 1.2304127216339111, Accuracy: 0.6123046875\n",
      "Batch: 78, Loss: 1.268277645111084, Accuracy: 0.62158203125\n",
      "Batch: 79, Loss: 1.3287882804870605, Accuracy: 0.60400390625\n",
      "Batch: 80, Loss: 1.2918806076049805, Accuracy: 0.58203125\n",
      "Batch: 81, Loss: 1.3576372861862183, Accuracy: 0.6015625\n",
      "Batch: 82, Loss: 1.2126555442810059, Accuracy: 0.6240234375\n",
      "Batch: 83, Loss: 1.2436342239379883, Accuracy: 0.603515625\n",
      "Batch: 84, Loss: 1.2151131629943848, Accuracy: 0.625\n",
      "Batch: 85, Loss: 1.1707969903945923, Accuracy: 0.62158203125\n",
      "Batch: 86, Loss: 1.4319273233413696, Accuracy: 0.57275390625\n",
      "Batch: 87, Loss: 1.2866524457931519, Accuracy: 0.5986328125\n",
      "Batch: 88, Loss: 1.346287727355957, Accuracy: 0.58544921875\n",
      "Batch: 89, Loss: 1.3282188177108765, Accuracy: 0.5966796875\n",
      "Batch: 90, Loss: 1.401723861694336, Accuracy: 0.55810546875\n",
      "Batch: 91, Loss: 1.2067657709121704, Accuracy: 0.623046875\n",
      "Batch: 92, Loss: 1.399066686630249, Accuracy: 0.5751953125\n",
      "Batch: 93, Loss: 1.2968952655792236, Accuracy: 0.6044921875\n",
      "Batch: 94, Loss: 1.389371633529663, Accuracy: 0.5888671875\n",
      "Batch: 95, Loss: 1.395391583442688, Accuracy: 0.56787109375\n",
      "Batch: 96, Loss: 1.3123239278793335, Accuracy: 0.61328125\n",
      "Batch: 97, Loss: 1.3250455856323242, Accuracy: 0.59814453125\n",
      "Batch: 98, Loss: 1.4618936777114868, Accuracy: 0.56591796875\n",
      "Batch: 99, Loss: 1.2713958024978638, Accuracy: 0.61474609375\n",
      "Batch: 100, Loss: 1.3677453994750977, Accuracy: 0.59423828125\n",
      "Batch: 101, Loss: 1.3717992305755615, Accuracy: 0.587890625\n",
      "Batch: 102, Loss: 1.255320429801941, Accuracy: 0.61474609375\n",
      "Batch: 103, Loss: 1.2837214469909668, Accuracy: 0.60693359375\n",
      "Batch: 104, Loss: 1.302207350730896, Accuracy: 0.59765625\n",
      "Batch: 105, Loss: 1.4098966121673584, Accuracy: 0.56396484375\n",
      "Batch: 106, Loss: 1.3853932619094849, Accuracy: 0.57666015625\n",
      "Batch: 107, Loss: 1.4136104583740234, Accuracy: 0.583984375\n",
      "Batch: 108, Loss: 1.3532569408416748, Accuracy: 0.59130859375\n",
      "Batch: 109, Loss: 1.3142307996749878, Accuracy: 0.59130859375\n",
      "Batch: 110, Loss: 1.261567234992981, Accuracy: 0.609375\n",
      "Batch: 111, Loss: 1.221611499786377, Accuracy: 0.6201171875\n",
      "Batch: 112, Loss: 1.339894413948059, Accuracy: 0.60107421875\n",
      "Batch: 113, Loss: 1.3377506732940674, Accuracy: 0.59619140625\n",
      "Batch: 114, Loss: 1.2598506212234497, Accuracy: 0.607421875\n",
      "Batch: 115, Loss: 1.2990038394927979, Accuracy: 0.5927734375\n",
      "Batch: 116, Loss: 1.2777732610702515, Accuracy: 0.61279296875\n",
      "Batch: 117, Loss: 1.2636663913726807, Accuracy: 0.59326171875\n",
      "Batch: 118, Loss: 1.2797671556472778, Accuracy: 0.6103515625\n",
      "Batch: 119, Loss: 1.2454512119293213, Accuracy: 0.60107421875\n",
      "Batch: 120, Loss: 1.280631184577942, Accuracy: 0.6005859375\n",
      "Batch: 121, Loss: 1.2440519332885742, Accuracy: 0.595703125\n",
      "Batch: 122, Loss: 1.2714085578918457, Accuracy: 0.61376953125\n",
      "Batch: 123, Loss: 1.294069528579712, Accuracy: 0.60693359375\n",
      "Batch: 124, Loss: 1.2389569282531738, Accuracy: 0.6220703125\n",
      "Batch: 125, Loss: 1.315467119216919, Accuracy: 0.59326171875\n",
      "Batch: 126, Loss: 1.231292724609375, Accuracy: 0.63232421875\n",
      "Batch: 127, Loss: 1.2486382722854614, Accuracy: 0.6201171875\n",
      "Batch: 128, Loss: 1.459760308265686, Accuracy: 0.56201171875\n",
      "Batch: 129, Loss: 1.4561824798583984, Accuracy: 0.5576171875\n",
      "Batch: 130, Loss: 1.4558038711547852, Accuracy: 0.55517578125\n",
      "Batch: 131, Loss: 1.3831605911254883, Accuracy: 0.58447265625\n",
      "Batch: 132, Loss: 1.1888799667358398, Accuracy: 0.64404296875\n",
      "Batch: 133, Loss: 1.2132123708724976, Accuracy: 0.6435546875\n",
      "Batch: 134, Loss: 1.336597204208374, Accuracy: 0.58544921875\n",
      "Batch: 135, Loss: 1.3543705940246582, Accuracy: 0.5771484375\n",
      "Batch: 136, Loss: 1.2348401546478271, Accuracy: 0.6083984375\n",
      "Batch: 137, Loss: 1.3198343515396118, Accuracy: 0.5986328125\n",
      "Batch: 138, Loss: 1.1636936664581299, Accuracy: 0.6455078125\n",
      "Batch: 139, Loss: 1.2734901905059814, Accuracy: 0.60400390625\n",
      "Batch: 140, Loss: 1.2278861999511719, Accuracy: 0.6064453125\n",
      "Batch: 141, Loss: 1.3211342096328735, Accuracy: 0.58544921875\n",
      "Batch: 142, Loss: 1.2198270559310913, Accuracy: 0.62060546875\n",
      "Batch: 143, Loss: 1.2765781879425049, Accuracy: 0.60498046875\n",
      "Batch: 144, Loss: 1.313223123550415, Accuracy: 0.599609375\n",
      "Batch: 145, Loss: 1.300572395324707, Accuracy: 0.60400390625\n",
      "Batch: 146, Loss: 1.3366563320159912, Accuracy: 0.587890625\n",
      "Batch: 147, Loss: 1.2852532863616943, Accuracy: 0.609375\n",
      "Batch: 148, Loss: 1.2537651062011719, Accuracy: 0.60791015625\n",
      "Batch: 149, Loss: 1.2258167266845703, Accuracy: 0.62744140625\n",
      "Batch: 150, Loss: 1.0998722314834595, Accuracy: 0.6640625\n",
      "Batch: 151, Loss: 1.1140031814575195, Accuracy: 0.64013671875\n",
      "Batch: 152, Loss: 1.1787794828414917, Accuracy: 0.625\n",
      "Batch: 153, Loss: 1.1639149188995361, Accuracy: 0.64111328125\n",
      "Batch: 154, Loss: 1.1753987073898315, Accuracy: 0.6279296875\n",
      "Batch: 155, Loss: 1.2103352546691895, Accuracy: 0.6337890625\n",
      "Batch: 156, Loss: 1.1752865314483643, Accuracy: 0.630859375\n",
      "Batch: 157, Loss: 1.1762545108795166, Accuracy: 0.62109375\n",
      "Batch: 158, Loss: 1.1826872825622559, Accuracy: 0.630859375\n",
      "Batch: 159, Loss: 1.1135985851287842, Accuracy: 0.654296875\n",
      "Batch: 160, Loss: 1.2089967727661133, Accuracy: 0.6201171875\n",
      "Batch: 161, Loss: 1.1851823329925537, Accuracy: 0.630859375\n",
      "Batch: 162, Loss: 1.2163009643554688, Accuracy: 0.62744140625\n",
      "Batch: 163, Loss: 1.223565697669983, Accuracy: 0.62646484375\n",
      "Batch: 164, Loss: 1.2746288776397705, Accuracy: 0.59765625\n",
      "Batch: 165, Loss: 1.1822528839111328, Accuracy: 0.63232421875\n",
      "Batch: 166, Loss: 1.2594683170318604, Accuracy: 0.61181640625\n",
      "Batch: 167, Loss: 1.1497769355773926, Accuracy: 0.64306640625\n",
      "Batch: 168, Loss: 1.141714096069336, Accuracy: 0.640625\n",
      "Batch: 169, Loss: 1.176837682723999, Accuracy: 0.62548828125\n",
      "Batch: 170, Loss: 1.2675837278366089, Accuracy: 0.61572265625\n",
      "Batch: 171, Loss: 1.195913314819336, Accuracy: 0.63330078125\n",
      "Batch: 172, Loss: 1.1829428672790527, Accuracy: 0.6201171875\n",
      "Batch: 173, Loss: 1.2637274265289307, Accuracy: 0.61376953125\n",
      "Batch: 174, Loss: 1.0904967784881592, Accuracy: 0.67333984375\n",
      "Batch: 175, Loss: 1.2648742198944092, Accuracy: 0.59619140625\n",
      "Batch: 176, Loss: 1.32566237449646, Accuracy: 0.59765625\n",
      "Batch: 177, Loss: 1.220686912536621, Accuracy: 0.62255859375\n",
      "Batch: 178, Loss: 1.1760493516921997, Accuracy: 0.63427734375\n",
      "Batch: 179, Loss: 1.2172114849090576, Accuracy: 0.62158203125\n",
      "Batch: 180, Loss: 1.3099348545074463, Accuracy: 0.595703125\n",
      "Epoch 10/200\n",
      "Batch: 1, Loss: 1.860969066619873, Accuracy: 0.52197265625\n",
      "Batch: 2, Loss: 1.2185471057891846, Accuracy: 0.62841796875\n",
      "Batch: 3, Loss: 1.2262734174728394, Accuracy: 0.619140625\n",
      "Batch: 4, Loss: 1.2802304029464722, Accuracy: 0.59521484375\n",
      "Batch: 5, Loss: 1.319190263748169, Accuracy: 0.59228515625\n",
      "Batch: 6, Loss: 1.2880816459655762, Accuracy: 0.59521484375\n",
      "Batch: 7, Loss: 1.2187473773956299, Accuracy: 0.62060546875\n",
      "Batch: 8, Loss: 1.2581160068511963, Accuracy: 0.6005859375\n",
      "Batch: 9, Loss: 1.3217926025390625, Accuracy: 0.61328125\n",
      "Batch: 10, Loss: 1.2956223487854004, Accuracy: 0.61572265625\n",
      "Batch: 11, Loss: 1.3151227235794067, Accuracy: 0.59716796875\n",
      "Batch: 12, Loss: 1.1858477592468262, Accuracy: 0.63232421875\n",
      "Batch: 13, Loss: 1.253150463104248, Accuracy: 0.6044921875\n",
      "Batch: 14, Loss: 1.295610785484314, Accuracy: 0.6015625\n",
      "Batch: 15, Loss: 1.2538847923278809, Accuracy: 0.61083984375\n",
      "Batch: 16, Loss: 1.3338432312011719, Accuracy: 0.60107421875\n",
      "Batch: 17, Loss: 1.2176897525787354, Accuracy: 0.63623046875\n",
      "Batch: 18, Loss: 1.2806956768035889, Accuracy: 0.59912109375\n",
      "Batch: 19, Loss: 1.2985339164733887, Accuracy: 0.60546875\n",
      "Batch: 20, Loss: 1.1709117889404297, Accuracy: 0.65380859375\n",
      "Batch: 21, Loss: 1.4255704879760742, Accuracy: 0.56640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 22, Loss: 1.2797242403030396, Accuracy: 0.6123046875\n",
      "Batch: 23, Loss: 1.2323651313781738, Accuracy: 0.611328125\n",
      "Batch: 24, Loss: 1.241544485092163, Accuracy: 0.61328125\n",
      "Batch: 25, Loss: 1.236973762512207, Accuracy: 0.61865234375\n",
      "Batch: 26, Loss: 1.2900629043579102, Accuracy: 0.61572265625\n",
      "Batch: 27, Loss: 1.2568011283874512, Accuracy: 0.599609375\n",
      "Batch: 28, Loss: 1.1841926574707031, Accuracy: 0.62451171875\n",
      "Batch: 29, Loss: 1.310587763786316, Accuracy: 0.59326171875\n",
      "Batch: 30, Loss: 1.2324070930480957, Accuracy: 0.6259765625\n",
      "Batch: 31, Loss: 1.3851726055145264, Accuracy: 0.58447265625\n",
      "Batch: 32, Loss: 1.3293697834014893, Accuracy: 0.58935546875\n",
      "Batch: 33, Loss: 1.3486955165863037, Accuracy: 0.5888671875\n",
      "Batch: 34, Loss: 1.3342385292053223, Accuracy: 0.5947265625\n",
      "Batch: 35, Loss: 1.383381962776184, Accuracy: 0.57568359375\n",
      "Batch: 36, Loss: 1.3108623027801514, Accuracy: 0.60205078125\n",
      "Batch: 37, Loss: 1.2693021297454834, Accuracy: 0.6123046875\n",
      "Batch: 38, Loss: 1.3176673650741577, Accuracy: 0.59375\n",
      "Batch: 39, Loss: 1.2750343084335327, Accuracy: 0.62060546875\n",
      "Batch: 40, Loss: 1.3285237550735474, Accuracy: 0.59716796875\n",
      "Batch: 41, Loss: 1.2861778736114502, Accuracy: 0.603515625\n",
      "Batch: 42, Loss: 1.2416902780532837, Accuracy: 0.60693359375\n",
      "Batch: 43, Loss: 1.2435048818588257, Accuracy: 0.634765625\n",
      "Batch: 44, Loss: 1.1406652927398682, Accuracy: 0.6435546875\n",
      "Batch: 45, Loss: 1.1969993114471436, Accuracy: 0.6259765625\n",
      "Batch: 46, Loss: 1.1445430517196655, Accuracy: 0.62451171875\n",
      "Batch: 47, Loss: 1.2148191928863525, Accuracy: 0.60986328125\n",
      "Batch: 48, Loss: 1.1755218505859375, Accuracy: 0.625\n",
      "Batch: 49, Loss: 1.2119221687316895, Accuracy: 0.6162109375\n",
      "Batch: 50, Loss: 1.244541049003601, Accuracy: 0.6162109375\n",
      "Batch: 51, Loss: 1.2226431369781494, Accuracy: 0.6220703125\n",
      "Batch: 52, Loss: 1.1910982131958008, Accuracy: 0.62060546875\n",
      "Batch: 53, Loss: 1.1658563613891602, Accuracy: 0.62744140625\n",
      "Batch: 54, Loss: 1.2252919673919678, Accuracy: 0.60693359375\n",
      "Batch: 55, Loss: 1.202257513999939, Accuracy: 0.61669921875\n",
      "Batch: 56, Loss: 1.1911689043045044, Accuracy: 0.61767578125\n",
      "Batch: 57, Loss: 1.2879949808120728, Accuracy: 0.61767578125\n",
      "Batch: 58, Loss: 1.2683287858963013, Accuracy: 0.60009765625\n",
      "Batch: 59, Loss: 1.3835183382034302, Accuracy: 0.572265625\n",
      "Batch: 60, Loss: 1.2729709148406982, Accuracy: 0.603515625\n",
      "Batch: 61, Loss: 1.1361908912658691, Accuracy: 0.6357421875\n",
      "Batch: 62, Loss: 1.1579222679138184, Accuracy: 0.6455078125\n",
      "Batch: 63, Loss: 1.22810959815979, Accuracy: 0.61474609375\n",
      "Batch: 64, Loss: 1.2234759330749512, Accuracy: 0.61279296875\n",
      "Batch: 65, Loss: 1.3123639822006226, Accuracy: 0.595703125\n",
      "Batch: 66, Loss: 1.2596688270568848, Accuracy: 0.607421875\n",
      "Batch: 67, Loss: 1.2603790760040283, Accuracy: 0.6083984375\n",
      "Batch: 68, Loss: 1.1644020080566406, Accuracy: 0.63525390625\n",
      "Batch: 69, Loss: 1.290461540222168, Accuracy: 0.5927734375\n",
      "Batch: 70, Loss: 1.293630599975586, Accuracy: 0.59375\n",
      "Batch: 71, Loss: 1.2338473796844482, Accuracy: 0.61279296875\n",
      "Batch: 72, Loss: 1.276798963546753, Accuracy: 0.6005859375\n",
      "Batch: 73, Loss: 1.3265959024429321, Accuracy: 0.59619140625\n",
      "Batch: 74, Loss: 1.3282325267791748, Accuracy: 0.59912109375\n",
      "Batch: 75, Loss: 1.2479579448699951, Accuracy: 0.6201171875\n",
      "Batch: 76, Loss: 1.229696273803711, Accuracy: 0.62353515625\n",
      "Batch: 77, Loss: 1.1784777641296387, Accuracy: 0.63330078125\n",
      "Batch: 78, Loss: 1.2126573324203491, Accuracy: 0.63134765625\n",
      "Batch: 79, Loss: 1.2629058361053467, Accuracy: 0.61669921875\n",
      "Batch: 80, Loss: 1.219893455505371, Accuracy: 0.5986328125\n",
      "Batch: 81, Loss: 1.3220067024230957, Accuracy: 0.60595703125\n",
      "Batch: 82, Loss: 1.1449750661849976, Accuracy: 0.6318359375\n",
      "Batch: 83, Loss: 1.1793451309204102, Accuracy: 0.625\n",
      "Batch: 84, Loss: 1.168717384338379, Accuracy: 0.62939453125\n",
      "Batch: 85, Loss: 1.1333094835281372, Accuracy: 0.64404296875\n",
      "Batch: 86, Loss: 1.3843005895614624, Accuracy: 0.58203125\n",
      "Batch: 87, Loss: 1.2220115661621094, Accuracy: 0.6142578125\n",
      "Batch: 88, Loss: 1.2933413982391357, Accuracy: 0.611328125\n",
      "Batch: 89, Loss: 1.2979201078414917, Accuracy: 0.60107421875\n",
      "Batch: 90, Loss: 1.3326302766799927, Accuracy: 0.58154296875\n",
      "Batch: 91, Loss: 1.154329776763916, Accuracy: 0.63671875\n",
      "Batch: 92, Loss: 1.3422036170959473, Accuracy: 0.578125\n",
      "Batch: 93, Loss: 1.2547714710235596, Accuracy: 0.6064453125\n",
      "Batch: 94, Loss: 1.3358123302459717, Accuracy: 0.59814453125\n",
      "Batch: 95, Loss: 1.355743408203125, Accuracy: 0.5849609375\n",
      "Batch: 96, Loss: 1.2538031339645386, Accuracy: 0.62744140625\n",
      "Batch: 97, Loss: 1.2665622234344482, Accuracy: 0.61962890625\n",
      "Batch: 98, Loss: 1.375361442565918, Accuracy: 0.57666015625\n",
      "Batch: 99, Loss: 1.2000257968902588, Accuracy: 0.63623046875\n",
      "Batch: 100, Loss: 1.328123927116394, Accuracy: 0.60546875\n",
      "Batch: 101, Loss: 1.338945746421814, Accuracy: 0.59423828125\n",
      "Batch: 102, Loss: 1.2068595886230469, Accuracy: 0.619140625\n",
      "Batch: 103, Loss: 1.242797613143921, Accuracy: 0.6201171875\n",
      "Batch: 104, Loss: 1.2602365016937256, Accuracy: 0.6025390625\n",
      "Batch: 105, Loss: 1.3497965335845947, Accuracy: 0.58984375\n",
      "Batch: 106, Loss: 1.3250025510787964, Accuracy: 0.59326171875\n",
      "Batch: 107, Loss: 1.3363243341445923, Accuracy: 0.5869140625\n",
      "Batch: 108, Loss: 1.3060121536254883, Accuracy: 0.59619140625\n",
      "Batch: 109, Loss: 1.2542988061904907, Accuracy: 0.6064453125\n",
      "Batch: 110, Loss: 1.2177733182907104, Accuracy: 0.61572265625\n",
      "Batch: 111, Loss: 1.1523621082305908, Accuracy: 0.634765625\n",
      "Batch: 112, Loss: 1.2856106758117676, Accuracy: 0.6201171875\n",
      "Batch: 113, Loss: 1.2965960502624512, Accuracy: 0.60498046875\n",
      "Batch: 114, Loss: 1.2275257110595703, Accuracy: 0.62158203125\n",
      "Batch: 115, Loss: 1.2409275770187378, Accuracy: 0.60302734375\n",
      "Batch: 116, Loss: 1.250708818435669, Accuracy: 0.609375\n",
      "Batch: 117, Loss: 1.2336074113845825, Accuracy: 0.60498046875\n",
      "Batch: 118, Loss: 1.2367305755615234, Accuracy: 0.60986328125\n",
      "Batch: 119, Loss: 1.19496750831604, Accuracy: 0.615234375\n",
      "Batch: 120, Loss: 1.2417023181915283, Accuracy: 0.60595703125\n",
      "Batch: 121, Loss: 1.2046699523925781, Accuracy: 0.6103515625\n",
      "Batch: 122, Loss: 1.2191126346588135, Accuracy: 0.6162109375\n",
      "Batch: 123, Loss: 1.2296643257141113, Accuracy: 0.6259765625\n",
      "Batch: 124, Loss: 1.204667568206787, Accuracy: 0.6220703125\n",
      "Batch: 125, Loss: 1.2637426853179932, Accuracy: 0.6005859375\n",
      "Batch: 126, Loss: 1.1870211362838745, Accuracy: 0.6396484375\n",
      "Batch: 127, Loss: 1.183183193206787, Accuracy: 0.6318359375\n",
      "Batch: 128, Loss: 1.4122511148452759, Accuracy: 0.57666015625\n",
      "Batch: 129, Loss: 1.4038081169128418, Accuracy: 0.57666015625\n",
      "Batch: 130, Loss: 1.3917710781097412, Accuracy: 0.57666015625\n",
      "Batch: 131, Loss: 1.3278093338012695, Accuracy: 0.60107421875\n",
      "Batch: 132, Loss: 1.1566548347473145, Accuracy: 0.6337890625\n",
      "Batch: 133, Loss: 1.1632661819458008, Accuracy: 0.64697265625\n",
      "Batch: 134, Loss: 1.257023572921753, Accuracy: 0.60791015625\n",
      "Batch: 135, Loss: 1.3076739311218262, Accuracy: 0.59228515625\n",
      "Batch: 136, Loss: 1.1894869804382324, Accuracy: 0.6162109375\n",
      "Batch: 137, Loss: 1.271464228630066, Accuracy: 0.6142578125\n",
      "Batch: 138, Loss: 1.1210205554962158, Accuracy: 0.650390625\n",
      "Batch: 139, Loss: 1.2410335540771484, Accuracy: 0.6162109375\n",
      "Batch: 140, Loss: 1.1690919399261475, Accuracy: 0.63623046875\n",
      "Batch: 141, Loss: 1.2797060012817383, Accuracy: 0.60107421875\n",
      "Batch: 142, Loss: 1.1606740951538086, Accuracy: 0.63330078125\n",
      "Batch: 143, Loss: 1.2238155603408813, Accuracy: 0.62109375\n",
      "Batch: 144, Loss: 1.2576600313186646, Accuracy: 0.62158203125\n",
      "Batch: 145, Loss: 1.24526846408844, Accuracy: 0.61376953125\n",
      "Batch: 146, Loss: 1.2885665893554688, Accuracy: 0.603515625\n",
      "Batch: 147, Loss: 1.2451337575912476, Accuracy: 0.61279296875\n",
      "Batch: 148, Loss: 1.2027742862701416, Accuracy: 0.62548828125\n",
      "Batch: 149, Loss: 1.185333490371704, Accuracy: 0.6318359375\n",
      "Batch: 150, Loss: 1.0485284328460693, Accuracy: 0.66943359375\n",
      "Batch: 151, Loss: 1.0630780458450317, Accuracy: 0.65625\n",
      "Batch: 152, Loss: 1.1480351686477661, Accuracy: 0.63232421875\n",
      "Batch: 153, Loss: 1.1137478351593018, Accuracy: 0.65087890625\n",
      "Batch: 154, Loss: 1.1349453926086426, Accuracy: 0.6435546875\n",
      "Batch: 155, Loss: 1.1941015720367432, Accuracy: 0.63232421875\n",
      "Batch: 156, Loss: 1.1288704872131348, Accuracy: 0.6474609375\n",
      "Batch: 157, Loss: 1.1186957359313965, Accuracy: 0.646484375\n",
      "Batch: 158, Loss: 1.1334607601165771, Accuracy: 0.64794921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 159, Loss: 1.0706843137741089, Accuracy: 0.6689453125\n",
      "Batch: 160, Loss: 1.1625392436981201, Accuracy: 0.6298828125\n",
      "Batch: 161, Loss: 1.1546169519424438, Accuracy: 0.6357421875\n",
      "Batch: 162, Loss: 1.1715871095657349, Accuracy: 0.6328125\n",
      "Batch: 163, Loss: 1.1949071884155273, Accuracy: 0.630859375\n",
      "Batch: 164, Loss: 1.216886043548584, Accuracy: 0.61767578125\n",
      "Batch: 165, Loss: 1.1384934186935425, Accuracy: 0.6494140625\n",
      "Batch: 166, Loss: 1.2029244899749756, Accuracy: 0.62109375\n",
      "Batch: 167, Loss: 1.0931084156036377, Accuracy: 0.6611328125\n",
      "Batch: 168, Loss: 1.0779361724853516, Accuracy: 0.662109375\n",
      "Batch: 169, Loss: 1.1229170560836792, Accuracy: 0.64111328125\n",
      "Batch: 170, Loss: 1.2300481796264648, Accuracy: 0.6240234375\n",
      "Batch: 171, Loss: 1.1440531015396118, Accuracy: 0.642578125\n",
      "Batch: 172, Loss: 1.1427323818206787, Accuracy: 0.63916015625\n",
      "Batch: 173, Loss: 1.2114838361740112, Accuracy: 0.6328125\n",
      "Batch: 174, Loss: 1.037982702255249, Accuracy: 0.68310546875\n",
      "Batch: 175, Loss: 1.2037049531936646, Accuracy: 0.61279296875\n",
      "Batch: 176, Loss: 1.2809451818466187, Accuracy: 0.60302734375\n",
      "Batch: 177, Loss: 1.1694695949554443, Accuracy: 0.6279296875\n",
      "Batch: 178, Loss: 1.1331653594970703, Accuracy: 0.638671875\n",
      "Batch: 179, Loss: 1.1694304943084717, Accuracy: 0.62158203125\n",
      "Batch: 180, Loss: 1.2577097415924072, Accuracy: 0.603515625\n",
      "Saved Weights at epoch 10 to file Weights_10.h5\n",
      "Epoch 11/200\n",
      "Batch: 1, Loss: 1.7823041677474976, Accuracy: 0.52734375\n",
      "Batch: 2, Loss: 1.1759042739868164, Accuracy: 0.64208984375\n",
      "Batch: 3, Loss: 1.1751599311828613, Accuracy: 0.64013671875\n",
      "Batch: 4, Loss: 1.2272446155548096, Accuracy: 0.61376953125\n",
      "Batch: 5, Loss: 1.2584055662155151, Accuracy: 0.6103515625\n",
      "Batch: 6, Loss: 1.2462475299835205, Accuracy: 0.61083984375\n",
      "Batch: 7, Loss: 1.139697551727295, Accuracy: 0.6298828125\n",
      "Batch: 8, Loss: 1.2166059017181396, Accuracy: 0.60693359375\n",
      "Batch: 9, Loss: 1.2664196491241455, Accuracy: 0.6142578125\n",
      "Batch: 10, Loss: 1.2442219257354736, Accuracy: 0.634765625\n",
      "Batch: 11, Loss: 1.2622299194335938, Accuracy: 0.60400390625\n",
      "Batch: 12, Loss: 1.1450576782226562, Accuracy: 0.638671875\n",
      "Batch: 13, Loss: 1.2031816244125366, Accuracy: 0.61669921875\n",
      "Batch: 14, Loss: 1.2400784492492676, Accuracy: 0.60693359375\n",
      "Batch: 15, Loss: 1.2142348289489746, Accuracy: 0.62939453125\n",
      "Batch: 16, Loss: 1.2763242721557617, Accuracy: 0.6103515625\n",
      "Batch: 17, Loss: 1.190436840057373, Accuracy: 0.6416015625\n",
      "Batch: 18, Loss: 1.238278865814209, Accuracy: 0.60205078125\n",
      "Batch: 19, Loss: 1.2537355422973633, Accuracy: 0.61376953125\n",
      "Batch: 20, Loss: 1.1542829275131226, Accuracy: 0.65869140625\n",
      "Batch: 21, Loss: 1.3601715564727783, Accuracy: 0.5869140625\n",
      "Batch: 22, Loss: 1.2555320262908936, Accuracy: 0.6162109375\n",
      "Batch: 23, Loss: 1.1906101703643799, Accuracy: 0.62744140625\n",
      "Batch: 24, Loss: 1.181015968322754, Accuracy: 0.62939453125\n",
      "Batch: 25, Loss: 1.1892497539520264, Accuracy: 0.62255859375\n",
      "Batch: 26, Loss: 1.226657509803772, Accuracy: 0.62890625\n",
      "Batch: 27, Loss: 1.224135398864746, Accuracy: 0.61181640625\n",
      "Batch: 28, Loss: 1.1220042705535889, Accuracy: 0.6416015625\n",
      "Batch: 29, Loss: 1.2643479108810425, Accuracy: 0.6103515625\n",
      "Batch: 30, Loss: 1.187697172164917, Accuracy: 0.62841796875\n",
      "Batch: 31, Loss: 1.326960802078247, Accuracy: 0.5927734375\n",
      "Batch: 32, Loss: 1.2801094055175781, Accuracy: 0.60205078125\n",
      "Batch: 33, Loss: 1.2837741374969482, Accuracy: 0.59521484375\n",
      "Batch: 34, Loss: 1.3079843521118164, Accuracy: 0.60400390625\n",
      "Batch: 35, Loss: 1.3322319984436035, Accuracy: 0.58154296875\n",
      "Batch: 36, Loss: 1.2655974626541138, Accuracy: 0.61083984375\n",
      "Batch: 37, Loss: 1.2161505222320557, Accuracy: 0.61962890625\n",
      "Batch: 38, Loss: 1.267240285873413, Accuracy: 0.60546875\n",
      "Batch: 39, Loss: 1.2367277145385742, Accuracy: 0.615234375\n",
      "Batch: 40, Loss: 1.2739741802215576, Accuracy: 0.60888671875\n",
      "Batch: 41, Loss: 1.252615213394165, Accuracy: 0.59912109375\n",
      "Batch: 42, Loss: 1.1884275674819946, Accuracy: 0.626953125\n",
      "Batch: 43, Loss: 1.1935880184173584, Accuracy: 0.64013671875\n",
      "Batch: 44, Loss: 1.0917402505874634, Accuracy: 0.65771484375\n",
      "Batch: 45, Loss: 1.1446163654327393, Accuracy: 0.6337890625\n",
      "Batch: 46, Loss: 1.1015796661376953, Accuracy: 0.63330078125\n",
      "Batch: 47, Loss: 1.1918307542800903, Accuracy: 0.62109375\n",
      "Batch: 48, Loss: 1.1490182876586914, Accuracy: 0.6376953125\n",
      "Batch: 49, Loss: 1.158828616142273, Accuracy: 0.62255859375\n",
      "Batch: 50, Loss: 1.2072267532348633, Accuracy: 0.62060546875\n",
      "Batch: 51, Loss: 1.1939266920089722, Accuracy: 0.6171875\n",
      "Batch: 52, Loss: 1.1581041812896729, Accuracy: 0.62841796875\n",
      "Batch: 53, Loss: 1.1308197975158691, Accuracy: 0.63720703125\n",
      "Batch: 54, Loss: 1.163501501083374, Accuracy: 0.61962890625\n",
      "Batch: 55, Loss: 1.1539584398269653, Accuracy: 0.64404296875\n",
      "Batch: 56, Loss: 1.1600871086120605, Accuracy: 0.634765625\n",
      "Batch: 57, Loss: 1.2481756210327148, Accuracy: 0.62158203125\n",
      "Batch: 58, Loss: 1.2112541198730469, Accuracy: 0.61474609375\n",
      "Batch: 59, Loss: 1.348341464996338, Accuracy: 0.58154296875\n",
      "Batch: 60, Loss: 1.2182215452194214, Accuracy: 0.6142578125\n",
      "Batch: 61, Loss: 1.1124804019927979, Accuracy: 0.6494140625\n",
      "Batch: 62, Loss: 1.1334521770477295, Accuracy: 0.6533203125\n",
      "Batch: 63, Loss: 1.1825950145721436, Accuracy: 0.62841796875\n",
      "Batch: 64, Loss: 1.1926931142807007, Accuracy: 0.6298828125\n",
      "Batch: 65, Loss: 1.2537481784820557, Accuracy: 0.607421875\n",
      "Batch: 66, Loss: 1.2101976871490479, Accuracy: 0.6201171875\n",
      "Batch: 67, Loss: 1.2367421388626099, Accuracy: 0.61865234375\n",
      "Batch: 68, Loss: 1.1232445240020752, Accuracy: 0.6513671875\n",
      "Batch: 69, Loss: 1.2403416633605957, Accuracy: 0.607421875\n",
      "Batch: 70, Loss: 1.2517913579940796, Accuracy: 0.60400390625\n",
      "Batch: 71, Loss: 1.2025864124298096, Accuracy: 0.6142578125\n",
      "Batch: 72, Loss: 1.2258226871490479, Accuracy: 0.6064453125\n",
      "Batch: 73, Loss: 1.2976808547973633, Accuracy: 0.5986328125\n",
      "Batch: 74, Loss: 1.2741639614105225, Accuracy: 0.60546875\n",
      "Batch: 75, Loss: 1.182354211807251, Accuracy: 0.63720703125\n",
      "Batch: 76, Loss: 1.1906664371490479, Accuracy: 0.626953125\n",
      "Batch: 77, Loss: 1.1472105979919434, Accuracy: 0.63525390625\n",
      "Batch: 78, Loss: 1.1718605756759644, Accuracy: 0.63720703125\n",
      "Batch: 79, Loss: 1.21219801902771, Accuracy: 0.64111328125\n",
      "Batch: 80, Loss: 1.1920580863952637, Accuracy: 0.61767578125\n",
      "Batch: 81, Loss: 1.2562551498413086, Accuracy: 0.615234375\n",
      "Batch: 82, Loss: 1.100405216217041, Accuracy: 0.630859375\n",
      "Batch: 83, Loss: 1.140195608139038, Accuracy: 0.6318359375\n",
      "Batch: 84, Loss: 1.1153295040130615, Accuracy: 0.64990234375\n",
      "Batch: 85, Loss: 1.0967159271240234, Accuracy: 0.63427734375\n",
      "Batch: 86, Loss: 1.3284991979599, Accuracy: 0.59228515625\n",
      "Batch: 87, Loss: 1.2065768241882324, Accuracy: 0.61865234375\n",
      "Batch: 88, Loss: 1.251354694366455, Accuracy: 0.6064453125\n",
      "Batch: 89, Loss: 1.241026759147644, Accuracy: 0.615234375\n",
      "Batch: 90, Loss: 1.2889937162399292, Accuracy: 0.580078125\n",
      "Batch: 91, Loss: 1.1145213842391968, Accuracy: 0.64990234375\n",
      "Batch: 92, Loss: 1.3048818111419678, Accuracy: 0.5966796875\n",
      "Batch: 93, Loss: 1.2099361419677734, Accuracy: 0.62109375\n",
      "Batch: 94, Loss: 1.2879694700241089, Accuracy: 0.611328125\n",
      "Batch: 95, Loss: 1.313908576965332, Accuracy: 0.5908203125\n",
      "Batch: 96, Loss: 1.2099294662475586, Accuracy: 0.6435546875\n",
      "Batch: 97, Loss: 1.1982276439666748, Accuracy: 0.63037109375\n",
      "Batch: 98, Loss: 1.3245368003845215, Accuracy: 0.58984375\n",
      "Batch: 99, Loss: 1.1536829471588135, Accuracy: 0.63623046875\n",
      "Batch: 100, Loss: 1.2851786613464355, Accuracy: 0.61962890625\n",
      "Batch: 101, Loss: 1.300361156463623, Accuracy: 0.6083984375\n",
      "Batch: 102, Loss: 1.1556546688079834, Accuracy: 0.62548828125\n",
      "Batch: 103, Loss: 1.1987617015838623, Accuracy: 0.61865234375\n",
      "Batch: 104, Loss: 1.1954259872436523, Accuracy: 0.62255859375\n",
      "Batch: 105, Loss: 1.3003902435302734, Accuracy: 0.58349609375\n",
      "Batch: 106, Loss: 1.29060697555542, Accuracy: 0.59912109375\n",
      "Batch: 107, Loss: 1.2848403453826904, Accuracy: 0.59619140625\n",
      "Batch: 108, Loss: 1.2728279829025269, Accuracy: 0.6103515625\n",
      "Batch: 109, Loss: 1.2312299013137817, Accuracy: 0.607421875\n",
      "Batch: 110, Loss: 1.1538375616073608, Accuracy: 0.6259765625\n",
      "Batch: 111, Loss: 1.1046864986419678, Accuracy: 0.64990234375\n",
      "Batch: 112, Loss: 1.2373363971710205, Accuracy: 0.6259765625\n",
      "Batch: 113, Loss: 1.2419277429580688, Accuracy: 0.6064453125\n",
      "Batch: 114, Loss: 1.1848621368408203, Accuracy: 0.62158203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 115, Loss: 1.2226369380950928, Accuracy: 0.6123046875\n",
      "Batch: 116, Loss: 1.1961572170257568, Accuracy: 0.6220703125\n",
      "Batch: 117, Loss: 1.196744680404663, Accuracy: 0.6142578125\n",
      "Batch: 118, Loss: 1.190967082977295, Accuracy: 0.62255859375\n",
      "Batch: 119, Loss: 1.167245864868164, Accuracy: 0.6162109375\n",
      "Batch: 120, Loss: 1.1970374584197998, Accuracy: 0.60595703125\n",
      "Batch: 121, Loss: 1.1884058713912964, Accuracy: 0.61083984375\n",
      "Batch: 122, Loss: 1.177405834197998, Accuracy: 0.6318359375\n",
      "Batch: 123, Loss: 1.195682168006897, Accuracy: 0.63916015625\n",
      "Batch: 124, Loss: 1.1503732204437256, Accuracy: 0.63720703125\n",
      "Batch: 125, Loss: 1.2129755020141602, Accuracy: 0.611328125\n",
      "Batch: 126, Loss: 1.136249303817749, Accuracy: 0.65185546875\n",
      "Batch: 127, Loss: 1.1296584606170654, Accuracy: 0.64404296875\n",
      "Batch: 128, Loss: 1.3638134002685547, Accuracy: 0.595703125\n",
      "Batch: 129, Loss: 1.3577487468719482, Accuracy: 0.591796875\n",
      "Batch: 130, Loss: 1.3521804809570312, Accuracy: 0.57763671875\n",
      "Batch: 131, Loss: 1.2906150817871094, Accuracy: 0.6103515625\n",
      "Batch: 132, Loss: 1.1154594421386719, Accuracy: 0.6474609375\n",
      "Batch: 133, Loss: 1.1193732023239136, Accuracy: 0.658203125\n",
      "Batch: 134, Loss: 1.238235592842102, Accuracy: 0.6181640625\n",
      "Batch: 135, Loss: 1.2558228969573975, Accuracy: 0.60009765625\n",
      "Batch: 136, Loss: 1.1672008037567139, Accuracy: 0.62158203125\n",
      "Batch: 137, Loss: 1.2277553081512451, Accuracy: 0.61474609375\n",
      "Batch: 138, Loss: 1.0918843746185303, Accuracy: 0.669921875\n",
      "Batch: 139, Loss: 1.2006545066833496, Accuracy: 0.6171875\n",
      "Batch: 140, Loss: 1.1449246406555176, Accuracy: 0.638671875\n",
      "Batch: 141, Loss: 1.2414449453353882, Accuracy: 0.61328125\n",
      "Batch: 142, Loss: 1.1166284084320068, Accuracy: 0.64599609375\n",
      "Batch: 143, Loss: 1.1788835525512695, Accuracy: 0.63818359375\n",
      "Batch: 144, Loss: 1.2170511484146118, Accuracy: 0.63232421875\n",
      "Batch: 145, Loss: 1.2135858535766602, Accuracy: 0.62744140625\n",
      "Batch: 146, Loss: 1.2311723232269287, Accuracy: 0.6123046875\n",
      "Batch: 147, Loss: 1.2133917808532715, Accuracy: 0.6201171875\n",
      "Batch: 148, Loss: 1.1899229288101196, Accuracy: 0.62255859375\n",
      "Batch: 149, Loss: 1.150072693824768, Accuracy: 0.6376953125\n",
      "Batch: 150, Loss: 1.0195167064666748, Accuracy: 0.6845703125\n",
      "Batch: 151, Loss: 1.0311938524246216, Accuracy: 0.6572265625\n",
      "Batch: 152, Loss: 1.0970379114151, Accuracy: 0.646484375\n",
      "Batch: 153, Loss: 1.09041166305542, Accuracy: 0.650390625\n",
      "Batch: 154, Loss: 1.0850951671600342, Accuracy: 0.66015625\n",
      "Batch: 155, Loss: 1.1488244533538818, Accuracy: 0.642578125\n",
      "Batch: 156, Loss: 1.0911056995391846, Accuracy: 0.6630859375\n",
      "Batch: 157, Loss: 1.0774527788162231, Accuracy: 0.65087890625\n",
      "Batch: 158, Loss: 1.0863304138183594, Accuracy: 0.6611328125\n",
      "Batch: 159, Loss: 1.0539908409118652, Accuracy: 0.6728515625\n",
      "Batch: 160, Loss: 1.1239213943481445, Accuracy: 0.6357421875\n",
      "Batch: 161, Loss: 1.1242482662200928, Accuracy: 0.6455078125\n",
      "Batch: 162, Loss: 1.1407902240753174, Accuracy: 0.64794921875\n",
      "Batch: 163, Loss: 1.1671667098999023, Accuracy: 0.63232421875\n",
      "Batch: 164, Loss: 1.19650137424469, Accuracy: 0.62744140625\n",
      "Batch: 165, Loss: 1.1187573671340942, Accuracy: 0.65869140625\n",
      "Batch: 166, Loss: 1.1789374351501465, Accuracy: 0.62646484375\n",
      "Batch: 167, Loss: 1.067179560661316, Accuracy: 0.66552734375\n",
      "Batch: 168, Loss: 1.0385324954986572, Accuracy: 0.6748046875\n",
      "Batch: 169, Loss: 1.0914366245269775, Accuracy: 0.6455078125\n",
      "Batch: 170, Loss: 1.188842535018921, Accuracy: 0.62890625\n",
      "Batch: 171, Loss: 1.1163609027862549, Accuracy: 0.64404296875\n",
      "Batch: 172, Loss: 1.1078197956085205, Accuracy: 0.64990234375\n",
      "Batch: 173, Loss: 1.1828386783599854, Accuracy: 0.63671875\n",
      "Batch: 174, Loss: 1.0077391862869263, Accuracy: 0.67431640625\n",
      "Batch: 175, Loss: 1.1916193962097168, Accuracy: 0.60986328125\n",
      "Batch: 176, Loss: 1.2451884746551514, Accuracy: 0.615234375\n",
      "Batch: 177, Loss: 1.1555001735687256, Accuracy: 0.64208984375\n",
      "Batch: 178, Loss: 1.0944359302520752, Accuracy: 0.6484375\n",
      "Batch: 179, Loss: 1.1461750268936157, Accuracy: 0.6298828125\n",
      "Batch: 180, Loss: 1.225814700126648, Accuracy: 0.6083984375\n",
      "Epoch 12/200\n",
      "Batch: 1, Loss: 1.7095720767974854, Accuracy: 0.54248046875\n",
      "Batch: 2, Loss: 1.1536118984222412, Accuracy: 0.64013671875\n",
      "Batch: 3, Loss: 1.154625415802002, Accuracy: 0.6455078125\n",
      "Batch: 4, Loss: 1.2191389799118042, Accuracy: 0.61865234375\n",
      "Batch: 5, Loss: 1.2241084575653076, Accuracy: 0.60791015625\n",
      "Batch: 6, Loss: 1.2046178579330444, Accuracy: 0.62255859375\n",
      "Batch: 7, Loss: 1.115242600440979, Accuracy: 0.638671875\n",
      "Batch: 8, Loss: 1.175226092338562, Accuracy: 0.623046875\n",
      "Batch: 9, Loss: 1.2452328205108643, Accuracy: 0.6298828125\n",
      "Batch: 10, Loss: 1.2110389471054077, Accuracy: 0.6337890625\n",
      "Batch: 11, Loss: 1.2247846126556396, Accuracy: 0.6240234375\n",
      "Batch: 12, Loss: 1.1126275062561035, Accuracy: 0.64404296875\n",
      "Batch: 13, Loss: 1.178038477897644, Accuracy: 0.62744140625\n",
      "Batch: 14, Loss: 1.207482933998108, Accuracy: 0.6171875\n",
      "Batch: 15, Loss: 1.1784569025039673, Accuracy: 0.640625\n",
      "Batch: 16, Loss: 1.2517356872558594, Accuracy: 0.61328125\n",
      "Batch: 17, Loss: 1.1409975290298462, Accuracy: 0.64013671875\n",
      "Batch: 18, Loss: 1.2032556533813477, Accuracy: 0.61328125\n",
      "Batch: 19, Loss: 1.233849048614502, Accuracy: 0.61962890625\n",
      "Batch: 20, Loss: 1.11922287940979, Accuracy: 0.6591796875\n",
      "Batch: 21, Loss: 1.3249127864837646, Accuracy: 0.591796875\n",
      "Batch: 22, Loss: 1.212619662284851, Accuracy: 0.61669921875\n",
      "Batch: 23, Loss: 1.138817310333252, Accuracy: 0.6396484375\n",
      "Batch: 24, Loss: 1.1683509349822998, Accuracy: 0.6318359375\n",
      "Batch: 25, Loss: 1.1486670970916748, Accuracy: 0.634765625\n",
      "Batch: 26, Loss: 1.1775195598602295, Accuracy: 0.6416015625\n",
      "Batch: 27, Loss: 1.1749751567840576, Accuracy: 0.62548828125\n",
      "Batch: 28, Loss: 1.0892915725708008, Accuracy: 0.6494140625\n",
      "Batch: 29, Loss: 1.221971035003662, Accuracy: 0.615234375\n",
      "Batch: 30, Loss: 1.1622412204742432, Accuracy: 0.63720703125\n",
      "Batch: 31, Loss: 1.3025667667388916, Accuracy: 0.5927734375\n",
      "Batch: 32, Loss: 1.2421385049819946, Accuracy: 0.6064453125\n",
      "Batch: 33, Loss: 1.2494908571243286, Accuracy: 0.59716796875\n",
      "Batch: 34, Loss: 1.272491693496704, Accuracy: 0.59423828125\n",
      "Batch: 35, Loss: 1.313340425491333, Accuracy: 0.5849609375\n",
      "Batch: 36, Loss: 1.2341731786727905, Accuracy: 0.611328125\n",
      "Batch: 37, Loss: 1.1910958290100098, Accuracy: 0.62451171875\n",
      "Batch: 38, Loss: 1.2554042339324951, Accuracy: 0.6025390625\n",
      "Batch: 39, Loss: 1.2015419006347656, Accuracy: 0.63134765625\n",
      "Batch: 40, Loss: 1.2512071132659912, Accuracy: 0.61767578125\n",
      "Batch: 41, Loss: 1.2165027856826782, Accuracy: 0.61669921875\n",
      "Batch: 42, Loss: 1.1598212718963623, Accuracy: 0.63037109375\n",
      "Batch: 43, Loss: 1.179318904876709, Accuracy: 0.646484375\n",
      "Batch: 44, Loss: 1.0748714208602905, Accuracy: 0.66552734375\n",
      "Batch: 45, Loss: 1.1166927814483643, Accuracy: 0.63623046875\n",
      "Batch: 46, Loss: 1.0805474519729614, Accuracy: 0.63671875\n",
      "Batch: 47, Loss: 1.1713533401489258, Accuracy: 0.6181640625\n",
      "Batch: 48, Loss: 1.1169347763061523, Accuracy: 0.6357421875\n",
      "Batch: 49, Loss: 1.118736743927002, Accuracy: 0.64111328125\n",
      "Batch: 50, Loss: 1.1824077367782593, Accuracy: 0.6220703125\n",
      "Batch: 51, Loss: 1.1488162279129028, Accuracy: 0.64599609375\n",
      "Batch: 52, Loss: 1.106593132019043, Accuracy: 0.6396484375\n",
      "Batch: 53, Loss: 1.0943660736083984, Accuracy: 0.64794921875\n",
      "Batch: 54, Loss: 1.1448174715042114, Accuracy: 0.62353515625\n",
      "Batch: 55, Loss: 1.1333961486816406, Accuracy: 0.64111328125\n",
      "Batch: 56, Loss: 1.1178886890411377, Accuracy: 0.650390625\n",
      "Batch: 57, Loss: 1.2210677862167358, Accuracy: 0.61572265625\n",
      "Batch: 58, Loss: 1.172743797302246, Accuracy: 0.6318359375\n",
      "Batch: 59, Loss: 1.3156625032424927, Accuracy: 0.5908203125\n",
      "Batch: 60, Loss: 1.1759721040725708, Accuracy: 0.62890625\n",
      "Batch: 61, Loss: 1.067392349243164, Accuracy: 0.65673828125\n",
      "Batch: 62, Loss: 1.0906050205230713, Accuracy: 0.65869140625\n",
      "Batch: 63, Loss: 1.147233486175537, Accuracy: 0.640625\n",
      "Batch: 64, Loss: 1.146098017692566, Accuracy: 0.63818359375\n",
      "Batch: 65, Loss: 1.2319350242614746, Accuracy: 0.6103515625\n",
      "Batch: 66, Loss: 1.1855497360229492, Accuracy: 0.62890625\n",
      "Batch: 67, Loss: 1.200393557548523, Accuracy: 0.62109375\n",
      "Batch: 68, Loss: 1.0941998958587646, Accuracy: 0.65380859375\n",
      "Batch: 69, Loss: 1.1865472793579102, Accuracy: 0.61376953125\n",
      "Batch: 70, Loss: 1.2124900817871094, Accuracy: 0.609375\n",
      "Batch: 71, Loss: 1.1780726909637451, Accuracy: 0.62109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 72, Loss: 1.1934274435043335, Accuracy: 0.61083984375\n",
      "Batch: 73, Loss: 1.2536368370056152, Accuracy: 0.59765625\n",
      "Batch: 74, Loss: 1.2341970205307007, Accuracy: 0.6162109375\n",
      "Batch: 75, Loss: 1.155750036239624, Accuracy: 0.63818359375\n",
      "Batch: 76, Loss: 1.146701455116272, Accuracy: 0.62939453125\n",
      "Batch: 77, Loss: 1.1040819883346558, Accuracy: 0.6494140625\n",
      "Batch: 78, Loss: 1.1557317972183228, Accuracy: 0.6435546875\n",
      "Batch: 79, Loss: 1.1805431842803955, Accuracy: 0.6376953125\n",
      "Batch: 80, Loss: 1.1370737552642822, Accuracy: 0.62646484375\n",
      "Batch: 81, Loss: 1.2282527685165405, Accuracy: 0.62744140625\n",
      "Batch: 82, Loss: 1.0779286623001099, Accuracy: 0.6435546875\n",
      "Batch: 83, Loss: 1.1000583171844482, Accuracy: 0.6435546875\n",
      "Batch: 84, Loss: 1.083937644958496, Accuracy: 0.64306640625\n",
      "Batch: 85, Loss: 1.0493505001068115, Accuracy: 0.66357421875\n",
      "Batch: 86, Loss: 1.2852119207382202, Accuracy: 0.5947265625\n",
      "Batch: 87, Loss: 1.1653542518615723, Accuracy: 0.6298828125\n",
      "Batch: 88, Loss: 1.2209155559539795, Accuracy: 0.6220703125\n",
      "Batch: 89, Loss: 1.2088985443115234, Accuracy: 0.6318359375\n",
      "Batch: 90, Loss: 1.2663559913635254, Accuracy: 0.595703125\n",
      "Batch: 91, Loss: 1.097559928894043, Accuracy: 0.650390625\n",
      "Batch: 92, Loss: 1.2650563716888428, Accuracy: 0.595703125\n",
      "Batch: 93, Loss: 1.1843373775482178, Accuracy: 0.6201171875\n",
      "Batch: 94, Loss: 1.2551729679107666, Accuracy: 0.62109375\n",
      "Batch: 95, Loss: 1.2742462158203125, Accuracy: 0.61376953125\n",
      "Batch: 96, Loss: 1.1965789794921875, Accuracy: 0.640625\n",
      "Batch: 97, Loss: 1.1808563470840454, Accuracy: 0.63671875\n",
      "Batch: 98, Loss: 1.303853154182434, Accuracy: 0.6025390625\n",
      "Batch: 99, Loss: 1.1459370851516724, Accuracy: 0.64892578125\n",
      "Batch: 100, Loss: 1.269798994064331, Accuracy: 0.62255859375\n",
      "Batch: 101, Loss: 1.2662228345870972, Accuracy: 0.607421875\n",
      "Batch: 102, Loss: 1.1231818199157715, Accuracy: 0.6376953125\n",
      "Batch: 103, Loss: 1.1713430881500244, Accuracy: 0.63671875\n",
      "Batch: 104, Loss: 1.1845152378082275, Accuracy: 0.62158203125\n",
      "Batch: 105, Loss: 1.2681827545166016, Accuracy: 0.5966796875\n",
      "Batch: 106, Loss: 1.243276834487915, Accuracy: 0.61376953125\n",
      "Batch: 107, Loss: 1.2580382823944092, Accuracy: 0.59814453125\n",
      "Batch: 108, Loss: 1.217597246170044, Accuracy: 0.62744140625\n",
      "Batch: 109, Loss: 1.190431833267212, Accuracy: 0.62158203125\n",
      "Batch: 110, Loss: 1.119764804840088, Accuracy: 0.63916015625\n",
      "Batch: 111, Loss: 1.073190689086914, Accuracy: 0.64697265625\n",
      "Batch: 112, Loss: 1.2018157243728638, Accuracy: 0.63818359375\n",
      "Batch: 113, Loss: 1.2071003913879395, Accuracy: 0.62060546875\n",
      "Batch: 114, Loss: 1.153151273727417, Accuracy: 0.63427734375\n",
      "Batch: 115, Loss: 1.181960940361023, Accuracy: 0.6240234375\n",
      "Batch: 116, Loss: 1.1823580265045166, Accuracy: 0.60986328125\n",
      "Batch: 117, Loss: 1.1509182453155518, Accuracy: 0.62353515625\n",
      "Batch: 118, Loss: 1.1663753986358643, Accuracy: 0.625\n",
      "Batch: 119, Loss: 1.1403157711029053, Accuracy: 0.61669921875\n",
      "Batch: 120, Loss: 1.1614162921905518, Accuracy: 0.611328125\n",
      "Batch: 121, Loss: 1.1400940418243408, Accuracy: 0.634765625\n",
      "Batch: 122, Loss: 1.1413785219192505, Accuracy: 0.6357421875\n",
      "Batch: 123, Loss: 1.1592564582824707, Accuracy: 0.640625\n",
      "Batch: 124, Loss: 1.123539686203003, Accuracy: 0.640625\n",
      "Batch: 125, Loss: 1.1853466033935547, Accuracy: 0.6201171875\n",
      "Batch: 126, Loss: 1.10898756980896, Accuracy: 0.654296875\n",
      "Batch: 127, Loss: 1.1050890684127808, Accuracy: 0.650390625\n",
      "Batch: 128, Loss: 1.3206150531768799, Accuracy: 0.5986328125\n",
      "Batch: 129, Loss: 1.3297219276428223, Accuracy: 0.58740234375\n",
      "Batch: 130, Loss: 1.3081116676330566, Accuracy: 0.5869140625\n",
      "Batch: 131, Loss: 1.2548441886901855, Accuracy: 0.62255859375\n",
      "Batch: 132, Loss: 1.093224287033081, Accuracy: 0.6435546875\n",
      "Batch: 133, Loss: 1.0854980945587158, Accuracy: 0.65673828125\n",
      "Batch: 134, Loss: 1.2020772695541382, Accuracy: 0.61181640625\n",
      "Batch: 135, Loss: 1.2306430339813232, Accuracy: 0.615234375\n",
      "Batch: 136, Loss: 1.1176100969314575, Accuracy: 0.63916015625\n",
      "Batch: 137, Loss: 1.194837212562561, Accuracy: 0.62255859375\n",
      "Batch: 138, Loss: 1.0623202323913574, Accuracy: 0.6689453125\n",
      "Batch: 139, Loss: 1.1789417266845703, Accuracy: 0.62255859375\n",
      "Batch: 140, Loss: 1.1097984313964844, Accuracy: 0.654296875\n",
      "Batch: 141, Loss: 1.2114055156707764, Accuracy: 0.62255859375\n",
      "Batch: 142, Loss: 1.0955051183700562, Accuracy: 0.64501953125\n",
      "Batch: 143, Loss: 1.157320499420166, Accuracy: 0.64599609375\n",
      "Batch: 144, Loss: 1.2051730155944824, Accuracy: 0.6357421875\n",
      "Batch: 145, Loss: 1.178472876548767, Accuracy: 0.64111328125\n",
      "Batch: 146, Loss: 1.209712028503418, Accuracy: 0.62255859375\n",
      "Batch: 147, Loss: 1.1826679706573486, Accuracy: 0.6337890625\n",
      "Batch: 148, Loss: 1.1676673889160156, Accuracy: 0.6279296875\n",
      "Batch: 149, Loss: 1.1210837364196777, Accuracy: 0.65673828125\n",
      "Batch: 150, Loss: 1.0116186141967773, Accuracy: 0.6865234375\n",
      "Batch: 151, Loss: 1.024572491645813, Accuracy: 0.66650390625\n",
      "Batch: 152, Loss: 1.0791794061660767, Accuracy: 0.654296875\n",
      "Batch: 153, Loss: 1.0455052852630615, Accuracy: 0.66943359375\n",
      "Batch: 154, Loss: 1.0743746757507324, Accuracy: 0.650390625\n",
      "Batch: 155, Loss: 1.1227030754089355, Accuracy: 0.64501953125\n",
      "Batch: 156, Loss: 1.0555729866027832, Accuracy: 0.66162109375\n",
      "Batch: 157, Loss: 1.06675124168396, Accuracy: 0.65966796875\n",
      "Batch: 158, Loss: 1.0594487190246582, Accuracy: 0.6572265625\n",
      "Batch: 159, Loss: 1.0244908332824707, Accuracy: 0.67626953125\n",
      "Batch: 160, Loss: 1.0929418802261353, Accuracy: 0.64306640625\n",
      "Batch: 161, Loss: 1.0935591459274292, Accuracy: 0.650390625\n",
      "Batch: 162, Loss: 1.1027305126190186, Accuracy: 0.6533203125\n",
      "Batch: 163, Loss: 1.1244465112686157, Accuracy: 0.64208984375\n",
      "Batch: 164, Loss: 1.170241355895996, Accuracy: 0.63037109375\n",
      "Batch: 165, Loss: 1.0881776809692383, Accuracy: 0.66064453125\n",
      "Batch: 166, Loss: 1.1446747779846191, Accuracy: 0.63720703125\n",
      "Batch: 167, Loss: 1.0589442253112793, Accuracy: 0.662109375\n",
      "Batch: 168, Loss: 1.0129568576812744, Accuracy: 0.68212890625\n",
      "Batch: 169, Loss: 1.082932949066162, Accuracy: 0.65478515625\n",
      "Batch: 170, Loss: 1.1705458164215088, Accuracy: 0.63623046875\n",
      "Batch: 171, Loss: 1.0967366695404053, Accuracy: 0.65380859375\n",
      "Batch: 172, Loss: 1.0836389064788818, Accuracy: 0.6484375\n",
      "Batch: 173, Loss: 1.1612814664840698, Accuracy: 0.6455078125\n",
      "Batch: 174, Loss: 0.980612576007843, Accuracy: 0.693359375\n",
      "Batch: 175, Loss: 1.1623220443725586, Accuracy: 0.62060546875\n",
      "Batch: 176, Loss: 1.2102303504943848, Accuracy: 0.62060546875\n",
      "Batch: 177, Loss: 1.1206862926483154, Accuracy: 0.6494140625\n",
      "Batch: 178, Loss: 1.077379584312439, Accuracy: 0.65283203125\n",
      "Batch: 179, Loss: 1.1196346282958984, Accuracy: 0.6328125\n",
      "Batch: 180, Loss: 1.2034375667572021, Accuracy: 0.61376953125\n",
      "Epoch 13/200\n",
      "Batch: 1, Loss: 1.6465611457824707, Accuracy: 0.56005859375\n",
      "Batch: 2, Loss: 1.1202850341796875, Accuracy: 0.6552734375\n",
      "Batch: 3, Loss: 1.1322333812713623, Accuracy: 0.65087890625\n",
      "Batch: 4, Loss: 1.1775331497192383, Accuracy: 0.63232421875\n",
      "Batch: 5, Loss: 1.1936373710632324, Accuracy: 0.62548828125\n",
      "Batch: 6, Loss: 1.1835556030273438, Accuracy: 0.63330078125\n",
      "Batch: 7, Loss: 1.0915749073028564, Accuracy: 0.64697265625\n",
      "Batch: 8, Loss: 1.1510893106460571, Accuracy: 0.623046875\n",
      "Batch: 9, Loss: 1.2076573371887207, Accuracy: 0.63427734375\n",
      "Batch: 10, Loss: 1.1742651462554932, Accuracy: 0.64501953125\n",
      "Batch: 11, Loss: 1.2090519666671753, Accuracy: 0.62548828125\n",
      "Batch: 12, Loss: 1.0861908197402954, Accuracy: 0.65380859375\n",
      "Batch: 13, Loss: 1.158084750175476, Accuracy: 0.62939453125\n",
      "Batch: 14, Loss: 1.1750167608261108, Accuracy: 0.63525390625\n",
      "Batch: 15, Loss: 1.1444636583328247, Accuracy: 0.6474609375\n",
      "Batch: 16, Loss: 1.2225730419158936, Accuracy: 0.61279296875\n",
      "Batch: 17, Loss: 1.1171255111694336, Accuracy: 0.64697265625\n",
      "Batch: 18, Loss: 1.1854420900344849, Accuracy: 0.62109375\n",
      "Batch: 19, Loss: 1.1800851821899414, Accuracy: 0.62646484375\n",
      "Batch: 20, Loss: 1.0950722694396973, Accuracy: 0.662109375\n",
      "Batch: 21, Loss: 1.2774326801300049, Accuracy: 0.60009765625\n",
      "Batch: 22, Loss: 1.1773133277893066, Accuracy: 0.62939453125\n",
      "Batch: 23, Loss: 1.106705665588379, Accuracy: 0.64794921875\n",
      "Batch: 24, Loss: 1.1372636556625366, Accuracy: 0.640625\n",
      "Batch: 25, Loss: 1.1147927045822144, Accuracy: 0.63916015625\n",
      "Batch: 26, Loss: 1.1549828052520752, Accuracy: 0.63720703125\n",
      "Batch: 27, Loss: 1.151742935180664, Accuracy: 0.6337890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 28, Loss: 1.0619854927062988, Accuracy: 0.66064453125\n",
      "Batch: 29, Loss: 1.1898068189620972, Accuracy: 0.62890625\n",
      "Batch: 30, Loss: 1.1465414762496948, Accuracy: 0.64111328125\n",
      "Batch: 31, Loss: 1.278505563735962, Accuracy: 0.599609375\n",
      "Batch: 32, Loss: 1.1986688375473022, Accuracy: 0.6123046875\n",
      "Batch: 33, Loss: 1.23114013671875, Accuracy: 0.6005859375\n",
      "Batch: 34, Loss: 1.2432057857513428, Accuracy: 0.6123046875\n",
      "Batch: 35, Loss: 1.2846568822860718, Accuracy: 0.59521484375\n",
      "Batch: 36, Loss: 1.232395887374878, Accuracy: 0.61669921875\n",
      "Batch: 37, Loss: 1.1770106554031372, Accuracy: 0.63671875\n",
      "Batch: 38, Loss: 1.2091494798660278, Accuracy: 0.60595703125\n",
      "Batch: 39, Loss: 1.1864919662475586, Accuracy: 0.64501953125\n",
      "Batch: 40, Loss: 1.2154550552368164, Accuracy: 0.61669921875\n",
      "Batch: 41, Loss: 1.2061514854431152, Accuracy: 0.6181640625\n",
      "Batch: 42, Loss: 1.131636381149292, Accuracy: 0.6328125\n",
      "Batch: 43, Loss: 1.1307530403137207, Accuracy: 0.654296875\n",
      "Batch: 44, Loss: 1.0475056171417236, Accuracy: 0.6708984375\n",
      "Batch: 45, Loss: 1.0943059921264648, Accuracy: 0.6484375\n",
      "Batch: 46, Loss: 1.0373802185058594, Accuracy: 0.65185546875\n",
      "Batch: 47, Loss: 1.1124879121780396, Accuracy: 0.63720703125\n",
      "Batch: 48, Loss: 1.0843586921691895, Accuracy: 0.646484375\n",
      "Batch: 49, Loss: 1.0856027603149414, Accuracy: 0.64892578125\n",
      "Batch: 50, Loss: 1.156280755996704, Accuracy: 0.62646484375\n",
      "Batch: 51, Loss: 1.129036784172058, Accuracy: 0.634765625\n",
      "Batch: 52, Loss: 1.0837619304656982, Accuracy: 0.640625\n",
      "Batch: 53, Loss: 1.0836445093154907, Accuracy: 0.65478515625\n",
      "Batch: 54, Loss: 1.1192889213562012, Accuracy: 0.63427734375\n",
      "Batch: 55, Loss: 1.0930202007293701, Accuracy: 0.6552734375\n",
      "Batch: 56, Loss: 1.091508388519287, Accuracy: 0.64794921875\n",
      "Batch: 57, Loss: 1.1732995510101318, Accuracy: 0.63330078125\n",
      "Batch: 58, Loss: 1.1494686603546143, Accuracy: 0.62890625\n",
      "Batch: 59, Loss: 1.2811574935913086, Accuracy: 0.59912109375\n",
      "Batch: 60, Loss: 1.1414092779159546, Accuracy: 0.63916015625\n",
      "Batch: 61, Loss: 1.042837381362915, Accuracy: 0.66650390625\n",
      "Batch: 62, Loss: 1.0698322057724, Accuracy: 0.6533203125\n",
      "Batch: 63, Loss: 1.1264233589172363, Accuracy: 0.62451171875\n",
      "Batch: 64, Loss: 1.1300692558288574, Accuracy: 0.63427734375\n",
      "Batch: 65, Loss: 1.1992557048797607, Accuracy: 0.62060546875\n",
      "Batch: 66, Loss: 1.1568320989608765, Accuracy: 0.63330078125\n",
      "Batch: 67, Loss: 1.1584535837173462, Accuracy: 0.6328125\n",
      "Batch: 68, Loss: 1.0630695819854736, Accuracy: 0.6533203125\n",
      "Batch: 69, Loss: 1.162031888961792, Accuracy: 0.61572265625\n",
      "Batch: 70, Loss: 1.1743162870407104, Accuracy: 0.6337890625\n",
      "Batch: 71, Loss: 1.1393165588378906, Accuracy: 0.62744140625\n",
      "Batch: 72, Loss: 1.1564464569091797, Accuracy: 0.6240234375\n",
      "Batch: 73, Loss: 1.22096586227417, Accuracy: 0.60498046875\n",
      "Batch: 74, Loss: 1.210099697113037, Accuracy: 0.61083984375\n",
      "Batch: 75, Loss: 1.1330952644348145, Accuracy: 0.63818359375\n",
      "Batch: 76, Loss: 1.1265015602111816, Accuracy: 0.63818359375\n",
      "Batch: 77, Loss: 1.0771284103393555, Accuracy: 0.658203125\n",
      "Batch: 78, Loss: 1.1078269481658936, Accuracy: 0.66064453125\n",
      "Batch: 79, Loss: 1.1441762447357178, Accuracy: 0.64501953125\n",
      "Batch: 80, Loss: 1.1220414638519287, Accuracy: 0.6435546875\n",
      "Batch: 81, Loss: 1.187835454940796, Accuracy: 0.63232421875\n",
      "Batch: 82, Loss: 1.0536928176879883, Accuracy: 0.650390625\n",
      "Batch: 83, Loss: 1.0645158290863037, Accuracy: 0.64306640625\n",
      "Batch: 84, Loss: 1.0557713508605957, Accuracy: 0.66162109375\n",
      "Batch: 85, Loss: 1.0266053676605225, Accuracy: 0.66064453125\n",
      "Batch: 86, Loss: 1.2581257820129395, Accuracy: 0.60791015625\n",
      "Batch: 87, Loss: 1.147322177886963, Accuracy: 0.63427734375\n",
      "Batch: 88, Loss: 1.1963376998901367, Accuracy: 0.6142578125\n",
      "Batch: 89, Loss: 1.1645684242248535, Accuracy: 0.6298828125\n",
      "Batch: 90, Loss: 1.211531162261963, Accuracy: 0.60888671875\n",
      "Batch: 91, Loss: 1.0749390125274658, Accuracy: 0.6533203125\n",
      "Batch: 92, Loss: 1.220031976699829, Accuracy: 0.6171875\n",
      "Batch: 93, Loss: 1.1549687385559082, Accuracy: 0.6240234375\n",
      "Batch: 94, Loss: 1.2359486818313599, Accuracy: 0.62451171875\n",
      "Batch: 95, Loss: 1.248056173324585, Accuracy: 0.6103515625\n",
      "Batch: 96, Loss: 1.150147557258606, Accuracy: 0.64404296875\n",
      "Batch: 97, Loss: 1.1475684642791748, Accuracy: 0.65185546875\n",
      "Batch: 98, Loss: 1.276529312133789, Accuracy: 0.60107421875\n",
      "Batch: 99, Loss: 1.0960710048675537, Accuracy: 0.6552734375\n",
      "Batch: 100, Loss: 1.2476532459259033, Accuracy: 0.61279296875\n",
      "Batch: 101, Loss: 1.2425172328948975, Accuracy: 0.6279296875\n",
      "Batch: 102, Loss: 1.1082723140716553, Accuracy: 0.6435546875\n",
      "Batch: 103, Loss: 1.1415915489196777, Accuracy: 0.64404296875\n",
      "Batch: 104, Loss: 1.1454557180404663, Accuracy: 0.63623046875\n",
      "Batch: 105, Loss: 1.233182668685913, Accuracy: 0.611328125\n",
      "Batch: 106, Loss: 1.2073194980621338, Accuracy: 0.61376953125\n",
      "Batch: 107, Loss: 1.2261992692947388, Accuracy: 0.62744140625\n",
      "Batch: 108, Loss: 1.1947110891342163, Accuracy: 0.63232421875\n",
      "Batch: 109, Loss: 1.1674938201904297, Accuracy: 0.62939453125\n",
      "Batch: 110, Loss: 1.111311674118042, Accuracy: 0.64453125\n",
      "Batch: 111, Loss: 1.0470340251922607, Accuracy: 0.6591796875\n",
      "Batch: 112, Loss: 1.1823246479034424, Accuracy: 0.63818359375\n",
      "Batch: 113, Loss: 1.1783268451690674, Accuracy: 0.626953125\n",
      "Batch: 114, Loss: 1.1347638368606567, Accuracy: 0.640625\n",
      "Batch: 115, Loss: 1.156931757926941, Accuracy: 0.6279296875\n",
      "Batch: 116, Loss: 1.1434797048568726, Accuracy: 0.6357421875\n",
      "Batch: 117, Loss: 1.1272330284118652, Accuracy: 0.63330078125\n",
      "Batch: 118, Loss: 1.1276342868804932, Accuracy: 0.6376953125\n",
      "Batch: 119, Loss: 1.1187307834625244, Accuracy: 0.6240234375\n",
      "Batch: 120, Loss: 1.1325291395187378, Accuracy: 0.623046875\n",
      "Batch: 121, Loss: 1.1272104978561401, Accuracy: 0.6396484375\n",
      "Batch: 122, Loss: 1.1023364067077637, Accuracy: 0.642578125\n",
      "Batch: 123, Loss: 1.1393623352050781, Accuracy: 0.640625\n",
      "Batch: 124, Loss: 1.0943305492401123, Accuracy: 0.6494140625\n",
      "Batch: 125, Loss: 1.1477251052856445, Accuracy: 0.623046875\n",
      "Batch: 126, Loss: 1.0726817846298218, Accuracy: 0.65576171875\n",
      "Batch: 127, Loss: 1.0831449031829834, Accuracy: 0.65478515625\n",
      "Batch: 128, Loss: 1.2953484058380127, Accuracy: 0.6103515625\n",
      "Batch: 129, Loss: 1.2964439392089844, Accuracy: 0.60693359375\n",
      "Batch: 130, Loss: 1.2704230546951294, Accuracy: 0.60009765625\n",
      "Batch: 131, Loss: 1.2137713432312012, Accuracy: 0.623046875\n",
      "Batch: 132, Loss: 1.0678889751434326, Accuracy: 0.65673828125\n",
      "Batch: 133, Loss: 1.0721213817596436, Accuracy: 0.6689453125\n",
      "Batch: 134, Loss: 1.195846438407898, Accuracy: 0.62109375\n",
      "Batch: 135, Loss: 1.198774814605713, Accuracy: 0.62353515625\n",
      "Batch: 136, Loss: 1.0992926359176636, Accuracy: 0.640625\n",
      "Batch: 137, Loss: 1.173607349395752, Accuracy: 0.6376953125\n",
      "Batch: 138, Loss: 1.0248782634735107, Accuracy: 0.68017578125\n",
      "Batch: 139, Loss: 1.1271255016326904, Accuracy: 0.646484375\n",
      "Batch: 140, Loss: 1.068755030632019, Accuracy: 0.65869140625\n",
      "Batch: 141, Loss: 1.1810944080352783, Accuracy: 0.61962890625\n",
      "Batch: 142, Loss: 1.0708926916122437, Accuracy: 0.650390625\n",
      "Batch: 143, Loss: 1.1331908702850342, Accuracy: 0.6455078125\n",
      "Batch: 144, Loss: 1.1657357215881348, Accuracy: 0.6435546875\n",
      "Batch: 145, Loss: 1.1454060077667236, Accuracy: 0.64453125\n",
      "Batch: 146, Loss: 1.1950771808624268, Accuracy: 0.62548828125\n",
      "Batch: 147, Loss: 1.1464102268218994, Accuracy: 0.63427734375\n",
      "Batch: 148, Loss: 1.1405091285705566, Accuracy: 0.6318359375\n",
      "Batch: 149, Loss: 1.0860618352890015, Accuracy: 0.6552734375\n",
      "Batch: 150, Loss: 0.9916934370994568, Accuracy: 0.68603515625\n",
      "Batch: 151, Loss: 0.9920182228088379, Accuracy: 0.6748046875\n",
      "Batch: 152, Loss: 1.0529778003692627, Accuracy: 0.658203125\n",
      "Batch: 153, Loss: 1.0336729288101196, Accuracy: 0.66064453125\n",
      "Batch: 154, Loss: 1.0505237579345703, Accuracy: 0.65576171875\n",
      "Batch: 155, Loss: 1.113396406173706, Accuracy: 0.64453125\n",
      "Batch: 156, Loss: 1.0357413291931152, Accuracy: 0.66796875\n",
      "Batch: 157, Loss: 1.0411527156829834, Accuracy: 0.658203125\n",
      "Batch: 158, Loss: 1.0661988258361816, Accuracy: 0.669921875\n",
      "Batch: 159, Loss: 1.0017280578613281, Accuracy: 0.6728515625\n",
      "Batch: 160, Loss: 1.0697181224822998, Accuracy: 0.6494140625\n",
      "Batch: 161, Loss: 1.0741996765136719, Accuracy: 0.65234375\n",
      "Batch: 162, Loss: 1.077018141746521, Accuracy: 0.662109375\n",
      "Batch: 163, Loss: 1.1127471923828125, Accuracy: 0.64501953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 164, Loss: 1.1573607921600342, Accuracy: 0.6357421875\n",
      "Batch: 165, Loss: 1.0544989109039307, Accuracy: 0.66845703125\n",
      "Batch: 166, Loss: 1.1278234720230103, Accuracy: 0.642578125\n",
      "Batch: 167, Loss: 1.0290908813476562, Accuracy: 0.67333984375\n",
      "Batch: 168, Loss: 1.0039825439453125, Accuracy: 0.67431640625\n",
      "Batch: 169, Loss: 1.0584096908569336, Accuracy: 0.6484375\n",
      "Batch: 170, Loss: 1.1546006202697754, Accuracy: 0.646484375\n",
      "Batch: 171, Loss: 1.060500144958496, Accuracy: 0.6640625\n",
      "Batch: 172, Loss: 1.0545237064361572, Accuracy: 0.66357421875\n",
      "Batch: 173, Loss: 1.1395691633224487, Accuracy: 0.64013671875\n",
      "Batch: 174, Loss: 0.9567191004753113, Accuracy: 0.697265625\n",
      "Batch: 175, Loss: 1.1437047719955444, Accuracy: 0.62841796875\n",
      "Batch: 176, Loss: 1.1897379159927368, Accuracy: 0.6279296875\n",
      "Batch: 177, Loss: 1.084460735321045, Accuracy: 0.65771484375\n",
      "Batch: 178, Loss: 1.045586347579956, Accuracy: 0.66357421875\n",
      "Batch: 179, Loss: 1.082000970840454, Accuracy: 0.64501953125\n",
      "Batch: 180, Loss: 1.1823015213012695, Accuracy: 0.623046875\n",
      "Epoch 14/200\n",
      "Batch: 1, Loss: 1.5879336595535278, Accuracy: 0.56884765625\n",
      "Batch: 2, Loss: 1.0968585014343262, Accuracy: 0.64794921875\n",
      "Batch: 3, Loss: 1.1058440208435059, Accuracy: 0.658203125\n",
      "Batch: 4, Loss: 1.1437739133834839, Accuracy: 0.64111328125\n",
      "Batch: 5, Loss: 1.1604267358779907, Accuracy: 0.62890625\n",
      "Batch: 6, Loss: 1.1780221462249756, Accuracy: 0.62451171875\n",
      "Batch: 7, Loss: 1.067589282989502, Accuracy: 0.65576171875\n",
      "Batch: 8, Loss: 1.1136579513549805, Accuracy: 0.646484375\n",
      "Batch: 9, Loss: 1.1924413442611694, Accuracy: 0.63818359375\n",
      "Batch: 10, Loss: 1.153990387916565, Accuracy: 0.64208984375\n",
      "Batch: 11, Loss: 1.1832396984100342, Accuracy: 0.6328125\n",
      "Batch: 12, Loss: 1.0717875957489014, Accuracy: 0.65087890625\n",
      "Batch: 13, Loss: 1.119707703590393, Accuracy: 0.63134765625\n",
      "Batch: 14, Loss: 1.1417534351348877, Accuracy: 0.6474609375\n",
      "Batch: 15, Loss: 1.1157389879226685, Accuracy: 0.650390625\n",
      "Batch: 16, Loss: 1.1885854005813599, Accuracy: 0.63427734375\n",
      "Batch: 17, Loss: 1.095973253250122, Accuracy: 0.65673828125\n",
      "Batch: 18, Loss: 1.160752296447754, Accuracy: 0.62744140625\n",
      "Batch: 19, Loss: 1.163055181503296, Accuracy: 0.646484375\n",
      "Batch: 20, Loss: 1.0530521869659424, Accuracy: 0.66748046875\n",
      "Batch: 21, Loss: 1.2572755813598633, Accuracy: 0.607421875\n",
      "Batch: 22, Loss: 1.1415711641311646, Accuracy: 0.63525390625\n",
      "Batch: 23, Loss: 1.0689880847930908, Accuracy: 0.66552734375\n",
      "Batch: 24, Loss: 1.1033964157104492, Accuracy: 0.6435546875\n",
      "Batch: 25, Loss: 1.0790107250213623, Accuracy: 0.65576171875\n",
      "Batch: 26, Loss: 1.0960662364959717, Accuracy: 0.6640625\n",
      "Batch: 27, Loss: 1.1211929321289062, Accuracy: 0.64892578125\n",
      "Batch: 28, Loss: 1.0562968254089355, Accuracy: 0.6572265625\n",
      "Batch: 29, Loss: 1.1628665924072266, Accuracy: 0.62841796875\n",
      "Batch: 30, Loss: 1.111696481704712, Accuracy: 0.65185546875\n",
      "Batch: 31, Loss: 1.2617144584655762, Accuracy: 0.61083984375\n",
      "Batch: 32, Loss: 1.177290916442871, Accuracy: 0.62060546875\n",
      "Batch: 33, Loss: 1.1981998682022095, Accuracy: 0.62353515625\n",
      "Batch: 34, Loss: 1.218381643295288, Accuracy: 0.619140625\n",
      "Batch: 35, Loss: 1.2650220394134521, Accuracy: 0.595703125\n",
      "Batch: 36, Loss: 1.1948120594024658, Accuracy: 0.6259765625\n",
      "Batch: 37, Loss: 1.1473588943481445, Accuracy: 0.63720703125\n",
      "Batch: 38, Loss: 1.2024846076965332, Accuracy: 0.61083984375\n",
      "Batch: 39, Loss: 1.1440588235855103, Accuracy: 0.6484375\n",
      "Batch: 40, Loss: 1.1929771900177002, Accuracy: 0.63134765625\n",
      "Batch: 41, Loss: 1.172398328781128, Accuracy: 0.62158203125\n",
      "Batch: 42, Loss: 1.100722312927246, Accuracy: 0.63623046875\n",
      "Batch: 43, Loss: 1.082390308380127, Accuracy: 0.666015625\n",
      "Batch: 44, Loss: 1.017898678779602, Accuracy: 0.6826171875\n",
      "Batch: 45, Loss: 1.058985948562622, Accuracy: 0.66064453125\n",
      "Batch: 46, Loss: 1.0221431255340576, Accuracy: 0.65234375\n",
      "Batch: 47, Loss: 1.09401535987854, Accuracy: 0.6435546875\n",
      "Batch: 48, Loss: 1.0768927335739136, Accuracy: 0.65087890625\n",
      "Batch: 49, Loss: 1.0796194076538086, Accuracy: 0.63818359375\n",
      "Batch: 50, Loss: 1.126826524734497, Accuracy: 0.64013671875\n",
      "Batch: 51, Loss: 1.0892552137374878, Accuracy: 0.65185546875\n",
      "Batch: 52, Loss: 1.0518112182617188, Accuracy: 0.66455078125\n",
      "Batch: 53, Loss: 1.0492205619812012, Accuracy: 0.65576171875\n",
      "Batch: 54, Loss: 1.09377121925354, Accuracy: 0.6337890625\n",
      "Batch: 55, Loss: 1.0686125755310059, Accuracy: 0.662109375\n",
      "Batch: 56, Loss: 1.0734107494354248, Accuracy: 0.65380859375\n",
      "Batch: 57, Loss: 1.1559207439422607, Accuracy: 0.6376953125\n",
      "Batch: 58, Loss: 1.1372041702270508, Accuracy: 0.6259765625\n",
      "Batch: 59, Loss: 1.2482824325561523, Accuracy: 0.61279296875\n",
      "Batch: 60, Loss: 1.1132700443267822, Accuracy: 0.64306640625\n",
      "Batch: 61, Loss: 1.010267734527588, Accuracy: 0.66943359375\n",
      "Batch: 62, Loss: 1.0601071119308472, Accuracy: 0.662109375\n",
      "Batch: 63, Loss: 1.0935852527618408, Accuracy: 0.6416015625\n",
      "Batch: 64, Loss: 1.0886425971984863, Accuracy: 0.6494140625\n",
      "Batch: 65, Loss: 1.1697289943695068, Accuracy: 0.63671875\n",
      "Batch: 66, Loss: 1.1135270595550537, Accuracy: 0.642578125\n",
      "Batch: 67, Loss: 1.1313679218292236, Accuracy: 0.6474609375\n",
      "Batch: 68, Loss: 1.0337616205215454, Accuracy: 0.66455078125\n",
      "Batch: 69, Loss: 1.131111741065979, Accuracy: 0.62841796875\n",
      "Batch: 70, Loss: 1.1417226791381836, Accuracy: 0.62353515625\n",
      "Batch: 71, Loss: 1.1012885570526123, Accuracy: 0.63623046875\n",
      "Batch: 72, Loss: 1.1387096643447876, Accuracy: 0.6328125\n",
      "Batch: 73, Loss: 1.1708002090454102, Accuracy: 0.62890625\n",
      "Batch: 74, Loss: 1.1625481843948364, Accuracy: 0.63525390625\n",
      "Batch: 75, Loss: 1.0951905250549316, Accuracy: 0.6396484375\n",
      "Batch: 76, Loss: 1.088737964630127, Accuracy: 0.64599609375\n",
      "Batch: 77, Loss: 1.0536630153656006, Accuracy: 0.66357421875\n",
      "Batch: 78, Loss: 1.0874578952789307, Accuracy: 0.66455078125\n",
      "Batch: 79, Loss: 1.127903699874878, Accuracy: 0.64013671875\n",
      "Batch: 80, Loss: 1.1038451194763184, Accuracy: 0.64208984375\n",
      "Batch: 81, Loss: 1.1539103984832764, Accuracy: 0.64794921875\n",
      "Batch: 82, Loss: 1.02272629737854, Accuracy: 0.65625\n",
      "Batch: 83, Loss: 1.041578769683838, Accuracy: 0.66162109375\n",
      "Batch: 84, Loss: 1.0284732580184937, Accuracy: 0.66552734375\n",
      "Batch: 85, Loss: 0.9988976120948792, Accuracy: 0.67041015625\n",
      "Batch: 86, Loss: 1.2067556381225586, Accuracy: 0.6171875\n",
      "Batch: 87, Loss: 1.1204235553741455, Accuracy: 0.64208984375\n",
      "Batch: 88, Loss: 1.1616566181182861, Accuracy: 0.63623046875\n",
      "Batch: 89, Loss: 1.1461982727050781, Accuracy: 0.6435546875\n",
      "Batch: 90, Loss: 1.1858108043670654, Accuracy: 0.609375\n",
      "Batch: 91, Loss: 1.0423790216445923, Accuracy: 0.6669921875\n",
      "Batch: 92, Loss: 1.228514313697815, Accuracy: 0.61328125\n",
      "Batch: 93, Loss: 1.149430513381958, Accuracy: 0.63232421875\n",
      "Batch: 94, Loss: 1.203383445739746, Accuracy: 0.630859375\n",
      "Batch: 95, Loss: 1.2085936069488525, Accuracy: 0.6201171875\n",
      "Batch: 96, Loss: 1.1291460990905762, Accuracy: 0.65478515625\n",
      "Batch: 97, Loss: 1.1104156970977783, Accuracy: 0.6650390625\n",
      "Batch: 98, Loss: 1.2164819240570068, Accuracy: 0.619140625\n",
      "Batch: 99, Loss: 1.083813190460205, Accuracy: 0.66455078125\n",
      "Batch: 100, Loss: 1.1998456716537476, Accuracy: 0.6259765625\n",
      "Batch: 101, Loss: 1.2030425071716309, Accuracy: 0.62109375\n",
      "Batch: 102, Loss: 1.083485722541809, Accuracy: 0.64453125\n",
      "Batch: 103, Loss: 1.1257402896881104, Accuracy: 0.62744140625\n",
      "Batch: 104, Loss: 1.1273170709609985, Accuracy: 0.6396484375\n",
      "Batch: 105, Loss: 1.1966629028320312, Accuracy: 0.61865234375\n",
      "Batch: 106, Loss: 1.1817705631256104, Accuracy: 0.61474609375\n",
      "Batch: 107, Loss: 1.2055045366287231, Accuracy: 0.62548828125\n",
      "Batch: 108, Loss: 1.144607424736023, Accuracy: 0.63427734375\n",
      "Batch: 109, Loss: 1.1366851329803467, Accuracy: 0.63720703125\n",
      "Batch: 110, Loss: 1.0727660655975342, Accuracy: 0.64794921875\n",
      "Batch: 111, Loss: 1.0036592483520508, Accuracy: 0.67138671875\n",
      "Batch: 112, Loss: 1.1261366605758667, Accuracy: 0.6533203125\n",
      "Batch: 113, Loss: 1.166579246520996, Accuracy: 0.62939453125\n",
      "Batch: 114, Loss: 1.099442481994629, Accuracy: 0.642578125\n",
      "Batch: 115, Loss: 1.1459617614746094, Accuracy: 0.642578125\n",
      "Batch: 116, Loss: 1.125828504562378, Accuracy: 0.64990234375\n",
      "Batch: 117, Loss: 1.1131536960601807, Accuracy: 0.63818359375\n",
      "Batch: 118, Loss: 1.091304063796997, Accuracy: 0.65283203125\n",
      "Batch: 119, Loss: 1.0841901302337646, Accuracy: 0.630859375\n",
      "Batch: 120, Loss: 1.0978944301605225, Accuracy: 0.64208984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 121, Loss: 1.0988397598266602, Accuracy: 0.6337890625\n",
      "Batch: 122, Loss: 1.0718393325805664, Accuracy: 0.6591796875\n",
      "Batch: 123, Loss: 1.1062968969345093, Accuracy: 0.6552734375\n",
      "Batch: 124, Loss: 1.0651861429214478, Accuracy: 0.65966796875\n",
      "Batch: 125, Loss: 1.124251127243042, Accuracy: 0.6376953125\n",
      "Batch: 126, Loss: 1.0414514541625977, Accuracy: 0.67041015625\n",
      "Batch: 127, Loss: 1.0596946477890015, Accuracy: 0.6572265625\n",
      "Batch: 128, Loss: 1.2362546920776367, Accuracy: 0.609375\n",
      "Batch: 129, Loss: 1.2500090599060059, Accuracy: 0.61181640625\n",
      "Batch: 130, Loss: 1.2410688400268555, Accuracy: 0.61328125\n",
      "Batch: 131, Loss: 1.1810622215270996, Accuracy: 0.62841796875\n",
      "Batch: 132, Loss: 1.036954402923584, Accuracy: 0.669921875\n",
      "Batch: 133, Loss: 1.0522913932800293, Accuracy: 0.67626953125\n",
      "Batch: 134, Loss: 1.1754026412963867, Accuracy: 0.6328125\n",
      "Batch: 135, Loss: 1.1584525108337402, Accuracy: 0.63330078125\n",
      "Batch: 136, Loss: 1.080289363861084, Accuracy: 0.6435546875\n",
      "Batch: 137, Loss: 1.1379354000091553, Accuracy: 0.6455078125\n",
      "Batch: 138, Loss: 1.0100537538528442, Accuracy: 0.6845703125\n",
      "Batch: 139, Loss: 1.1014134883880615, Accuracy: 0.658203125\n",
      "Batch: 140, Loss: 1.049243450164795, Accuracy: 0.66015625\n",
      "Batch: 141, Loss: 1.1486778259277344, Accuracy: 0.634765625\n",
      "Batch: 142, Loss: 1.0277717113494873, Accuracy: 0.66162109375\n",
      "Batch: 143, Loss: 1.0962917804718018, Accuracy: 0.65234375\n",
      "Batch: 144, Loss: 1.1521012783050537, Accuracy: 0.65478515625\n",
      "Batch: 145, Loss: 1.1318711042404175, Accuracy: 0.6455078125\n",
      "Batch: 146, Loss: 1.1617698669433594, Accuracy: 0.63232421875\n",
      "Batch: 147, Loss: 1.1365896463394165, Accuracy: 0.63818359375\n",
      "Batch: 148, Loss: 1.1072379350662231, Accuracy: 0.63232421875\n",
      "Batch: 149, Loss: 1.0770082473754883, Accuracy: 0.65380859375\n",
      "Batch: 150, Loss: 0.9513614773750305, Accuracy: 0.6904296875\n",
      "Batch: 151, Loss: 0.9724912643432617, Accuracy: 0.67919921875\n",
      "Batch: 152, Loss: 1.032971978187561, Accuracy: 0.669921875\n",
      "Batch: 153, Loss: 1.00254487991333, Accuracy: 0.673828125\n",
      "Batch: 154, Loss: 1.0193259716033936, Accuracy: 0.67138671875\n",
      "Batch: 155, Loss: 1.0889161825180054, Accuracy: 0.65771484375\n",
      "Batch: 156, Loss: 0.9983104467391968, Accuracy: 0.6845703125\n",
      "Batch: 157, Loss: 1.0114729404449463, Accuracy: 0.66943359375\n",
      "Batch: 158, Loss: 1.0118522644042969, Accuracy: 0.67822265625\n",
      "Batch: 159, Loss: 0.995070219039917, Accuracy: 0.6806640625\n",
      "Batch: 160, Loss: 1.0448644161224365, Accuracy: 0.65771484375\n",
      "Batch: 161, Loss: 1.0495054721832275, Accuracy: 0.66552734375\n",
      "Batch: 162, Loss: 1.0534324645996094, Accuracy: 0.67529296875\n",
      "Batch: 163, Loss: 1.096834659576416, Accuracy: 0.640625\n",
      "Batch: 164, Loss: 1.1362595558166504, Accuracy: 0.6337890625\n",
      "Batch: 165, Loss: 1.061972737312317, Accuracy: 0.6669921875\n",
      "Batch: 166, Loss: 1.1118645668029785, Accuracy: 0.6484375\n",
      "Batch: 167, Loss: 1.0112013816833496, Accuracy: 0.6748046875\n",
      "Batch: 168, Loss: 0.9830847382545471, Accuracy: 0.67626953125\n",
      "Batch: 169, Loss: 1.0500115156173706, Accuracy: 0.66015625\n",
      "Batch: 170, Loss: 1.1254100799560547, Accuracy: 0.650390625\n",
      "Batch: 171, Loss: 1.0694581270217896, Accuracy: 0.65185546875\n",
      "Batch: 172, Loss: 1.023640513420105, Accuracy: 0.66748046875\n",
      "Batch: 173, Loss: 1.1165568828582764, Accuracy: 0.65771484375\n",
      "Batch: 174, Loss: 0.9383771419525146, Accuracy: 0.708984375\n",
      "Batch: 175, Loss: 1.1227697134017944, Accuracy: 0.6376953125\n",
      "Batch: 176, Loss: 1.1747539043426514, Accuracy: 0.63623046875\n",
      "Batch: 177, Loss: 1.0736392736434937, Accuracy: 0.6552734375\n",
      "Batch: 178, Loss: 1.0244617462158203, Accuracy: 0.666015625\n",
      "Batch: 179, Loss: 1.0704345703125, Accuracy: 0.6484375\n",
      "Batch: 180, Loss: 1.1500563621520996, Accuracy: 0.63525390625\n",
      "Epoch 15/200\n",
      "Batch: 1, Loss: 1.5505690574645996, Accuracy: 0.5751953125\n",
      "Batch: 2, Loss: 1.0682706832885742, Accuracy: 0.65625\n",
      "Batch: 3, Loss: 1.0692466497421265, Accuracy: 0.658203125\n",
      "Batch: 4, Loss: 1.1180241107940674, Accuracy: 0.65380859375\n",
      "Batch: 5, Loss: 1.1336570978164673, Accuracy: 0.64111328125\n",
      "Batch: 6, Loss: 1.1374478340148926, Accuracy: 0.64794921875\n",
      "Batch: 7, Loss: 1.0394840240478516, Accuracy: 0.671875\n",
      "Batch: 8, Loss: 1.1066327095031738, Accuracy: 0.638671875\n",
      "Batch: 9, Loss: 1.1457996368408203, Accuracy: 0.64794921875\n",
      "Batch: 10, Loss: 1.1149250268936157, Accuracy: 0.65478515625\n",
      "Batch: 11, Loss: 1.1624701023101807, Accuracy: 0.63720703125\n",
      "Batch: 12, Loss: 1.0490822792053223, Accuracy: 0.66943359375\n",
      "Batch: 13, Loss: 1.0954771041870117, Accuracy: 0.63720703125\n",
      "Batch: 14, Loss: 1.1193170547485352, Accuracy: 0.64697265625\n",
      "Batch: 15, Loss: 1.1090625524520874, Accuracy: 0.65771484375\n",
      "Batch: 16, Loss: 1.1630449295043945, Accuracy: 0.63818359375\n",
      "Batch: 17, Loss: 1.0758311748504639, Accuracy: 0.66015625\n",
      "Batch: 18, Loss: 1.1301274299621582, Accuracy: 0.634765625\n",
      "Batch: 19, Loss: 1.1393451690673828, Accuracy: 0.64599609375\n",
      "Batch: 20, Loss: 1.0608752965927124, Accuracy: 0.66748046875\n",
      "Batch: 21, Loss: 1.2238918542861938, Accuracy: 0.61669921875\n",
      "Batch: 22, Loss: 1.1075395345687866, Accuracy: 0.64453125\n",
      "Batch: 23, Loss: 1.0388920307159424, Accuracy: 0.6669921875\n",
      "Batch: 24, Loss: 1.0866248607635498, Accuracy: 0.64697265625\n",
      "Batch: 25, Loss: 1.0802054405212402, Accuracy: 0.6533203125\n",
      "Batch: 26, Loss: 1.0969271659851074, Accuracy: 0.66162109375\n",
      "Batch: 27, Loss: 1.0926830768585205, Accuracy: 0.65380859375\n",
      "Batch: 28, Loss: 1.0349501371383667, Accuracy: 0.6630859375\n",
      "Batch: 29, Loss: 1.1411082744598389, Accuracy: 0.63720703125\n",
      "Batch: 30, Loss: 1.087822437286377, Accuracy: 0.6552734375\n",
      "Batch: 31, Loss: 1.239795446395874, Accuracy: 0.603515625\n",
      "Batch: 32, Loss: 1.1419563293457031, Accuracy: 0.646484375\n",
      "Batch: 33, Loss: 1.188273549079895, Accuracy: 0.6220703125\n",
      "Batch: 34, Loss: 1.202842116355896, Accuracy: 0.62939453125\n",
      "Batch: 35, Loss: 1.2126426696777344, Accuracy: 0.62353515625\n",
      "Batch: 36, Loss: 1.1634721755981445, Accuracy: 0.6328125\n",
      "Batch: 37, Loss: 1.1249910593032837, Accuracy: 0.64697265625\n",
      "Batch: 38, Loss: 1.1819700002670288, Accuracy: 0.615234375\n",
      "Batch: 39, Loss: 1.1207114458084106, Accuracy: 0.66064453125\n",
      "Batch: 40, Loss: 1.1695449352264404, Accuracy: 0.6357421875\n",
      "Batch: 41, Loss: 1.1338355541229248, Accuracy: 0.63671875\n",
      "Batch: 42, Loss: 1.072856068611145, Accuracy: 0.63525390625\n",
      "Batch: 43, Loss: 1.058197259902954, Accuracy: 0.67724609375\n",
      "Batch: 44, Loss: 1.0084871053695679, Accuracy: 0.67822265625\n",
      "Batch: 45, Loss: 1.0400294065475464, Accuracy: 0.6650390625\n",
      "Batch: 46, Loss: 1.0000791549682617, Accuracy: 0.66015625\n",
      "Batch: 47, Loss: 1.0743522644042969, Accuracy: 0.64697265625\n",
      "Batch: 48, Loss: 1.0201064348220825, Accuracy: 0.673828125\n",
      "Batch: 49, Loss: 1.0482795238494873, Accuracy: 0.66845703125\n",
      "Batch: 50, Loss: 1.1107014417648315, Accuracy: 0.64892578125\n",
      "Batch: 51, Loss: 1.0616862773895264, Accuracy: 0.65576171875\n",
      "Batch: 52, Loss: 1.0272338390350342, Accuracy: 0.65625\n",
      "Batch: 53, Loss: 1.0121650695800781, Accuracy: 0.671875\n",
      "Batch: 54, Loss: 1.0687543153762817, Accuracy: 0.64111328125\n",
      "Batch: 55, Loss: 1.0359070301055908, Accuracy: 0.67431640625\n",
      "Batch: 56, Loss: 1.0409104824066162, Accuracy: 0.66357421875\n",
      "Batch: 57, Loss: 1.1380066871643066, Accuracy: 0.63916015625\n",
      "Batch: 58, Loss: 1.1078743934631348, Accuracy: 0.63330078125\n",
      "Batch: 59, Loss: 1.2062764167785645, Accuracy: 0.6240234375\n",
      "Batch: 60, Loss: 1.0896711349487305, Accuracy: 0.64599609375\n",
      "Batch: 61, Loss: 1.0089826583862305, Accuracy: 0.68115234375\n",
      "Batch: 62, Loss: 1.0330393314361572, Accuracy: 0.67626953125\n",
      "Batch: 63, Loss: 1.073844313621521, Accuracy: 0.6513671875\n",
      "Batch: 64, Loss: 1.0812515020370483, Accuracy: 0.64306640625\n",
      "Batch: 65, Loss: 1.1407248973846436, Accuracy: 0.64111328125\n",
      "Batch: 66, Loss: 1.090428352355957, Accuracy: 0.646484375\n",
      "Batch: 67, Loss: 1.1122684478759766, Accuracy: 0.6494140625\n",
      "Batch: 68, Loss: 1.0150920152664185, Accuracy: 0.669921875\n",
      "Batch: 69, Loss: 1.0946900844573975, Accuracy: 0.623046875\n",
      "Batch: 70, Loss: 1.101264238357544, Accuracy: 0.646484375\n",
      "Batch: 71, Loss: 1.0812227725982666, Accuracy: 0.642578125\n",
      "Batch: 72, Loss: 1.1139206886291504, Accuracy: 0.62548828125\n",
      "Batch: 73, Loss: 1.1467225551605225, Accuracy: 0.62890625\n",
      "Batch: 74, Loss: 1.155012845993042, Accuracy: 0.63623046875\n",
      "Batch: 75, Loss: 1.0713220834732056, Accuracy: 0.6591796875\n",
      "Batch: 76, Loss: 1.0486000776290894, Accuracy: 0.658203125\n",
      "Batch: 77, Loss: 1.033806324005127, Accuracy: 0.6640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 78, Loss: 1.0678775310516357, Accuracy: 0.65478515625\n",
      "Batch: 79, Loss: 1.1110783815383911, Accuracy: 0.64697265625\n",
      "Batch: 80, Loss: 1.0676047801971436, Accuracy: 0.6396484375\n",
      "Batch: 81, Loss: 1.1288050413131714, Accuracy: 0.65283203125\n",
      "Batch: 82, Loss: 1.0173810720443726, Accuracy: 0.658203125\n",
      "Batch: 83, Loss: 1.0120518207550049, Accuracy: 0.6728515625\n",
      "Batch: 84, Loss: 1.0146114826202393, Accuracy: 0.666015625\n",
      "Batch: 85, Loss: 0.9835130572319031, Accuracy: 0.67041015625\n",
      "Batch: 86, Loss: 1.1840300559997559, Accuracy: 0.6123046875\n",
      "Batch: 87, Loss: 1.0872689485549927, Accuracy: 0.65380859375\n",
      "Batch: 88, Loss: 1.16533362865448, Accuracy: 0.6416015625\n",
      "Batch: 89, Loss: 1.1374011039733887, Accuracy: 0.64306640625\n",
      "Batch: 90, Loss: 1.1610349416732788, Accuracy: 0.62255859375\n",
      "Batch: 91, Loss: 1.050626277923584, Accuracy: 0.66259765625\n",
      "Batch: 92, Loss: 1.1917215585708618, Accuracy: 0.6279296875\n",
      "Batch: 93, Loss: 1.1222572326660156, Accuracy: 0.6337890625\n",
      "Batch: 94, Loss: 1.1832119226455688, Accuracy: 0.64501953125\n",
      "Batch: 95, Loss: 1.2079472541809082, Accuracy: 0.62451171875\n",
      "Batch: 96, Loss: 1.113404393196106, Accuracy: 0.65625\n",
      "Batch: 97, Loss: 1.1085951328277588, Accuracy: 0.65478515625\n",
      "Batch: 98, Loss: 1.2023422718048096, Accuracy: 0.62744140625\n",
      "Batch: 99, Loss: 1.0440661907196045, Accuracy: 0.6748046875\n",
      "Batch: 100, Loss: 1.1768364906311035, Accuracy: 0.63720703125\n",
      "Batch: 101, Loss: 1.1950469017028809, Accuracy: 0.61962890625\n",
      "Batch: 102, Loss: 1.0532386302947998, Accuracy: 0.6611328125\n",
      "Batch: 103, Loss: 1.1090030670166016, Accuracy: 0.64453125\n",
      "Batch: 104, Loss: 1.1011581420898438, Accuracy: 0.6513671875\n",
      "Batch: 105, Loss: 1.1711702346801758, Accuracy: 0.62451171875\n",
      "Batch: 106, Loss: 1.170249342918396, Accuracy: 0.62353515625\n",
      "Batch: 107, Loss: 1.191253423690796, Accuracy: 0.63671875\n",
      "Batch: 108, Loss: 1.134178876876831, Accuracy: 0.63671875\n",
      "Batch: 109, Loss: 1.1177809238433838, Accuracy: 0.6484375\n",
      "Batch: 110, Loss: 1.0565918684005737, Accuracy: 0.65625\n",
      "Batch: 111, Loss: 1.0079755783081055, Accuracy: 0.673828125\n",
      "Batch: 112, Loss: 1.122525930404663, Accuracy: 0.65283203125\n",
      "Batch: 113, Loss: 1.1239697933197021, Accuracy: 0.64794921875\n",
      "Batch: 114, Loss: 1.0820887088775635, Accuracy: 0.65087890625\n",
      "Batch: 115, Loss: 1.098827838897705, Accuracy: 0.64990234375\n",
      "Batch: 116, Loss: 1.0953599214553833, Accuracy: 0.64990234375\n",
      "Batch: 117, Loss: 1.1021842956542969, Accuracy: 0.6416015625\n",
      "Batch: 118, Loss: 1.063134789466858, Accuracy: 0.64453125\n",
      "Batch: 119, Loss: 1.0780187845230103, Accuracy: 0.6376953125\n",
      "Batch: 120, Loss: 1.0725102424621582, Accuracy: 0.646484375\n",
      "Batch: 121, Loss: 1.0775904655456543, Accuracy: 0.6474609375\n",
      "Batch: 122, Loss: 1.0577293634414673, Accuracy: 0.6572265625\n",
      "Batch: 123, Loss: 1.070768117904663, Accuracy: 0.6591796875\n",
      "Batch: 124, Loss: 1.042923927307129, Accuracy: 0.6611328125\n",
      "Batch: 125, Loss: 1.1090224981307983, Accuracy: 0.6396484375\n",
      "Batch: 126, Loss: 1.0148828029632568, Accuracy: 0.677734375\n",
      "Batch: 127, Loss: 1.0157737731933594, Accuracy: 0.6650390625\n",
      "Batch: 128, Loss: 1.2191615104675293, Accuracy: 0.619140625\n",
      "Batch: 129, Loss: 1.2288347482681274, Accuracy: 0.61572265625\n",
      "Batch: 130, Loss: 1.2182252407073975, Accuracy: 0.611328125\n",
      "Batch: 131, Loss: 1.1549334526062012, Accuracy: 0.64208984375\n",
      "Batch: 132, Loss: 1.0144052505493164, Accuracy: 0.6708984375\n",
      "Batch: 133, Loss: 1.0255775451660156, Accuracy: 0.68701171875\n",
      "Batch: 134, Loss: 1.1375858783721924, Accuracy: 0.6357421875\n",
      "Batch: 135, Loss: 1.120091199874878, Accuracy: 0.63671875\n",
      "Batch: 136, Loss: 1.034430742263794, Accuracy: 0.65380859375\n",
      "Batch: 137, Loss: 1.1247174739837646, Accuracy: 0.64306640625\n",
      "Batch: 138, Loss: 0.9765353202819824, Accuracy: 0.697265625\n",
      "Batch: 139, Loss: 1.0756202936172485, Accuracy: 0.6533203125\n",
      "Batch: 140, Loss: 1.0239219665527344, Accuracy: 0.67431640625\n",
      "Batch: 141, Loss: 1.1395840644836426, Accuracy: 0.63916015625\n",
      "Batch: 142, Loss: 1.0201914310455322, Accuracy: 0.66552734375\n",
      "Batch: 143, Loss: 1.0532289743423462, Accuracy: 0.6630859375\n",
      "Batch: 144, Loss: 1.1240935325622559, Accuracy: 0.65771484375\n",
      "Batch: 145, Loss: 1.0958499908447266, Accuracy: 0.65869140625\n",
      "Batch: 146, Loss: 1.1444478034973145, Accuracy: 0.61962890625\n",
      "Batch: 147, Loss: 1.114516258239746, Accuracy: 0.64599609375\n",
      "Batch: 148, Loss: 1.0950244665145874, Accuracy: 0.6435546875\n",
      "Batch: 149, Loss: 1.059158205986023, Accuracy: 0.65576171875\n",
      "Batch: 150, Loss: 0.9199055433273315, Accuracy: 0.70068359375\n",
      "Batch: 151, Loss: 0.9564152956008911, Accuracy: 0.68505859375\n",
      "Batch: 152, Loss: 1.0168745517730713, Accuracy: 0.67333984375\n",
      "Batch: 153, Loss: 0.9801883101463318, Accuracy: 0.6865234375\n",
      "Batch: 154, Loss: 0.9950610995292664, Accuracy: 0.67578125\n",
      "Batch: 155, Loss: 1.0664368867874146, Accuracy: 0.66162109375\n",
      "Batch: 156, Loss: 0.9995806813240051, Accuracy: 0.6787109375\n",
      "Batch: 157, Loss: 0.9792494773864746, Accuracy: 0.6826171875\n",
      "Batch: 158, Loss: 0.9963982701301575, Accuracy: 0.68310546875\n",
      "Batch: 159, Loss: 0.957556962966919, Accuracy: 0.68505859375\n",
      "Batch: 160, Loss: 1.0273023843765259, Accuracy: 0.6611328125\n",
      "Batch: 161, Loss: 1.0328742265701294, Accuracy: 0.65966796875\n",
      "Batch: 162, Loss: 1.029367208480835, Accuracy: 0.673828125\n",
      "Batch: 163, Loss: 1.075270652770996, Accuracy: 0.65380859375\n",
      "Batch: 164, Loss: 1.1093915700912476, Accuracy: 0.64306640625\n",
      "Batch: 165, Loss: 1.0258867740631104, Accuracy: 0.6708984375\n",
      "Batch: 166, Loss: 1.0755298137664795, Accuracy: 0.66015625\n",
      "Batch: 167, Loss: 0.9876432418823242, Accuracy: 0.677734375\n",
      "Batch: 168, Loss: 0.9612931609153748, Accuracy: 0.6884765625\n",
      "Batch: 169, Loss: 1.0365374088287354, Accuracy: 0.6591796875\n",
      "Batch: 170, Loss: 1.100830078125, Accuracy: 0.662109375\n",
      "Batch: 171, Loss: 1.0513134002685547, Accuracy: 0.6650390625\n",
      "Batch: 172, Loss: 1.0163958072662354, Accuracy: 0.66943359375\n",
      "Batch: 173, Loss: 1.088714599609375, Accuracy: 0.671875\n",
      "Batch: 174, Loss: 0.917739987373352, Accuracy: 0.7041015625\n",
      "Batch: 175, Loss: 1.1021614074707031, Accuracy: 0.64208984375\n",
      "Batch: 176, Loss: 1.1452199220657349, Accuracy: 0.6337890625\n",
      "Batch: 177, Loss: 1.0382394790649414, Accuracy: 0.66455078125\n",
      "Batch: 178, Loss: 1.004492998123169, Accuracy: 0.67578125\n",
      "Batch: 179, Loss: 1.0477416515350342, Accuracy: 0.66015625\n",
      "Batch: 180, Loss: 1.122117042541504, Accuracy: 0.6416015625\n",
      "Epoch 16/200\n",
      "Batch: 1, Loss: 1.5209345817565918, Accuracy: 0.587890625\n",
      "Batch: 2, Loss: 1.0509228706359863, Accuracy: 0.6591796875\n",
      "Batch: 3, Loss: 1.0504950284957886, Accuracy: 0.66015625\n",
      "Batch: 4, Loss: 1.0972470045089722, Accuracy: 0.66015625\n",
      "Batch: 5, Loss: 1.092179298400879, Accuracy: 0.650390625\n",
      "Batch: 6, Loss: 1.0963730812072754, Accuracy: 0.64697265625\n",
      "Batch: 7, Loss: 1.008952260017395, Accuracy: 0.67626953125\n",
      "Batch: 8, Loss: 1.0686581134796143, Accuracy: 0.65869140625\n",
      "Batch: 9, Loss: 1.1331384181976318, Accuracy: 0.6572265625\n",
      "Batch: 10, Loss: 1.089247465133667, Accuracy: 0.6611328125\n",
      "Batch: 11, Loss: 1.141391396522522, Accuracy: 0.64892578125\n",
      "Batch: 12, Loss: 1.0274245738983154, Accuracy: 0.67919921875\n",
      "Batch: 13, Loss: 1.0820646286010742, Accuracy: 0.65380859375\n",
      "Batch: 14, Loss: 1.0837085247039795, Accuracy: 0.654296875\n",
      "Batch: 15, Loss: 1.0705621242523193, Accuracy: 0.66943359375\n",
      "Batch: 16, Loss: 1.1257414817810059, Accuracy: 0.65771484375\n",
      "Batch: 17, Loss: 1.051516056060791, Accuracy: 0.673828125\n",
      "Batch: 18, Loss: 1.1201993227005005, Accuracy: 0.6337890625\n",
      "Batch: 19, Loss: 1.113208293914795, Accuracy: 0.65625\n",
      "Batch: 20, Loss: 1.0189752578735352, Accuracy: 0.67138671875\n",
      "Batch: 21, Loss: 1.20632803440094, Accuracy: 0.63037109375\n",
      "Batch: 22, Loss: 1.089726448059082, Accuracy: 0.6533203125\n",
      "Batch: 23, Loss: 1.0371190309524536, Accuracy: 0.66845703125\n",
      "Batch: 24, Loss: 1.071385145187378, Accuracy: 0.6611328125\n",
      "Batch: 25, Loss: 1.0562559366226196, Accuracy: 0.67041015625\n",
      "Batch: 26, Loss: 1.0601222515106201, Accuracy: 0.6630859375\n",
      "Batch: 27, Loss: 1.0807745456695557, Accuracy: 0.6591796875\n",
      "Batch: 28, Loss: 1.0175498723983765, Accuracy: 0.67138671875\n",
      "Batch: 29, Loss: 1.1110191345214844, Accuracy: 0.64794921875\n",
      "Batch: 30, Loss: 1.0636759996414185, Accuracy: 0.66162109375\n",
      "Batch: 31, Loss: 1.2074308395385742, Accuracy: 0.6201171875\n",
      "Batch: 32, Loss: 1.129150390625, Accuracy: 0.63916015625\n",
      "Batch: 33, Loss: 1.1436269283294678, Accuracy: 0.6259765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 34, Loss: 1.1742702722549438, Accuracy: 0.63818359375\n",
      "Batch: 35, Loss: 1.1881275177001953, Accuracy: 0.62451171875\n",
      "Batch: 36, Loss: 1.1552529335021973, Accuracy: 0.64013671875\n",
      "Batch: 37, Loss: 1.1066933870315552, Accuracy: 0.64697265625\n",
      "Batch: 38, Loss: 1.167712688446045, Accuracy: 0.61474609375\n",
      "Batch: 39, Loss: 1.1078753471374512, Accuracy: 0.65087890625\n",
      "Batch: 40, Loss: 1.1354396343231201, Accuracy: 0.63623046875\n",
      "Batch: 41, Loss: 1.1061280965805054, Accuracy: 0.63623046875\n",
      "Batch: 42, Loss: 1.0592646598815918, Accuracy: 0.65869140625\n",
      "Batch: 43, Loss: 1.042799949645996, Accuracy: 0.68017578125\n",
      "Batch: 44, Loss: 0.9694308042526245, Accuracy: 0.6865234375\n",
      "Batch: 45, Loss: 1.0292398929595947, Accuracy: 0.6630859375\n",
      "Batch: 46, Loss: 0.9791306257247925, Accuracy: 0.66015625\n",
      "Batch: 47, Loss: 1.0623892545700073, Accuracy: 0.6484375\n",
      "Batch: 48, Loss: 1.017857313156128, Accuracy: 0.6689453125\n",
      "Batch: 49, Loss: 1.0258283615112305, Accuracy: 0.6640625\n",
      "Batch: 50, Loss: 1.0841100215911865, Accuracy: 0.65869140625\n",
      "Batch: 51, Loss: 1.0310559272766113, Accuracy: 0.66357421875\n",
      "Batch: 52, Loss: 1.0141067504882812, Accuracy: 0.66943359375\n",
      "Batch: 53, Loss: 1.0001095533370972, Accuracy: 0.67919921875\n",
      "Batch: 54, Loss: 1.0440094470977783, Accuracy: 0.6552734375\n",
      "Batch: 55, Loss: 1.0119028091430664, Accuracy: 0.68505859375\n",
      "Batch: 56, Loss: 1.0240429639816284, Accuracy: 0.6611328125\n",
      "Batch: 57, Loss: 1.1025617122650146, Accuracy: 0.64501953125\n",
      "Batch: 58, Loss: 1.068029761314392, Accuracy: 0.65185546875\n",
      "Batch: 59, Loss: 1.1897637844085693, Accuracy: 0.63037109375\n",
      "Batch: 60, Loss: 1.0753552913665771, Accuracy: 0.65380859375\n",
      "Batch: 61, Loss: 0.9880119562149048, Accuracy: 0.69091796875\n",
      "Batch: 62, Loss: 1.017881155014038, Accuracy: 0.6748046875\n",
      "Batch: 63, Loss: 1.0469707250595093, Accuracy: 0.6572265625\n",
      "Batch: 64, Loss: 1.0586445331573486, Accuracy: 0.64990234375\n",
      "Batch: 65, Loss: 1.1168324947357178, Accuracy: 0.65380859375\n",
      "Batch: 66, Loss: 1.080644130706787, Accuracy: 0.6513671875\n",
      "Batch: 67, Loss: 1.0799615383148193, Accuracy: 0.64990234375\n",
      "Batch: 68, Loss: 0.9968588948249817, Accuracy: 0.67333984375\n",
      "Batch: 69, Loss: 1.084511399269104, Accuracy: 0.63330078125\n",
      "Batch: 70, Loss: 1.0916857719421387, Accuracy: 0.64013671875\n",
      "Batch: 71, Loss: 1.0475404262542725, Accuracy: 0.65478515625\n",
      "Batch: 72, Loss: 1.0840766429901123, Accuracy: 0.638671875\n",
      "Batch: 73, Loss: 1.144300937652588, Accuracy: 0.61865234375\n",
      "Batch: 74, Loss: 1.1181094646453857, Accuracy: 0.6484375\n",
      "Batch: 75, Loss: 1.0487234592437744, Accuracy: 0.6591796875\n",
      "Batch: 76, Loss: 1.0490691661834717, Accuracy: 0.66064453125\n",
      "Batch: 77, Loss: 1.0010795593261719, Accuracy: 0.67431640625\n",
      "Batch: 78, Loss: 1.043735146522522, Accuracy: 0.67724609375\n",
      "Batch: 79, Loss: 1.0789114236831665, Accuracy: 0.65966796875\n",
      "Batch: 80, Loss: 1.0537810325622559, Accuracy: 0.6552734375\n",
      "Batch: 81, Loss: 1.1075036525726318, Accuracy: 0.65625\n",
      "Batch: 82, Loss: 1.0064125061035156, Accuracy: 0.66650390625\n",
      "Batch: 83, Loss: 0.99575275182724, Accuracy: 0.6650390625\n",
      "Batch: 84, Loss: 0.9886204600334167, Accuracy: 0.6806640625\n",
      "Batch: 85, Loss: 0.9682822227478027, Accuracy: 0.68408203125\n",
      "Batch: 86, Loss: 1.1554841995239258, Accuracy: 0.6298828125\n",
      "Batch: 87, Loss: 1.0537313222885132, Accuracy: 0.66064453125\n",
      "Batch: 88, Loss: 1.1006660461425781, Accuracy: 0.65087890625\n",
      "Batch: 89, Loss: 1.1043249368667603, Accuracy: 0.64453125\n",
      "Batch: 90, Loss: 1.1220228672027588, Accuracy: 0.634765625\n",
      "Batch: 91, Loss: 1.0235881805419922, Accuracy: 0.66796875\n",
      "Batch: 92, Loss: 1.1643965244293213, Accuracy: 0.62744140625\n",
      "Batch: 93, Loss: 1.0960099697113037, Accuracy: 0.6435546875\n",
      "Batch: 94, Loss: 1.162818193435669, Accuracy: 0.64111328125\n",
      "Batch: 95, Loss: 1.1580946445465088, Accuracy: 0.6396484375\n",
      "Batch: 96, Loss: 1.0994970798492432, Accuracy: 0.6650390625\n",
      "Batch: 97, Loss: 1.073359727859497, Accuracy: 0.6630859375\n",
      "Batch: 98, Loss: 1.189058542251587, Accuracy: 0.6201171875\n",
      "Batch: 99, Loss: 1.0483982563018799, Accuracy: 0.6650390625\n",
      "Batch: 100, Loss: 1.1636826992034912, Accuracy: 0.64013671875\n",
      "Batch: 101, Loss: 1.178332805633545, Accuracy: 0.62353515625\n",
      "Batch: 102, Loss: 1.0368263721466064, Accuracy: 0.67236328125\n",
      "Batch: 103, Loss: 1.0987026691436768, Accuracy: 0.646484375\n",
      "Batch: 104, Loss: 1.078291654586792, Accuracy: 0.65234375\n",
      "Batch: 105, Loss: 1.1555122137069702, Accuracy: 0.630859375\n",
      "Batch: 106, Loss: 1.1262967586517334, Accuracy: 0.64013671875\n",
      "Batch: 107, Loss: 1.1525444984436035, Accuracy: 0.63525390625\n",
      "Batch: 108, Loss: 1.0982977151870728, Accuracy: 0.6591796875\n",
      "Batch: 109, Loss: 1.086927890777588, Accuracy: 0.6572265625\n",
      "Batch: 110, Loss: 1.0289686918258667, Accuracy: 0.66748046875\n",
      "Batch: 111, Loss: 0.9946567416191101, Accuracy: 0.6748046875\n",
      "Batch: 112, Loss: 1.0782532691955566, Accuracy: 0.66015625\n",
      "Batch: 113, Loss: 1.1087700128555298, Accuracy: 0.640625\n",
      "Batch: 114, Loss: 1.066185712814331, Accuracy: 0.65234375\n",
      "Batch: 115, Loss: 1.0814706087112427, Accuracy: 0.64599609375\n",
      "Batch: 116, Loss: 1.0838353633880615, Accuracy: 0.65234375\n",
      "Batch: 117, Loss: 1.0852906703948975, Accuracy: 0.6484375\n",
      "Batch: 118, Loss: 1.0686240196228027, Accuracy: 0.65087890625\n",
      "Batch: 119, Loss: 1.0527262687683105, Accuracy: 0.64013671875\n",
      "Batch: 120, Loss: 1.0597786903381348, Accuracy: 0.64697265625\n",
      "Batch: 121, Loss: 1.0710289478302002, Accuracy: 0.64892578125\n",
      "Batch: 122, Loss: 1.0284477472305298, Accuracy: 0.67236328125\n",
      "Batch: 123, Loss: 1.054999589920044, Accuracy: 0.66455078125\n",
      "Batch: 124, Loss: 1.0270663499832153, Accuracy: 0.66259765625\n",
      "Batch: 125, Loss: 1.0847610235214233, Accuracy: 0.6513671875\n",
      "Batch: 126, Loss: 1.0131169557571411, Accuracy: 0.6689453125\n",
      "Batch: 127, Loss: 1.02812659740448, Accuracy: 0.669921875\n",
      "Batch: 128, Loss: 1.1840975284576416, Accuracy: 0.62841796875\n",
      "Batch: 129, Loss: 1.2272005081176758, Accuracy: 0.60693359375\n",
      "Batch: 130, Loss: 1.1937646865844727, Accuracy: 0.626953125\n",
      "Batch: 131, Loss: 1.1345988512039185, Accuracy: 0.64453125\n",
      "Batch: 132, Loss: 1.0016603469848633, Accuracy: 0.67578125\n",
      "Batch: 133, Loss: 0.9991452693939209, Accuracy: 0.677734375\n",
      "Batch: 134, Loss: 1.115037202835083, Accuracy: 0.6416015625\n",
      "Batch: 135, Loss: 1.113680362701416, Accuracy: 0.63916015625\n",
      "Batch: 136, Loss: 1.0259944200515747, Accuracy: 0.65966796875\n",
      "Batch: 137, Loss: 1.0815446376800537, Accuracy: 0.6494140625\n",
      "Batch: 138, Loss: 0.960332453250885, Accuracy: 0.70849609375\n",
      "Batch: 139, Loss: 1.0600322484970093, Accuracy: 0.6728515625\n",
      "Batch: 140, Loss: 1.0043675899505615, Accuracy: 0.6845703125\n",
      "Batch: 141, Loss: 1.1018779277801514, Accuracy: 0.64208984375\n",
      "Batch: 142, Loss: 1.0059293508529663, Accuracy: 0.6728515625\n",
      "Batch: 143, Loss: 1.0410304069519043, Accuracy: 0.671875\n",
      "Batch: 144, Loss: 1.1046972274780273, Accuracy: 0.6640625\n",
      "Batch: 145, Loss: 1.0767875909805298, Accuracy: 0.66064453125\n",
      "Batch: 146, Loss: 1.1254972219467163, Accuracy: 0.64501953125\n",
      "Batch: 147, Loss: 1.0977762937545776, Accuracy: 0.64599609375\n",
      "Batch: 148, Loss: 1.0558533668518066, Accuracy: 0.65087890625\n",
      "Batch: 149, Loss: 1.0452461242675781, Accuracy: 0.66357421875\n",
      "Batch: 150, Loss: 0.9149296283721924, Accuracy: 0.7001953125\n",
      "Batch: 151, Loss: 0.9332029819488525, Accuracy: 0.69482421875\n",
      "Batch: 152, Loss: 0.9753105044364929, Accuracy: 0.68310546875\n",
      "Batch: 153, Loss: 0.9510552883148193, Accuracy: 0.69384765625\n",
      "Batch: 154, Loss: 0.9744972586631775, Accuracy: 0.67724609375\n",
      "Batch: 155, Loss: 1.046120524406433, Accuracy: 0.66845703125\n",
      "Batch: 156, Loss: 0.9740476608276367, Accuracy: 0.69091796875\n",
      "Batch: 157, Loss: 0.965596079826355, Accuracy: 0.68603515625\n",
      "Batch: 158, Loss: 0.9662787914276123, Accuracy: 0.69140625\n",
      "Batch: 159, Loss: 0.9425435066223145, Accuracy: 0.69580078125\n",
      "Batch: 160, Loss: 1.007004976272583, Accuracy: 0.66943359375\n",
      "Batch: 161, Loss: 1.0103676319122314, Accuracy: 0.66845703125\n",
      "Batch: 162, Loss: 1.0083343982696533, Accuracy: 0.68115234375\n",
      "Batch: 163, Loss: 1.05659818649292, Accuracy: 0.658203125\n",
      "Batch: 164, Loss: 1.0791285037994385, Accuracy: 0.65234375\n",
      "Batch: 165, Loss: 0.9987474083900452, Accuracy: 0.68359375\n",
      "Batch: 166, Loss: 1.0518805980682373, Accuracy: 0.66748046875\n",
      "Batch: 167, Loss: 0.9710534811019897, Accuracy: 0.68603515625\n",
      "Batch: 168, Loss: 0.9382439851760864, Accuracy: 0.69580078125\n",
      "Batch: 169, Loss: 1.0136388540267944, Accuracy: 0.666015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 170, Loss: 1.0907196998596191, Accuracy: 0.65283203125\n",
      "Batch: 171, Loss: 1.0176869630813599, Accuracy: 0.67529296875\n",
      "Batch: 172, Loss: 1.005973219871521, Accuracy: 0.6728515625\n",
      "Batch: 173, Loss: 1.0678822994232178, Accuracy: 0.671875\n",
      "Batch: 174, Loss: 0.9102215766906738, Accuracy: 0.71337890625\n",
      "Batch: 175, Loss: 1.0750212669372559, Accuracy: 0.646484375\n",
      "Batch: 176, Loss: 1.0977429151535034, Accuracy: 0.650390625\n",
      "Batch: 177, Loss: 1.0226097106933594, Accuracy: 0.669921875\n",
      "Batch: 178, Loss: 0.9873472452163696, Accuracy: 0.673828125\n",
      "Batch: 179, Loss: 1.01552414894104, Accuracy: 0.66064453125\n",
      "Batch: 180, Loss: 1.0828863382339478, Accuracy: 0.6533203125\n",
      "Epoch 17/200\n",
      "Batch: 1, Loss: 1.497396469116211, Accuracy: 0.58984375\n",
      "Batch: 2, Loss: 1.0292166471481323, Accuracy: 0.66845703125\n",
      "Batch: 3, Loss: 1.025895357131958, Accuracy: 0.66845703125\n",
      "Batch: 4, Loss: 1.0814883708953857, Accuracy: 0.654296875\n",
      "Batch: 5, Loss: 1.0757560729980469, Accuracy: 0.65380859375\n",
      "Batch: 6, Loss: 1.0907362699508667, Accuracy: 0.65625\n",
      "Batch: 7, Loss: 0.9886288046836853, Accuracy: 0.68212890625\n",
      "Batch: 8, Loss: 1.0584183931350708, Accuracy: 0.65673828125\n",
      "Batch: 9, Loss: 1.11354398727417, Accuracy: 0.6611328125\n",
      "Batch: 10, Loss: 1.0815327167510986, Accuracy: 0.6640625\n",
      "Batch: 11, Loss: 1.127188801765442, Accuracy: 0.64697265625\n",
      "Batch: 12, Loss: 1.0050727128982544, Accuracy: 0.6806640625\n",
      "Batch: 13, Loss: 1.0677317380905151, Accuracy: 0.64599609375\n",
      "Batch: 14, Loss: 1.0690596103668213, Accuracy: 0.6708984375\n",
      "Batch: 15, Loss: 1.049551010131836, Accuracy: 0.67578125\n",
      "Batch: 16, Loss: 1.1101136207580566, Accuracy: 0.64892578125\n",
      "Batch: 17, Loss: 1.0424267053604126, Accuracy: 0.6767578125\n",
      "Batch: 18, Loss: 1.0917093753814697, Accuracy: 0.6396484375\n",
      "Batch: 19, Loss: 1.0785000324249268, Accuracy: 0.66357421875\n",
      "Batch: 20, Loss: 0.9884963035583496, Accuracy: 0.68359375\n",
      "Batch: 21, Loss: 1.189897060394287, Accuracy: 0.63525390625\n",
      "Batch: 22, Loss: 1.0687534809112549, Accuracy: 0.673828125\n",
      "Batch: 23, Loss: 1.017720341682434, Accuracy: 0.677734375\n",
      "Batch: 24, Loss: 1.0378941297531128, Accuracy: 0.66796875\n",
      "Batch: 25, Loss: 1.0274633169174194, Accuracy: 0.68115234375\n",
      "Batch: 26, Loss: 1.0522751808166504, Accuracy: 0.66748046875\n",
      "Batch: 27, Loss: 1.0489413738250732, Accuracy: 0.65771484375\n",
      "Batch: 28, Loss: 1.0021613836288452, Accuracy: 0.6767578125\n",
      "Batch: 29, Loss: 1.0958644151687622, Accuracy: 0.64697265625\n",
      "Batch: 30, Loss: 1.04701828956604, Accuracy: 0.673828125\n",
      "Batch: 31, Loss: 1.1825475692749023, Accuracy: 0.63623046875\n",
      "Batch: 32, Loss: 1.087350845336914, Accuracy: 0.6416015625\n",
      "Batch: 33, Loss: 1.119282603263855, Accuracy: 0.63525390625\n",
      "Batch: 34, Loss: 1.1600091457366943, Accuracy: 0.634765625\n",
      "Batch: 35, Loss: 1.1777329444885254, Accuracy: 0.62255859375\n",
      "Batch: 36, Loss: 1.11252760887146, Accuracy: 0.65087890625\n",
      "Batch: 37, Loss: 1.0886926651000977, Accuracy: 0.66162109375\n",
      "Batch: 38, Loss: 1.137876033782959, Accuracy: 0.6220703125\n",
      "Batch: 39, Loss: 1.0907061100006104, Accuracy: 0.6533203125\n",
      "Batch: 40, Loss: 1.1205425262451172, Accuracy: 0.646484375\n",
      "Batch: 41, Loss: 1.0896844863891602, Accuracy: 0.65185546875\n",
      "Batch: 42, Loss: 1.0355277061462402, Accuracy: 0.65478515625\n",
      "Batch: 43, Loss: 1.0284665822982788, Accuracy: 0.68212890625\n",
      "Batch: 44, Loss: 0.954651951789856, Accuracy: 0.69140625\n",
      "Batch: 45, Loss: 1.0063601732254028, Accuracy: 0.66455078125\n",
      "Batch: 46, Loss: 0.950717568397522, Accuracy: 0.6796875\n",
      "Batch: 47, Loss: 1.0404000282287598, Accuracy: 0.6552734375\n",
      "Batch: 48, Loss: 1.0095672607421875, Accuracy: 0.67626953125\n",
      "Batch: 49, Loss: 0.993981122970581, Accuracy: 0.669921875\n",
      "Batch: 50, Loss: 1.052712082862854, Accuracy: 0.65234375\n",
      "Batch: 51, Loss: 1.0191490650177002, Accuracy: 0.6806640625\n",
      "Batch: 52, Loss: 0.9816598296165466, Accuracy: 0.68798828125\n",
      "Batch: 53, Loss: 0.9667783379554749, Accuracy: 0.6826171875\n",
      "Batch: 54, Loss: 1.0196447372436523, Accuracy: 0.6572265625\n",
      "Batch: 55, Loss: 0.9943163394927979, Accuracy: 0.6845703125\n",
      "Batch: 56, Loss: 1.0115262269973755, Accuracy: 0.67138671875\n",
      "Batch: 57, Loss: 1.0867763757705688, Accuracy: 0.654296875\n",
      "Batch: 58, Loss: 1.0341496467590332, Accuracy: 0.65966796875\n",
      "Batch: 59, Loss: 1.1607351303100586, Accuracy: 0.63037109375\n",
      "Batch: 60, Loss: 1.031580924987793, Accuracy: 0.67431640625\n",
      "Batch: 61, Loss: 0.9653195142745972, Accuracy: 0.6796875\n",
      "Batch: 62, Loss: 0.9853568077087402, Accuracy: 0.68896484375\n",
      "Batch: 63, Loss: 1.037202000617981, Accuracy: 0.6572265625\n",
      "Batch: 64, Loss: 1.0487496852874756, Accuracy: 0.65234375\n",
      "Batch: 65, Loss: 1.0924551486968994, Accuracy: 0.65234375\n",
      "Batch: 66, Loss: 1.0708509683609009, Accuracy: 0.6513671875\n",
      "Batch: 67, Loss: 1.0530242919921875, Accuracy: 0.66357421875\n",
      "Batch: 68, Loss: 0.9882786870002747, Accuracy: 0.6689453125\n",
      "Batch: 69, Loss: 1.0618503093719482, Accuracy: 0.6435546875\n",
      "Batch: 70, Loss: 1.0727986097335815, Accuracy: 0.64892578125\n",
      "Batch: 71, Loss: 1.0380157232284546, Accuracy: 0.65869140625\n",
      "Batch: 72, Loss: 1.076898217201233, Accuracy: 0.63525390625\n",
      "Batch: 73, Loss: 1.116952896118164, Accuracy: 0.63330078125\n",
      "Batch: 74, Loss: 1.0908379554748535, Accuracy: 0.65185546875\n",
      "Batch: 75, Loss: 1.0274544954299927, Accuracy: 0.66357421875\n",
      "Batch: 76, Loss: 1.0093648433685303, Accuracy: 0.66455078125\n",
      "Batch: 77, Loss: 0.9850795865058899, Accuracy: 0.68408203125\n",
      "Batch: 78, Loss: 1.0514471530914307, Accuracy: 0.67236328125\n",
      "Batch: 79, Loss: 1.067800760269165, Accuracy: 0.66064453125\n",
      "Batch: 80, Loss: 1.0326495170593262, Accuracy: 0.658203125\n",
      "Batch: 81, Loss: 1.0801290273666382, Accuracy: 0.65966796875\n",
      "Batch: 82, Loss: 0.9773781299591064, Accuracy: 0.677734375\n",
      "Batch: 83, Loss: 0.9747265577316284, Accuracy: 0.67578125\n",
      "Batch: 84, Loss: 0.970361053943634, Accuracy: 0.67236328125\n",
      "Batch: 85, Loss: 0.9519171714782715, Accuracy: 0.68896484375\n",
      "Batch: 86, Loss: 1.1493327617645264, Accuracy: 0.6337890625\n",
      "Batch: 87, Loss: 1.045670986175537, Accuracy: 0.66357421875\n",
      "Batch: 88, Loss: 1.089395523071289, Accuracy: 0.65478515625\n",
      "Batch: 89, Loss: 1.1059157848358154, Accuracy: 0.63916015625\n",
      "Batch: 90, Loss: 1.1194740533828735, Accuracy: 0.6416015625\n",
      "Batch: 91, Loss: 1.0145444869995117, Accuracy: 0.67919921875\n",
      "Batch: 92, Loss: 1.1495074033737183, Accuracy: 0.63916015625\n",
      "Batch: 93, Loss: 1.0808463096618652, Accuracy: 0.6513671875\n",
      "Batch: 94, Loss: 1.1233114004135132, Accuracy: 0.6513671875\n",
      "Batch: 95, Loss: 1.151627540588379, Accuracy: 0.6396484375\n",
      "Batch: 96, Loss: 1.101465106010437, Accuracy: 0.65869140625\n",
      "Batch: 97, Loss: 1.0485949516296387, Accuracy: 0.673828125\n",
      "Batch: 98, Loss: 1.1621637344360352, Accuracy: 0.62744140625\n",
      "Batch: 99, Loss: 1.021350622177124, Accuracy: 0.6904296875\n",
      "Batch: 100, Loss: 1.1514602899551392, Accuracy: 0.64453125\n",
      "Batch: 101, Loss: 1.1668578386306763, Accuracy: 0.64111328125\n",
      "Batch: 102, Loss: 1.0222299098968506, Accuracy: 0.67138671875\n",
      "Batch: 103, Loss: 1.0878629684448242, Accuracy: 0.65673828125\n",
      "Batch: 104, Loss: 1.0599477291107178, Accuracy: 0.65234375\n",
      "Batch: 105, Loss: 1.1126680374145508, Accuracy: 0.64013671875\n",
      "Batch: 106, Loss: 1.1127712726593018, Accuracy: 0.642578125\n",
      "Batch: 107, Loss: 1.1272835731506348, Accuracy: 0.64501953125\n",
      "Batch: 108, Loss: 1.0695469379425049, Accuracy: 0.65380859375\n",
      "Batch: 109, Loss: 1.0707093477249146, Accuracy: 0.65185546875\n",
      "Batch: 110, Loss: 1.0036022663116455, Accuracy: 0.671875\n",
      "Batch: 111, Loss: 0.9541385769844055, Accuracy: 0.6865234375\n",
      "Batch: 112, Loss: 1.0664477348327637, Accuracy: 0.66552734375\n",
      "Batch: 113, Loss: 1.0677475929260254, Accuracy: 0.6552734375\n",
      "Batch: 114, Loss: 1.042710542678833, Accuracy: 0.66796875\n",
      "Batch: 115, Loss: 1.0593229532241821, Accuracy: 0.6640625\n",
      "Batch: 116, Loss: 1.0475622415542603, Accuracy: 0.65478515625\n",
      "Batch: 117, Loss: 1.068332552909851, Accuracy: 0.6455078125\n",
      "Batch: 118, Loss: 1.0377521514892578, Accuracy: 0.6669921875\n",
      "Batch: 119, Loss: 1.0343033075332642, Accuracy: 0.64794921875\n",
      "Batch: 120, Loss: 1.0351974964141846, Accuracy: 0.66357421875\n",
      "Batch: 121, Loss: 1.0582573413848877, Accuracy: 0.6552734375\n",
      "Batch: 122, Loss: 1.0055768489837646, Accuracy: 0.68017578125\n",
      "Batch: 123, Loss: 1.0313175916671753, Accuracy: 0.671875\n",
      "Batch: 124, Loss: 1.0097644329071045, Accuracy: 0.66650390625\n",
      "Batch: 125, Loss: 1.083583116531372, Accuracy: 0.65380859375\n",
      "Batch: 126, Loss: 0.9897482991218567, Accuracy: 0.6845703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 127, Loss: 0.9909121990203857, Accuracy: 0.69091796875\n",
      "Batch: 128, Loss: 1.1866202354431152, Accuracy: 0.63037109375\n",
      "Batch: 129, Loss: 1.1846086978912354, Accuracy: 0.625\n",
      "Batch: 130, Loss: 1.179975986480713, Accuracy: 0.6259765625\n",
      "Batch: 131, Loss: 1.1155918836593628, Accuracy: 0.64501953125\n",
      "Batch: 132, Loss: 0.9754514694213867, Accuracy: 0.68994140625\n",
      "Batch: 133, Loss: 0.9859403967857361, Accuracy: 0.703125\n",
      "Batch: 134, Loss: 1.1035809516906738, Accuracy: 0.64306640625\n",
      "Batch: 135, Loss: 1.0871801376342773, Accuracy: 0.650390625\n",
      "Batch: 136, Loss: 1.0101678371429443, Accuracy: 0.66748046875\n",
      "Batch: 137, Loss: 1.081366777420044, Accuracy: 0.65185546875\n",
      "Batch: 138, Loss: 0.9407641291618347, Accuracy: 0.70263671875\n",
      "Batch: 139, Loss: 1.041975498199463, Accuracy: 0.6669921875\n",
      "Batch: 140, Loss: 0.9718391299247742, Accuracy: 0.68359375\n",
      "Batch: 141, Loss: 1.097564697265625, Accuracy: 0.6396484375\n",
      "Batch: 142, Loss: 0.9822201728820801, Accuracy: 0.67724609375\n",
      "Batch: 143, Loss: 1.024840235710144, Accuracy: 0.68017578125\n",
      "Batch: 144, Loss: 1.0804636478424072, Accuracy: 0.6728515625\n",
      "Batch: 145, Loss: 1.0764992237091064, Accuracy: 0.66015625\n",
      "Batch: 146, Loss: 1.1062345504760742, Accuracy: 0.6376953125\n",
      "Batch: 147, Loss: 1.0591259002685547, Accuracy: 0.65966796875\n",
      "Batch: 148, Loss: 1.059731125831604, Accuracy: 0.6572265625\n",
      "Batch: 149, Loss: 1.0227351188659668, Accuracy: 0.669921875\n",
      "Batch: 150, Loss: 0.8879783153533936, Accuracy: 0.71533203125\n",
      "Batch: 151, Loss: 0.9107165336608887, Accuracy: 0.70263671875\n",
      "Batch: 152, Loss: 0.9763309359550476, Accuracy: 0.6884765625\n",
      "Batch: 153, Loss: 0.9381989240646362, Accuracy: 0.693359375\n",
      "Batch: 154, Loss: 0.9684278964996338, Accuracy: 0.6884765625\n",
      "Batch: 155, Loss: 1.022621989250183, Accuracy: 0.6875\n",
      "Batch: 156, Loss: 0.9535301923751831, Accuracy: 0.6875\n",
      "Batch: 157, Loss: 0.9321500062942505, Accuracy: 0.6884765625\n",
      "Batch: 158, Loss: 0.9701805114746094, Accuracy: 0.6884765625\n",
      "Batch: 159, Loss: 0.9312560558319092, Accuracy: 0.70654296875\n",
      "Batch: 160, Loss: 0.9992382526397705, Accuracy: 0.67041015625\n",
      "Batch: 161, Loss: 0.9986274838447571, Accuracy: 0.6689453125\n",
      "Batch: 162, Loss: 0.9946770668029785, Accuracy: 0.68798828125\n",
      "Batch: 163, Loss: 1.0604541301727295, Accuracy: 0.666015625\n",
      "Batch: 164, Loss: 1.070826768875122, Accuracy: 0.6591796875\n",
      "Batch: 165, Loss: 0.9895685911178589, Accuracy: 0.69189453125\n",
      "Batch: 166, Loss: 1.038628339767456, Accuracy: 0.67041015625\n",
      "Batch: 167, Loss: 0.9619500041007996, Accuracy: 0.6884765625\n",
      "Batch: 168, Loss: 0.9171800017356873, Accuracy: 0.697265625\n",
      "Batch: 169, Loss: 0.9996309876441956, Accuracy: 0.6748046875\n",
      "Batch: 170, Loss: 1.0647214651107788, Accuracy: 0.66357421875\n",
      "Batch: 171, Loss: 1.0089221000671387, Accuracy: 0.67138671875\n",
      "Batch: 172, Loss: 0.9849050045013428, Accuracy: 0.67724609375\n",
      "Batch: 173, Loss: 1.064713954925537, Accuracy: 0.67041015625\n",
      "Batch: 174, Loss: 0.8881171941757202, Accuracy: 0.71337890625\n",
      "Batch: 175, Loss: 1.0561912059783936, Accuracy: 0.6513671875\n",
      "Batch: 176, Loss: 1.1112117767333984, Accuracy: 0.65625\n",
      "Batch: 177, Loss: 1.0152579545974731, Accuracy: 0.66796875\n",
      "Batch: 178, Loss: 0.9691728353500366, Accuracy: 0.6767578125\n",
      "Batch: 179, Loss: 1.0033001899719238, Accuracy: 0.67138671875\n",
      "Batch: 180, Loss: 1.0751323699951172, Accuracy: 0.64794921875\n",
      "Epoch 18/200\n",
      "Batch: 1, Loss: 1.4621679782867432, Accuracy: 0.60205078125\n",
      "Batch: 2, Loss: 1.0224565267562866, Accuracy: 0.66357421875\n",
      "Batch: 3, Loss: 1.0246387720108032, Accuracy: 0.66943359375\n",
      "Batch: 4, Loss: 1.0581828355789185, Accuracy: 0.66455078125\n",
      "Batch: 5, Loss: 1.0610551834106445, Accuracy: 0.65771484375\n",
      "Batch: 6, Loss: 1.0630614757537842, Accuracy: 0.658203125\n",
      "Batch: 7, Loss: 0.9764223098754883, Accuracy: 0.67919921875\n",
      "Batch: 8, Loss: 1.0386245250701904, Accuracy: 0.662109375\n",
      "Batch: 9, Loss: 1.1056220531463623, Accuracy: 0.6650390625\n",
      "Batch: 10, Loss: 1.0610013008117676, Accuracy: 0.6640625\n",
      "Batch: 11, Loss: 1.1100696325302124, Accuracy: 0.65185546875\n",
      "Batch: 12, Loss: 0.9824045896530151, Accuracy: 0.685546875\n",
      "Batch: 13, Loss: 1.0335829257965088, Accuracy: 0.65966796875\n",
      "Batch: 14, Loss: 1.0549037456512451, Accuracy: 0.666015625\n",
      "Batch: 15, Loss: 1.0299711227416992, Accuracy: 0.6708984375\n",
      "Batch: 16, Loss: 1.1140000820159912, Accuracy: 0.6572265625\n",
      "Batch: 17, Loss: 1.0090382099151611, Accuracy: 0.6865234375\n",
      "Batch: 18, Loss: 1.0727136135101318, Accuracy: 0.64794921875\n",
      "Batch: 19, Loss: 1.0652061700820923, Accuracy: 0.66845703125\n",
      "Batch: 20, Loss: 0.9733434915542603, Accuracy: 0.69091796875\n",
      "Batch: 21, Loss: 1.1669447422027588, Accuracy: 0.6328125\n",
      "Batch: 22, Loss: 1.0421088933944702, Accuracy: 0.67041015625\n",
      "Batch: 23, Loss: 1.0030720233917236, Accuracy: 0.69189453125\n",
      "Batch: 24, Loss: 1.0188192129135132, Accuracy: 0.67138671875\n",
      "Batch: 25, Loss: 1.0107855796813965, Accuracy: 0.67919921875\n",
      "Batch: 26, Loss: 1.0274721384048462, Accuracy: 0.6796875\n",
      "Batch: 27, Loss: 1.0320558547973633, Accuracy: 0.662109375\n",
      "Batch: 28, Loss: 0.981736421585083, Accuracy: 0.6806640625\n",
      "Batch: 29, Loss: 1.079441785812378, Accuracy: 0.6552734375\n",
      "Batch: 30, Loss: 1.0454540252685547, Accuracy: 0.66845703125\n",
      "Batch: 31, Loss: 1.1745223999023438, Accuracy: 0.626953125\n",
      "Batch: 32, Loss: 1.0838205814361572, Accuracy: 0.6552734375\n",
      "Batch: 33, Loss: 1.1075689792633057, Accuracy: 0.63818359375\n",
      "Batch: 34, Loss: 1.133888840675354, Accuracy: 0.64794921875\n",
      "Batch: 35, Loss: 1.158642292022705, Accuracy: 0.63525390625\n",
      "Batch: 36, Loss: 1.0988492965698242, Accuracy: 0.65576171875\n",
      "Batch: 37, Loss: 1.0666580200195312, Accuracy: 0.65966796875\n",
      "Batch: 38, Loss: 1.131962776184082, Accuracy: 0.63427734375\n",
      "Batch: 39, Loss: 1.0651710033416748, Accuracy: 0.6630859375\n",
      "Batch: 40, Loss: 1.1138678789138794, Accuracy: 0.63818359375\n",
      "Batch: 41, Loss: 1.067823052406311, Accuracy: 0.65625\n",
      "Batch: 42, Loss: 1.0187784433364868, Accuracy: 0.66796875\n",
      "Batch: 43, Loss: 1.0060899257659912, Accuracy: 0.68505859375\n",
      "Batch: 44, Loss: 0.9334578514099121, Accuracy: 0.70361328125\n",
      "Batch: 45, Loss: 0.9789876937866211, Accuracy: 0.68115234375\n",
      "Batch: 46, Loss: 0.9438593983650208, Accuracy: 0.6806640625\n",
      "Batch: 47, Loss: 1.0238243341445923, Accuracy: 0.66796875\n",
      "Batch: 48, Loss: 0.9843536615371704, Accuracy: 0.67919921875\n",
      "Batch: 49, Loss: 0.9871970415115356, Accuracy: 0.6806640625\n",
      "Batch: 50, Loss: 1.0478957891464233, Accuracy: 0.6650390625\n",
      "Batch: 51, Loss: 1.0159815549850464, Accuracy: 0.66162109375\n",
      "Batch: 52, Loss: 0.9829118847846985, Accuracy: 0.68359375\n",
      "Batch: 53, Loss: 0.9742180705070496, Accuracy: 0.68505859375\n",
      "Batch: 54, Loss: 1.009127140045166, Accuracy: 0.66064453125\n",
      "Batch: 55, Loss: 0.9809815287590027, Accuracy: 0.68994140625\n",
      "Batch: 56, Loss: 0.9880774021148682, Accuracy: 0.67822265625\n",
      "Batch: 57, Loss: 1.073345422744751, Accuracy: 0.662109375\n",
      "Batch: 58, Loss: 1.015380620956421, Accuracy: 0.6669921875\n",
      "Batch: 59, Loss: 1.1382014751434326, Accuracy: 0.6494140625\n",
      "Batch: 60, Loss: 1.032771110534668, Accuracy: 0.6669921875\n",
      "Batch: 61, Loss: 0.9431256055831909, Accuracy: 0.69482421875\n",
      "Batch: 62, Loss: 0.9938614964485168, Accuracy: 0.68603515625\n",
      "Batch: 63, Loss: 1.0074552297592163, Accuracy: 0.6708984375\n",
      "Batch: 64, Loss: 1.0115115642547607, Accuracy: 0.654296875\n",
      "Batch: 65, Loss: 1.0773468017578125, Accuracy: 0.65771484375\n",
      "Batch: 66, Loss: 1.0307731628417969, Accuracy: 0.66552734375\n",
      "Batch: 67, Loss: 1.0481929779052734, Accuracy: 0.6689453125\n",
      "Batch: 68, Loss: 0.9697967767715454, Accuracy: 0.6748046875\n",
      "Batch: 69, Loss: 1.039405107498169, Accuracy: 0.6533203125\n",
      "Batch: 70, Loss: 1.0421679019927979, Accuracy: 0.66455078125\n",
      "Batch: 71, Loss: 1.0102205276489258, Accuracy: 0.66845703125\n",
      "Batch: 72, Loss: 1.0639615058898926, Accuracy: 0.64794921875\n",
      "Batch: 73, Loss: 1.094261646270752, Accuracy: 0.64697265625\n",
      "Batch: 74, Loss: 1.0805654525756836, Accuracy: 0.65380859375\n",
      "Batch: 75, Loss: 1.0143756866455078, Accuracy: 0.66845703125\n",
      "Batch: 76, Loss: 0.9879111051559448, Accuracy: 0.673828125\n",
      "Batch: 77, Loss: 0.9705435037612915, Accuracy: 0.69287109375\n",
      "Batch: 78, Loss: 1.0059000253677368, Accuracy: 0.68408203125\n",
      "Batch: 79, Loss: 1.0371942520141602, Accuracy: 0.673828125\n",
      "Batch: 80, Loss: 1.0260732173919678, Accuracy: 0.65283203125\n",
      "Batch: 81, Loss: 1.0772972106933594, Accuracy: 0.67431640625\n",
      "Batch: 82, Loss: 0.9693576693534851, Accuracy: 0.67138671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 83, Loss: 0.9528114199638367, Accuracy: 0.6796875\n",
      "Batch: 84, Loss: 0.9487487077713013, Accuracy: 0.6884765625\n",
      "Batch: 85, Loss: 0.9276846647262573, Accuracy: 0.693359375\n",
      "Batch: 86, Loss: 1.1039948463439941, Accuracy: 0.6416015625\n",
      "Batch: 87, Loss: 1.0006942749023438, Accuracy: 0.67822265625\n",
      "Batch: 88, Loss: 1.066983699798584, Accuracy: 0.65966796875\n",
      "Batch: 89, Loss: 1.0656540393829346, Accuracy: 0.65234375\n",
      "Batch: 90, Loss: 1.084162712097168, Accuracy: 0.6533203125\n",
      "Batch: 91, Loss: 0.9878684878349304, Accuracy: 0.67919921875\n",
      "Batch: 92, Loss: 1.1305607557296753, Accuracy: 0.6328125\n",
      "Batch: 93, Loss: 1.0593377351760864, Accuracy: 0.6640625\n",
      "Batch: 94, Loss: 1.1072845458984375, Accuracy: 0.65869140625\n",
      "Batch: 95, Loss: 1.1071619987487793, Accuracy: 0.65185546875\n",
      "Batch: 96, Loss: 1.0578598976135254, Accuracy: 0.67724609375\n",
      "Batch: 97, Loss: 1.040321707725525, Accuracy: 0.6865234375\n",
      "Batch: 98, Loss: 1.135663628578186, Accuracy: 0.6416015625\n",
      "Batch: 99, Loss: 1.0018184185028076, Accuracy: 0.68603515625\n",
      "Batch: 100, Loss: 1.1120954751968384, Accuracy: 0.65771484375\n",
      "Batch: 101, Loss: 1.1383463144302368, Accuracy: 0.638671875\n",
      "Batch: 102, Loss: 1.016664981842041, Accuracy: 0.67822265625\n",
      "Batch: 103, Loss: 1.0691423416137695, Accuracy: 0.662109375\n",
      "Batch: 104, Loss: 1.0291999578475952, Accuracy: 0.6689453125\n",
      "Batch: 105, Loss: 1.1050500869750977, Accuracy: 0.6416015625\n",
      "Batch: 106, Loss: 1.0898714065551758, Accuracy: 0.6474609375\n",
      "Batch: 107, Loss: 1.097541093826294, Accuracy: 0.6396484375\n",
      "Batch: 108, Loss: 1.0379438400268555, Accuracy: 0.6748046875\n",
      "Batch: 109, Loss: 1.0421947240829468, Accuracy: 0.6708984375\n",
      "Batch: 110, Loss: 0.9886128902435303, Accuracy: 0.6845703125\n",
      "Batch: 111, Loss: 0.9371329545974731, Accuracy: 0.69189453125\n",
      "Batch: 112, Loss: 1.026678204536438, Accuracy: 0.6845703125\n",
      "Batch: 113, Loss: 1.0561895370483398, Accuracy: 0.65869140625\n",
      "Batch: 114, Loss: 1.00822114944458, Accuracy: 0.67919921875\n",
      "Batch: 115, Loss: 1.032860279083252, Accuracy: 0.66943359375\n",
      "Batch: 116, Loss: 1.051637053489685, Accuracy: 0.6533203125\n",
      "Batch: 117, Loss: 1.045764446258545, Accuracy: 0.65625\n",
      "Batch: 118, Loss: 1.037514567375183, Accuracy: 0.6669921875\n",
      "Batch: 119, Loss: 1.0130765438079834, Accuracy: 0.658203125\n",
      "Batch: 120, Loss: 1.017829418182373, Accuracy: 0.6630859375\n",
      "Batch: 121, Loss: 1.0266625881195068, Accuracy: 0.658203125\n",
      "Batch: 122, Loss: 0.986751139163971, Accuracy: 0.68603515625\n",
      "Batch: 123, Loss: 1.0041518211364746, Accuracy: 0.681640625\n",
      "Batch: 124, Loss: 0.9885544776916504, Accuracy: 0.681640625\n",
      "Batch: 125, Loss: 1.0326976776123047, Accuracy: 0.6650390625\n",
      "Batch: 126, Loss: 0.9672144055366516, Accuracy: 0.68701171875\n",
      "Batch: 127, Loss: 0.963181734085083, Accuracy: 0.685546875\n",
      "Batch: 128, Loss: 1.1618447303771973, Accuracy: 0.63671875\n",
      "Batch: 129, Loss: 1.181862711906433, Accuracy: 0.62646484375\n",
      "Batch: 130, Loss: 1.1452291011810303, Accuracy: 0.6376953125\n",
      "Batch: 131, Loss: 1.084719181060791, Accuracy: 0.65185546875\n",
      "Batch: 132, Loss: 0.9658075571060181, Accuracy: 0.68359375\n",
      "Batch: 133, Loss: 0.9795286655426025, Accuracy: 0.68896484375\n",
      "Batch: 134, Loss: 1.072275161743164, Accuracy: 0.65673828125\n",
      "Batch: 135, Loss: 1.0488722324371338, Accuracy: 0.65673828125\n",
      "Batch: 136, Loss: 0.9797438979148865, Accuracy: 0.673828125\n",
      "Batch: 137, Loss: 1.046037197113037, Accuracy: 0.66650390625\n",
      "Batch: 138, Loss: 0.9357610940933228, Accuracy: 0.7001953125\n",
      "Batch: 139, Loss: 1.018660068511963, Accuracy: 0.67041015625\n",
      "Batch: 140, Loss: 0.9583249688148499, Accuracy: 0.6865234375\n",
      "Batch: 141, Loss: 1.0791910886764526, Accuracy: 0.64453125\n",
      "Batch: 142, Loss: 0.9473375082015991, Accuracy: 0.69580078125\n",
      "Batch: 143, Loss: 1.0046770572662354, Accuracy: 0.68798828125\n",
      "Batch: 144, Loss: 1.0627961158752441, Accuracy: 0.67236328125\n",
      "Batch: 145, Loss: 1.0322587490081787, Accuracy: 0.68798828125\n",
      "Batch: 146, Loss: 1.0915403366088867, Accuracy: 0.65234375\n",
      "Batch: 147, Loss: 1.0529966354370117, Accuracy: 0.666015625\n",
      "Batch: 148, Loss: 1.038461446762085, Accuracy: 0.65625\n",
      "Batch: 149, Loss: 1.0073539018630981, Accuracy: 0.66845703125\n",
      "Batch: 150, Loss: 0.8598395586013794, Accuracy: 0.7216796875\n",
      "Batch: 151, Loss: 0.8971574306488037, Accuracy: 0.7041015625\n",
      "Batch: 152, Loss: 0.9660555124282837, Accuracy: 0.6875\n",
      "Batch: 153, Loss: 0.9333940148353577, Accuracy: 0.7001953125\n",
      "Batch: 154, Loss: 0.9403295516967773, Accuracy: 0.697265625\n",
      "Batch: 155, Loss: 1.0369846820831299, Accuracy: 0.66357421875\n",
      "Batch: 156, Loss: 0.9479373097419739, Accuracy: 0.6953125\n",
      "Batch: 157, Loss: 0.9418072700500488, Accuracy: 0.6923828125\n",
      "Batch: 158, Loss: 0.9441701173782349, Accuracy: 0.69775390625\n",
      "Batch: 159, Loss: 0.9280595779418945, Accuracy: 0.70361328125\n",
      "Batch: 160, Loss: 0.9636133909225464, Accuracy: 0.68798828125\n",
      "Batch: 161, Loss: 0.9850850105285645, Accuracy: 0.6728515625\n",
      "Batch: 162, Loss: 0.9797176122665405, Accuracy: 0.6904296875\n",
      "Batch: 163, Loss: 1.0357630252838135, Accuracy: 0.6650390625\n",
      "Batch: 164, Loss: 1.0622626543045044, Accuracy: 0.6611328125\n",
      "Batch: 165, Loss: 0.9779441952705383, Accuracy: 0.689453125\n",
      "Batch: 166, Loss: 1.0158421993255615, Accuracy: 0.6767578125\n",
      "Batch: 167, Loss: 0.9481616020202637, Accuracy: 0.6962890625\n",
      "Batch: 168, Loss: 0.9101141691207886, Accuracy: 0.70361328125\n",
      "Batch: 169, Loss: 0.9849134683609009, Accuracy: 0.67724609375\n",
      "Batch: 170, Loss: 1.0544642210006714, Accuracy: 0.666015625\n",
      "Batch: 171, Loss: 0.9867625832557678, Accuracy: 0.677734375\n",
      "Batch: 172, Loss: 0.9559571743011475, Accuracy: 0.67822265625\n",
      "Batch: 173, Loss: 1.03399658203125, Accuracy: 0.67919921875\n",
      "Batch: 174, Loss: 0.8768259286880493, Accuracy: 0.71875\n",
      "Batch: 175, Loss: 1.0347403287887573, Accuracy: 0.65771484375\n",
      "Batch: 176, Loss: 1.0853677988052368, Accuracy: 0.64697265625\n",
      "Batch: 177, Loss: 0.9854527115821838, Accuracy: 0.6845703125\n",
      "Batch: 178, Loss: 0.953631579875946, Accuracy: 0.68359375\n",
      "Batch: 179, Loss: 0.98211270570755, Accuracy: 0.681640625\n",
      "Batch: 180, Loss: 1.058983564376831, Accuracy: 0.6611328125\n",
      "Epoch 19/200\n",
      "Batch: 1, Loss: 1.4273029565811157, Accuracy: 0.60791015625\n",
      "Batch: 2, Loss: 1.0078659057617188, Accuracy: 0.6630859375\n",
      "Batch: 3, Loss: 0.9946622252464294, Accuracy: 0.68115234375\n",
      "Batch: 4, Loss: 1.047029972076416, Accuracy: 0.66796875\n",
      "Batch: 5, Loss: 1.0485448837280273, Accuracy: 0.65185546875\n",
      "Batch: 6, Loss: 1.0350687503814697, Accuracy: 0.6708984375\n",
      "Batch: 7, Loss: 0.9481723308563232, Accuracy: 0.68212890625\n",
      "Batch: 8, Loss: 1.0182502269744873, Accuracy: 0.66357421875\n",
      "Batch: 9, Loss: 1.0942671298980713, Accuracy: 0.669921875\n",
      "Batch: 10, Loss: 1.0202643871307373, Accuracy: 0.67138671875\n",
      "Batch: 11, Loss: 1.101186752319336, Accuracy: 0.658203125\n",
      "Batch: 12, Loss: 0.9695777893066406, Accuracy: 0.693359375\n",
      "Batch: 13, Loss: 1.0311493873596191, Accuracy: 0.66650390625\n",
      "Batch: 14, Loss: 1.0357860326766968, Accuracy: 0.6708984375\n",
      "Batch: 15, Loss: 1.0272464752197266, Accuracy: 0.68359375\n",
      "Batch: 16, Loss: 1.092265009880066, Accuracy: 0.6630859375\n",
      "Batch: 17, Loss: 1.0066534280776978, Accuracy: 0.68310546875\n",
      "Batch: 18, Loss: 1.0682661533355713, Accuracy: 0.65478515625\n",
      "Batch: 19, Loss: 1.0500279664993286, Accuracy: 0.673828125\n",
      "Batch: 20, Loss: 0.960598349571228, Accuracy: 0.6884765625\n",
      "Batch: 21, Loss: 1.1395398378372192, Accuracy: 0.640625\n",
      "Batch: 22, Loss: 1.0198068618774414, Accuracy: 0.67919921875\n",
      "Batch: 23, Loss: 0.9658572673797607, Accuracy: 0.69384765625\n",
      "Batch: 24, Loss: 1.004884123802185, Accuracy: 0.6708984375\n",
      "Batch: 25, Loss: 0.9749389886856079, Accuracy: 0.6875\n",
      "Batch: 26, Loss: 1.0177557468414307, Accuracy: 0.677734375\n",
      "Batch: 27, Loss: 1.033848524093628, Accuracy: 0.671875\n",
      "Batch: 28, Loss: 0.9782085418701172, Accuracy: 0.67919921875\n",
      "Batch: 29, Loss: 1.0734565258026123, Accuracy: 0.6611328125\n",
      "Batch: 30, Loss: 1.0193352699279785, Accuracy: 0.68505859375\n",
      "Batch: 31, Loss: 1.150190830230713, Accuracy: 0.638671875\n",
      "Batch: 32, Loss: 1.070099115371704, Accuracy: 0.666015625\n",
      "Batch: 33, Loss: 1.083626389503479, Accuracy: 0.65234375\n",
      "Batch: 34, Loss: 1.1178133487701416, Accuracy: 0.64306640625\n",
      "Batch: 35, Loss: 1.139294981956482, Accuracy: 0.63671875\n",
      "Batch: 36, Loss: 1.0724821090698242, Accuracy: 0.65185546875\n",
      "Batch: 37, Loss: 1.0427918434143066, Accuracy: 0.6767578125\n",
      "Batch: 38, Loss: 1.1104546785354614, Accuracy: 0.6337890625\n",
      "Batch: 39, Loss: 1.0511406660079956, Accuracy: 0.666015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 40, Loss: 1.0878045558929443, Accuracy: 0.6552734375\n",
      "Batch: 41, Loss: 1.0645275115966797, Accuracy: 0.6533203125\n",
      "Batch: 42, Loss: 0.9983338117599487, Accuracy: 0.66650390625\n",
      "Batch: 43, Loss: 0.994249701499939, Accuracy: 0.68896484375\n",
      "Batch: 44, Loss: 0.9128183126449585, Accuracy: 0.7001953125\n",
      "Batch: 45, Loss: 0.9713517427444458, Accuracy: 0.68212890625\n",
      "Batch: 46, Loss: 0.9342193007469177, Accuracy: 0.67529296875\n",
      "Batch: 47, Loss: 1.011040210723877, Accuracy: 0.67236328125\n",
      "Batch: 48, Loss: 0.960446298122406, Accuracy: 0.68994140625\n",
      "Batch: 49, Loss: 0.9722139835357666, Accuracy: 0.68701171875\n",
      "Batch: 50, Loss: 1.0258307456970215, Accuracy: 0.67138671875\n",
      "Batch: 51, Loss: 0.9768373966217041, Accuracy: 0.6884765625\n",
      "Batch: 52, Loss: 0.9448583722114563, Accuracy: 0.6904296875\n",
      "Batch: 53, Loss: 0.9580147862434387, Accuracy: 0.681640625\n",
      "Batch: 54, Loss: 0.9885444641113281, Accuracy: 0.66162109375\n",
      "Batch: 55, Loss: 0.9599066972732544, Accuracy: 0.69775390625\n",
      "Batch: 56, Loss: 0.9670354723930359, Accuracy: 0.68701171875\n",
      "Batch: 57, Loss: 1.0486476421356201, Accuracy: 0.669921875\n",
      "Batch: 58, Loss: 1.0060327053070068, Accuracy: 0.67333984375\n",
      "Batch: 59, Loss: 1.1306867599487305, Accuracy: 0.650390625\n",
      "Batch: 60, Loss: 1.0291657447814941, Accuracy: 0.66845703125\n",
      "Batch: 61, Loss: 0.9525184631347656, Accuracy: 0.69580078125\n",
      "Batch: 62, Loss: 0.9661330580711365, Accuracy: 0.6953125\n",
      "Batch: 63, Loss: 1.0071914196014404, Accuracy: 0.6787109375\n",
      "Batch: 64, Loss: 1.0222949981689453, Accuracy: 0.6669921875\n",
      "Batch: 65, Loss: 1.067255973815918, Accuracy: 0.662109375\n",
      "Batch: 66, Loss: 1.0435361862182617, Accuracy: 0.666015625\n",
      "Batch: 67, Loss: 1.0289254188537598, Accuracy: 0.66748046875\n",
      "Batch: 68, Loss: 0.9423304796218872, Accuracy: 0.69287109375\n",
      "Batch: 69, Loss: 1.0180439949035645, Accuracy: 0.6591796875\n",
      "Batch: 70, Loss: 1.0454442501068115, Accuracy: 0.6484375\n",
      "Batch: 71, Loss: 1.0163824558258057, Accuracy: 0.6630859375\n",
      "Batch: 72, Loss: 1.0494884252548218, Accuracy: 0.654296875\n",
      "Batch: 73, Loss: 1.0760116577148438, Accuracy: 0.6484375\n",
      "Batch: 74, Loss: 1.0612444877624512, Accuracy: 0.66357421875\n",
      "Batch: 75, Loss: 0.9838418960571289, Accuracy: 0.67822265625\n",
      "Batch: 76, Loss: 0.9918476939201355, Accuracy: 0.67431640625\n",
      "Batch: 77, Loss: 0.9346261620521545, Accuracy: 0.708984375\n",
      "Batch: 78, Loss: 1.0069340467453003, Accuracy: 0.6669921875\n",
      "Batch: 79, Loss: 1.0158663988113403, Accuracy: 0.6728515625\n",
      "Batch: 80, Loss: 0.9960514307022095, Accuracy: 0.66748046875\n",
      "Batch: 81, Loss: 1.0545908212661743, Accuracy: 0.6767578125\n",
      "Batch: 82, Loss: 0.9560869932174683, Accuracy: 0.68017578125\n",
      "Batch: 83, Loss: 0.9507226943969727, Accuracy: 0.6884765625\n",
      "Batch: 84, Loss: 0.9320995807647705, Accuracy: 0.68798828125\n",
      "Batch: 85, Loss: 0.9260704517364502, Accuracy: 0.6904296875\n",
      "Batch: 86, Loss: 1.0903666019439697, Accuracy: 0.64599609375\n",
      "Batch: 87, Loss: 0.9984070062637329, Accuracy: 0.673828125\n",
      "Batch: 88, Loss: 1.062528133392334, Accuracy: 0.6552734375\n",
      "Batch: 89, Loss: 1.057757019996643, Accuracy: 0.6630859375\n",
      "Batch: 90, Loss: 1.0920078754425049, Accuracy: 0.6376953125\n",
      "Batch: 91, Loss: 0.982404351234436, Accuracy: 0.68505859375\n",
      "Batch: 92, Loss: 1.1184377670288086, Accuracy: 0.6279296875\n",
      "Batch: 93, Loss: 1.0519827604293823, Accuracy: 0.65771484375\n",
      "Batch: 94, Loss: 1.08704674243927, Accuracy: 0.669921875\n",
      "Batch: 95, Loss: 1.105165958404541, Accuracy: 0.65380859375\n",
      "Batch: 96, Loss: 1.0479354858398438, Accuracy: 0.67919921875\n",
      "Batch: 97, Loss: 1.0317785739898682, Accuracy: 0.68017578125\n",
      "Batch: 98, Loss: 1.1300904750823975, Accuracy: 0.6455078125\n",
      "Batch: 99, Loss: 0.976001501083374, Accuracy: 0.69384765625\n",
      "Batch: 100, Loss: 1.1158286333084106, Accuracy: 0.65576171875\n",
      "Batch: 101, Loss: 1.1259219646453857, Accuracy: 0.6474609375\n",
      "Batch: 102, Loss: 1.0000286102294922, Accuracy: 0.6796875\n",
      "Batch: 103, Loss: 1.0564351081848145, Accuracy: 0.66064453125\n",
      "Batch: 104, Loss: 1.0248074531555176, Accuracy: 0.6650390625\n",
      "Batch: 105, Loss: 1.0773128271102905, Accuracy: 0.65380859375\n",
      "Batch: 106, Loss: 1.0582122802734375, Accuracy: 0.65478515625\n",
      "Batch: 107, Loss: 1.069221019744873, Accuracy: 0.65966796875\n",
      "Batch: 108, Loss: 1.0473898649215698, Accuracy: 0.6689453125\n",
      "Batch: 109, Loss: 1.010434627532959, Accuracy: 0.67578125\n",
      "Batch: 110, Loss: 0.9724173545837402, Accuracy: 0.68408203125\n",
      "Batch: 111, Loss: 0.9168230891227722, Accuracy: 0.69482421875\n",
      "Batch: 112, Loss: 1.0080902576446533, Accuracy: 0.68505859375\n",
      "Batch: 113, Loss: 1.0400621891021729, Accuracy: 0.66259765625\n",
      "Batch: 114, Loss: 1.0145635604858398, Accuracy: 0.6669921875\n",
      "Batch: 115, Loss: 1.0091447830200195, Accuracy: 0.671875\n",
      "Batch: 116, Loss: 1.016401767730713, Accuracy: 0.66455078125\n",
      "Batch: 117, Loss: 1.0213814973831177, Accuracy: 0.6650390625\n",
      "Batch: 118, Loss: 1.0134217739105225, Accuracy: 0.67041015625\n",
      "Batch: 119, Loss: 0.9954327344894409, Accuracy: 0.66015625\n",
      "Batch: 120, Loss: 1.0028831958770752, Accuracy: 0.66943359375\n",
      "Batch: 121, Loss: 1.0326128005981445, Accuracy: 0.6689453125\n",
      "Batch: 122, Loss: 0.9764548540115356, Accuracy: 0.68359375\n",
      "Batch: 123, Loss: 1.0032683610916138, Accuracy: 0.6865234375\n",
      "Batch: 124, Loss: 0.9749035835266113, Accuracy: 0.6845703125\n",
      "Batch: 125, Loss: 1.0330928564071655, Accuracy: 0.66552734375\n",
      "Batch: 126, Loss: 0.9539629220962524, Accuracy: 0.6943359375\n",
      "Batch: 127, Loss: 0.9399711489677429, Accuracy: 0.703125\n",
      "Batch: 128, Loss: 1.1424555778503418, Accuracy: 0.6484375\n",
      "Batch: 129, Loss: 1.147350549697876, Accuracy: 0.64404296875\n",
      "Batch: 130, Loss: 1.1413111686706543, Accuracy: 0.63037109375\n",
      "Batch: 131, Loss: 1.0883772373199463, Accuracy: 0.65478515625\n",
      "Batch: 132, Loss: 0.9474097490310669, Accuracy: 0.70166015625\n",
      "Batch: 133, Loss: 0.9516610503196716, Accuracy: 0.70458984375\n",
      "Batch: 134, Loss: 1.0589920282363892, Accuracy: 0.650390625\n",
      "Batch: 135, Loss: 1.02276611328125, Accuracy: 0.669921875\n",
      "Batch: 136, Loss: 0.9564107656478882, Accuracy: 0.6806640625\n",
      "Batch: 137, Loss: 1.038867473602295, Accuracy: 0.66357421875\n",
      "Batch: 138, Loss: 0.9007839560508728, Accuracy: 0.71826171875\n",
      "Batch: 139, Loss: 0.9893933534622192, Accuracy: 0.68701171875\n",
      "Batch: 140, Loss: 0.9511865377426147, Accuracy: 0.6982421875\n",
      "Batch: 141, Loss: 1.0374908447265625, Accuracy: 0.6630859375\n",
      "Batch: 142, Loss: 0.9399697780609131, Accuracy: 0.6875\n",
      "Batch: 143, Loss: 0.9787033200263977, Accuracy: 0.68896484375\n",
      "Batch: 144, Loss: 1.039198875427246, Accuracy: 0.6845703125\n",
      "Batch: 145, Loss: 1.0130908489227295, Accuracy: 0.68994140625\n",
      "Batch: 146, Loss: 1.0643916130065918, Accuracy: 0.666015625\n",
      "Batch: 147, Loss: 1.0118714570999146, Accuracy: 0.67529296875\n",
      "Batch: 148, Loss: 1.0392475128173828, Accuracy: 0.6572265625\n",
      "Batch: 149, Loss: 0.9838762283325195, Accuracy: 0.6787109375\n",
      "Batch: 150, Loss: 0.8711504936218262, Accuracy: 0.7158203125\n",
      "Batch: 151, Loss: 0.8772121071815491, Accuracy: 0.7177734375\n",
      "Batch: 152, Loss: 0.9214363098144531, Accuracy: 0.703125\n",
      "Batch: 153, Loss: 0.9135736227035522, Accuracy: 0.7021484375\n",
      "Batch: 154, Loss: 0.9387715458869934, Accuracy: 0.6962890625\n",
      "Batch: 155, Loss: 1.017465591430664, Accuracy: 0.6748046875\n",
      "Batch: 156, Loss: 0.933814287185669, Accuracy: 0.70068359375\n",
      "Batch: 157, Loss: 0.9125826358795166, Accuracy: 0.69091796875\n",
      "Batch: 158, Loss: 0.9198232293128967, Accuracy: 0.71240234375\n",
      "Batch: 159, Loss: 0.8983557224273682, Accuracy: 0.708984375\n",
      "Batch: 160, Loss: 0.9505469799041748, Accuracy: 0.68798828125\n",
      "Batch: 161, Loss: 0.9738160371780396, Accuracy: 0.67529296875\n",
      "Batch: 162, Loss: 0.9496857523918152, Accuracy: 0.71044921875\n",
      "Batch: 163, Loss: 1.014725685119629, Accuracy: 0.66748046875\n",
      "Batch: 164, Loss: 1.0458579063415527, Accuracy: 0.67138671875\n",
      "Batch: 165, Loss: 0.9710210561752319, Accuracy: 0.68896484375\n",
      "Batch: 166, Loss: 0.9942315220832825, Accuracy: 0.68603515625\n",
      "Batch: 167, Loss: 0.9484056234359741, Accuracy: 0.68896484375\n",
      "Batch: 168, Loss: 0.9001438617706299, Accuracy: 0.71630859375\n",
      "Batch: 169, Loss: 0.9659585356712341, Accuracy: 0.68896484375\n",
      "Batch: 170, Loss: 1.035915493965149, Accuracy: 0.671875\n",
      "Batch: 171, Loss: 0.9657111167907715, Accuracy: 0.67919921875\n",
      "Batch: 172, Loss: 0.9432002305984497, Accuracy: 0.6884765625\n",
      "Batch: 173, Loss: 1.0147234201431274, Accuracy: 0.68994140625\n",
      "Batch: 174, Loss: 0.8633420467376709, Accuracy: 0.72705078125\n",
      "Batch: 175, Loss: 1.0283946990966797, Accuracy: 0.662109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 176, Loss: 1.0634169578552246, Accuracy: 0.6708984375\n",
      "Batch: 177, Loss: 0.9890379905700684, Accuracy: 0.68603515625\n",
      "Batch: 178, Loss: 0.9400243759155273, Accuracy: 0.6923828125\n",
      "Batch: 179, Loss: 0.9733622074127197, Accuracy: 0.681640625\n",
      "Batch: 180, Loss: 1.0498771667480469, Accuracy: 0.66455078125\n",
      "Epoch 20/200\n",
      "Batch: 1, Loss: 1.408689022064209, Accuracy: 0.6064453125\n",
      "Batch: 2, Loss: 0.9849637150764465, Accuracy: 0.68408203125\n",
      "Batch: 3, Loss: 0.9912062883377075, Accuracy: 0.681640625\n",
      "Batch: 4, Loss: 1.0209641456604004, Accuracy: 0.6796875\n",
      "Batch: 5, Loss: 1.0290756225585938, Accuracy: 0.671875\n",
      "Batch: 6, Loss: 1.0465373992919922, Accuracy: 0.6689453125\n",
      "Batch: 7, Loss: 0.9525030851364136, Accuracy: 0.6953125\n",
      "Batch: 8, Loss: 1.004629373550415, Accuracy: 0.66845703125\n",
      "Batch: 9, Loss: 1.0664421319961548, Accuracy: 0.67626953125\n",
      "Batch: 10, Loss: 1.0315269231796265, Accuracy: 0.6767578125\n",
      "Batch: 11, Loss: 1.0640535354614258, Accuracy: 0.66845703125\n",
      "Batch: 12, Loss: 0.966956377029419, Accuracy: 0.69287109375\n",
      "Batch: 13, Loss: 1.0025781393051147, Accuracy: 0.67138671875\n",
      "Batch: 14, Loss: 1.0027689933776855, Accuracy: 0.68994140625\n",
      "Batch: 15, Loss: 0.984765350818634, Accuracy: 0.68994140625\n",
      "Batch: 16, Loss: 1.0614739656448364, Accuracy: 0.66748046875\n",
      "Batch: 17, Loss: 0.9708955883979797, Accuracy: 0.69189453125\n",
      "Batch: 18, Loss: 1.051518440246582, Accuracy: 0.6650390625\n",
      "Batch: 19, Loss: 1.027968168258667, Accuracy: 0.67724609375\n",
      "Batch: 20, Loss: 0.9386186003684998, Accuracy: 0.7021484375\n",
      "Batch: 21, Loss: 1.111886739730835, Accuracy: 0.6513671875\n",
      "Batch: 22, Loss: 1.0032739639282227, Accuracy: 0.6806640625\n",
      "Batch: 23, Loss: 0.9559836387634277, Accuracy: 0.70166015625\n",
      "Batch: 24, Loss: 0.9891622066497803, Accuracy: 0.67431640625\n",
      "Batch: 25, Loss: 0.9659009575843811, Accuracy: 0.68896484375\n",
      "Batch: 26, Loss: 0.9845211505889893, Accuracy: 0.68603515625\n",
      "Batch: 27, Loss: 1.011369228363037, Accuracy: 0.67529296875\n",
      "Batch: 28, Loss: 0.9562556743621826, Accuracy: 0.693359375\n",
      "Batch: 29, Loss: 1.0451910495758057, Accuracy: 0.6640625\n",
      "Batch: 30, Loss: 1.0027626752853394, Accuracy: 0.67919921875\n",
      "Batch: 31, Loss: 1.143471598625183, Accuracy: 0.6455078125\n",
      "Batch: 32, Loss: 1.0383167266845703, Accuracy: 0.67578125\n",
      "Batch: 33, Loss: 1.0627450942993164, Accuracy: 0.64892578125\n",
      "Batch: 34, Loss: 1.1003410816192627, Accuracy: 0.6552734375\n",
      "Batch: 35, Loss: 1.11922287940979, Accuracy: 0.63720703125\n",
      "Batch: 36, Loss: 1.0644294023513794, Accuracy: 0.66552734375\n",
      "Batch: 37, Loss: 1.0365405082702637, Accuracy: 0.6650390625\n",
      "Batch: 38, Loss: 1.0768495798110962, Accuracy: 0.6455078125\n",
      "Batch: 39, Loss: 1.0233368873596191, Accuracy: 0.6767578125\n",
      "Batch: 40, Loss: 1.084712028503418, Accuracy: 0.65625\n",
      "Batch: 41, Loss: 1.04001784324646, Accuracy: 0.658203125\n",
      "Batch: 42, Loss: 0.9881125688552856, Accuracy: 0.68017578125\n",
      "Batch: 43, Loss: 0.9731122851371765, Accuracy: 0.6953125\n",
      "Batch: 44, Loss: 0.9092720746994019, Accuracy: 0.70947265625\n",
      "Batch: 45, Loss: 0.9480901956558228, Accuracy: 0.69091796875\n",
      "Batch: 46, Loss: 0.9097799062728882, Accuracy: 0.6845703125\n",
      "Batch: 47, Loss: 1.004272222518921, Accuracy: 0.6689453125\n",
      "Batch: 48, Loss: 0.9371427297592163, Accuracy: 0.6923828125\n",
      "Batch: 49, Loss: 0.9506910443305969, Accuracy: 0.685546875\n",
      "Batch: 50, Loss: 1.0226070880889893, Accuracy: 0.67236328125\n",
      "Batch: 51, Loss: 0.9734329581260681, Accuracy: 0.6962890625\n",
      "Batch: 52, Loss: 0.9480745792388916, Accuracy: 0.6796875\n",
      "Batch: 53, Loss: 0.9552322626113892, Accuracy: 0.6884765625\n",
      "Batch: 54, Loss: 0.9967445135116577, Accuracy: 0.673828125\n",
      "Batch: 55, Loss: 0.9372880458831787, Accuracy: 0.6953125\n",
      "Batch: 56, Loss: 0.9456877112388611, Accuracy: 0.697265625\n",
      "Batch: 57, Loss: 1.0370216369628906, Accuracy: 0.677734375\n",
      "Batch: 58, Loss: 0.9866018295288086, Accuracy: 0.669921875\n",
      "Batch: 59, Loss: 1.1166632175445557, Accuracy: 0.64697265625\n",
      "Batch: 60, Loss: 0.9898937940597534, Accuracy: 0.6787109375\n",
      "Batch: 61, Loss: 0.9212552309036255, Accuracy: 0.70947265625\n",
      "Batch: 62, Loss: 0.93675696849823, Accuracy: 0.71142578125\n",
      "Batch: 63, Loss: 0.9795148372650146, Accuracy: 0.68408203125\n",
      "Batch: 64, Loss: 1.001556634902954, Accuracy: 0.66748046875\n",
      "Batch: 65, Loss: 1.0555483102798462, Accuracy: 0.67333984375\n",
      "Batch: 66, Loss: 1.0231258869171143, Accuracy: 0.666015625\n",
      "Batch: 67, Loss: 1.0112240314483643, Accuracy: 0.6767578125\n",
      "Batch: 68, Loss: 0.9318637847900391, Accuracy: 0.6962890625\n",
      "Batch: 69, Loss: 1.0073597431182861, Accuracy: 0.67431640625\n",
      "Batch: 70, Loss: 1.0020933151245117, Accuracy: 0.67431640625\n",
      "Batch: 71, Loss: 0.9935228228569031, Accuracy: 0.67431640625\n",
      "Batch: 72, Loss: 1.0209059715270996, Accuracy: 0.66162109375\n",
      "Batch: 73, Loss: 1.0484858751296997, Accuracy: 0.64208984375\n",
      "Batch: 74, Loss: 1.0524563789367676, Accuracy: 0.66259765625\n",
      "Batch: 75, Loss: 0.9661860466003418, Accuracy: 0.67578125\n",
      "Batch: 76, Loss: 0.9522521495819092, Accuracy: 0.6875\n",
      "Batch: 77, Loss: 0.923564612865448, Accuracy: 0.708984375\n",
      "Batch: 78, Loss: 0.9713831543922424, Accuracy: 0.6943359375\n",
      "Batch: 79, Loss: 0.9961807131767273, Accuracy: 0.68896484375\n",
      "Batch: 80, Loss: 1.0038065910339355, Accuracy: 0.6748046875\n",
      "Batch: 81, Loss: 1.0406569242477417, Accuracy: 0.66845703125\n",
      "Batch: 82, Loss: 0.9350460767745972, Accuracy: 0.68359375\n",
      "Batch: 83, Loss: 0.935905933380127, Accuracy: 0.68701171875\n",
      "Batch: 84, Loss: 0.9299827218055725, Accuracy: 0.6982421875\n",
      "Batch: 85, Loss: 0.9057719707489014, Accuracy: 0.69921875\n",
      "Batch: 86, Loss: 1.0777143239974976, Accuracy: 0.65478515625\n",
      "Batch: 87, Loss: 0.9600803852081299, Accuracy: 0.6767578125\n",
      "Batch: 88, Loss: 1.056642770767212, Accuracy: 0.654296875\n",
      "Batch: 89, Loss: 1.026379108428955, Accuracy: 0.67138671875\n",
      "Batch: 90, Loss: 1.0453028678894043, Accuracy: 0.65087890625\n",
      "Batch: 91, Loss: 0.9635124206542969, Accuracy: 0.693359375\n",
      "Batch: 92, Loss: 1.0920791625976562, Accuracy: 0.6474609375\n",
      "Batch: 93, Loss: 1.034049153327942, Accuracy: 0.6708984375\n",
      "Batch: 94, Loss: 1.0644947290420532, Accuracy: 0.6650390625\n",
      "Batch: 95, Loss: 1.0771429538726807, Accuracy: 0.6640625\n",
      "Batch: 96, Loss: 1.0212615728378296, Accuracy: 0.6748046875\n",
      "Batch: 97, Loss: 1.0106732845306396, Accuracy: 0.6865234375\n",
      "Batch: 98, Loss: 1.1147584915161133, Accuracy: 0.65234375\n",
      "Batch: 99, Loss: 0.9818118810653687, Accuracy: 0.689453125\n",
      "Batch: 100, Loss: 1.0911239385604858, Accuracy: 0.65771484375\n",
      "Batch: 101, Loss: 1.092860221862793, Accuracy: 0.6484375\n",
      "Batch: 102, Loss: 0.9835066795349121, Accuracy: 0.67919921875\n",
      "Batch: 103, Loss: 1.027188777923584, Accuracy: 0.66943359375\n",
      "Batch: 104, Loss: 1.0126595497131348, Accuracy: 0.669921875\n",
      "Batch: 105, Loss: 1.072141408920288, Accuracy: 0.650390625\n",
      "Batch: 106, Loss: 1.0612468719482422, Accuracy: 0.6533203125\n",
      "Batch: 107, Loss: 1.054136037826538, Accuracy: 0.66748046875\n",
      "Batch: 108, Loss: 1.016031265258789, Accuracy: 0.666015625\n",
      "Batch: 109, Loss: 1.0288488864898682, Accuracy: 0.6806640625\n",
      "Batch: 110, Loss: 0.9531009197235107, Accuracy: 0.67724609375\n",
      "Batch: 111, Loss: 0.9046051502227783, Accuracy: 0.70458984375\n",
      "Batch: 112, Loss: 0.990621030330658, Accuracy: 0.6865234375\n",
      "Batch: 113, Loss: 1.0270711183547974, Accuracy: 0.67138671875\n",
      "Batch: 114, Loss: 0.9932737946510315, Accuracy: 0.6787109375\n",
      "Batch: 115, Loss: 1.0104585886001587, Accuracy: 0.67724609375\n",
      "Batch: 116, Loss: 1.0098910331726074, Accuracy: 0.677734375\n",
      "Batch: 117, Loss: 1.0011098384857178, Accuracy: 0.6865234375\n",
      "Batch: 118, Loss: 0.9909425377845764, Accuracy: 0.6796875\n",
      "Batch: 119, Loss: 0.9986299276351929, Accuracy: 0.6650390625\n",
      "Batch: 120, Loss: 0.9902020692825317, Accuracy: 0.66943359375\n",
      "Batch: 121, Loss: 1.002421498298645, Accuracy: 0.66943359375\n",
      "Batch: 122, Loss: 0.9545159339904785, Accuracy: 0.68896484375\n",
      "Batch: 123, Loss: 0.9812324643135071, Accuracy: 0.68994140625\n",
      "Batch: 124, Loss: 0.9548051357269287, Accuracy: 0.6875\n",
      "Batch: 125, Loss: 1.00810968875885, Accuracy: 0.669921875\n",
      "Batch: 126, Loss: 0.92568439245224, Accuracy: 0.69921875\n",
      "Batch: 127, Loss: 0.937993049621582, Accuracy: 0.69677734375\n",
      "Batch: 128, Loss: 1.1303116083145142, Accuracy: 0.658203125\n",
      "Batch: 129, Loss: 1.136772871017456, Accuracy: 0.64404296875\n",
      "Batch: 130, Loss: 1.1385282278060913, Accuracy: 0.6357421875\n",
      "Batch: 131, Loss: 1.0638248920440674, Accuracy: 0.66455078125\n",
      "Batch: 132, Loss: 0.9361318945884705, Accuracy: 0.6982421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 133, Loss: 0.928737223148346, Accuracy: 0.71484375\n",
      "Batch: 134, Loss: 1.0467188358306885, Accuracy: 0.66162109375\n",
      "Batch: 135, Loss: 1.0202040672302246, Accuracy: 0.67529296875\n",
      "Batch: 136, Loss: 0.9612702131271362, Accuracy: 0.68115234375\n",
      "Batch: 137, Loss: 1.0131239891052246, Accuracy: 0.669921875\n",
      "Batch: 138, Loss: 0.883414626121521, Accuracy: 0.71728515625\n",
      "Batch: 139, Loss: 0.959912896156311, Accuracy: 0.69677734375\n",
      "Batch: 140, Loss: 0.9222913384437561, Accuracy: 0.69677734375\n",
      "Batch: 141, Loss: 1.019964337348938, Accuracy: 0.67578125\n",
      "Batch: 142, Loss: 0.921845555305481, Accuracy: 0.708984375\n",
      "Batch: 143, Loss: 0.9736791253089905, Accuracy: 0.69482421875\n",
      "Batch: 144, Loss: 1.0339384078979492, Accuracy: 0.69091796875\n",
      "Batch: 145, Loss: 0.9929091930389404, Accuracy: 0.6875\n",
      "Batch: 146, Loss: 1.0584964752197266, Accuracy: 0.6689453125\n",
      "Batch: 147, Loss: 1.0000925064086914, Accuracy: 0.67333984375\n",
      "Batch: 148, Loss: 1.0214476585388184, Accuracy: 0.66845703125\n",
      "Batch: 149, Loss: 0.992236852645874, Accuracy: 0.6845703125\n",
      "Batch: 150, Loss: 0.844508707523346, Accuracy: 0.7275390625\n",
      "Batch: 151, Loss: 0.8683766722679138, Accuracy: 0.7216796875\n",
      "Batch: 152, Loss: 0.9244580864906311, Accuracy: 0.69775390625\n",
      "Batch: 153, Loss: 0.8934760093688965, Accuracy: 0.72119140625\n",
      "Batch: 154, Loss: 0.9198640584945679, Accuracy: 0.6982421875\n",
      "Batch: 155, Loss: 1.0029596090316772, Accuracy: 0.6826171875\n",
      "Batch: 156, Loss: 0.9100024104118347, Accuracy: 0.701171875\n",
      "Batch: 157, Loss: 0.9008475542068481, Accuracy: 0.70556640625\n",
      "Batch: 158, Loss: 0.9074198007583618, Accuracy: 0.72021484375\n",
      "Batch: 159, Loss: 0.8923884034156799, Accuracy: 0.7197265625\n",
      "Batch: 160, Loss: 0.9324266910552979, Accuracy: 0.69189453125\n",
      "Batch: 161, Loss: 0.9512420892715454, Accuracy: 0.68994140625\n",
      "Batch: 162, Loss: 0.9386923313140869, Accuracy: 0.705078125\n",
      "Batch: 163, Loss: 1.0123496055603027, Accuracy: 0.67236328125\n",
      "Batch: 164, Loss: 1.015251874923706, Accuracy: 0.66748046875\n",
      "Batch: 165, Loss: 0.9568732380867004, Accuracy: 0.69482421875\n",
      "Batch: 166, Loss: 0.9831717014312744, Accuracy: 0.68798828125\n",
      "Batch: 167, Loss: 0.9329643249511719, Accuracy: 0.70068359375\n",
      "Batch: 168, Loss: 0.8903794884681702, Accuracy: 0.71337890625\n",
      "Batch: 169, Loss: 0.9597534537315369, Accuracy: 0.68994140625\n",
      "Batch: 170, Loss: 1.013587236404419, Accuracy: 0.68212890625\n",
      "Batch: 171, Loss: 0.9409782886505127, Accuracy: 0.68603515625\n",
      "Batch: 172, Loss: 0.9305088520050049, Accuracy: 0.69921875\n",
      "Batch: 173, Loss: 0.9941034317016602, Accuracy: 0.685546875\n",
      "Batch: 174, Loss: 0.8485554456710815, Accuracy: 0.732421875\n",
      "Batch: 175, Loss: 1.0065491199493408, Accuracy: 0.65771484375\n",
      "Batch: 176, Loss: 1.0381444692611694, Accuracy: 0.6689453125\n",
      "Batch: 177, Loss: 0.9507795572280884, Accuracy: 0.697265625\n",
      "Batch: 178, Loss: 0.9207966327667236, Accuracy: 0.705078125\n",
      "Batch: 179, Loss: 0.9540671110153198, Accuracy: 0.689453125\n",
      "Batch: 180, Loss: 1.0295679569244385, Accuracy: 0.66796875\n",
      "Saved Weights at epoch 20 to file Weights_20.h5\n",
      "Epoch 21/200\n",
      "Batch: 1, Loss: 1.374114990234375, Accuracy: 0.62255859375\n",
      "Batch: 2, Loss: 0.967875599861145, Accuracy: 0.67822265625\n",
      "Batch: 3, Loss: 0.971403956413269, Accuracy: 0.6767578125\n",
      "Batch: 4, Loss: 1.0036652088165283, Accuracy: 0.6806640625\n",
      "Batch: 5, Loss: 1.012081265449524, Accuracy: 0.66552734375\n",
      "Batch: 6, Loss: 1.028244972229004, Accuracy: 0.67138671875\n",
      "Batch: 7, Loss: 0.9351080656051636, Accuracy: 0.6923828125\n",
      "Batch: 8, Loss: 0.9883771538734436, Accuracy: 0.6845703125\n",
      "Batch: 9, Loss: 1.0449926853179932, Accuracy: 0.68017578125\n",
      "Batch: 10, Loss: 0.9866719245910645, Accuracy: 0.69091796875\n",
      "Batch: 11, Loss: 1.0420278310775757, Accuracy: 0.67431640625\n",
      "Batch: 12, Loss: 0.9280921816825867, Accuracy: 0.705078125\n",
      "Batch: 13, Loss: 1.0026341676712036, Accuracy: 0.67431640625\n",
      "Batch: 14, Loss: 0.988091230392456, Accuracy: 0.68994140625\n",
      "Batch: 15, Loss: 0.9742751121520996, Accuracy: 0.69287109375\n",
      "Batch: 16, Loss: 1.0477222204208374, Accuracy: 0.673828125\n",
      "Batch: 17, Loss: 0.9537360072135925, Accuracy: 0.70166015625\n",
      "Batch: 18, Loss: 1.0342613458633423, Accuracy: 0.66357421875\n",
      "Batch: 19, Loss: 1.019926905632019, Accuracy: 0.68896484375\n",
      "Batch: 20, Loss: 0.9405946135520935, Accuracy: 0.6953125\n",
      "Batch: 21, Loss: 1.1007685661315918, Accuracy: 0.662109375\n",
      "Batch: 22, Loss: 0.9746385216712952, Accuracy: 0.69482421875\n",
      "Batch: 23, Loss: 0.9497308731079102, Accuracy: 0.7001953125\n",
      "Batch: 24, Loss: 0.9736701846122742, Accuracy: 0.6884765625\n",
      "Batch: 25, Loss: 0.941474437713623, Accuracy: 0.69970703125\n",
      "Batch: 26, Loss: 0.9674464464187622, Accuracy: 0.69873046875\n",
      "Batch: 27, Loss: 0.9941362738609314, Accuracy: 0.677734375\n",
      "Batch: 28, Loss: 0.9422155618667603, Accuracy: 0.69384765625\n",
      "Batch: 29, Loss: 1.024104118347168, Accuracy: 0.67919921875\n",
      "Batch: 30, Loss: 0.9888156056404114, Accuracy: 0.6943359375\n",
      "Batch: 31, Loss: 1.1308341026306152, Accuracy: 0.64208984375\n",
      "Batch: 32, Loss: 1.0182645320892334, Accuracy: 0.673828125\n",
      "Batch: 33, Loss: 1.03934645652771, Accuracy: 0.65966796875\n",
      "Batch: 34, Loss: 1.0814487934112549, Accuracy: 0.66259765625\n",
      "Batch: 35, Loss: 1.0917165279388428, Accuracy: 0.6533203125\n",
      "Batch: 36, Loss: 1.0453746318817139, Accuracy: 0.6796875\n",
      "Batch: 37, Loss: 1.0077701807022095, Accuracy: 0.67822265625\n",
      "Batch: 38, Loss: 1.0780556201934814, Accuracy: 0.65234375\n",
      "Batch: 39, Loss: 1.0151524543762207, Accuracy: 0.6826171875\n",
      "Batch: 40, Loss: 1.0760960578918457, Accuracy: 0.64990234375\n",
      "Batch: 41, Loss: 1.0088253021240234, Accuracy: 0.662109375\n",
      "Batch: 42, Loss: 0.9606859683990479, Accuracy: 0.681640625\n",
      "Batch: 43, Loss: 0.9580069780349731, Accuracy: 0.705078125\n",
      "Batch: 44, Loss: 0.8822933435440063, Accuracy: 0.71630859375\n",
      "Batch: 45, Loss: 0.9368695020675659, Accuracy: 0.6923828125\n",
      "Batch: 46, Loss: 0.8890508413314819, Accuracy: 0.6875\n",
      "Batch: 47, Loss: 0.9752216339111328, Accuracy: 0.6748046875\n",
      "Batch: 48, Loss: 0.9404362440109253, Accuracy: 0.70751953125\n",
      "Batch: 49, Loss: 0.9375172853469849, Accuracy: 0.69140625\n",
      "Batch: 50, Loss: 0.9833405017852783, Accuracy: 0.68701171875\n",
      "Batch: 51, Loss: 0.9577183723449707, Accuracy: 0.68994140625\n",
      "Batch: 52, Loss: 0.9306963682174683, Accuracy: 0.6953125\n",
      "Batch: 53, Loss: 0.9227258563041687, Accuracy: 0.69775390625\n",
      "Batch: 54, Loss: 0.9714365005493164, Accuracy: 0.67724609375\n",
      "Batch: 55, Loss: 0.9192022085189819, Accuracy: 0.71337890625\n",
      "Batch: 56, Loss: 0.9417493343353271, Accuracy: 0.69677734375\n",
      "Batch: 57, Loss: 1.020111083984375, Accuracy: 0.67333984375\n",
      "Batch: 58, Loss: 0.9706032276153564, Accuracy: 0.67529296875\n",
      "Batch: 59, Loss: 1.0946080684661865, Accuracy: 0.6474609375\n",
      "Batch: 60, Loss: 0.9703931212425232, Accuracy: 0.6904296875\n",
      "Batch: 61, Loss: 0.8974599838256836, Accuracy: 0.7099609375\n",
      "Batch: 62, Loss: 0.9452424049377441, Accuracy: 0.7099609375\n",
      "Batch: 63, Loss: 0.9643221497535706, Accuracy: 0.68701171875\n",
      "Batch: 64, Loss: 0.9784768223762512, Accuracy: 0.66943359375\n",
      "Batch: 65, Loss: 1.037274718284607, Accuracy: 0.6689453125\n",
      "Batch: 66, Loss: 0.9915673732757568, Accuracy: 0.6767578125\n",
      "Batch: 67, Loss: 1.0083529949188232, Accuracy: 0.669921875\n",
      "Batch: 68, Loss: 0.9279698133468628, Accuracy: 0.69677734375\n",
      "Batch: 69, Loss: 0.9792191386222839, Accuracy: 0.677734375\n",
      "Batch: 70, Loss: 0.9908945560455322, Accuracy: 0.67626953125\n",
      "Batch: 71, Loss: 0.9958945512771606, Accuracy: 0.67431640625\n",
      "Batch: 72, Loss: 0.9973528385162354, Accuracy: 0.669921875\n",
      "Batch: 73, Loss: 1.038782000541687, Accuracy: 0.6669921875\n",
      "Batch: 74, Loss: 1.0259532928466797, Accuracy: 0.66748046875\n",
      "Batch: 75, Loss: 0.9515148401260376, Accuracy: 0.6826171875\n",
      "Batch: 76, Loss: 0.9379599690437317, Accuracy: 0.6953125\n",
      "Batch: 77, Loss: 0.9274904727935791, Accuracy: 0.6904296875\n",
      "Batch: 78, Loss: 0.9638708829879761, Accuracy: 0.70166015625\n",
      "Batch: 79, Loss: 0.9754320383071899, Accuracy: 0.69580078125\n",
      "Batch: 80, Loss: 0.9855348467826843, Accuracy: 0.673828125\n",
      "Batch: 81, Loss: 1.0149900913238525, Accuracy: 0.67919921875\n",
      "Batch: 82, Loss: 0.916607141494751, Accuracy: 0.69189453125\n",
      "Batch: 83, Loss: 0.9214891195297241, Accuracy: 0.68603515625\n",
      "Batch: 84, Loss: 0.9099174737930298, Accuracy: 0.7060546875\n",
      "Batch: 85, Loss: 0.9001595973968506, Accuracy: 0.70849609375\n",
      "Batch: 86, Loss: 1.0542088747024536, Accuracy: 0.662109375\n",
      "Batch: 87, Loss: 0.9566575288772583, Accuracy: 0.69287109375\n",
      "Batch: 88, Loss: 1.0204110145568848, Accuracy: 0.673828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 89, Loss: 1.0185863971710205, Accuracy: 0.6767578125\n",
      "Batch: 90, Loss: 1.0406556129455566, Accuracy: 0.65283203125\n",
      "Batch: 91, Loss: 0.9550566673278809, Accuracy: 0.69091796875\n",
      "Batch: 92, Loss: 1.0849828720092773, Accuracy: 0.64501953125\n",
      "Batch: 93, Loss: 1.0146974325180054, Accuracy: 0.67041015625\n",
      "Batch: 94, Loss: 1.0585064888000488, Accuracy: 0.6728515625\n",
      "Batch: 95, Loss: 1.0518466234207153, Accuracy: 0.669921875\n",
      "Batch: 96, Loss: 1.0266000032424927, Accuracy: 0.67822265625\n",
      "Batch: 97, Loss: 0.9874272346496582, Accuracy: 0.6884765625\n",
      "Batch: 98, Loss: 1.1037274599075317, Accuracy: 0.65380859375\n",
      "Batch: 99, Loss: 0.9510501623153687, Accuracy: 0.69970703125\n",
      "Batch: 100, Loss: 1.0652618408203125, Accuracy: 0.66015625\n",
      "Batch: 101, Loss: 1.0931800603866577, Accuracy: 0.64501953125\n",
      "Batch: 102, Loss: 0.952831506729126, Accuracy: 0.68603515625\n",
      "Batch: 103, Loss: 1.0059964656829834, Accuracy: 0.6806640625\n",
      "Batch: 104, Loss: 0.9778045415878296, Accuracy: 0.6845703125\n",
      "Batch: 105, Loss: 1.0510075092315674, Accuracy: 0.66259765625\n",
      "Batch: 106, Loss: 1.0237795114517212, Accuracy: 0.67236328125\n",
      "Batch: 107, Loss: 1.0408214330673218, Accuracy: 0.66552734375\n",
      "Batch: 108, Loss: 1.0093127489089966, Accuracy: 0.67724609375\n",
      "Batch: 109, Loss: 0.9844512939453125, Accuracy: 0.67626953125\n",
      "Batch: 110, Loss: 0.940625786781311, Accuracy: 0.68994140625\n",
      "Batch: 111, Loss: 0.8925672769546509, Accuracy: 0.7080078125\n",
      "Batch: 112, Loss: 0.9796602129936218, Accuracy: 0.6962890625\n",
      "Batch: 113, Loss: 1.001185655593872, Accuracy: 0.6689453125\n",
      "Batch: 114, Loss: 0.9766337275505066, Accuracy: 0.69140625\n",
      "Batch: 115, Loss: 1.004695177078247, Accuracy: 0.68359375\n",
      "Batch: 116, Loss: 0.9897940754890442, Accuracy: 0.67041015625\n",
      "Batch: 117, Loss: 0.9889603853225708, Accuracy: 0.6708984375\n",
      "Batch: 118, Loss: 0.9835343956947327, Accuracy: 0.68017578125\n",
      "Batch: 119, Loss: 0.9769662618637085, Accuracy: 0.6640625\n",
      "Batch: 120, Loss: 0.9712557196617126, Accuracy: 0.68408203125\n",
      "Batch: 121, Loss: 0.9974848628044128, Accuracy: 0.6826171875\n",
      "Batch: 122, Loss: 0.9418383836746216, Accuracy: 0.6962890625\n",
      "Batch: 123, Loss: 0.9629857540130615, Accuracy: 0.7001953125\n",
      "Batch: 124, Loss: 0.9426237344741821, Accuracy: 0.6923828125\n",
      "Batch: 125, Loss: 0.9989497065544128, Accuracy: 0.6865234375\n",
      "Batch: 126, Loss: 0.9249328374862671, Accuracy: 0.70361328125\n",
      "Batch: 127, Loss: 0.9249939918518066, Accuracy: 0.69873046875\n",
      "Batch: 128, Loss: 1.097024917602539, Accuracy: 0.65185546875\n",
      "Batch: 129, Loss: 1.108617901802063, Accuracy: 0.6533203125\n",
      "Batch: 130, Loss: 1.1035573482513428, Accuracy: 0.6376953125\n",
      "Batch: 131, Loss: 1.053897500038147, Accuracy: 0.66552734375\n",
      "Batch: 132, Loss: 0.9216246604919434, Accuracy: 0.708984375\n",
      "Batch: 133, Loss: 0.9157992005348206, Accuracy: 0.71240234375\n",
      "Batch: 134, Loss: 1.0135509967803955, Accuracy: 0.67236328125\n",
      "Batch: 135, Loss: 1.0062520503997803, Accuracy: 0.6826171875\n",
      "Batch: 136, Loss: 0.9157410860061646, Accuracy: 0.69580078125\n",
      "Batch: 137, Loss: 0.9872826337814331, Accuracy: 0.6806640625\n",
      "Batch: 138, Loss: 0.8837190270423889, Accuracy: 0.72802734375\n",
      "Batch: 139, Loss: 0.9684759378433228, Accuracy: 0.69189453125\n",
      "Batch: 140, Loss: 0.9147989749908447, Accuracy: 0.70556640625\n",
      "Batch: 141, Loss: 1.0258972644805908, Accuracy: 0.66748046875\n",
      "Batch: 142, Loss: 0.9244046211242676, Accuracy: 0.701171875\n",
      "Batch: 143, Loss: 0.9718867540359497, Accuracy: 0.7001953125\n",
      "Batch: 144, Loss: 1.0174072980880737, Accuracy: 0.6748046875\n",
      "Batch: 145, Loss: 0.9905104041099548, Accuracy: 0.689453125\n",
      "Batch: 146, Loss: 1.045742392539978, Accuracy: 0.6650390625\n",
      "Batch: 147, Loss: 0.9994009137153625, Accuracy: 0.67626953125\n",
      "Batch: 148, Loss: 1.0044784545898438, Accuracy: 0.669921875\n",
      "Batch: 149, Loss: 0.9726445078849792, Accuracy: 0.68359375\n",
      "Batch: 150, Loss: 0.8542458415031433, Accuracy: 0.7265625\n",
      "Batch: 151, Loss: 0.8442167639732361, Accuracy: 0.73046875\n",
      "Batch: 152, Loss: 0.9128872752189636, Accuracy: 0.71533203125\n",
      "Batch: 153, Loss: 0.8905108571052551, Accuracy: 0.7138671875\n",
      "Batch: 154, Loss: 0.9016344547271729, Accuracy: 0.70361328125\n",
      "Batch: 155, Loss: 0.9779453277587891, Accuracy: 0.6884765625\n",
      "Batch: 156, Loss: 0.889998733997345, Accuracy: 0.71533203125\n",
      "Batch: 157, Loss: 0.8835415244102478, Accuracy: 0.7119140625\n",
      "Batch: 158, Loss: 0.8884561061859131, Accuracy: 0.71923828125\n",
      "Batch: 159, Loss: 0.8628232479095459, Accuracy: 0.72607421875\n",
      "Batch: 160, Loss: 0.9262602925300598, Accuracy: 0.6943359375\n",
      "Batch: 161, Loss: 0.9602134227752686, Accuracy: 0.68701171875\n",
      "Batch: 162, Loss: 0.9322290420532227, Accuracy: 0.705078125\n",
      "Batch: 163, Loss: 0.9928076267242432, Accuracy: 0.685546875\n",
      "Batch: 164, Loss: 1.024132251739502, Accuracy: 0.67578125\n",
      "Batch: 165, Loss: 0.9417198896408081, Accuracy: 0.693359375\n",
      "Batch: 166, Loss: 0.977972149848938, Accuracy: 0.68359375\n",
      "Batch: 167, Loss: 0.9080021977424622, Accuracy: 0.708984375\n",
      "Batch: 168, Loss: 0.8591753244400024, Accuracy: 0.71826171875\n",
      "Batch: 169, Loss: 0.9337154626846313, Accuracy: 0.697265625\n",
      "Batch: 170, Loss: 1.0028965473175049, Accuracy: 0.6796875\n",
      "Batch: 171, Loss: 0.9502643346786499, Accuracy: 0.68505859375\n",
      "Batch: 172, Loss: 0.9076082110404968, Accuracy: 0.7060546875\n",
      "Batch: 173, Loss: 0.9903014898300171, Accuracy: 0.701171875\n",
      "Batch: 174, Loss: 0.8431482315063477, Accuracy: 0.72900390625\n",
      "Batch: 175, Loss: 0.9791309833526611, Accuracy: 0.67431640625\n",
      "Batch: 176, Loss: 1.0317862033843994, Accuracy: 0.6826171875\n",
      "Batch: 177, Loss: 0.9603348970413208, Accuracy: 0.68701171875\n",
      "Batch: 178, Loss: 0.9117028713226318, Accuracy: 0.70068359375\n",
      "Batch: 179, Loss: 0.924217700958252, Accuracy: 0.69873046875\n",
      "Batch: 180, Loss: 1.0080924034118652, Accuracy: 0.67431640625\n",
      "Epoch 22/200\n",
      "Batch: 1, Loss: 1.3725382089614868, Accuracy: 0.62255859375\n",
      "Batch: 2, Loss: 0.9657561779022217, Accuracy: 0.68310546875\n",
      "Batch: 3, Loss: 0.9763349890708923, Accuracy: 0.685546875\n",
      "Batch: 4, Loss: 1.0065405368804932, Accuracy: 0.6767578125\n",
      "Batch: 5, Loss: 1.0086407661437988, Accuracy: 0.67236328125\n",
      "Batch: 6, Loss: 1.0156762599945068, Accuracy: 0.67578125\n",
      "Batch: 7, Loss: 0.9206811189651489, Accuracy: 0.69873046875\n",
      "Batch: 8, Loss: 0.9843222498893738, Accuracy: 0.68115234375\n",
      "Batch: 9, Loss: 1.0146090984344482, Accuracy: 0.68505859375\n",
      "Batch: 10, Loss: 0.9754022359848022, Accuracy: 0.6923828125\n",
      "Batch: 11, Loss: 1.0314745903015137, Accuracy: 0.671875\n",
      "Batch: 12, Loss: 0.9180876612663269, Accuracy: 0.70751953125\n",
      "Batch: 13, Loss: 0.9688469171524048, Accuracy: 0.67626953125\n",
      "Batch: 14, Loss: 0.9597344398498535, Accuracy: 0.69970703125\n",
      "Batch: 15, Loss: 0.9634170532226562, Accuracy: 0.703125\n",
      "Batch: 16, Loss: 1.0381884574890137, Accuracy: 0.67626953125\n",
      "Batch: 17, Loss: 0.9648775458335876, Accuracy: 0.7060546875\n",
      "Batch: 18, Loss: 1.042600154876709, Accuracy: 0.66357421875\n",
      "Batch: 19, Loss: 1.0063400268554688, Accuracy: 0.68359375\n",
      "Batch: 20, Loss: 0.9090767502784729, Accuracy: 0.70458984375\n",
      "Batch: 21, Loss: 1.0878045558929443, Accuracy: 0.65576171875\n",
      "Batch: 22, Loss: 0.9689936637878418, Accuracy: 0.69580078125\n",
      "Batch: 23, Loss: 0.9363822937011719, Accuracy: 0.70166015625\n",
      "Batch: 24, Loss: 0.9409040212631226, Accuracy: 0.69384765625\n",
      "Batch: 25, Loss: 0.9390386343002319, Accuracy: 0.701171875\n",
      "Batch: 26, Loss: 0.9545717239379883, Accuracy: 0.701171875\n",
      "Batch: 27, Loss: 0.9841164350509644, Accuracy: 0.6875\n",
      "Batch: 28, Loss: 0.9106824398040771, Accuracy: 0.6982421875\n",
      "Batch: 29, Loss: 1.0224332809448242, Accuracy: 0.6708984375\n",
      "Batch: 30, Loss: 0.9814993143081665, Accuracy: 0.68896484375\n",
      "Batch: 31, Loss: 1.108414649963379, Accuracy: 0.6611328125\n",
      "Batch: 32, Loss: 1.0106292963027954, Accuracy: 0.67724609375\n",
      "Batch: 33, Loss: 1.014571189880371, Accuracy: 0.67822265625\n",
      "Batch: 34, Loss: 1.056901454925537, Accuracy: 0.66943359375\n",
      "Batch: 35, Loss: 1.0827491283416748, Accuracy: 0.6455078125\n",
      "Batch: 36, Loss: 1.0380346775054932, Accuracy: 0.67626953125\n",
      "Batch: 37, Loss: 1.0013779401779175, Accuracy: 0.6806640625\n",
      "Batch: 38, Loss: 1.064624309539795, Accuracy: 0.65771484375\n",
      "Batch: 39, Loss: 1.0082823038101196, Accuracy: 0.68701171875\n",
      "Batch: 40, Loss: 1.0493078231811523, Accuracy: 0.66943359375\n",
      "Batch: 41, Loss: 1.0096145868301392, Accuracy: 0.68017578125\n",
      "Batch: 42, Loss: 0.9582598209381104, Accuracy: 0.6806640625\n",
      "Batch: 43, Loss: 0.940956175327301, Accuracy: 0.70751953125\n",
      "Batch: 44, Loss: 0.8650627136230469, Accuracy: 0.72314453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 45, Loss: 0.9295067191123962, Accuracy: 0.69580078125\n",
      "Batch: 46, Loss: 0.8939875364303589, Accuracy: 0.69091796875\n",
      "Batch: 47, Loss: 0.9603082537651062, Accuracy: 0.68310546875\n",
      "Batch: 48, Loss: 0.9280703663825989, Accuracy: 0.69140625\n",
      "Batch: 49, Loss: 0.9355737566947937, Accuracy: 0.68505859375\n",
      "Batch: 50, Loss: 0.9753750562667847, Accuracy: 0.68505859375\n",
      "Batch: 51, Loss: 0.9551118612289429, Accuracy: 0.6953125\n",
      "Batch: 52, Loss: 0.9053810238838196, Accuracy: 0.705078125\n",
      "Batch: 53, Loss: 0.9256972074508667, Accuracy: 0.69091796875\n",
      "Batch: 54, Loss: 0.9551874399185181, Accuracy: 0.68408203125\n",
      "Batch: 55, Loss: 0.9054797291755676, Accuracy: 0.71923828125\n",
      "Batch: 56, Loss: 0.9374798536300659, Accuracy: 0.69775390625\n",
      "Batch: 57, Loss: 1.0221195220947266, Accuracy: 0.68359375\n",
      "Batch: 58, Loss: 0.9504092931747437, Accuracy: 0.68359375\n",
      "Batch: 59, Loss: 1.0824750661849976, Accuracy: 0.65673828125\n",
      "Batch: 60, Loss: 0.977104902267456, Accuracy: 0.68994140625\n",
      "Batch: 61, Loss: 0.889756977558136, Accuracy: 0.716796875\n",
      "Batch: 62, Loss: 0.9141559600830078, Accuracy: 0.7109375\n",
      "Batch: 63, Loss: 0.9479025602340698, Accuracy: 0.69140625\n",
      "Batch: 64, Loss: 0.9687454104423523, Accuracy: 0.68017578125\n",
      "Batch: 65, Loss: 1.0204190015792847, Accuracy: 0.6796875\n",
      "Batch: 66, Loss: 0.9835172891616821, Accuracy: 0.6845703125\n",
      "Batch: 67, Loss: 0.968255877494812, Accuracy: 0.68017578125\n",
      "Batch: 68, Loss: 0.9132863283157349, Accuracy: 0.69873046875\n",
      "Batch: 69, Loss: 0.9631523489952087, Accuracy: 0.67529296875\n",
      "Batch: 70, Loss: 0.9606314897537231, Accuracy: 0.68896484375\n",
      "Batch: 71, Loss: 0.9572504162788391, Accuracy: 0.6845703125\n",
      "Batch: 72, Loss: 0.9798024892807007, Accuracy: 0.6845703125\n",
      "Batch: 73, Loss: 1.0352566242218018, Accuracy: 0.66552734375\n",
      "Batch: 74, Loss: 1.0021977424621582, Accuracy: 0.685546875\n",
      "Batch: 75, Loss: 0.940029501914978, Accuracy: 0.69287109375\n",
      "Batch: 76, Loss: 0.9190757274627686, Accuracy: 0.68603515625\n",
      "Batch: 77, Loss: 0.903261661529541, Accuracy: 0.70849609375\n",
      "Batch: 78, Loss: 0.9553460478782654, Accuracy: 0.693359375\n",
      "Batch: 79, Loss: 0.9701458811759949, Accuracy: 0.6845703125\n",
      "Batch: 80, Loss: 0.9593671560287476, Accuracy: 0.68115234375\n",
      "Batch: 81, Loss: 0.998761773109436, Accuracy: 0.68017578125\n",
      "Batch: 82, Loss: 0.9367471933364868, Accuracy: 0.69287109375\n",
      "Batch: 83, Loss: 0.9048119783401489, Accuracy: 0.69482421875\n",
      "Batch: 84, Loss: 0.8873478174209595, Accuracy: 0.72021484375\n",
      "Batch: 85, Loss: 0.892580509185791, Accuracy: 0.7119140625\n",
      "Batch: 86, Loss: 1.049659252166748, Accuracy: 0.6669921875\n",
      "Batch: 87, Loss: 0.9363747239112854, Accuracy: 0.69384765625\n",
      "Batch: 88, Loss: 1.0083520412445068, Accuracy: 0.6787109375\n",
      "Batch: 89, Loss: 1.0142236948013306, Accuracy: 0.6787109375\n",
      "Batch: 90, Loss: 1.0419646501541138, Accuracy: 0.6572265625\n",
      "Batch: 91, Loss: 0.9399380683898926, Accuracy: 0.6982421875\n",
      "Batch: 92, Loss: 1.0804075002670288, Accuracy: 0.65478515625\n",
      "Batch: 93, Loss: 0.994182825088501, Accuracy: 0.67333984375\n",
      "Batch: 94, Loss: 1.0379438400268555, Accuracy: 0.66748046875\n",
      "Batch: 95, Loss: 1.044620156288147, Accuracy: 0.6748046875\n",
      "Batch: 96, Loss: 0.9992917776107788, Accuracy: 0.689453125\n",
      "Batch: 97, Loss: 0.9546293020248413, Accuracy: 0.69921875\n",
      "Batch: 98, Loss: 1.0843334197998047, Accuracy: 0.6611328125\n",
      "Batch: 99, Loss: 0.9525389075279236, Accuracy: 0.70361328125\n",
      "Batch: 100, Loss: 1.0638211965560913, Accuracy: 0.658203125\n",
      "Batch: 101, Loss: 1.0786287784576416, Accuracy: 0.65771484375\n",
      "Batch: 102, Loss: 0.9268961548805237, Accuracy: 0.6962890625\n",
      "Batch: 103, Loss: 1.0038650035858154, Accuracy: 0.6796875\n",
      "Batch: 104, Loss: 0.9817538261413574, Accuracy: 0.68701171875\n",
      "Batch: 105, Loss: 1.0356513261795044, Accuracy: 0.6630859375\n",
      "Batch: 106, Loss: 1.005743384361267, Accuracy: 0.677734375\n",
      "Batch: 107, Loss: 1.0238516330718994, Accuracy: 0.6708984375\n",
      "Batch: 108, Loss: 0.9838144779205322, Accuracy: 0.689453125\n",
      "Batch: 109, Loss: 0.9710369110107422, Accuracy: 0.69189453125\n",
      "Batch: 110, Loss: 0.9423235058784485, Accuracy: 0.68212890625\n",
      "Batch: 111, Loss: 0.8816401362419128, Accuracy: 0.71875\n",
      "Batch: 112, Loss: 0.9598498344421387, Accuracy: 0.70654296875\n",
      "Batch: 113, Loss: 1.0044372081756592, Accuracy: 0.673828125\n",
      "Batch: 114, Loss: 0.965907633304596, Accuracy: 0.6904296875\n",
      "Batch: 115, Loss: 0.9759505987167358, Accuracy: 0.6962890625\n",
      "Batch: 116, Loss: 0.9766092300415039, Accuracy: 0.67578125\n",
      "Batch: 117, Loss: 0.9677813053131104, Accuracy: 0.68310546875\n",
      "Batch: 118, Loss: 0.9696826338768005, Accuracy: 0.693359375\n",
      "Batch: 119, Loss: 0.9664804935455322, Accuracy: 0.67529296875\n",
      "Batch: 120, Loss: 0.9620245099067688, Accuracy: 0.6806640625\n",
      "Batch: 121, Loss: 0.9657169580459595, Accuracy: 0.68896484375\n",
      "Batch: 122, Loss: 0.9153326749801636, Accuracy: 0.70947265625\n",
      "Batch: 123, Loss: 0.947502613067627, Accuracy: 0.7001953125\n",
      "Batch: 124, Loss: 0.9258750677108765, Accuracy: 0.69384765625\n",
      "Batch: 125, Loss: 0.9710388779640198, Accuracy: 0.6943359375\n",
      "Batch: 126, Loss: 0.9038379192352295, Accuracy: 0.7119140625\n",
      "Batch: 127, Loss: 0.9214043617248535, Accuracy: 0.70263671875\n",
      "Batch: 128, Loss: 1.0908982753753662, Accuracy: 0.6591796875\n",
      "Batch: 129, Loss: 1.092366099357605, Accuracy: 0.64794921875\n",
      "Batch: 130, Loss: 1.0852519273757935, Accuracy: 0.6455078125\n",
      "Batch: 131, Loss: 1.005447506904602, Accuracy: 0.67919921875\n",
      "Batch: 132, Loss: 0.8953274488449097, Accuracy: 0.716796875\n",
      "Batch: 133, Loss: 0.9051003456115723, Accuracy: 0.72119140625\n",
      "Batch: 134, Loss: 1.016971468925476, Accuracy: 0.671875\n",
      "Batch: 135, Loss: 0.9759438037872314, Accuracy: 0.68994140625\n",
      "Batch: 136, Loss: 0.9140653610229492, Accuracy: 0.69873046875\n",
      "Batch: 137, Loss: 0.9658347368240356, Accuracy: 0.697265625\n",
      "Batch: 138, Loss: 0.8538010120391846, Accuracy: 0.7392578125\n",
      "Batch: 139, Loss: 0.9341351985931396, Accuracy: 0.7001953125\n",
      "Batch: 140, Loss: 0.8955745697021484, Accuracy: 0.6962890625\n",
      "Batch: 141, Loss: 1.0199052095413208, Accuracy: 0.66650390625\n",
      "Batch: 142, Loss: 0.8867181539535522, Accuracy: 0.70751953125\n",
      "Batch: 143, Loss: 0.942433774471283, Accuracy: 0.70361328125\n",
      "Batch: 144, Loss: 0.9976873397827148, Accuracy: 0.68505859375\n",
      "Batch: 145, Loss: 0.9627902507781982, Accuracy: 0.6962890625\n",
      "Batch: 146, Loss: 1.013235092163086, Accuracy: 0.671875\n",
      "Batch: 147, Loss: 0.9677730798721313, Accuracy: 0.6865234375\n",
      "Batch: 148, Loss: 0.9804598093032837, Accuracy: 0.67529296875\n",
      "Batch: 149, Loss: 0.9602255821228027, Accuracy: 0.6923828125\n",
      "Batch: 150, Loss: 0.8272988796234131, Accuracy: 0.728515625\n",
      "Batch: 151, Loss: 0.8381277322769165, Accuracy: 0.72900390625\n",
      "Batch: 152, Loss: 0.8937918543815613, Accuracy: 0.70849609375\n",
      "Batch: 153, Loss: 0.8727329969406128, Accuracy: 0.71533203125\n",
      "Batch: 154, Loss: 0.8882863521575928, Accuracy: 0.7041015625\n",
      "Batch: 155, Loss: 0.9683725237846375, Accuracy: 0.6845703125\n",
      "Batch: 156, Loss: 0.8866679072380066, Accuracy: 0.71484375\n",
      "Batch: 157, Loss: 0.8771805763244629, Accuracy: 0.70654296875\n",
      "Batch: 158, Loss: 0.86583411693573, Accuracy: 0.724609375\n",
      "Batch: 159, Loss: 0.8580907583236694, Accuracy: 0.7255859375\n",
      "Batch: 160, Loss: 0.9073224067687988, Accuracy: 0.70166015625\n",
      "Batch: 161, Loss: 0.9281125068664551, Accuracy: 0.69140625\n",
      "Batch: 162, Loss: 0.896451473236084, Accuracy: 0.72216796875\n",
      "Batch: 163, Loss: 0.9765362739562988, Accuracy: 0.68505859375\n",
      "Batch: 164, Loss: 1.0167346000671387, Accuracy: 0.6796875\n",
      "Batch: 165, Loss: 0.9271668195724487, Accuracy: 0.7080078125\n",
      "Batch: 166, Loss: 0.9372284412384033, Accuracy: 0.69482421875\n",
      "Batch: 167, Loss: 0.9009205102920532, Accuracy: 0.7138671875\n",
      "Batch: 168, Loss: 0.8525238037109375, Accuracy: 0.732421875\n",
      "Batch: 169, Loss: 0.9200031757354736, Accuracy: 0.70654296875\n",
      "Batch: 170, Loss: 0.9996511936187744, Accuracy: 0.67529296875\n",
      "Batch: 171, Loss: 0.9167745113372803, Accuracy: 0.70263671875\n",
      "Batch: 172, Loss: 0.913878321647644, Accuracy: 0.70068359375\n",
      "Batch: 173, Loss: 0.9820572137832642, Accuracy: 0.69921875\n",
      "Batch: 174, Loss: 0.8173292875289917, Accuracy: 0.73876953125\n",
      "Batch: 175, Loss: 0.9814865589141846, Accuracy: 0.6767578125\n",
      "Batch: 176, Loss: 1.0113401412963867, Accuracy: 0.6796875\n",
      "Batch: 177, Loss: 0.9330224990844727, Accuracy: 0.7060546875\n",
      "Batch: 178, Loss: 0.906753420829773, Accuracy: 0.6953125\n",
      "Batch: 179, Loss: 0.9089454412460327, Accuracy: 0.7099609375\n",
      "Batch: 180, Loss: 1.0049705505371094, Accuracy: 0.6865234375\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Loss: 1.3601635694503784, Accuracy: 0.6162109375\n",
      "Batch: 2, Loss: 0.9448306560516357, Accuracy: 0.68212890625\n",
      "Batch: 3, Loss: 0.9434913396835327, Accuracy: 0.68505859375\n",
      "Batch: 4, Loss: 0.9840962886810303, Accuracy: 0.677734375\n",
      "Batch: 5, Loss: 0.9893569350242615, Accuracy: 0.67822265625\n",
      "Batch: 6, Loss: 1.0024815797805786, Accuracy: 0.68017578125\n",
      "Batch: 7, Loss: 0.9066045880317688, Accuracy: 0.708984375\n",
      "Batch: 8, Loss: 0.9652128219604492, Accuracy: 0.6796875\n",
      "Batch: 9, Loss: 1.0266362428665161, Accuracy: 0.6796875\n",
      "Batch: 10, Loss: 0.9684993028640747, Accuracy: 0.7041015625\n",
      "Batch: 11, Loss: 1.0109996795654297, Accuracy: 0.66748046875\n",
      "Batch: 12, Loss: 0.9032219052314758, Accuracy: 0.720703125\n",
      "Batch: 13, Loss: 0.9668958783149719, Accuracy: 0.68994140625\n",
      "Batch: 14, Loss: 0.9572996497154236, Accuracy: 0.69873046875\n",
      "Batch: 15, Loss: 0.9569190740585327, Accuracy: 0.70361328125\n",
      "Batch: 16, Loss: 1.0244216918945312, Accuracy: 0.67919921875\n",
      "Batch: 17, Loss: 0.9405947327613831, Accuracy: 0.70166015625\n",
      "Batch: 18, Loss: 1.0173165798187256, Accuracy: 0.6728515625\n",
      "Batch: 19, Loss: 0.990843653678894, Accuracy: 0.69091796875\n",
      "Batch: 20, Loss: 0.916629433631897, Accuracy: 0.7021484375\n",
      "Batch: 21, Loss: 1.080733060836792, Accuracy: 0.66162109375\n",
      "Batch: 22, Loss: 0.9343396425247192, Accuracy: 0.7041015625\n",
      "Batch: 23, Loss: 0.9196757078170776, Accuracy: 0.71533203125\n",
      "Batch: 24, Loss: 0.9463139772415161, Accuracy: 0.69970703125\n",
      "Batch: 25, Loss: 0.9172332286834717, Accuracy: 0.7109375\n",
      "Batch: 26, Loss: 0.9408007860183716, Accuracy: 0.705078125\n",
      "Batch: 27, Loss: 0.9695910215377808, Accuracy: 0.6796875\n",
      "Batch: 28, Loss: 0.9121493101119995, Accuracy: 0.7119140625\n",
      "Batch: 29, Loss: 1.0143330097198486, Accuracy: 0.68701171875\n",
      "Batch: 30, Loss: 0.9652880430221558, Accuracy: 0.69384765625\n",
      "Batch: 31, Loss: 1.0857347249984741, Accuracy: 0.662109375\n",
      "Batch: 32, Loss: 0.9901548624038696, Accuracy: 0.6884765625\n",
      "Batch: 33, Loss: 1.0189051628112793, Accuracy: 0.66748046875\n",
      "Batch: 34, Loss: 1.0403285026550293, Accuracy: 0.671875\n",
      "Batch: 35, Loss: 1.0613903999328613, Accuracy: 0.65771484375\n",
      "Batch: 36, Loss: 1.0370714664459229, Accuracy: 0.6845703125\n",
      "Batch: 37, Loss: 0.9895148873329163, Accuracy: 0.68017578125\n",
      "Batch: 38, Loss: 1.0471365451812744, Accuracy: 0.65234375\n",
      "Batch: 39, Loss: 0.9744077920913696, Accuracy: 0.69384765625\n",
      "Batch: 40, Loss: 1.0331921577453613, Accuracy: 0.68212890625\n",
      "Batch: 41, Loss: 0.9980820417404175, Accuracy: 0.66650390625\n",
      "Batch: 42, Loss: 0.95289146900177, Accuracy: 0.68798828125\n",
      "Batch: 43, Loss: 0.9279593229293823, Accuracy: 0.7099609375\n",
      "Batch: 44, Loss: 0.8615031242370605, Accuracy: 0.728515625\n",
      "Batch: 45, Loss: 0.9177659153938293, Accuracy: 0.69775390625\n",
      "Batch: 46, Loss: 0.8838486671447754, Accuracy: 0.69677734375\n",
      "Batch: 47, Loss: 0.9460917711257935, Accuracy: 0.6904296875\n",
      "Batch: 48, Loss: 0.8976183533668518, Accuracy: 0.71240234375\n",
      "Batch: 49, Loss: 0.902593731880188, Accuracy: 0.701171875\n",
      "Batch: 50, Loss: 0.9606659412384033, Accuracy: 0.69970703125\n",
      "Batch: 51, Loss: 0.9408718347549438, Accuracy: 0.7041015625\n",
      "Batch: 52, Loss: 0.8850419521331787, Accuracy: 0.70654296875\n",
      "Batch: 53, Loss: 0.9057663679122925, Accuracy: 0.69921875\n",
      "Batch: 54, Loss: 0.9427677392959595, Accuracy: 0.68505859375\n",
      "Batch: 55, Loss: 0.9032268524169922, Accuracy: 0.71240234375\n",
      "Batch: 56, Loss: 0.9196771383285522, Accuracy: 0.70263671875\n",
      "Batch: 57, Loss: 0.9961376786231995, Accuracy: 0.68603515625\n",
      "Batch: 58, Loss: 0.9386693835258484, Accuracy: 0.68994140625\n",
      "Batch: 59, Loss: 1.0654232501983643, Accuracy: 0.66748046875\n",
      "Batch: 60, Loss: 0.9545038938522339, Accuracy: 0.69677734375\n",
      "Batch: 61, Loss: 0.8675435781478882, Accuracy: 0.720703125\n",
      "Batch: 62, Loss: 0.901816725730896, Accuracy: 0.71826171875\n",
      "Batch: 63, Loss: 0.9297311305999756, Accuracy: 0.70068359375\n",
      "Batch: 64, Loss: 0.9465577006340027, Accuracy: 0.6767578125\n",
      "Batch: 65, Loss: 1.0012836456298828, Accuracy: 0.68310546875\n",
      "Batch: 66, Loss: 0.9822142124176025, Accuracy: 0.68212890625\n",
      "Batch: 67, Loss: 0.9760350584983826, Accuracy: 0.6767578125\n",
      "Batch: 68, Loss: 0.9004709720611572, Accuracy: 0.69287109375\n",
      "Batch: 69, Loss: 0.9646356105804443, Accuracy: 0.68359375\n",
      "Batch: 70, Loss: 0.9752308130264282, Accuracy: 0.68115234375\n",
      "Batch: 71, Loss: 0.9528810977935791, Accuracy: 0.6845703125\n",
      "Batch: 72, Loss: 0.9906547665596008, Accuracy: 0.66650390625\n",
      "Batch: 73, Loss: 0.9931443929672241, Accuracy: 0.67626953125\n",
      "Batch: 74, Loss: 1.017213225364685, Accuracy: 0.67724609375\n",
      "Batch: 75, Loss: 0.9234437942504883, Accuracy: 0.6943359375\n",
      "Batch: 76, Loss: 0.9016510248184204, Accuracy: 0.71240234375\n",
      "Batch: 77, Loss: 0.8991457223892212, Accuracy: 0.71728515625\n",
      "Batch: 78, Loss: 0.9381272792816162, Accuracy: 0.705078125\n",
      "Batch: 79, Loss: 0.9662877321243286, Accuracy: 0.70263671875\n",
      "Batch: 80, Loss: 0.9468812346458435, Accuracy: 0.68505859375\n",
      "Batch: 81, Loss: 0.9943730235099792, Accuracy: 0.69189453125\n",
      "Batch: 82, Loss: 0.9090279340744019, Accuracy: 0.69287109375\n",
      "Batch: 83, Loss: 0.8898917436599731, Accuracy: 0.70947265625\n",
      "Batch: 84, Loss: 0.8618495464324951, Accuracy: 0.7236328125\n",
      "Batch: 85, Loss: 0.8810921907424927, Accuracy: 0.7060546875\n",
      "Batch: 86, Loss: 1.0379050970077515, Accuracy: 0.6728515625\n",
      "Batch: 87, Loss: 0.9165118336677551, Accuracy: 0.70166015625\n",
      "Batch: 88, Loss: 0.9834823608398438, Accuracy: 0.69580078125\n",
      "Batch: 89, Loss: 0.9834418892860413, Accuracy: 0.68701171875\n",
      "Batch: 90, Loss: 1.0025275945663452, Accuracy: 0.669921875\n",
      "Batch: 91, Loss: 0.9366580247879028, Accuracy: 0.70458984375\n",
      "Batch: 92, Loss: 1.0661497116088867, Accuracy: 0.65380859375\n",
      "Batch: 93, Loss: 0.9846241474151611, Accuracy: 0.669921875\n",
      "Batch: 94, Loss: 1.0363221168518066, Accuracy: 0.6826171875\n",
      "Batch: 95, Loss: 1.0378916263580322, Accuracy: 0.67578125\n",
      "Batch: 96, Loss: 0.9927699565887451, Accuracy: 0.68408203125\n",
      "Batch: 97, Loss: 0.9437851905822754, Accuracy: 0.705078125\n",
      "Batch: 98, Loss: 1.0609066486358643, Accuracy: 0.67529296875\n",
      "Batch: 99, Loss: 0.9288767576217651, Accuracy: 0.7158203125\n",
      "Batch: 100, Loss: 1.0495599508285522, Accuracy: 0.66650390625\n",
      "Batch: 101, Loss: 1.0578745603561401, Accuracy: 0.66357421875\n",
      "Batch: 102, Loss: 0.9365281462669373, Accuracy: 0.69921875\n",
      "Batch: 103, Loss: 0.990932047367096, Accuracy: 0.67333984375\n",
      "Batch: 104, Loss: 0.9589819312095642, Accuracy: 0.68701171875\n",
      "Batch: 105, Loss: 1.0154547691345215, Accuracy: 0.67138671875\n",
      "Batch: 106, Loss: 0.9816466569900513, Accuracy: 0.68505859375\n",
      "Batch: 107, Loss: 0.9987325072288513, Accuracy: 0.6806640625\n",
      "Batch: 108, Loss: 0.9767523407936096, Accuracy: 0.6845703125\n",
      "Batch: 109, Loss: 0.9579127430915833, Accuracy: 0.693359375\n",
      "Batch: 110, Loss: 0.9167166352272034, Accuracy: 0.69677734375\n",
      "Batch: 111, Loss: 0.8610330820083618, Accuracy: 0.720703125\n",
      "Batch: 112, Loss: 0.9467233419418335, Accuracy: 0.6982421875\n",
      "Batch: 113, Loss: 0.9688699245452881, Accuracy: 0.685546875\n",
      "Batch: 114, Loss: 0.9632174372673035, Accuracy: 0.68603515625\n",
      "Batch: 115, Loss: 0.9525707364082336, Accuracy: 0.6904296875\n",
      "Batch: 116, Loss: 0.9704740047454834, Accuracy: 0.68994140625\n",
      "Batch: 117, Loss: 0.9664825201034546, Accuracy: 0.69580078125\n",
      "Batch: 118, Loss: 0.9690914750099182, Accuracy: 0.6845703125\n",
      "Batch: 119, Loss: 0.9545539021492004, Accuracy: 0.6875\n",
      "Batch: 120, Loss: 0.9545727968215942, Accuracy: 0.68603515625\n",
      "Batch: 121, Loss: 0.958712100982666, Accuracy: 0.68115234375\n",
      "Batch: 122, Loss: 0.9094387292861938, Accuracy: 0.712890625\n",
      "Batch: 123, Loss: 0.9286251664161682, Accuracy: 0.71240234375\n",
      "Batch: 124, Loss: 0.9035187363624573, Accuracy: 0.697265625\n",
      "Batch: 125, Loss: 0.9557909369468689, Accuracy: 0.70361328125\n",
      "Batch: 126, Loss: 0.9065396785736084, Accuracy: 0.7080078125\n",
      "Batch: 127, Loss: 0.883377194404602, Accuracy: 0.71630859375\n",
      "Batch: 128, Loss: 1.0502270460128784, Accuracy: 0.6728515625\n",
      "Batch: 129, Loss: 1.0837372541427612, Accuracy: 0.66650390625\n",
      "Batch: 130, Loss: 1.0836970806121826, Accuracy: 0.64892578125\n",
      "Batch: 131, Loss: 1.0146574974060059, Accuracy: 0.66845703125\n",
      "Batch: 132, Loss: 0.8988212943077087, Accuracy: 0.71484375\n",
      "Batch: 133, Loss: 0.8956990242004395, Accuracy: 0.720703125\n",
      "Batch: 134, Loss: 1.0005340576171875, Accuracy: 0.67822265625\n",
      "Batch: 135, Loss: 0.9617056250572205, Accuracy: 0.69189453125\n",
      "Batch: 136, Loss: 0.9095334410667419, Accuracy: 0.6982421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 137, Loss: 0.9689106941223145, Accuracy: 0.689453125\n",
      "Batch: 138, Loss: 0.8468342423439026, Accuracy: 0.73681640625\n",
      "Batch: 139, Loss: 0.9264615774154663, Accuracy: 0.7001953125\n",
      "Batch: 140, Loss: 0.8663390278816223, Accuracy: 0.7197265625\n",
      "Batch: 141, Loss: 1.0076625347137451, Accuracy: 0.67236328125\n",
      "Batch: 142, Loss: 0.8928471803665161, Accuracy: 0.71142578125\n",
      "Batch: 143, Loss: 0.9234961271286011, Accuracy: 0.71044921875\n",
      "Batch: 144, Loss: 0.9895540475845337, Accuracy: 0.69482421875\n",
      "Batch: 145, Loss: 0.961411714553833, Accuracy: 0.6982421875\n",
      "Batch: 146, Loss: 1.0092358589172363, Accuracy: 0.677734375\n",
      "Batch: 147, Loss: 0.9688541293144226, Accuracy: 0.68994140625\n",
      "Batch: 148, Loss: 0.9809867143630981, Accuracy: 0.66943359375\n",
      "Batch: 149, Loss: 0.962524950504303, Accuracy: 0.6865234375\n",
      "Batch: 150, Loss: 0.81535804271698, Accuracy: 0.72900390625\n",
      "Batch: 151, Loss: 0.8352830410003662, Accuracy: 0.724609375\n",
      "Batch: 152, Loss: 0.8829342126846313, Accuracy: 0.7216796875\n",
      "Batch: 153, Loss: 0.8565399050712585, Accuracy: 0.72216796875\n",
      "Batch: 154, Loss: 0.8799037933349609, Accuracy: 0.7119140625\n",
      "Batch: 155, Loss: 0.9693939685821533, Accuracy: 0.68896484375\n",
      "Batch: 156, Loss: 0.8838208913803101, Accuracy: 0.712890625\n",
      "Batch: 157, Loss: 0.8696541786193848, Accuracy: 0.70947265625\n",
      "Batch: 158, Loss: 0.8551362752914429, Accuracy: 0.72802734375\n",
      "Batch: 159, Loss: 0.8532302379608154, Accuracy: 0.7197265625\n",
      "Batch: 160, Loss: 0.9138003587722778, Accuracy: 0.69921875\n",
      "Batch: 161, Loss: 0.9304417371749878, Accuracy: 0.69873046875\n",
      "Batch: 162, Loss: 0.899623453617096, Accuracy: 0.724609375\n",
      "Batch: 163, Loss: 0.96366286277771, Accuracy: 0.69287109375\n",
      "Batch: 164, Loss: 0.999156653881073, Accuracy: 0.68896484375\n",
      "Batch: 165, Loss: 0.910754382610321, Accuracy: 0.7138671875\n",
      "Batch: 166, Loss: 0.9345666170120239, Accuracy: 0.703125\n",
      "Batch: 167, Loss: 0.8947599530220032, Accuracy: 0.7099609375\n",
      "Batch: 168, Loss: 0.8452365398406982, Accuracy: 0.7294921875\n",
      "Batch: 169, Loss: 0.9248191118240356, Accuracy: 0.69775390625\n",
      "Batch: 170, Loss: 0.9941353797912598, Accuracy: 0.6875\n",
      "Batch: 171, Loss: 0.919339656829834, Accuracy: 0.701171875\n",
      "Batch: 172, Loss: 0.8928524255752563, Accuracy: 0.71240234375\n",
      "Batch: 173, Loss: 0.9568686485290527, Accuracy: 0.70654296875\n",
      "Batch: 174, Loss: 0.8134814500808716, Accuracy: 0.74462890625\n",
      "Batch: 175, Loss: 0.9712876081466675, Accuracy: 0.671875\n",
      "Batch: 176, Loss: 1.0019363164901733, Accuracy: 0.6748046875\n",
      "Batch: 177, Loss: 0.9344708919525146, Accuracy: 0.69921875\n",
      "Batch: 178, Loss: 0.8829270005226135, Accuracy: 0.71630859375\n",
      "Batch: 179, Loss: 0.9090210199356079, Accuracy: 0.71142578125\n",
      "Batch: 180, Loss: 0.9848228693008423, Accuracy: 0.68212890625\n",
      "Epoch 24/200\n",
      "Batch: 1, Loss: 1.3351314067840576, Accuracy: 0.63232421875\n",
      "Batch: 2, Loss: 0.925979733467102, Accuracy: 0.68310546875\n",
      "Batch: 3, Loss: 0.9406517148017883, Accuracy: 0.68798828125\n",
      "Batch: 4, Loss: 0.9751161336898804, Accuracy: 0.68408203125\n",
      "Batch: 5, Loss: 0.9676676988601685, Accuracy: 0.68115234375\n",
      "Batch: 6, Loss: 0.9899733066558838, Accuracy: 0.67822265625\n",
      "Batch: 7, Loss: 0.8956631422042847, Accuracy: 0.71142578125\n",
      "Batch: 8, Loss: 0.9547662734985352, Accuracy: 0.68896484375\n",
      "Batch: 9, Loss: 1.022704839706421, Accuracy: 0.681640625\n",
      "Batch: 10, Loss: 0.9612252712249756, Accuracy: 0.69970703125\n",
      "Batch: 11, Loss: 1.0126986503601074, Accuracy: 0.67041015625\n",
      "Batch: 12, Loss: 0.8832911252975464, Accuracy: 0.7216796875\n",
      "Batch: 13, Loss: 0.9456064105033875, Accuracy: 0.68505859375\n",
      "Batch: 14, Loss: 0.9512882828712463, Accuracy: 0.7080078125\n",
      "Batch: 15, Loss: 0.9449677467346191, Accuracy: 0.70263671875\n",
      "Batch: 16, Loss: 1.0101101398468018, Accuracy: 0.67236328125\n",
      "Batch: 17, Loss: 0.9409072995185852, Accuracy: 0.70068359375\n",
      "Batch: 18, Loss: 1.0023640394210815, Accuracy: 0.68798828125\n",
      "Batch: 19, Loss: 0.9734787940979004, Accuracy: 0.69091796875\n",
      "Batch: 20, Loss: 0.8879685997962952, Accuracy: 0.7119140625\n",
      "Batch: 21, Loss: 1.0686674118041992, Accuracy: 0.66796875\n",
      "Batch: 22, Loss: 0.9533786773681641, Accuracy: 0.693359375\n",
      "Batch: 23, Loss: 0.9063159227371216, Accuracy: 0.703125\n",
      "Batch: 24, Loss: 0.9325631856918335, Accuracy: 0.69189453125\n",
      "Batch: 25, Loss: 0.9156131148338318, Accuracy: 0.7119140625\n",
      "Batch: 26, Loss: 0.9314700365066528, Accuracy: 0.69384765625\n",
      "Batch: 27, Loss: 0.9570720195770264, Accuracy: 0.6875\n",
      "Batch: 28, Loss: 0.908033549785614, Accuracy: 0.697265625\n",
      "Batch: 29, Loss: 0.9970617294311523, Accuracy: 0.6865234375\n",
      "Batch: 30, Loss: 0.9541431665420532, Accuracy: 0.6943359375\n",
      "Batch: 31, Loss: 1.0784924030303955, Accuracy: 0.6640625\n",
      "Batch: 32, Loss: 0.9874475002288818, Accuracy: 0.689453125\n",
      "Batch: 33, Loss: 0.9982092976570129, Accuracy: 0.669921875\n",
      "Batch: 34, Loss: 1.0381553173065186, Accuracy: 0.673828125\n",
      "Batch: 35, Loss: 1.0684776306152344, Accuracy: 0.65966796875\n",
      "Batch: 36, Loss: 1.0141605138778687, Accuracy: 0.6845703125\n",
      "Batch: 37, Loss: 0.9846087098121643, Accuracy: 0.6806640625\n",
      "Batch: 38, Loss: 1.0381065607070923, Accuracy: 0.66943359375\n",
      "Batch: 39, Loss: 0.9778797626495361, Accuracy: 0.703125\n",
      "Batch: 40, Loss: 1.032428503036499, Accuracy: 0.67919921875\n",
      "Batch: 41, Loss: 0.9815331697463989, Accuracy: 0.68212890625\n",
      "Batch: 42, Loss: 0.9430248737335205, Accuracy: 0.6845703125\n",
      "Batch: 43, Loss: 0.9242507815361023, Accuracy: 0.70458984375\n",
      "Batch: 44, Loss: 0.8595585823059082, Accuracy: 0.7236328125\n",
      "Batch: 45, Loss: 0.9002287983894348, Accuracy: 0.70751953125\n",
      "Batch: 46, Loss: 0.8790591359138489, Accuracy: 0.69482421875\n",
      "Batch: 47, Loss: 0.9393815398216248, Accuracy: 0.69384765625\n",
      "Batch: 48, Loss: 0.894530177116394, Accuracy: 0.71533203125\n",
      "Batch: 49, Loss: 0.9082232117652893, Accuracy: 0.7021484375\n",
      "Batch: 50, Loss: 0.9530726075172424, Accuracy: 0.69140625\n",
      "Batch: 51, Loss: 0.9204015135765076, Accuracy: 0.7021484375\n",
      "Batch: 52, Loss: 0.8865078687667847, Accuracy: 0.705078125\n",
      "Batch: 53, Loss: 0.9011072516441345, Accuracy: 0.70556640625\n",
      "Batch: 54, Loss: 0.9331759214401245, Accuracy: 0.69384765625\n",
      "Batch: 55, Loss: 0.9008201360702515, Accuracy: 0.7177734375\n",
      "Batch: 56, Loss: 0.8859779834747314, Accuracy: 0.7099609375\n",
      "Batch: 57, Loss: 0.9932373762130737, Accuracy: 0.68603515625\n",
      "Batch: 58, Loss: 0.9238716959953308, Accuracy: 0.69677734375\n",
      "Batch: 59, Loss: 1.0417771339416504, Accuracy: 0.671875\n",
      "Batch: 60, Loss: 0.9336382150650024, Accuracy: 0.70068359375\n",
      "Batch: 61, Loss: 0.8793451189994812, Accuracy: 0.7197265625\n",
      "Batch: 62, Loss: 0.909269392490387, Accuracy: 0.71484375\n",
      "Batch: 63, Loss: 0.9287387728691101, Accuracy: 0.70458984375\n",
      "Batch: 64, Loss: 0.926916778087616, Accuracy: 0.6875\n",
      "Batch: 65, Loss: 0.9737683534622192, Accuracy: 0.69091796875\n",
      "Batch: 66, Loss: 0.9709495306015015, Accuracy: 0.68310546875\n",
      "Batch: 67, Loss: 0.9626693725585938, Accuracy: 0.69091796875\n",
      "Batch: 68, Loss: 0.8875335454940796, Accuracy: 0.70751953125\n",
      "Batch: 69, Loss: 0.9626414775848389, Accuracy: 0.6884765625\n",
      "Batch: 70, Loss: 0.9609555602073669, Accuracy: 0.68212890625\n",
      "Batch: 71, Loss: 0.9463363885879517, Accuracy: 0.69140625\n",
      "Batch: 72, Loss: 0.9527839422225952, Accuracy: 0.68115234375\n",
      "Batch: 73, Loss: 0.9885762929916382, Accuracy: 0.67822265625\n",
      "Batch: 74, Loss: 0.9900057911872864, Accuracy: 0.68798828125\n",
      "Batch: 75, Loss: 0.9055070281028748, Accuracy: 0.70654296875\n",
      "Batch: 76, Loss: 0.893032431602478, Accuracy: 0.716796875\n",
      "Batch: 77, Loss: 0.8938618898391724, Accuracy: 0.71337890625\n",
      "Batch: 78, Loss: 0.9363633394241333, Accuracy: 0.70361328125\n",
      "Batch: 79, Loss: 0.9481102824211121, Accuracy: 0.6982421875\n",
      "Batch: 80, Loss: 0.9323097467422485, Accuracy: 0.68798828125\n",
      "Batch: 81, Loss: 0.9607324600219727, Accuracy: 0.69921875\n",
      "Batch: 82, Loss: 0.8891345262527466, Accuracy: 0.70458984375\n",
      "Batch: 83, Loss: 0.8823910355567932, Accuracy: 0.70458984375\n",
      "Batch: 84, Loss: 0.8653481602668762, Accuracy: 0.72119140625\n",
      "Batch: 85, Loss: 0.8703018426895142, Accuracy: 0.71044921875\n",
      "Batch: 86, Loss: 0.9993835091590881, Accuracy: 0.68212890625\n",
      "Batch: 87, Loss: 0.8880331516265869, Accuracy: 0.712890625\n",
      "Batch: 88, Loss: 0.9771053791046143, Accuracy: 0.6904296875\n",
      "Batch: 89, Loss: 0.9565863609313965, Accuracy: 0.6904296875\n",
      "Batch: 90, Loss: 1.0063393115997314, Accuracy: 0.66162109375\n",
      "Batch: 91, Loss: 0.9193869829177856, Accuracy: 0.70263671875\n",
      "Batch: 92, Loss: 1.0404249429702759, Accuracy: 0.65966796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 93, Loss: 0.9949056506156921, Accuracy: 0.67041015625\n",
      "Batch: 94, Loss: 1.0029339790344238, Accuracy: 0.6875\n",
      "Batch: 95, Loss: 1.0254278182983398, Accuracy: 0.66650390625\n",
      "Batch: 96, Loss: 0.9689086675643921, Accuracy: 0.6943359375\n",
      "Batch: 97, Loss: 0.9322611093521118, Accuracy: 0.70166015625\n",
      "Batch: 98, Loss: 1.02615225315094, Accuracy: 0.6796875\n",
      "Batch: 99, Loss: 0.9142414331436157, Accuracy: 0.720703125\n",
      "Batch: 100, Loss: 1.0230488777160645, Accuracy: 0.6748046875\n",
      "Batch: 101, Loss: 1.0549561977386475, Accuracy: 0.66845703125\n",
      "Batch: 102, Loss: 0.9253473281860352, Accuracy: 0.6982421875\n",
      "Batch: 103, Loss: 0.9923783540725708, Accuracy: 0.68798828125\n",
      "Batch: 104, Loss: 0.9557621479034424, Accuracy: 0.7001953125\n",
      "Batch: 105, Loss: 0.993162989616394, Accuracy: 0.6875\n",
      "Batch: 106, Loss: 0.9675496816635132, Accuracy: 0.68505859375\n",
      "Batch: 107, Loss: 1.003801941871643, Accuracy: 0.68603515625\n",
      "Batch: 108, Loss: 0.9559961557388306, Accuracy: 0.705078125\n",
      "Batch: 109, Loss: 0.9540339708328247, Accuracy: 0.69189453125\n",
      "Batch: 110, Loss: 0.9171230792999268, Accuracy: 0.69970703125\n",
      "Batch: 111, Loss: 0.8383839130401611, Accuracy: 0.72900390625\n",
      "Batch: 112, Loss: 0.9399975538253784, Accuracy: 0.70166015625\n",
      "Batch: 113, Loss: 0.9625650644302368, Accuracy: 0.68798828125\n",
      "Batch: 114, Loss: 0.9430637359619141, Accuracy: 0.6904296875\n",
      "Batch: 115, Loss: 0.9492212533950806, Accuracy: 0.6953125\n",
      "Batch: 116, Loss: 0.9521855711936951, Accuracy: 0.6904296875\n",
      "Batch: 117, Loss: 0.9724462032318115, Accuracy: 0.68115234375\n",
      "Batch: 118, Loss: 0.9441689848899841, Accuracy: 0.69482421875\n",
      "Batch: 119, Loss: 0.950498640537262, Accuracy: 0.68505859375\n",
      "Batch: 120, Loss: 0.949357271194458, Accuracy: 0.6875\n",
      "Batch: 121, Loss: 0.9460978507995605, Accuracy: 0.6923828125\n",
      "Batch: 122, Loss: 0.8964402675628662, Accuracy: 0.71533203125\n",
      "Batch: 123, Loss: 0.9357208013534546, Accuracy: 0.70654296875\n",
      "Batch: 124, Loss: 0.9002282619476318, Accuracy: 0.7109375\n",
      "Batch: 125, Loss: 0.9392584562301636, Accuracy: 0.69775390625\n",
      "Batch: 126, Loss: 0.8998156189918518, Accuracy: 0.7060546875\n",
      "Batch: 127, Loss: 0.8672498464584351, Accuracy: 0.72265625\n",
      "Batch: 128, Loss: 1.031279444694519, Accuracy: 0.67431640625\n",
      "Batch: 129, Loss: 1.0753527879714966, Accuracy: 0.6669921875\n",
      "Batch: 130, Loss: 1.0567489862442017, Accuracy: 0.6650390625\n",
      "Batch: 131, Loss: 1.015551209449768, Accuracy: 0.67529296875\n",
      "Batch: 132, Loss: 0.8822070956230164, Accuracy: 0.7255859375\n",
      "Batch: 133, Loss: 0.8814433217048645, Accuracy: 0.72607421875\n",
      "Batch: 134, Loss: 0.9796462059020996, Accuracy: 0.6875\n",
      "Batch: 135, Loss: 0.9652926921844482, Accuracy: 0.69580078125\n",
      "Batch: 136, Loss: 0.8907789587974548, Accuracy: 0.70458984375\n",
      "Batch: 137, Loss: 0.9641309976577759, Accuracy: 0.68994140625\n",
      "Batch: 138, Loss: 0.8449839353561401, Accuracy: 0.73388671875\n",
      "Batch: 139, Loss: 0.9214593172073364, Accuracy: 0.703125\n",
      "Batch: 140, Loss: 0.8695513010025024, Accuracy: 0.71630859375\n",
      "Batch: 141, Loss: 0.9880179166793823, Accuracy: 0.68017578125\n",
      "Batch: 142, Loss: 0.8693169355392456, Accuracy: 0.7109375\n",
      "Batch: 143, Loss: 0.9114753007888794, Accuracy: 0.7109375\n",
      "Batch: 144, Loss: 0.9697798490524292, Accuracy: 0.70263671875\n",
      "Batch: 145, Loss: 0.9423810839653015, Accuracy: 0.70166015625\n",
      "Batch: 146, Loss: 1.0012600421905518, Accuracy: 0.67529296875\n",
      "Batch: 147, Loss: 0.9479985237121582, Accuracy: 0.70703125\n",
      "Batch: 148, Loss: 0.9654706120491028, Accuracy: 0.67578125\n",
      "Batch: 149, Loss: 0.9344301223754883, Accuracy: 0.70654296875\n",
      "Batch: 150, Loss: 0.8051061630249023, Accuracy: 0.73583984375\n",
      "Batch: 151, Loss: 0.8169310092926025, Accuracy: 0.73486328125\n",
      "Batch: 152, Loss: 0.8799420595169067, Accuracy: 0.72021484375\n",
      "Batch: 153, Loss: 0.8627057075500488, Accuracy: 0.71337890625\n",
      "Batch: 154, Loss: 0.8625452518463135, Accuracy: 0.71728515625\n",
      "Batch: 155, Loss: 0.93650221824646, Accuracy: 0.70556640625\n",
      "Batch: 156, Loss: 0.8634963035583496, Accuracy: 0.72509765625\n",
      "Batch: 157, Loss: 0.8308901190757751, Accuracy: 0.72314453125\n",
      "Batch: 158, Loss: 0.8456240892410278, Accuracy: 0.7275390625\n",
      "Batch: 159, Loss: 0.8289482593536377, Accuracy: 0.73193359375\n",
      "Batch: 160, Loss: 0.8850728869438171, Accuracy: 0.7158203125\n",
      "Batch: 161, Loss: 0.9019967317581177, Accuracy: 0.70654296875\n",
      "Batch: 162, Loss: 0.8855898976325989, Accuracy: 0.71875\n",
      "Batch: 163, Loss: 0.9471599459648132, Accuracy: 0.69482421875\n",
      "Batch: 164, Loss: 0.9788283109664917, Accuracy: 0.69384765625\n",
      "Batch: 165, Loss: 0.8920843601226807, Accuracy: 0.71240234375\n",
      "Batch: 166, Loss: 0.9270471334457397, Accuracy: 0.705078125\n",
      "Batch: 167, Loss: 0.8706938028335571, Accuracy: 0.72314453125\n",
      "Batch: 168, Loss: 0.8254219889640808, Accuracy: 0.73974609375\n",
      "Batch: 169, Loss: 0.9065402746200562, Accuracy: 0.7109375\n",
      "Batch: 170, Loss: 0.9619126319885254, Accuracy: 0.69189453125\n",
      "Batch: 171, Loss: 0.9099217653274536, Accuracy: 0.7099609375\n",
      "Batch: 172, Loss: 0.8739962577819824, Accuracy: 0.7197265625\n",
      "Batch: 173, Loss: 0.9296458959579468, Accuracy: 0.7109375\n",
      "Batch: 174, Loss: 0.7959129214286804, Accuracy: 0.73876953125\n",
      "Batch: 175, Loss: 0.9438968300819397, Accuracy: 0.6826171875\n",
      "Batch: 176, Loss: 0.9885530471801758, Accuracy: 0.685546875\n",
      "Batch: 177, Loss: 0.914229154586792, Accuracy: 0.7041015625\n",
      "Batch: 178, Loss: 0.863527774810791, Accuracy: 0.7265625\n",
      "Batch: 179, Loss: 0.9010285139083862, Accuracy: 0.7099609375\n",
      "Batch: 180, Loss: 0.957446813583374, Accuracy: 0.69140625\n",
      "Epoch 25/200\n",
      "Batch: 1, Loss: 1.3148882389068604, Accuracy: 0.634765625\n",
      "Batch: 2, Loss: 0.9241147041320801, Accuracy: 0.69140625\n",
      "Batch: 3, Loss: 0.9153239130973816, Accuracy: 0.69140625\n",
      "Batch: 4, Loss: 0.9601235389709473, Accuracy: 0.69287109375\n",
      "Batch: 5, Loss: 0.9586760997772217, Accuracy: 0.6923828125\n",
      "Batch: 6, Loss: 0.9668043255805969, Accuracy: 0.68994140625\n",
      "Batch: 7, Loss: 0.8787310123443604, Accuracy: 0.72509765625\n",
      "Batch: 8, Loss: 0.9406174421310425, Accuracy: 0.6923828125\n",
      "Batch: 9, Loss: 0.9981223344802856, Accuracy: 0.6845703125\n",
      "Batch: 10, Loss: 0.9310085773468018, Accuracy: 0.7109375\n",
      "Batch: 11, Loss: 0.9971092939376831, Accuracy: 0.66748046875\n",
      "Batch: 12, Loss: 0.8782099485397339, Accuracy: 0.7138671875\n",
      "Batch: 13, Loss: 0.929582417011261, Accuracy: 0.69482421875\n",
      "Batch: 14, Loss: 0.9220504760742188, Accuracy: 0.7109375\n",
      "Batch: 15, Loss: 0.9356755018234253, Accuracy: 0.70703125\n",
      "Batch: 16, Loss: 0.9981222152709961, Accuracy: 0.677734375\n",
      "Batch: 17, Loss: 0.9143500328063965, Accuracy: 0.71875\n",
      "Batch: 18, Loss: 0.978654146194458, Accuracy: 0.69775390625\n",
      "Batch: 19, Loss: 0.9604928493499756, Accuracy: 0.6982421875\n",
      "Batch: 20, Loss: 0.8707165122032166, Accuracy: 0.71826171875\n",
      "Batch: 21, Loss: 1.0414878129959106, Accuracy: 0.673828125\n",
      "Batch: 22, Loss: 0.9212440848350525, Accuracy: 0.70654296875\n",
      "Batch: 23, Loss: 0.9006623029708862, Accuracy: 0.712890625\n",
      "Batch: 24, Loss: 0.9213330745697021, Accuracy: 0.7001953125\n",
      "Batch: 25, Loss: 0.884543776512146, Accuracy: 0.71826171875\n",
      "Batch: 26, Loss: 0.9250320792198181, Accuracy: 0.70556640625\n",
      "Batch: 27, Loss: 0.9638493061065674, Accuracy: 0.6806640625\n",
      "Batch: 28, Loss: 0.8932111859321594, Accuracy: 0.71826171875\n",
      "Batch: 29, Loss: 0.9736266732215881, Accuracy: 0.6982421875\n",
      "Batch: 30, Loss: 0.9258036613464355, Accuracy: 0.70654296875\n",
      "Batch: 31, Loss: 1.0732957124710083, Accuracy: 0.66943359375\n",
      "Batch: 32, Loss: 0.9594905376434326, Accuracy: 0.7041015625\n",
      "Batch: 33, Loss: 1.012159824371338, Accuracy: 0.66943359375\n",
      "Batch: 34, Loss: 1.022953987121582, Accuracy: 0.673828125\n",
      "Batch: 35, Loss: 1.0512663125991821, Accuracy: 0.66455078125\n",
      "Batch: 36, Loss: 1.0021852254867554, Accuracy: 0.681640625\n",
      "Batch: 37, Loss: 0.9871184825897217, Accuracy: 0.68798828125\n",
      "Batch: 38, Loss: 1.018420934677124, Accuracy: 0.66748046875\n",
      "Batch: 39, Loss: 0.9667654037475586, Accuracy: 0.7001953125\n",
      "Batch: 40, Loss: 1.0078375339508057, Accuracy: 0.69140625\n",
      "Batch: 41, Loss: 0.9727180600166321, Accuracy: 0.6845703125\n",
      "Batch: 42, Loss: 0.9411913156509399, Accuracy: 0.685546875\n",
      "Batch: 43, Loss: 0.9073721170425415, Accuracy: 0.71435546875\n",
      "Batch: 44, Loss: 0.8506715297698975, Accuracy: 0.72802734375\n",
      "Batch: 45, Loss: 0.8972722887992859, Accuracy: 0.71435546875\n",
      "Batch: 46, Loss: 0.8488694429397583, Accuracy: 0.71826171875\n",
      "Batch: 47, Loss: 0.9209399223327637, Accuracy: 0.69921875\n",
      "Batch: 48, Loss: 0.8857276439666748, Accuracy: 0.72705078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 49, Loss: 0.8908387422561646, Accuracy: 0.7021484375\n",
      "Batch: 50, Loss: 0.9294791221618652, Accuracy: 0.705078125\n",
      "Batch: 51, Loss: 0.9024519324302673, Accuracy: 0.70361328125\n",
      "Batch: 52, Loss: 0.87564617395401, Accuracy: 0.70751953125\n",
      "Batch: 53, Loss: 0.8916672468185425, Accuracy: 0.71044921875\n",
      "Batch: 54, Loss: 0.9360028505325317, Accuracy: 0.68994140625\n",
      "Batch: 55, Loss: 0.8736369609832764, Accuracy: 0.72119140625\n",
      "Batch: 56, Loss: 0.8676505088806152, Accuracy: 0.71728515625\n",
      "Batch: 57, Loss: 0.9683834314346313, Accuracy: 0.7060546875\n",
      "Batch: 58, Loss: 0.9301173090934753, Accuracy: 0.69189453125\n",
      "Batch: 59, Loss: 1.0338177680969238, Accuracy: 0.6728515625\n",
      "Batch: 60, Loss: 0.9313780069351196, Accuracy: 0.70654296875\n",
      "Batch: 61, Loss: 0.8593343496322632, Accuracy: 0.7255859375\n",
      "Batch: 62, Loss: 0.8899067640304565, Accuracy: 0.72265625\n",
      "Batch: 63, Loss: 0.9052374362945557, Accuracy: 0.70263671875\n",
      "Batch: 64, Loss: 0.9325898885726929, Accuracy: 0.689453125\n",
      "Batch: 65, Loss: 0.9711812138557434, Accuracy: 0.69580078125\n",
      "Batch: 66, Loss: 0.948601484298706, Accuracy: 0.69921875\n",
      "Batch: 67, Loss: 0.950698971748352, Accuracy: 0.69580078125\n",
      "Batch: 68, Loss: 0.8801181316375732, Accuracy: 0.71240234375\n",
      "Batch: 69, Loss: 0.9437006711959839, Accuracy: 0.69189453125\n",
      "Batch: 70, Loss: 0.9551267623901367, Accuracy: 0.68505859375\n",
      "Batch: 71, Loss: 0.9328005313873291, Accuracy: 0.70751953125\n",
      "Batch: 72, Loss: 0.9603272080421448, Accuracy: 0.6865234375\n",
      "Batch: 73, Loss: 0.9732176065444946, Accuracy: 0.673828125\n",
      "Batch: 74, Loss: 0.9845665693283081, Accuracy: 0.69140625\n",
      "Batch: 75, Loss: 0.9010797739028931, Accuracy: 0.7060546875\n",
      "Batch: 76, Loss: 0.8837580680847168, Accuracy: 0.71435546875\n",
      "Batch: 77, Loss: 0.8691856861114502, Accuracy: 0.71337890625\n",
      "Batch: 78, Loss: 0.9116032719612122, Accuracy: 0.71484375\n",
      "Batch: 79, Loss: 0.9529742002487183, Accuracy: 0.7060546875\n",
      "Batch: 80, Loss: 0.9253041744232178, Accuracy: 0.6904296875\n",
      "Batch: 81, Loss: 0.9783458709716797, Accuracy: 0.69287109375\n",
      "Batch: 82, Loss: 0.8835195302963257, Accuracy: 0.703125\n",
      "Batch: 83, Loss: 0.875655472278595, Accuracy: 0.70068359375\n",
      "Batch: 84, Loss: 0.8569347262382507, Accuracy: 0.72265625\n",
      "Batch: 85, Loss: 0.8676517009735107, Accuracy: 0.70361328125\n",
      "Batch: 86, Loss: 1.0014255046844482, Accuracy: 0.67578125\n",
      "Batch: 87, Loss: 0.8900848627090454, Accuracy: 0.7216796875\n",
      "Batch: 88, Loss: 0.9679990410804749, Accuracy: 0.69580078125\n",
      "Batch: 89, Loss: 0.9492301940917969, Accuracy: 0.6953125\n",
      "Batch: 90, Loss: 1.0077059268951416, Accuracy: 0.66650390625\n",
      "Batch: 91, Loss: 0.912800669670105, Accuracy: 0.70263671875\n",
      "Batch: 92, Loss: 1.0225452184677124, Accuracy: 0.66552734375\n",
      "Batch: 93, Loss: 0.9549025297164917, Accuracy: 0.693359375\n",
      "Batch: 94, Loss: 0.9999923706054688, Accuracy: 0.67724609375\n",
      "Batch: 95, Loss: 1.015059232711792, Accuracy: 0.68212890625\n",
      "Batch: 96, Loss: 0.9719274044036865, Accuracy: 0.69580078125\n",
      "Batch: 97, Loss: 0.9246357083320618, Accuracy: 0.7216796875\n",
      "Batch: 98, Loss: 1.033597707748413, Accuracy: 0.66845703125\n",
      "Batch: 99, Loss: 0.8922440409660339, Accuracy: 0.72119140625\n",
      "Batch: 100, Loss: 1.0197862386703491, Accuracy: 0.67431640625\n",
      "Batch: 101, Loss: 1.0386039018630981, Accuracy: 0.67041015625\n",
      "Batch: 102, Loss: 0.9041712880134583, Accuracy: 0.712890625\n",
      "Batch: 103, Loss: 0.9586154222488403, Accuracy: 0.68994140625\n",
      "Batch: 104, Loss: 0.9295110702514648, Accuracy: 0.708984375\n",
      "Batch: 105, Loss: 0.9834647178649902, Accuracy: 0.68896484375\n",
      "Batch: 106, Loss: 0.9651113748550415, Accuracy: 0.6904296875\n",
      "Batch: 107, Loss: 0.9866708517074585, Accuracy: 0.6767578125\n",
      "Batch: 108, Loss: 0.9355069994926453, Accuracy: 0.6962890625\n",
      "Batch: 109, Loss: 0.9437588453292847, Accuracy: 0.6943359375\n",
      "Batch: 110, Loss: 0.8971117734909058, Accuracy: 0.70361328125\n",
      "Batch: 111, Loss: 0.8375120759010315, Accuracy: 0.72314453125\n",
      "Batch: 112, Loss: 0.9097699522972107, Accuracy: 0.71240234375\n",
      "Batch: 113, Loss: 0.9524343609809875, Accuracy: 0.69921875\n",
      "Batch: 114, Loss: 0.915823221206665, Accuracy: 0.70263671875\n",
      "Batch: 115, Loss: 0.9487194418907166, Accuracy: 0.70458984375\n",
      "Batch: 116, Loss: 0.9369766712188721, Accuracy: 0.69580078125\n",
      "Batch: 117, Loss: 0.9374395608901978, Accuracy: 0.69921875\n",
      "Batch: 118, Loss: 0.9535384178161621, Accuracy: 0.68798828125\n",
      "Batch: 119, Loss: 0.9416649341583252, Accuracy: 0.68115234375\n",
      "Batch: 120, Loss: 0.9135540723800659, Accuracy: 0.69580078125\n",
      "Batch: 121, Loss: 0.9366967082023621, Accuracy: 0.69140625\n",
      "Batch: 122, Loss: 0.8895735740661621, Accuracy: 0.70849609375\n",
      "Batch: 123, Loss: 0.9147565364837646, Accuracy: 0.7119140625\n",
      "Batch: 124, Loss: 0.8973363637924194, Accuracy: 0.7001953125\n",
      "Batch: 125, Loss: 0.9260345697402954, Accuracy: 0.6962890625\n",
      "Batch: 126, Loss: 0.869127631187439, Accuracy: 0.71923828125\n",
      "Batch: 127, Loss: 0.85302734375, Accuracy: 0.73046875\n",
      "Batch: 128, Loss: 1.034142255783081, Accuracy: 0.67138671875\n",
      "Batch: 129, Loss: 1.0630757808685303, Accuracy: 0.66650390625\n",
      "Batch: 130, Loss: 1.036104679107666, Accuracy: 0.6572265625\n",
      "Batch: 131, Loss: 0.9687684178352356, Accuracy: 0.6953125\n",
      "Batch: 132, Loss: 0.8587523698806763, Accuracy: 0.7255859375\n",
      "Batch: 133, Loss: 0.858696699142456, Accuracy: 0.73486328125\n",
      "Batch: 134, Loss: 0.9789153337478638, Accuracy: 0.68310546875\n",
      "Batch: 135, Loss: 0.9401006698608398, Accuracy: 0.697265625\n",
      "Batch: 136, Loss: 0.8672451972961426, Accuracy: 0.7109375\n",
      "Batch: 137, Loss: 0.9404060244560242, Accuracy: 0.7001953125\n",
      "Batch: 138, Loss: 0.8172620534896851, Accuracy: 0.7509765625\n",
      "Batch: 139, Loss: 0.9063233137130737, Accuracy: 0.70751953125\n",
      "Batch: 140, Loss: 0.8570444583892822, Accuracy: 0.720703125\n",
      "Batch: 141, Loss: 0.9629902839660645, Accuracy: 0.69140625\n",
      "Batch: 142, Loss: 0.8744984269142151, Accuracy: 0.70703125\n",
      "Batch: 143, Loss: 0.9110807776451111, Accuracy: 0.71337890625\n",
      "Batch: 144, Loss: 0.9504709243774414, Accuracy: 0.7001953125\n",
      "Batch: 145, Loss: 0.9306309223175049, Accuracy: 0.708984375\n",
      "Batch: 146, Loss: 0.9828259944915771, Accuracy: 0.67578125\n",
      "Batch: 147, Loss: 0.9229533076286316, Accuracy: 0.7001953125\n",
      "Batch: 148, Loss: 0.94688880443573, Accuracy: 0.69384765625\n",
      "Batch: 149, Loss: 0.9362143874168396, Accuracy: 0.701171875\n",
      "Batch: 150, Loss: 0.7894390225410461, Accuracy: 0.748046875\n",
      "Batch: 151, Loss: 0.8009594678878784, Accuracy: 0.74462890625\n",
      "Batch: 152, Loss: 0.8598498702049255, Accuracy: 0.72705078125\n",
      "Batch: 153, Loss: 0.8397549390792847, Accuracy: 0.73291015625\n",
      "Batch: 154, Loss: 0.8426923751831055, Accuracy: 0.7236328125\n",
      "Batch: 155, Loss: 0.9435504674911499, Accuracy: 0.701171875\n",
      "Batch: 156, Loss: 0.8468124866485596, Accuracy: 0.7333984375\n",
      "Batch: 157, Loss: 0.8319368958473206, Accuracy: 0.720703125\n",
      "Batch: 158, Loss: 0.8293548822402954, Accuracy: 0.73974609375\n",
      "Batch: 159, Loss: 0.8384217619895935, Accuracy: 0.734375\n",
      "Batch: 160, Loss: 0.8728475570678711, Accuracy: 0.72314453125\n",
      "Batch: 161, Loss: 0.9028037786483765, Accuracy: 0.7001953125\n",
      "Batch: 162, Loss: 0.8681378364562988, Accuracy: 0.7236328125\n",
      "Batch: 163, Loss: 0.9444725513458252, Accuracy: 0.6953125\n",
      "Batch: 164, Loss: 0.971214771270752, Accuracy: 0.69384765625\n",
      "Batch: 165, Loss: 0.8976560831069946, Accuracy: 0.708984375\n",
      "Batch: 166, Loss: 0.9130026698112488, Accuracy: 0.708984375\n",
      "Batch: 167, Loss: 0.8685761094093323, Accuracy: 0.72802734375\n",
      "Batch: 168, Loss: 0.8221533298492432, Accuracy: 0.7392578125\n",
      "Batch: 169, Loss: 0.886500358581543, Accuracy: 0.705078125\n",
      "Batch: 170, Loss: 0.9592564702033997, Accuracy: 0.68896484375\n",
      "Batch: 171, Loss: 0.8948264718055725, Accuracy: 0.71142578125\n",
      "Batch: 172, Loss: 0.8631899952888489, Accuracy: 0.71875\n",
      "Batch: 173, Loss: 0.9389477372169495, Accuracy: 0.7119140625\n",
      "Batch: 174, Loss: 0.7887961864471436, Accuracy: 0.74169921875\n",
      "Batch: 175, Loss: 0.9464123249053955, Accuracy: 0.68408203125\n",
      "Batch: 176, Loss: 0.9786692261695862, Accuracy: 0.693359375\n",
      "Batch: 177, Loss: 0.8822267055511475, Accuracy: 0.72314453125\n",
      "Batch: 178, Loss: 0.8688911199569702, Accuracy: 0.70947265625\n",
      "Batch: 179, Loss: 0.9013818502426147, Accuracy: 0.716796875\n",
      "Batch: 180, Loss: 0.9550200700759888, Accuracy: 0.7001953125\n",
      "Epoch 26/200\n",
      "Batch: 1, Loss: 1.3130664825439453, Accuracy: 0.642578125\n",
      "Batch: 2, Loss: 0.8988670706748962, Accuracy: 0.70947265625\n",
      "Batch: 3, Loss: 0.9082801342010498, Accuracy: 0.7080078125\n",
      "Batch: 4, Loss: 0.9347594976425171, Accuracy: 0.69775390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 5, Loss: 0.9415926933288574, Accuracy: 0.70751953125\n",
      "Batch: 6, Loss: 0.9452013969421387, Accuracy: 0.69921875\n",
      "Batch: 7, Loss: 0.8587145805358887, Accuracy: 0.72216796875\n",
      "Batch: 8, Loss: 0.9286295175552368, Accuracy: 0.69775390625\n",
      "Batch: 9, Loss: 0.9834970235824585, Accuracy: 0.68505859375\n",
      "Batch: 10, Loss: 0.9385651350021362, Accuracy: 0.70166015625\n",
      "Batch: 11, Loss: 0.9911614060401917, Accuracy: 0.67626953125\n",
      "Batch: 12, Loss: 0.8558033108711243, Accuracy: 0.71875\n",
      "Batch: 13, Loss: 0.925360918045044, Accuracy: 0.69921875\n",
      "Batch: 14, Loss: 0.8988697528839111, Accuracy: 0.70947265625\n",
      "Batch: 15, Loss: 0.9223248362541199, Accuracy: 0.7080078125\n",
      "Batch: 16, Loss: 0.9840227961540222, Accuracy: 0.689453125\n",
      "Batch: 17, Loss: 0.9081906080245972, Accuracy: 0.70947265625\n",
      "Batch: 18, Loss: 0.96120285987854, Accuracy: 0.68994140625\n",
      "Batch: 19, Loss: 0.956324577331543, Accuracy: 0.70703125\n",
      "Batch: 20, Loss: 0.8546792268753052, Accuracy: 0.7236328125\n",
      "Batch: 21, Loss: 1.0115985870361328, Accuracy: 0.69189453125\n",
      "Batch: 22, Loss: 0.9048924446105957, Accuracy: 0.708984375\n",
      "Batch: 23, Loss: 0.8863268494606018, Accuracy: 0.7216796875\n",
      "Batch: 24, Loss: 0.8998725414276123, Accuracy: 0.7119140625\n",
      "Batch: 25, Loss: 0.879724383354187, Accuracy: 0.71728515625\n",
      "Batch: 26, Loss: 0.8986071348190308, Accuracy: 0.7099609375\n",
      "Batch: 27, Loss: 0.9329685568809509, Accuracy: 0.6953125\n",
      "Batch: 28, Loss: 0.8754637241363525, Accuracy: 0.71630859375\n",
      "Batch: 29, Loss: 0.972480297088623, Accuracy: 0.693359375\n",
      "Batch: 30, Loss: 0.9304438829421997, Accuracy: 0.70556640625\n",
      "Batch: 31, Loss: 1.0536694526672363, Accuracy: 0.6767578125\n",
      "Batch: 32, Loss: 0.9780781269073486, Accuracy: 0.6953125\n",
      "Batch: 33, Loss: 0.9705990552902222, Accuracy: 0.6923828125\n",
      "Batch: 34, Loss: 1.000382900238037, Accuracy: 0.68359375\n",
      "Batch: 35, Loss: 1.040871500968933, Accuracy: 0.66064453125\n",
      "Batch: 36, Loss: 0.9777563810348511, Accuracy: 0.69677734375\n",
      "Batch: 37, Loss: 0.9715194702148438, Accuracy: 0.6904296875\n",
      "Batch: 38, Loss: 1.0006364583969116, Accuracy: 0.67724609375\n",
      "Batch: 39, Loss: 0.9506228566169739, Accuracy: 0.7021484375\n",
      "Batch: 40, Loss: 1.0067487955093384, Accuracy: 0.67626953125\n",
      "Batch: 41, Loss: 0.9390391111373901, Accuracy: 0.69091796875\n",
      "Batch: 42, Loss: 0.9265133738517761, Accuracy: 0.68798828125\n",
      "Batch: 43, Loss: 0.8865351676940918, Accuracy: 0.72998046875\n",
      "Batch: 44, Loss: 0.8167356252670288, Accuracy: 0.73681640625\n",
      "Batch: 45, Loss: 0.8763266801834106, Accuracy: 0.71484375\n",
      "Batch: 46, Loss: 0.8570103645324707, Accuracy: 0.705078125\n",
      "Batch: 47, Loss: 0.9085105657577515, Accuracy: 0.7080078125\n",
      "Batch: 48, Loss: 0.8813473582267761, Accuracy: 0.72412109375\n",
      "Batch: 49, Loss: 0.8720526695251465, Accuracy: 0.7060546875\n",
      "Batch: 50, Loss: 0.910474419593811, Accuracy: 0.70654296875\n",
      "Batch: 51, Loss: 0.8933860063552856, Accuracy: 0.7109375\n",
      "Batch: 52, Loss: 0.8629920482635498, Accuracy: 0.7138671875\n",
      "Batch: 53, Loss: 0.8733843564987183, Accuracy: 0.71435546875\n",
      "Batch: 54, Loss: 0.9125020503997803, Accuracy: 0.70068359375\n",
      "Batch: 55, Loss: 0.8680007457733154, Accuracy: 0.71875\n",
      "Batch: 56, Loss: 0.8728642463684082, Accuracy: 0.7177734375\n",
      "Batch: 57, Loss: 0.9599381685256958, Accuracy: 0.7080078125\n",
      "Batch: 58, Loss: 0.8949236869812012, Accuracy: 0.705078125\n",
      "Batch: 59, Loss: 1.0151078701019287, Accuracy: 0.68115234375\n",
      "Batch: 60, Loss: 0.9076764583587646, Accuracy: 0.70849609375\n",
      "Batch: 61, Loss: 0.8474070429801941, Accuracy: 0.7314453125\n",
      "Batch: 62, Loss: 0.881898045539856, Accuracy: 0.72509765625\n",
      "Batch: 63, Loss: 0.8926603198051453, Accuracy: 0.70556640625\n",
      "Batch: 64, Loss: 0.9226890206336975, Accuracy: 0.69091796875\n",
      "Batch: 65, Loss: 0.9838168025016785, Accuracy: 0.6953125\n",
      "Batch: 66, Loss: 0.9400593042373657, Accuracy: 0.697265625\n",
      "Batch: 67, Loss: 0.9490617513656616, Accuracy: 0.68505859375\n",
      "Batch: 68, Loss: 0.8569256067276001, Accuracy: 0.7197265625\n",
      "Batch: 69, Loss: 0.9452412128448486, Accuracy: 0.685546875\n",
      "Batch: 70, Loss: 0.9260913729667664, Accuracy: 0.69140625\n",
      "Batch: 71, Loss: 0.9101359844207764, Accuracy: 0.70703125\n",
      "Batch: 72, Loss: 0.9483810663223267, Accuracy: 0.68603515625\n",
      "Batch: 73, Loss: 0.9646708965301514, Accuracy: 0.69287109375\n",
      "Batch: 74, Loss: 0.9601559042930603, Accuracy: 0.701171875\n",
      "Batch: 75, Loss: 0.8657013177871704, Accuracy: 0.716796875\n",
      "Batch: 76, Loss: 0.8756175637245178, Accuracy: 0.712890625\n",
      "Batch: 77, Loss: 0.8671762943267822, Accuracy: 0.728515625\n",
      "Batch: 78, Loss: 0.9139969944953918, Accuracy: 0.71484375\n",
      "Batch: 79, Loss: 0.9246832132339478, Accuracy: 0.7138671875\n",
      "Batch: 80, Loss: 0.9270024299621582, Accuracy: 0.6953125\n",
      "Batch: 81, Loss: 0.9485411643981934, Accuracy: 0.7021484375\n",
      "Batch: 82, Loss: 0.8800897598266602, Accuracy: 0.7119140625\n",
      "Batch: 83, Loss: 0.8515310883522034, Accuracy: 0.724609375\n",
      "Batch: 84, Loss: 0.8421400785446167, Accuracy: 0.73291015625\n",
      "Batch: 85, Loss: 0.8588905334472656, Accuracy: 0.71044921875\n",
      "Batch: 86, Loss: 0.9807113409042358, Accuracy: 0.68798828125\n",
      "Batch: 87, Loss: 0.8682949542999268, Accuracy: 0.72265625\n",
      "Batch: 88, Loss: 0.9426194429397583, Accuracy: 0.7099609375\n",
      "Batch: 89, Loss: 0.9385424852371216, Accuracy: 0.69482421875\n",
      "Batch: 90, Loss: 0.9867327213287354, Accuracy: 0.67822265625\n",
      "Batch: 91, Loss: 0.8969202041625977, Accuracy: 0.7021484375\n",
      "Batch: 92, Loss: 1.0203006267547607, Accuracy: 0.6787109375\n",
      "Batch: 93, Loss: 0.9489474892616272, Accuracy: 0.69970703125\n",
      "Batch: 94, Loss: 0.9649937748908997, Accuracy: 0.6962890625\n",
      "Batch: 95, Loss: 0.9953768849372864, Accuracy: 0.68408203125\n",
      "Batch: 96, Loss: 0.9448044300079346, Accuracy: 0.693359375\n",
      "Batch: 97, Loss: 0.9218616485595703, Accuracy: 0.71337890625\n",
      "Batch: 98, Loss: 1.0122952461242676, Accuracy: 0.67919921875\n",
      "Batch: 99, Loss: 0.8974829912185669, Accuracy: 0.7236328125\n",
      "Batch: 100, Loss: 0.9964691400527954, Accuracy: 0.68359375\n",
      "Batch: 101, Loss: 1.0218478441238403, Accuracy: 0.66796875\n",
      "Batch: 102, Loss: 0.8784245252609253, Accuracy: 0.7119140625\n",
      "Batch: 103, Loss: 0.9595025181770325, Accuracy: 0.6943359375\n",
      "Batch: 104, Loss: 0.9222986698150635, Accuracy: 0.70068359375\n",
      "Batch: 105, Loss: 0.9714078307151794, Accuracy: 0.68798828125\n",
      "Batch: 106, Loss: 0.9464036822319031, Accuracy: 0.69091796875\n",
      "Batch: 107, Loss: 0.9619708061218262, Accuracy: 0.6884765625\n",
      "Batch: 108, Loss: 0.9308932423591614, Accuracy: 0.7001953125\n",
      "Batch: 109, Loss: 0.9168990850448608, Accuracy: 0.70849609375\n",
      "Batch: 110, Loss: 0.8996057510375977, Accuracy: 0.7060546875\n",
      "Batch: 111, Loss: 0.8285088539123535, Accuracy: 0.73486328125\n",
      "Batch: 112, Loss: 0.916305422782898, Accuracy: 0.724609375\n",
      "Batch: 113, Loss: 0.9465972185134888, Accuracy: 0.69677734375\n",
      "Batch: 114, Loss: 0.9211117625236511, Accuracy: 0.6982421875\n",
      "Batch: 115, Loss: 0.9229567050933838, Accuracy: 0.7119140625\n",
      "Batch: 116, Loss: 0.9268356561660767, Accuracy: 0.70068359375\n",
      "Batch: 117, Loss: 0.9393197298049927, Accuracy: 0.6953125\n",
      "Batch: 118, Loss: 0.9119176864624023, Accuracy: 0.70849609375\n",
      "Batch: 119, Loss: 0.9252213835716248, Accuracy: 0.69140625\n",
      "Batch: 120, Loss: 0.9016932249069214, Accuracy: 0.70654296875\n",
      "Batch: 121, Loss: 0.9363389015197754, Accuracy: 0.69287109375\n",
      "Batch: 122, Loss: 0.872182309627533, Accuracy: 0.71923828125\n",
      "Batch: 123, Loss: 0.9032697677612305, Accuracy: 0.71484375\n",
      "Batch: 124, Loss: 0.8776819705963135, Accuracy: 0.71142578125\n",
      "Batch: 125, Loss: 0.9106267690658569, Accuracy: 0.708984375\n",
      "Batch: 126, Loss: 0.8657881617546082, Accuracy: 0.71484375\n",
      "Batch: 127, Loss: 0.8481199145317078, Accuracy: 0.734375\n",
      "Batch: 128, Loss: 1.0156270265579224, Accuracy: 0.68359375\n",
      "Batch: 129, Loss: 1.0473982095718384, Accuracy: 0.67236328125\n",
      "Batch: 130, Loss: 1.024592399597168, Accuracy: 0.67236328125\n",
      "Batch: 131, Loss: 0.9662959575653076, Accuracy: 0.697265625\n",
      "Batch: 132, Loss: 0.867634654045105, Accuracy: 0.71533203125\n",
      "Batch: 133, Loss: 0.853000283241272, Accuracy: 0.7353515625\n",
      "Batch: 134, Loss: 0.9529315233230591, Accuracy: 0.693359375\n",
      "Batch: 135, Loss: 0.9251890182495117, Accuracy: 0.70361328125\n",
      "Batch: 136, Loss: 0.8700029850006104, Accuracy: 0.705078125\n",
      "Batch: 137, Loss: 0.9336687326431274, Accuracy: 0.70556640625\n",
      "Batch: 138, Loss: 0.8185913562774658, Accuracy: 0.74365234375\n",
      "Batch: 139, Loss: 0.8828288316726685, Accuracy: 0.72119140625\n",
      "Batch: 140, Loss: 0.835862934589386, Accuracy: 0.73046875\n",
      "Batch: 141, Loss: 0.9613436460494995, Accuracy: 0.689453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 142, Loss: 0.8409984111785889, Accuracy: 0.72900390625\n",
      "Batch: 143, Loss: 0.8785173892974854, Accuracy: 0.720703125\n",
      "Batch: 144, Loss: 0.9412996172904968, Accuracy: 0.705078125\n",
      "Batch: 145, Loss: 0.9190770387649536, Accuracy: 0.7119140625\n",
      "Batch: 146, Loss: 0.9631040692329407, Accuracy: 0.68017578125\n",
      "Batch: 147, Loss: 0.9045959115028381, Accuracy: 0.712890625\n",
      "Batch: 148, Loss: 0.9450259208679199, Accuracy: 0.6923828125\n",
      "Batch: 149, Loss: 0.9117956161499023, Accuracy: 0.70556640625\n",
      "Batch: 150, Loss: 0.7882399559020996, Accuracy: 0.74462890625\n",
      "Batch: 151, Loss: 0.812749981880188, Accuracy: 0.72998046875\n",
      "Batch: 152, Loss: 0.8631352186203003, Accuracy: 0.72265625\n",
      "Batch: 153, Loss: 0.8242157697677612, Accuracy: 0.736328125\n",
      "Batch: 154, Loss: 0.8379181623458862, Accuracy: 0.7236328125\n",
      "Batch: 155, Loss: 0.9308197498321533, Accuracy: 0.70751953125\n",
      "Batch: 156, Loss: 0.8429358005523682, Accuracy: 0.72314453125\n",
      "Batch: 157, Loss: 0.8174476623535156, Accuracy: 0.72412109375\n",
      "Batch: 158, Loss: 0.8317857384681702, Accuracy: 0.7353515625\n",
      "Batch: 159, Loss: 0.8239692449569702, Accuracy: 0.73583984375\n",
      "Batch: 160, Loss: 0.8554754853248596, Accuracy: 0.72216796875\n",
      "Batch: 161, Loss: 0.8816165924072266, Accuracy: 0.70556640625\n",
      "Batch: 162, Loss: 0.8630004525184631, Accuracy: 0.73388671875\n",
      "Batch: 163, Loss: 0.9357011318206787, Accuracy: 0.69873046875\n",
      "Batch: 164, Loss: 0.9478459358215332, Accuracy: 0.70556640625\n",
      "Batch: 165, Loss: 0.8804054856300354, Accuracy: 0.72119140625\n",
      "Batch: 166, Loss: 0.8998551964759827, Accuracy: 0.70947265625\n",
      "Batch: 167, Loss: 0.8575121164321899, Accuracy: 0.72314453125\n",
      "Batch: 168, Loss: 0.8021520376205444, Accuracy: 0.7412109375\n",
      "Batch: 169, Loss: 0.8744280934333801, Accuracy: 0.7138671875\n",
      "Batch: 170, Loss: 0.9475228786468506, Accuracy: 0.69677734375\n",
      "Batch: 171, Loss: 0.8739467859268188, Accuracy: 0.71923828125\n",
      "Batch: 172, Loss: 0.8493599891662598, Accuracy: 0.7197265625\n",
      "Batch: 173, Loss: 0.918053388595581, Accuracy: 0.70849609375\n",
      "Batch: 174, Loss: 0.7649087905883789, Accuracy: 0.748046875\n",
      "Batch: 175, Loss: 0.9271575212478638, Accuracy: 0.69189453125\n",
      "Batch: 176, Loss: 0.9423562288284302, Accuracy: 0.7041015625\n",
      "Batch: 177, Loss: 0.876189112663269, Accuracy: 0.7216796875\n",
      "Batch: 178, Loss: 0.8465843200683594, Accuracy: 0.72802734375\n",
      "Batch: 179, Loss: 0.8833218216896057, Accuracy: 0.7294921875\n",
      "Batch: 180, Loss: 0.9441500902175903, Accuracy: 0.69482421875\n",
      "Epoch 27/200\n",
      "Batch: 1, Loss: 1.2877285480499268, Accuracy: 0.64111328125\n",
      "Batch: 2, Loss: 0.8915146589279175, Accuracy: 0.7080078125\n",
      "Batch: 3, Loss: 0.9160293340682983, Accuracy: 0.70703125\n",
      "Batch: 4, Loss: 0.9246161580085754, Accuracy: 0.69873046875\n",
      "Batch: 5, Loss: 0.9346551895141602, Accuracy: 0.70556640625\n",
      "Batch: 6, Loss: 0.9406863451004028, Accuracy: 0.6982421875\n",
      "Batch: 7, Loss: 0.8556991815567017, Accuracy: 0.724609375\n",
      "Batch: 8, Loss: 0.9076999425888062, Accuracy: 0.705078125\n",
      "Batch: 9, Loss: 0.9729710817337036, Accuracy: 0.70166015625\n",
      "Batch: 10, Loss: 0.9279022812843323, Accuracy: 0.7109375\n",
      "Batch: 11, Loss: 0.957150936126709, Accuracy: 0.6953125\n",
      "Batch: 12, Loss: 0.8493379354476929, Accuracy: 0.7333984375\n",
      "Batch: 13, Loss: 0.9131419658660889, Accuracy: 0.7021484375\n",
      "Batch: 14, Loss: 0.9080148339271545, Accuracy: 0.70947265625\n",
      "Batch: 15, Loss: 0.9135527610778809, Accuracy: 0.71337890625\n",
      "Batch: 16, Loss: 0.986545205116272, Accuracy: 0.68310546875\n",
      "Batch: 17, Loss: 0.8899593353271484, Accuracy: 0.71728515625\n",
      "Batch: 18, Loss: 0.9536691904067993, Accuracy: 0.69384765625\n",
      "Batch: 19, Loss: 0.9580950736999512, Accuracy: 0.69921875\n",
      "Batch: 20, Loss: 0.8503299951553345, Accuracy: 0.728515625\n",
      "Batch: 21, Loss: 1.0158276557922363, Accuracy: 0.68798828125\n",
      "Batch: 22, Loss: 0.8812920451164246, Accuracy: 0.72509765625\n",
      "Batch: 23, Loss: 0.8737784028053284, Accuracy: 0.70751953125\n",
      "Batch: 24, Loss: 0.882394552230835, Accuracy: 0.71240234375\n",
      "Batch: 25, Loss: 0.881271481513977, Accuracy: 0.7197265625\n",
      "Batch: 26, Loss: 0.900484561920166, Accuracy: 0.71875\n",
      "Batch: 27, Loss: 0.910470187664032, Accuracy: 0.7060546875\n",
      "Batch: 28, Loss: 0.8749547004699707, Accuracy: 0.7158203125\n",
      "Batch: 29, Loss: 0.9583122730255127, Accuracy: 0.697265625\n",
      "Batch: 30, Loss: 0.9157758951187134, Accuracy: 0.7099609375\n",
      "Batch: 31, Loss: 1.0383591651916504, Accuracy: 0.67919921875\n",
      "Batch: 32, Loss: 0.9399236440658569, Accuracy: 0.70166015625\n",
      "Batch: 33, Loss: 0.9687171578407288, Accuracy: 0.6875\n",
      "Batch: 34, Loss: 1.0061910152435303, Accuracy: 0.673828125\n",
      "Batch: 35, Loss: 1.036141037940979, Accuracy: 0.66943359375\n",
      "Batch: 36, Loss: 0.9756305813789368, Accuracy: 0.69677734375\n",
      "Batch: 37, Loss: 0.9279766082763672, Accuracy: 0.70263671875\n",
      "Batch: 38, Loss: 0.9870010614395142, Accuracy: 0.68017578125\n",
      "Batch: 39, Loss: 0.9513357877731323, Accuracy: 0.69775390625\n",
      "Batch: 40, Loss: 0.9882994890213013, Accuracy: 0.68994140625\n",
      "Batch: 41, Loss: 0.9386703968048096, Accuracy: 0.703125\n",
      "Batch: 42, Loss: 0.9166500568389893, Accuracy: 0.6962890625\n",
      "Batch: 43, Loss: 0.8878797292709351, Accuracy: 0.72802734375\n",
      "Batch: 44, Loss: 0.8156469464302063, Accuracy: 0.74072265625\n",
      "Batch: 45, Loss: 0.8494569063186646, Accuracy: 0.72900390625\n",
      "Batch: 46, Loss: 0.8328690528869629, Accuracy: 0.71533203125\n",
      "Batch: 47, Loss: 0.8989633917808533, Accuracy: 0.71337890625\n",
      "Batch: 48, Loss: 0.8519790172576904, Accuracy: 0.73388671875\n",
      "Batch: 49, Loss: 0.8614901900291443, Accuracy: 0.7177734375\n",
      "Batch: 50, Loss: 0.9100304841995239, Accuracy: 0.71435546875\n",
      "Batch: 51, Loss: 0.8917989134788513, Accuracy: 0.71240234375\n",
      "Batch: 52, Loss: 0.8505147099494934, Accuracy: 0.71826171875\n",
      "Batch: 53, Loss: 0.8603744506835938, Accuracy: 0.72216796875\n",
      "Batch: 54, Loss: 0.9117492437362671, Accuracy: 0.69873046875\n",
      "Batch: 55, Loss: 0.8540468215942383, Accuracy: 0.728515625\n",
      "Batch: 56, Loss: 0.8639597296714783, Accuracy: 0.72216796875\n",
      "Batch: 57, Loss: 0.9479913711547852, Accuracy: 0.70068359375\n",
      "Batch: 58, Loss: 0.8960072994232178, Accuracy: 0.701171875\n",
      "Batch: 59, Loss: 1.0232727527618408, Accuracy: 0.6708984375\n",
      "Batch: 60, Loss: 0.8903911113739014, Accuracy: 0.7265625\n",
      "Batch: 61, Loss: 0.844452440738678, Accuracy: 0.72265625\n",
      "Batch: 62, Loss: 0.8710869550704956, Accuracy: 0.734375\n",
      "Batch: 63, Loss: 0.8817093968391418, Accuracy: 0.708984375\n",
      "Batch: 64, Loss: 0.8926178812980652, Accuracy: 0.70556640625\n",
      "Batch: 65, Loss: 0.9474025368690491, Accuracy: 0.7041015625\n",
      "Batch: 66, Loss: 0.9563775062561035, Accuracy: 0.70263671875\n",
      "Batch: 67, Loss: 0.9328583478927612, Accuracy: 0.69482421875\n",
      "Batch: 68, Loss: 0.8542248010635376, Accuracy: 0.71728515625\n",
      "Batch: 69, Loss: 0.9042545557022095, Accuracy: 0.69775390625\n",
      "Batch: 70, Loss: 0.8995373249053955, Accuracy: 0.70654296875\n",
      "Batch: 71, Loss: 0.904879093170166, Accuracy: 0.69970703125\n",
      "Batch: 72, Loss: 0.9207485914230347, Accuracy: 0.68505859375\n",
      "Batch: 73, Loss: 0.9478046894073486, Accuracy: 0.689453125\n",
      "Batch: 74, Loss: 0.9462724328041077, Accuracy: 0.705078125\n",
      "Batch: 75, Loss: 0.864860475063324, Accuracy: 0.71435546875\n",
      "Batch: 76, Loss: 0.8541837930679321, Accuracy: 0.73046875\n",
      "Batch: 77, Loss: 0.8643203973770142, Accuracy: 0.72216796875\n",
      "Batch: 78, Loss: 0.896948516368866, Accuracy: 0.71923828125\n",
      "Batch: 79, Loss: 0.901911735534668, Accuracy: 0.7197265625\n",
      "Batch: 80, Loss: 0.916671633720398, Accuracy: 0.69140625\n",
      "Batch: 81, Loss: 0.9352010488510132, Accuracy: 0.71533203125\n",
      "Batch: 82, Loss: 0.8755961656570435, Accuracy: 0.71142578125\n",
      "Batch: 83, Loss: 0.8456754684448242, Accuracy: 0.71630859375\n",
      "Batch: 84, Loss: 0.8374372720718384, Accuracy: 0.728515625\n",
      "Batch: 85, Loss: 0.8456664085388184, Accuracy: 0.71728515625\n",
      "Batch: 86, Loss: 0.9861730337142944, Accuracy: 0.689453125\n",
      "Batch: 87, Loss: 0.8519413471221924, Accuracy: 0.7314453125\n",
      "Batch: 88, Loss: 0.9354270100593567, Accuracy: 0.70703125\n",
      "Batch: 89, Loss: 0.9121516942977905, Accuracy: 0.7138671875\n",
      "Batch: 90, Loss: 0.9660372138023376, Accuracy: 0.6904296875\n",
      "Batch: 91, Loss: 0.879007875919342, Accuracy: 0.716796875\n",
      "Batch: 92, Loss: 1.0083837509155273, Accuracy: 0.673828125\n",
      "Batch: 93, Loss: 0.9456454515457153, Accuracy: 0.68994140625\n",
      "Batch: 94, Loss: 0.9482988119125366, Accuracy: 0.70849609375\n",
      "Batch: 95, Loss: 0.9812144041061401, Accuracy: 0.68603515625\n",
      "Batch: 96, Loss: 0.9261137247085571, Accuracy: 0.705078125\n",
      "Batch: 97, Loss: 0.8938332796096802, Accuracy: 0.72119140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 98, Loss: 1.0080198049545288, Accuracy: 0.6875\n",
      "Batch: 99, Loss: 0.8886328339576721, Accuracy: 0.7197265625\n",
      "Batch: 100, Loss: 0.9798313975334167, Accuracy: 0.6953125\n",
      "Batch: 101, Loss: 1.0042264461517334, Accuracy: 0.68017578125\n",
      "Batch: 102, Loss: 0.8752477765083313, Accuracy: 0.716796875\n",
      "Batch: 103, Loss: 0.9424644112586975, Accuracy: 0.70654296875\n",
      "Batch: 104, Loss: 0.9242385625839233, Accuracy: 0.70361328125\n",
      "Batch: 105, Loss: 0.9702309370040894, Accuracy: 0.69091796875\n",
      "Batch: 106, Loss: 0.9152193069458008, Accuracy: 0.705078125\n",
      "Batch: 107, Loss: 0.9587715268135071, Accuracy: 0.68994140625\n",
      "Batch: 108, Loss: 0.9167572259902954, Accuracy: 0.7001953125\n",
      "Batch: 109, Loss: 0.9210227131843567, Accuracy: 0.70703125\n",
      "Batch: 110, Loss: 0.8815518021583557, Accuracy: 0.71484375\n",
      "Batch: 111, Loss: 0.8149784803390503, Accuracy: 0.734375\n",
      "Batch: 112, Loss: 0.897595226764679, Accuracy: 0.72314453125\n",
      "Batch: 113, Loss: 0.9364361763000488, Accuracy: 0.703125\n",
      "Batch: 114, Loss: 0.8923722505569458, Accuracy: 0.712890625\n",
      "Batch: 115, Loss: 0.9213425517082214, Accuracy: 0.70361328125\n",
      "Batch: 116, Loss: 0.9124178290367126, Accuracy: 0.69921875\n",
      "Batch: 117, Loss: 0.9242744445800781, Accuracy: 0.70458984375\n",
      "Batch: 118, Loss: 0.911179780960083, Accuracy: 0.70751953125\n",
      "Batch: 119, Loss: 0.9250690937042236, Accuracy: 0.6943359375\n",
      "Batch: 120, Loss: 0.8932561874389648, Accuracy: 0.705078125\n",
      "Batch: 121, Loss: 0.9023258090019226, Accuracy: 0.7060546875\n",
      "Batch: 122, Loss: 0.8564449548721313, Accuracy: 0.7255859375\n",
      "Batch: 123, Loss: 0.8879432678222656, Accuracy: 0.71826171875\n",
      "Batch: 124, Loss: 0.8599058985710144, Accuracy: 0.71630859375\n",
      "Batch: 125, Loss: 0.9054136276245117, Accuracy: 0.70166015625\n",
      "Batch: 126, Loss: 0.8585876822471619, Accuracy: 0.7236328125\n",
      "Batch: 127, Loss: 0.8459231853485107, Accuracy: 0.72705078125\n",
      "Batch: 128, Loss: 1.0019298791885376, Accuracy: 0.6865234375\n",
      "Batch: 129, Loss: 1.0204322338104248, Accuracy: 0.6787109375\n",
      "Batch: 130, Loss: 1.0224604606628418, Accuracy: 0.6689453125\n",
      "Batch: 131, Loss: 0.9570364952087402, Accuracy: 0.69580078125\n",
      "Batch: 132, Loss: 0.8602267503738403, Accuracy: 0.72119140625\n",
      "Batch: 133, Loss: 0.8388444185256958, Accuracy: 0.748046875\n",
      "Batch: 134, Loss: 0.9419023990631104, Accuracy: 0.69482421875\n",
      "Batch: 135, Loss: 0.905974268913269, Accuracy: 0.70556640625\n",
      "Batch: 136, Loss: 0.856606125831604, Accuracy: 0.7080078125\n",
      "Batch: 137, Loss: 0.9180271625518799, Accuracy: 0.716796875\n",
      "Batch: 138, Loss: 0.8079562187194824, Accuracy: 0.759765625\n",
      "Batch: 139, Loss: 0.8923470377922058, Accuracy: 0.71142578125\n",
      "Batch: 140, Loss: 0.8422598242759705, Accuracy: 0.73095703125\n",
      "Batch: 141, Loss: 0.9431777000427246, Accuracy: 0.697265625\n",
      "Batch: 142, Loss: 0.8470637798309326, Accuracy: 0.7275390625\n",
      "Batch: 143, Loss: 0.8724925518035889, Accuracy: 0.7197265625\n",
      "Batch: 144, Loss: 0.9484131336212158, Accuracy: 0.703125\n",
      "Batch: 145, Loss: 0.9153134822845459, Accuracy: 0.71728515625\n",
      "Batch: 146, Loss: 0.9686928987503052, Accuracy: 0.677734375\n",
      "Batch: 147, Loss: 0.90736985206604, Accuracy: 0.708984375\n",
      "Batch: 148, Loss: 0.9309580326080322, Accuracy: 0.697265625\n",
      "Batch: 149, Loss: 0.893875777721405, Accuracy: 0.70654296875\n",
      "Batch: 150, Loss: 0.7842838764190674, Accuracy: 0.7509765625\n",
      "Batch: 151, Loss: 0.7953028678894043, Accuracy: 0.7431640625\n",
      "Batch: 152, Loss: 0.843745231628418, Accuracy: 0.73291015625\n",
      "Batch: 153, Loss: 0.8339310884475708, Accuracy: 0.7333984375\n",
      "Batch: 154, Loss: 0.8376381397247314, Accuracy: 0.72509765625\n",
      "Batch: 155, Loss: 0.9273690581321716, Accuracy: 0.69970703125\n",
      "Batch: 156, Loss: 0.8177891969680786, Accuracy: 0.728515625\n",
      "Batch: 157, Loss: 0.8184488415718079, Accuracy: 0.72412109375\n",
      "Batch: 158, Loss: 0.8122597932815552, Accuracy: 0.74267578125\n",
      "Batch: 159, Loss: 0.8079894781112671, Accuracy: 0.736328125\n",
      "Batch: 160, Loss: 0.8685667514801025, Accuracy: 0.71826171875\n",
      "Batch: 161, Loss: 0.8798356056213379, Accuracy: 0.7119140625\n",
      "Batch: 162, Loss: 0.8399134874343872, Accuracy: 0.73828125\n",
      "Batch: 163, Loss: 0.9226540327072144, Accuracy: 0.70458984375\n",
      "Batch: 164, Loss: 0.9592031240463257, Accuracy: 0.69384765625\n",
      "Batch: 165, Loss: 0.8587545156478882, Accuracy: 0.72802734375\n",
      "Batch: 166, Loss: 0.890910267829895, Accuracy: 0.7216796875\n",
      "Batch: 167, Loss: 0.8495776653289795, Accuracy: 0.72607421875\n",
      "Batch: 168, Loss: 0.7925021052360535, Accuracy: 0.75341796875\n",
      "Batch: 169, Loss: 0.8611462712287903, Accuracy: 0.71875\n",
      "Batch: 170, Loss: 0.9193397164344788, Accuracy: 0.7041015625\n",
      "Batch: 171, Loss: 0.8588549494743347, Accuracy: 0.7275390625\n",
      "Batch: 172, Loss: 0.8469862937927246, Accuracy: 0.7216796875\n",
      "Batch: 173, Loss: 0.9246118664741516, Accuracy: 0.71923828125\n",
      "Batch: 174, Loss: 0.757473349571228, Accuracy: 0.75048828125\n",
      "Batch: 175, Loss: 0.9114635586738586, Accuracy: 0.703125\n",
      "Batch: 176, Loss: 0.943428635597229, Accuracy: 0.7060546875\n",
      "Batch: 177, Loss: 0.8855171203613281, Accuracy: 0.71142578125\n",
      "Batch: 178, Loss: 0.8378373384475708, Accuracy: 0.72998046875\n",
      "Batch: 179, Loss: 0.8797186613082886, Accuracy: 0.720703125\n",
      "Batch: 180, Loss: 0.930307149887085, Accuracy: 0.7001953125\n",
      "Epoch 28/200\n",
      "Batch: 1, Loss: 1.2903410196304321, Accuracy: 0.6357421875\n",
      "Batch: 2, Loss: 0.885149359703064, Accuracy: 0.70068359375\n",
      "Batch: 3, Loss: 0.9048433303833008, Accuracy: 0.7041015625\n",
      "Batch: 4, Loss: 0.9373255372047424, Accuracy: 0.69775390625\n",
      "Batch: 5, Loss: 0.9182242155075073, Accuracy: 0.71142578125\n",
      "Batch: 6, Loss: 0.9300475716590881, Accuracy: 0.7021484375\n",
      "Batch: 7, Loss: 0.8540374040603638, Accuracy: 0.728515625\n",
      "Batch: 8, Loss: 0.8926773071289062, Accuracy: 0.7080078125\n",
      "Batch: 9, Loss: 0.9545109272003174, Accuracy: 0.70068359375\n",
      "Batch: 10, Loss: 0.8805211186408997, Accuracy: 0.7314453125\n",
      "Batch: 11, Loss: 0.9368910193443298, Accuracy: 0.693359375\n",
      "Batch: 12, Loss: 0.8397986888885498, Accuracy: 0.7294921875\n",
      "Batch: 13, Loss: 0.905901312828064, Accuracy: 0.70703125\n",
      "Batch: 14, Loss: 0.8743033409118652, Accuracy: 0.72509765625\n",
      "Batch: 15, Loss: 0.8955370187759399, Accuracy: 0.7119140625\n",
      "Batch: 16, Loss: 0.9686001539230347, Accuracy: 0.69580078125\n",
      "Batch: 17, Loss: 0.8963644504547119, Accuracy: 0.7197265625\n",
      "Batch: 18, Loss: 0.9342390298843384, Accuracy: 0.69482421875\n",
      "Batch: 19, Loss: 0.9310096502304077, Accuracy: 0.71533203125\n",
      "Batch: 20, Loss: 0.8383572697639465, Accuracy: 0.7373046875\n",
      "Batch: 21, Loss: 0.9952329397201538, Accuracy: 0.69921875\n",
      "Batch: 22, Loss: 0.8743646740913391, Accuracy: 0.71240234375\n",
      "Batch: 23, Loss: 0.8693287968635559, Accuracy: 0.71630859375\n",
      "Batch: 24, Loss: 0.8744567036628723, Accuracy: 0.72021484375\n",
      "Batch: 25, Loss: 0.8565347790718079, Accuracy: 0.724609375\n",
      "Batch: 26, Loss: 0.87151700258255, Accuracy: 0.73095703125\n",
      "Batch: 27, Loss: 0.9090887308120728, Accuracy: 0.69677734375\n",
      "Batch: 28, Loss: 0.8440133929252625, Accuracy: 0.7197265625\n",
      "Batch: 29, Loss: 0.938118577003479, Accuracy: 0.69384765625\n",
      "Batch: 30, Loss: 0.8962620496749878, Accuracy: 0.712890625\n",
      "Batch: 31, Loss: 1.0317823886871338, Accuracy: 0.67236328125\n",
      "Batch: 32, Loss: 0.947456955909729, Accuracy: 0.697265625\n",
      "Batch: 33, Loss: 0.9530919194221497, Accuracy: 0.68994140625\n",
      "Batch: 34, Loss: 0.9902675151824951, Accuracy: 0.68994140625\n",
      "Batch: 35, Loss: 1.0020980834960938, Accuracy: 0.67578125\n",
      "Batch: 36, Loss: 0.9706991910934448, Accuracy: 0.6962890625\n",
      "Batch: 37, Loss: 0.929768443107605, Accuracy: 0.69970703125\n",
      "Batch: 38, Loss: 0.985430121421814, Accuracy: 0.68115234375\n",
      "Batch: 39, Loss: 0.9192588329315186, Accuracy: 0.7158203125\n",
      "Batch: 40, Loss: 0.9756648540496826, Accuracy: 0.6826171875\n",
      "Batch: 41, Loss: 0.9296160936355591, Accuracy: 0.69580078125\n",
      "Batch: 42, Loss: 0.9031105041503906, Accuracy: 0.69921875\n",
      "Batch: 43, Loss: 0.8776962161064148, Accuracy: 0.7265625\n",
      "Batch: 44, Loss: 0.8015583753585815, Accuracy: 0.74072265625\n",
      "Batch: 45, Loss: 0.8618698120117188, Accuracy: 0.7236328125\n",
      "Batch: 46, Loss: 0.8191359043121338, Accuracy: 0.72412109375\n",
      "Batch: 47, Loss: 0.8721557855606079, Accuracy: 0.71923828125\n",
      "Batch: 48, Loss: 0.8423577547073364, Accuracy: 0.736328125\n",
      "Batch: 49, Loss: 0.8494577407836914, Accuracy: 0.72314453125\n",
      "Batch: 50, Loss: 0.8990248441696167, Accuracy: 0.7177734375\n",
      "Batch: 51, Loss: 0.8896310329437256, Accuracy: 0.71484375\n",
      "Batch: 52, Loss: 0.8475087881088257, Accuracy: 0.72412109375\n",
      "Batch: 53, Loss: 0.8524022698402405, Accuracy: 0.70947265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 54, Loss: 0.892770528793335, Accuracy: 0.6962890625\n",
      "Batch: 55, Loss: 0.8569533824920654, Accuracy: 0.720703125\n",
      "Batch: 56, Loss: 0.8523697853088379, Accuracy: 0.73046875\n",
      "Batch: 57, Loss: 0.9290995597839355, Accuracy: 0.70751953125\n",
      "Batch: 58, Loss: 0.8849321007728577, Accuracy: 0.70947265625\n",
      "Batch: 59, Loss: 0.9970489740371704, Accuracy: 0.68798828125\n",
      "Batch: 60, Loss: 0.8936519622802734, Accuracy: 0.71826171875\n",
      "Batch: 61, Loss: 0.8328729867935181, Accuracy: 0.7275390625\n",
      "Batch: 62, Loss: 0.8514194488525391, Accuracy: 0.734375\n",
      "Batch: 63, Loss: 0.8768692016601562, Accuracy: 0.71142578125\n",
      "Batch: 64, Loss: 0.8862621784210205, Accuracy: 0.708984375\n",
      "Batch: 65, Loss: 0.9375419616699219, Accuracy: 0.705078125\n",
      "Batch: 66, Loss: 0.9290456771850586, Accuracy: 0.7060546875\n",
      "Batch: 67, Loss: 0.9248892068862915, Accuracy: 0.69921875\n",
      "Batch: 68, Loss: 0.8499730229377747, Accuracy: 0.72412109375\n",
      "Batch: 69, Loss: 0.9069775342941284, Accuracy: 0.70068359375\n",
      "Batch: 70, Loss: 0.9008842706680298, Accuracy: 0.705078125\n",
      "Batch: 71, Loss: 0.8891658186912537, Accuracy: 0.71630859375\n",
      "Batch: 72, Loss: 0.9204725027084351, Accuracy: 0.69287109375\n",
      "Batch: 73, Loss: 0.950434684753418, Accuracy: 0.69482421875\n",
      "Batch: 74, Loss: 0.9256108999252319, Accuracy: 0.70751953125\n",
      "Batch: 75, Loss: 0.849791407585144, Accuracy: 0.7177734375\n",
      "Batch: 76, Loss: 0.8579002618789673, Accuracy: 0.7255859375\n",
      "Batch: 77, Loss: 0.8368844389915466, Accuracy: 0.7294921875\n",
      "Batch: 78, Loss: 0.8784087300300598, Accuracy: 0.72216796875\n",
      "Batch: 79, Loss: 0.9016992449760437, Accuracy: 0.70703125\n",
      "Batch: 80, Loss: 0.9148038625717163, Accuracy: 0.7041015625\n",
      "Batch: 81, Loss: 0.9424221515655518, Accuracy: 0.7041015625\n",
      "Batch: 82, Loss: 0.8698137998580933, Accuracy: 0.7099609375\n",
      "Batch: 83, Loss: 0.826894223690033, Accuracy: 0.72119140625\n",
      "Batch: 84, Loss: 0.8209630250930786, Accuracy: 0.736328125\n",
      "Batch: 85, Loss: 0.8356664180755615, Accuracy: 0.7197265625\n",
      "Batch: 86, Loss: 0.9425721168518066, Accuracy: 0.697265625\n",
      "Batch: 87, Loss: 0.8537619113922119, Accuracy: 0.72998046875\n",
      "Batch: 88, Loss: 0.9402406811714172, Accuracy: 0.7041015625\n",
      "Batch: 89, Loss: 0.892657995223999, Accuracy: 0.7138671875\n",
      "Batch: 90, Loss: 0.9717328548431396, Accuracy: 0.677734375\n",
      "Batch: 91, Loss: 0.8761876821517944, Accuracy: 0.7197265625\n",
      "Batch: 92, Loss: 1.0098975896835327, Accuracy: 0.6708984375\n",
      "Batch: 93, Loss: 0.954256534576416, Accuracy: 0.6884765625\n",
      "Batch: 94, Loss: 0.9363277554512024, Accuracy: 0.70556640625\n",
      "Batch: 95, Loss: 0.977954089641571, Accuracy: 0.685546875\n",
      "Batch: 96, Loss: 0.9128695726394653, Accuracy: 0.716796875\n",
      "Batch: 97, Loss: 0.8910768032073975, Accuracy: 0.724609375\n",
      "Batch: 98, Loss: 0.9923975467681885, Accuracy: 0.67626953125\n",
      "Batch: 99, Loss: 0.8827765583992004, Accuracy: 0.72412109375\n",
      "Batch: 100, Loss: 0.9870410561561584, Accuracy: 0.68505859375\n",
      "Batch: 101, Loss: 1.006632924079895, Accuracy: 0.6796875\n",
      "Batch: 102, Loss: 0.8769105672836304, Accuracy: 0.7158203125\n",
      "Batch: 103, Loss: 0.923798680305481, Accuracy: 0.701171875\n",
      "Batch: 104, Loss: 0.8970277309417725, Accuracy: 0.71533203125\n",
      "Batch: 105, Loss: 0.9532604217529297, Accuracy: 0.705078125\n",
      "Batch: 106, Loss: 0.9316771030426025, Accuracy: 0.70166015625\n",
      "Batch: 107, Loss: 0.9528415203094482, Accuracy: 0.69775390625\n",
      "Batch: 108, Loss: 0.9015874266624451, Accuracy: 0.70556640625\n",
      "Batch: 109, Loss: 0.9031564593315125, Accuracy: 0.7138671875\n",
      "Batch: 110, Loss: 0.8743889927864075, Accuracy: 0.71533203125\n",
      "Batch: 111, Loss: 0.8025192022323608, Accuracy: 0.7373046875\n",
      "Batch: 112, Loss: 0.8899552822113037, Accuracy: 0.71875\n",
      "Batch: 113, Loss: 0.9371627569198608, Accuracy: 0.7001953125\n",
      "Batch: 114, Loss: 0.8862876892089844, Accuracy: 0.71142578125\n",
      "Batch: 115, Loss: 0.8931199312210083, Accuracy: 0.71142578125\n",
      "Batch: 116, Loss: 0.9247969388961792, Accuracy: 0.70263671875\n",
      "Batch: 117, Loss: 0.9109929800033569, Accuracy: 0.70849609375\n",
      "Batch: 118, Loss: 0.8972740173339844, Accuracy: 0.71044921875\n",
      "Batch: 119, Loss: 0.9080432653427124, Accuracy: 0.70166015625\n",
      "Batch: 120, Loss: 0.8924686312675476, Accuracy: 0.7099609375\n",
      "Batch: 121, Loss: 0.9264774322509766, Accuracy: 0.70166015625\n",
      "Batch: 122, Loss: 0.850274920463562, Accuracy: 0.7275390625\n",
      "Batch: 123, Loss: 0.8688104748725891, Accuracy: 0.73095703125\n",
      "Batch: 124, Loss: 0.8493269681930542, Accuracy: 0.724609375\n",
      "Batch: 125, Loss: 0.888302206993103, Accuracy: 0.70703125\n",
      "Batch: 126, Loss: 0.8440046310424805, Accuracy: 0.720703125\n",
      "Batch: 127, Loss: 0.8322179317474365, Accuracy: 0.740234375\n",
      "Batch: 128, Loss: 0.9977074265480042, Accuracy: 0.685546875\n",
      "Batch: 129, Loss: 1.0260251760482788, Accuracy: 0.67578125\n",
      "Batch: 130, Loss: 1.010061502456665, Accuracy: 0.685546875\n",
      "Batch: 131, Loss: 0.9440567493438721, Accuracy: 0.697265625\n",
      "Batch: 132, Loss: 0.8462338447570801, Accuracy: 0.7265625\n",
      "Batch: 133, Loss: 0.8287004232406616, Accuracy: 0.75048828125\n",
      "Batch: 134, Loss: 0.9323486089706421, Accuracy: 0.6953125\n",
      "Batch: 135, Loss: 0.9200306534767151, Accuracy: 0.7119140625\n",
      "Batch: 136, Loss: 0.8451618552207947, Accuracy: 0.7216796875\n",
      "Batch: 137, Loss: 0.9123402237892151, Accuracy: 0.7119140625\n",
      "Batch: 138, Loss: 0.7922139167785645, Accuracy: 0.75439453125\n",
      "Batch: 139, Loss: 0.8678253889083862, Accuracy: 0.720703125\n",
      "Batch: 140, Loss: 0.8228627443313599, Accuracy: 0.72998046875\n",
      "Batch: 141, Loss: 0.9327211380004883, Accuracy: 0.697265625\n",
      "Batch: 142, Loss: 0.8324152231216431, Accuracy: 0.73388671875\n",
      "Batch: 143, Loss: 0.8730186223983765, Accuracy: 0.71728515625\n",
      "Batch: 144, Loss: 0.9380697011947632, Accuracy: 0.70654296875\n",
      "Batch: 145, Loss: 0.9204768538475037, Accuracy: 0.71044921875\n",
      "Batch: 146, Loss: 0.9385497570037842, Accuracy: 0.7001953125\n",
      "Batch: 147, Loss: 0.8929387927055359, Accuracy: 0.71533203125\n",
      "Batch: 148, Loss: 0.9177480340003967, Accuracy: 0.697265625\n",
      "Batch: 149, Loss: 0.9013586044311523, Accuracy: 0.70166015625\n",
      "Batch: 150, Loss: 0.7636218667030334, Accuracy: 0.75537109375\n",
      "Batch: 151, Loss: 0.7895842790603638, Accuracy: 0.7451171875\n",
      "Batch: 152, Loss: 0.8427441716194153, Accuracy: 0.73046875\n",
      "Batch: 153, Loss: 0.8194460868835449, Accuracy: 0.73486328125\n",
      "Batch: 154, Loss: 0.816162645816803, Accuracy: 0.72998046875\n",
      "Batch: 155, Loss: 0.9015304446220398, Accuracy: 0.71142578125\n",
      "Batch: 156, Loss: 0.8157714605331421, Accuracy: 0.7353515625\n",
      "Batch: 157, Loss: 0.7856159210205078, Accuracy: 0.73681640625\n",
      "Batch: 158, Loss: 0.8055568933486938, Accuracy: 0.73779296875\n",
      "Batch: 159, Loss: 0.809292733669281, Accuracy: 0.74365234375\n",
      "Batch: 160, Loss: 0.8271839022636414, Accuracy: 0.7314453125\n",
      "Batch: 161, Loss: 0.8628726005554199, Accuracy: 0.72314453125\n",
      "Batch: 162, Loss: 0.8328670263290405, Accuracy: 0.744140625\n",
      "Batch: 163, Loss: 0.908302903175354, Accuracy: 0.69873046875\n",
      "Batch: 164, Loss: 0.943785548210144, Accuracy: 0.693359375\n",
      "Batch: 165, Loss: 0.8579964637756348, Accuracy: 0.7373046875\n",
      "Batch: 166, Loss: 0.8748233318328857, Accuracy: 0.7275390625\n",
      "Batch: 167, Loss: 0.8486737608909607, Accuracy: 0.72412109375\n",
      "Batch: 168, Loss: 0.7803325653076172, Accuracy: 0.74951171875\n",
      "Batch: 169, Loss: 0.8626614809036255, Accuracy: 0.72412109375\n",
      "Batch: 170, Loss: 0.9094853401184082, Accuracy: 0.7138671875\n",
      "Batch: 171, Loss: 0.851999044418335, Accuracy: 0.7294921875\n",
      "Batch: 172, Loss: 0.82811439037323, Accuracy: 0.72802734375\n",
      "Batch: 173, Loss: 0.8950439691543579, Accuracy: 0.7177734375\n",
      "Batch: 174, Loss: 0.7500041127204895, Accuracy: 0.7529296875\n",
      "Batch: 175, Loss: 0.8994408249855042, Accuracy: 0.693359375\n",
      "Batch: 176, Loss: 0.9240726828575134, Accuracy: 0.70458984375\n",
      "Batch: 177, Loss: 0.8665347099304199, Accuracy: 0.72119140625\n",
      "Batch: 178, Loss: 0.8342073559761047, Accuracy: 0.72509765625\n",
      "Batch: 179, Loss: 0.8595923185348511, Accuracy: 0.7158203125\n",
      "Batch: 180, Loss: 0.9112921953201294, Accuracy: 0.7158203125\n",
      "Epoch 29/200\n",
      "Batch: 1, Loss: 1.262099027633667, Accuracy: 0.64208984375\n",
      "Batch: 2, Loss: 0.8796772360801697, Accuracy: 0.70654296875\n",
      "Batch: 3, Loss: 0.8748159408569336, Accuracy: 0.7138671875\n",
      "Batch: 4, Loss: 0.9309037923812866, Accuracy: 0.6982421875\n",
      "Batch: 5, Loss: 0.8984981775283813, Accuracy: 0.71240234375\n",
      "Batch: 6, Loss: 0.906158447265625, Accuracy: 0.71533203125\n",
      "Batch: 7, Loss: 0.8353956341743469, Accuracy: 0.72998046875\n",
      "Batch: 8, Loss: 0.8992536067962646, Accuracy: 0.703125\n",
      "Batch: 9, Loss: 0.942808985710144, Accuracy: 0.712890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10, Loss: 0.8815783858299255, Accuracy: 0.72265625\n",
      "Batch: 11, Loss: 0.9432279467582703, Accuracy: 0.7001953125\n",
      "Batch: 12, Loss: 0.8405696749687195, Accuracy: 0.73046875\n",
      "Batch: 13, Loss: 0.8930613994598389, Accuracy: 0.70703125\n",
      "Batch: 14, Loss: 0.867072343826294, Accuracy: 0.72509765625\n",
      "Batch: 15, Loss: 0.8752694725990295, Accuracy: 0.72509765625\n",
      "Batch: 16, Loss: 0.9615657329559326, Accuracy: 0.69287109375\n",
      "Batch: 17, Loss: 0.8730579614639282, Accuracy: 0.728515625\n",
      "Batch: 18, Loss: 0.9241158962249756, Accuracy: 0.70361328125\n",
      "Batch: 19, Loss: 0.9183343648910522, Accuracy: 0.71728515625\n",
      "Batch: 20, Loss: 0.838951587677002, Accuracy: 0.73046875\n",
      "Batch: 21, Loss: 0.9876285791397095, Accuracy: 0.693359375\n",
      "Batch: 22, Loss: 0.8765372037887573, Accuracy: 0.720703125\n",
      "Batch: 23, Loss: 0.8383822441101074, Accuracy: 0.73046875\n",
      "Batch: 24, Loss: 0.8689904808998108, Accuracy: 0.71484375\n",
      "Batch: 25, Loss: 0.855167031288147, Accuracy: 0.72900390625\n",
      "Batch: 26, Loss: 0.8876414895057678, Accuracy: 0.7197265625\n",
      "Batch: 27, Loss: 0.9109971523284912, Accuracy: 0.7060546875\n",
      "Batch: 28, Loss: 0.8513619899749756, Accuracy: 0.71728515625\n",
      "Batch: 29, Loss: 0.9339417815208435, Accuracy: 0.70263671875\n",
      "Batch: 30, Loss: 0.9113219976425171, Accuracy: 0.7109375\n",
      "Batch: 31, Loss: 1.026413917541504, Accuracy: 0.67822265625\n",
      "Batch: 32, Loss: 0.9296566843986511, Accuracy: 0.7021484375\n",
      "Batch: 33, Loss: 0.9377706050872803, Accuracy: 0.7021484375\n",
      "Batch: 34, Loss: 0.9648284912109375, Accuracy: 0.69482421875\n",
      "Batch: 35, Loss: 0.9971893429756165, Accuracy: 0.67919921875\n",
      "Batch: 36, Loss: 0.9511569738388062, Accuracy: 0.7099609375\n",
      "Batch: 37, Loss: 0.9292272925376892, Accuracy: 0.70556640625\n",
      "Batch: 38, Loss: 0.9817441701889038, Accuracy: 0.68798828125\n",
      "Batch: 39, Loss: 0.9204113483428955, Accuracy: 0.71240234375\n",
      "Batch: 40, Loss: 0.9580327272415161, Accuracy: 0.69287109375\n",
      "Batch: 41, Loss: 0.9337953329086304, Accuracy: 0.69482421875\n",
      "Batch: 42, Loss: 0.8766920566558838, Accuracy: 0.70458984375\n",
      "Batch: 43, Loss: 0.8720488548278809, Accuracy: 0.72265625\n",
      "Batch: 44, Loss: 0.7815494537353516, Accuracy: 0.75048828125\n",
      "Batch: 45, Loss: 0.8486723899841309, Accuracy: 0.7275390625\n",
      "Batch: 46, Loss: 0.8200029134750366, Accuracy: 0.724609375\n",
      "Batch: 47, Loss: 0.8716555833816528, Accuracy: 0.7177734375\n",
      "Batch: 48, Loss: 0.842054009437561, Accuracy: 0.72705078125\n",
      "Batch: 49, Loss: 0.8406725525856018, Accuracy: 0.72509765625\n",
      "Batch: 50, Loss: 0.8956213593482971, Accuracy: 0.71630859375\n",
      "Batch: 51, Loss: 0.8666650652885437, Accuracy: 0.716796875\n",
      "Batch: 52, Loss: 0.835113525390625, Accuracy: 0.72802734375\n",
      "Batch: 53, Loss: 0.8479229211807251, Accuracy: 0.7158203125\n",
      "Batch: 54, Loss: 0.8838684558868408, Accuracy: 0.69970703125\n",
      "Batch: 55, Loss: 0.8426401615142822, Accuracy: 0.728515625\n",
      "Batch: 56, Loss: 0.8344700336456299, Accuracy: 0.72412109375\n",
      "Batch: 57, Loss: 0.9182796478271484, Accuracy: 0.708984375\n",
      "Batch: 58, Loss: 0.8753345012664795, Accuracy: 0.71240234375\n",
      "Batch: 59, Loss: 0.9921050667762756, Accuracy: 0.68310546875\n",
      "Batch: 60, Loss: 0.8547124862670898, Accuracy: 0.73779296875\n",
      "Batch: 61, Loss: 0.8239044547080994, Accuracy: 0.74072265625\n",
      "Batch: 62, Loss: 0.8478351831436157, Accuracy: 0.73779296875\n",
      "Batch: 63, Loss: 0.8451769351959229, Accuracy: 0.72021484375\n",
      "Batch: 64, Loss: 0.8817440271377563, Accuracy: 0.71337890625\n",
      "Batch: 65, Loss: 0.9384317398071289, Accuracy: 0.703125\n",
      "Batch: 66, Loss: 0.9211234450340271, Accuracy: 0.70458984375\n",
      "Batch: 67, Loss: 0.9191732406616211, Accuracy: 0.70654296875\n",
      "Batch: 68, Loss: 0.8227798938751221, Accuracy: 0.72998046875\n",
      "Batch: 69, Loss: 0.8828632831573486, Accuracy: 0.71044921875\n",
      "Batch: 70, Loss: 0.9008789658546448, Accuracy: 0.7158203125\n",
      "Batch: 71, Loss: 0.883325457572937, Accuracy: 0.708984375\n",
      "Batch: 72, Loss: 0.9177913665771484, Accuracy: 0.693359375\n",
      "Batch: 73, Loss: 0.9281319379806519, Accuracy: 0.7021484375\n",
      "Batch: 74, Loss: 0.9248619079589844, Accuracy: 0.70654296875\n",
      "Batch: 75, Loss: 0.8562756180763245, Accuracy: 0.72412109375\n",
      "Batch: 76, Loss: 0.8201842308044434, Accuracy: 0.740234375\n",
      "Batch: 77, Loss: 0.8241679072380066, Accuracy: 0.73583984375\n",
      "Batch: 78, Loss: 0.8755427598953247, Accuracy: 0.7255859375\n",
      "Batch: 79, Loss: 0.8900008201599121, Accuracy: 0.716796875\n",
      "Batch: 80, Loss: 0.8940635919570923, Accuracy: 0.70654296875\n",
      "Batch: 81, Loss: 0.9096261262893677, Accuracy: 0.7080078125\n",
      "Batch: 82, Loss: 0.8493479490280151, Accuracy: 0.7177734375\n",
      "Batch: 83, Loss: 0.8323270082473755, Accuracy: 0.7275390625\n",
      "Batch: 84, Loss: 0.8140958547592163, Accuracy: 0.73974609375\n",
      "Batch: 85, Loss: 0.8282214403152466, Accuracy: 0.73046875\n",
      "Batch: 86, Loss: 0.9558547735214233, Accuracy: 0.7041015625\n",
      "Batch: 87, Loss: 0.8297516107559204, Accuracy: 0.736328125\n",
      "Batch: 88, Loss: 0.9153289794921875, Accuracy: 0.712890625\n",
      "Batch: 89, Loss: 0.8942168354988098, Accuracy: 0.7236328125\n",
      "Batch: 90, Loss: 0.9376378059387207, Accuracy: 0.69091796875\n",
      "Batch: 91, Loss: 0.8473057746887207, Accuracy: 0.72998046875\n",
      "Batch: 92, Loss: 0.9904465079307556, Accuracy: 0.6845703125\n",
      "Batch: 93, Loss: 0.9381276965141296, Accuracy: 0.69677734375\n",
      "Batch: 94, Loss: 0.918785810470581, Accuracy: 0.71923828125\n",
      "Batch: 95, Loss: 0.9586044549942017, Accuracy: 0.70068359375\n",
      "Batch: 96, Loss: 0.896694004535675, Accuracy: 0.71142578125\n",
      "Batch: 97, Loss: 0.8759815692901611, Accuracy: 0.7255859375\n",
      "Batch: 98, Loss: 0.9766736030578613, Accuracy: 0.69140625\n",
      "Batch: 99, Loss: 0.8674948215484619, Accuracy: 0.72900390625\n",
      "Batch: 100, Loss: 0.9710839986801147, Accuracy: 0.69384765625\n",
      "Batch: 101, Loss: 0.9949628710746765, Accuracy: 0.6865234375\n",
      "Batch: 102, Loss: 0.8488708734512329, Accuracy: 0.72216796875\n",
      "Batch: 103, Loss: 0.929662823677063, Accuracy: 0.71337890625\n",
      "Batch: 104, Loss: 0.8993157148361206, Accuracy: 0.71533203125\n",
      "Batch: 105, Loss: 0.9421641826629639, Accuracy: 0.69873046875\n",
      "Batch: 106, Loss: 0.907050609588623, Accuracy: 0.6982421875\n",
      "Batch: 107, Loss: 0.9284931421279907, Accuracy: 0.70751953125\n",
      "Batch: 108, Loss: 0.879427433013916, Accuracy: 0.71484375\n",
      "Batch: 109, Loss: 0.8883401155471802, Accuracy: 0.71240234375\n",
      "Batch: 110, Loss: 0.8597512245178223, Accuracy: 0.71875\n",
      "Batch: 111, Loss: 0.7975339889526367, Accuracy: 0.73974609375\n",
      "Batch: 112, Loss: 0.8708827495574951, Accuracy: 0.7197265625\n",
      "Batch: 113, Loss: 0.9292441010475159, Accuracy: 0.70068359375\n",
      "Batch: 114, Loss: 0.8756200075149536, Accuracy: 0.71728515625\n",
      "Batch: 115, Loss: 0.8950044512748718, Accuracy: 0.7080078125\n",
      "Batch: 116, Loss: 0.9123142957687378, Accuracy: 0.70458984375\n",
      "Batch: 117, Loss: 0.8867335915565491, Accuracy: 0.71728515625\n",
      "Batch: 118, Loss: 0.8823646306991577, Accuracy: 0.7099609375\n",
      "Batch: 119, Loss: 0.8986285328865051, Accuracy: 0.701171875\n",
      "Batch: 120, Loss: 0.8878200650215149, Accuracy: 0.71044921875\n",
      "Batch: 121, Loss: 0.8971592783927917, Accuracy: 0.70458984375\n",
      "Batch: 122, Loss: 0.8371628522872925, Accuracy: 0.72119140625\n",
      "Batch: 123, Loss: 0.8585911393165588, Accuracy: 0.720703125\n",
      "Batch: 124, Loss: 0.8386582136154175, Accuracy: 0.72509765625\n",
      "Batch: 125, Loss: 0.8796430230140686, Accuracy: 0.71533203125\n",
      "Batch: 126, Loss: 0.8272199630737305, Accuracy: 0.72607421875\n",
      "Batch: 127, Loss: 0.8198668956756592, Accuracy: 0.74462890625\n",
      "Batch: 128, Loss: 0.9835689663887024, Accuracy: 0.6982421875\n",
      "Batch: 129, Loss: 1.0215561389923096, Accuracy: 0.68115234375\n",
      "Batch: 130, Loss: 1.0016021728515625, Accuracy: 0.66748046875\n",
      "Batch: 131, Loss: 0.9222424030303955, Accuracy: 0.70458984375\n",
      "Batch: 132, Loss: 0.8403701782226562, Accuracy: 0.73291015625\n",
      "Batch: 133, Loss: 0.8203796744346619, Accuracy: 0.7373046875\n",
      "Batch: 134, Loss: 0.9249497652053833, Accuracy: 0.70361328125\n",
      "Batch: 135, Loss: 0.8894345164299011, Accuracy: 0.7197265625\n",
      "Batch: 136, Loss: 0.8361749053001404, Accuracy: 0.71630859375\n",
      "Batch: 137, Loss: 0.9050447940826416, Accuracy: 0.7197265625\n",
      "Batch: 138, Loss: 0.7881180047988892, Accuracy: 0.75927734375\n",
      "Batch: 139, Loss: 0.870948314666748, Accuracy: 0.72119140625\n",
      "Batch: 140, Loss: 0.8219329118728638, Accuracy: 0.73193359375\n",
      "Batch: 141, Loss: 0.9219610095024109, Accuracy: 0.69921875\n",
      "Batch: 142, Loss: 0.8222228288650513, Accuracy: 0.7314453125\n",
      "Batch: 143, Loss: 0.8582916259765625, Accuracy: 0.7314453125\n",
      "Batch: 144, Loss: 0.9284330606460571, Accuracy: 0.70361328125\n",
      "Batch: 145, Loss: 0.8837110996246338, Accuracy: 0.7177734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 146, Loss: 0.9405604600906372, Accuracy: 0.6943359375\n",
      "Batch: 147, Loss: 0.8898962736129761, Accuracy: 0.7216796875\n",
      "Batch: 148, Loss: 0.9181756973266602, Accuracy: 0.703125\n",
      "Batch: 149, Loss: 0.8963766098022461, Accuracy: 0.71044921875\n",
      "Batch: 150, Loss: 0.7452889680862427, Accuracy: 0.76123046875\n",
      "Batch: 151, Loss: 0.7676106691360474, Accuracy: 0.76318359375\n",
      "Batch: 152, Loss: 0.8204020261764526, Accuracy: 0.736328125\n",
      "Batch: 153, Loss: 0.803269624710083, Accuracy: 0.748046875\n",
      "Batch: 154, Loss: 0.8315560817718506, Accuracy: 0.72607421875\n",
      "Batch: 155, Loss: 0.8957874774932861, Accuracy: 0.7158203125\n",
      "Batch: 156, Loss: 0.811485767364502, Accuracy: 0.73583984375\n",
      "Batch: 157, Loss: 0.7902600765228271, Accuracy: 0.7412109375\n",
      "Batch: 158, Loss: 0.7898564338684082, Accuracy: 0.74267578125\n",
      "Batch: 159, Loss: 0.7870581150054932, Accuracy: 0.7490234375\n",
      "Batch: 160, Loss: 0.817070722579956, Accuracy: 0.732421875\n",
      "Batch: 161, Loss: 0.8544355630874634, Accuracy: 0.72607421875\n",
      "Batch: 162, Loss: 0.8290938138961792, Accuracy: 0.7412109375\n",
      "Batch: 163, Loss: 0.9021419882774353, Accuracy: 0.7080078125\n",
      "Batch: 164, Loss: 0.9252603650093079, Accuracy: 0.70556640625\n",
      "Batch: 165, Loss: 0.8547959327697754, Accuracy: 0.732421875\n",
      "Batch: 166, Loss: 0.8717542886734009, Accuracy: 0.724609375\n",
      "Batch: 167, Loss: 0.8234579563140869, Accuracy: 0.7421875\n",
      "Batch: 168, Loss: 0.7873101234436035, Accuracy: 0.7470703125\n",
      "Batch: 169, Loss: 0.834368109703064, Accuracy: 0.732421875\n",
      "Batch: 170, Loss: 0.9161250591278076, Accuracy: 0.70703125\n",
      "Batch: 171, Loss: 0.838854193687439, Accuracy: 0.72314453125\n",
      "Batch: 172, Loss: 0.8300500512123108, Accuracy: 0.728515625\n",
      "Batch: 173, Loss: 0.8821073770523071, Accuracy: 0.7197265625\n",
      "Batch: 174, Loss: 0.763066828250885, Accuracy: 0.7529296875\n",
      "Batch: 175, Loss: 0.8883165717124939, Accuracy: 0.69970703125\n",
      "Batch: 176, Loss: 0.8999845385551453, Accuracy: 0.716796875\n",
      "Batch: 177, Loss: 0.8479782342910767, Accuracy: 0.720703125\n",
      "Batch: 178, Loss: 0.8248714804649353, Accuracy: 0.72607421875\n",
      "Batch: 179, Loss: 0.8462880253791809, Accuracy: 0.7265625\n",
      "Batch: 180, Loss: 0.9170415997505188, Accuracy: 0.70556640625\n",
      "Epoch 30/200\n",
      "Batch: 1, Loss: 1.2376207113265991, Accuracy: 0.64892578125\n",
      "Batch: 2, Loss: 0.8736898899078369, Accuracy: 0.7119140625\n",
      "Batch: 3, Loss: 0.8771435022354126, Accuracy: 0.71435546875\n",
      "Batch: 4, Loss: 0.9012068510055542, Accuracy: 0.70556640625\n",
      "Batch: 5, Loss: 0.8987779021263123, Accuracy: 0.71044921875\n",
      "Batch: 6, Loss: 0.8975063562393188, Accuracy: 0.70751953125\n",
      "Batch: 7, Loss: 0.8281139135360718, Accuracy: 0.73095703125\n",
      "Batch: 8, Loss: 0.8743165731430054, Accuracy: 0.71630859375\n",
      "Batch: 9, Loss: 0.9267234802246094, Accuracy: 0.70849609375\n",
      "Batch: 10, Loss: 0.87358558177948, Accuracy: 0.7236328125\n",
      "Batch: 11, Loss: 0.9324030876159668, Accuracy: 0.70263671875\n",
      "Batch: 12, Loss: 0.8272751569747925, Accuracy: 0.73291015625\n",
      "Batch: 13, Loss: 0.8849594593048096, Accuracy: 0.71435546875\n",
      "Batch: 14, Loss: 0.8701619505882263, Accuracy: 0.724609375\n",
      "Batch: 15, Loss: 0.8669258952140808, Accuracy: 0.7275390625\n",
      "Batch: 16, Loss: 0.9433236122131348, Accuracy: 0.69580078125\n",
      "Batch: 17, Loss: 0.8693500757217407, Accuracy: 0.73681640625\n",
      "Batch: 18, Loss: 0.9143587350845337, Accuracy: 0.7099609375\n",
      "Batch: 19, Loss: 0.9121185541152954, Accuracy: 0.70263671875\n",
      "Batch: 20, Loss: 0.7980173230171204, Accuracy: 0.73583984375\n",
      "Batch: 21, Loss: 0.9741555452346802, Accuracy: 0.6982421875\n",
      "Batch: 22, Loss: 0.8502911329269409, Accuracy: 0.73193359375\n",
      "Batch: 23, Loss: 0.8485474586486816, Accuracy: 0.7314453125\n",
      "Batch: 24, Loss: 0.8449008464813232, Accuracy: 0.72705078125\n",
      "Batch: 25, Loss: 0.8332662582397461, Accuracy: 0.73095703125\n",
      "Batch: 26, Loss: 0.8619980812072754, Accuracy: 0.728515625\n",
      "Batch: 27, Loss: 0.9044423699378967, Accuracy: 0.69580078125\n",
      "Batch: 28, Loss: 0.8388022780418396, Accuracy: 0.72802734375\n",
      "Batch: 29, Loss: 0.927044153213501, Accuracy: 0.708984375\n",
      "Batch: 30, Loss: 0.8807219862937927, Accuracy: 0.71630859375\n",
      "Batch: 31, Loss: 1.0049065351486206, Accuracy: 0.68359375\n",
      "Batch: 32, Loss: 0.9207897186279297, Accuracy: 0.70947265625\n",
      "Batch: 33, Loss: 0.9405981302261353, Accuracy: 0.69189453125\n",
      "Batch: 34, Loss: 0.9600595831871033, Accuracy: 0.69921875\n",
      "Batch: 35, Loss: 0.9820500016212463, Accuracy: 0.68701171875\n",
      "Batch: 36, Loss: 0.9505524635314941, Accuracy: 0.70751953125\n",
      "Batch: 37, Loss: 0.9105234146118164, Accuracy: 0.70068359375\n",
      "Batch: 38, Loss: 0.9619898200035095, Accuracy: 0.693359375\n",
      "Batch: 39, Loss: 0.9078575372695923, Accuracy: 0.7177734375\n",
      "Batch: 40, Loss: 0.9553854465484619, Accuracy: 0.70458984375\n",
      "Batch: 41, Loss: 0.9091938734054565, Accuracy: 0.70361328125\n",
      "Batch: 42, Loss: 0.8762664794921875, Accuracy: 0.712890625\n",
      "Batch: 43, Loss: 0.8586884140968323, Accuracy: 0.7333984375\n",
      "Batch: 44, Loss: 0.778433084487915, Accuracy: 0.75\n",
      "Batch: 45, Loss: 0.8429147005081177, Accuracy: 0.73876953125\n",
      "Batch: 46, Loss: 0.8086193799972534, Accuracy: 0.7216796875\n",
      "Batch: 47, Loss: 0.853506326675415, Accuracy: 0.72119140625\n",
      "Batch: 48, Loss: 0.8410916328430176, Accuracy: 0.72705078125\n",
      "Batch: 49, Loss: 0.8349024057388306, Accuracy: 0.72705078125\n",
      "Batch: 50, Loss: 0.8807529211044312, Accuracy: 0.72314453125\n",
      "Batch: 51, Loss: 0.8542371988296509, Accuracy: 0.7275390625\n",
      "Batch: 52, Loss: 0.8203754425048828, Accuracy: 0.724609375\n",
      "Batch: 53, Loss: 0.8365339040756226, Accuracy: 0.71240234375\n",
      "Batch: 54, Loss: 0.8844907879829407, Accuracy: 0.70556640625\n",
      "Batch: 55, Loss: 0.839083731174469, Accuracy: 0.72802734375\n",
      "Batch: 56, Loss: 0.8352104425430298, Accuracy: 0.73828125\n",
      "Batch: 57, Loss: 0.9125416278839111, Accuracy: 0.7138671875\n",
      "Batch: 58, Loss: 0.8736214637756348, Accuracy: 0.7080078125\n",
      "Batch: 59, Loss: 0.980670690536499, Accuracy: 0.68701171875\n",
      "Batch: 60, Loss: 0.8663730025291443, Accuracy: 0.73681640625\n",
      "Batch: 61, Loss: 0.8084712028503418, Accuracy: 0.74560546875\n",
      "Batch: 62, Loss: 0.8370240330696106, Accuracy: 0.7421875\n",
      "Batch: 63, Loss: 0.8486404418945312, Accuracy: 0.72314453125\n",
      "Batch: 64, Loss: 0.8756245374679565, Accuracy: 0.71728515625\n",
      "Batch: 65, Loss: 0.9269834756851196, Accuracy: 0.70947265625\n",
      "Batch: 66, Loss: 0.9335189461708069, Accuracy: 0.703125\n",
      "Batch: 67, Loss: 0.9121028184890747, Accuracy: 0.6923828125\n",
      "Batch: 68, Loss: 0.8220592141151428, Accuracy: 0.73486328125\n",
      "Batch: 69, Loss: 0.8768424987792969, Accuracy: 0.7060546875\n",
      "Batch: 70, Loss: 0.8609742522239685, Accuracy: 0.71875\n",
      "Batch: 71, Loss: 0.869692325592041, Accuracy: 0.71337890625\n",
      "Batch: 72, Loss: 0.9040582180023193, Accuracy: 0.70166015625\n",
      "Batch: 73, Loss: 0.9213994741439819, Accuracy: 0.701171875\n",
      "Batch: 74, Loss: 0.9015744924545288, Accuracy: 0.712890625\n",
      "Batch: 75, Loss: 0.8336160182952881, Accuracy: 0.7294921875\n",
      "Batch: 76, Loss: 0.8226958513259888, Accuracy: 0.75048828125\n",
      "Batch: 77, Loss: 0.8226609826087952, Accuracy: 0.7451171875\n",
      "Batch: 78, Loss: 0.8557697534561157, Accuracy: 0.7216796875\n",
      "Batch: 79, Loss: 0.8630592823028564, Accuracy: 0.72509765625\n",
      "Batch: 80, Loss: 0.8986803293228149, Accuracy: 0.708984375\n",
      "Batch: 81, Loss: 0.9172165393829346, Accuracy: 0.7138671875\n",
      "Batch: 82, Loss: 0.8468637466430664, Accuracy: 0.7158203125\n",
      "Batch: 83, Loss: 0.8156566619873047, Accuracy: 0.73876953125\n",
      "Batch: 84, Loss: 0.7996780872344971, Accuracy: 0.751953125\n",
      "Batch: 85, Loss: 0.8171876668930054, Accuracy: 0.732421875\n",
      "Batch: 86, Loss: 0.9221628904342651, Accuracy: 0.7099609375\n",
      "Batch: 87, Loss: 0.8312373757362366, Accuracy: 0.74267578125\n",
      "Batch: 88, Loss: 0.9051810503005981, Accuracy: 0.70703125\n",
      "Batch: 89, Loss: 0.898749053478241, Accuracy: 0.7080078125\n",
      "Batch: 90, Loss: 0.92708820104599, Accuracy: 0.6923828125\n",
      "Batch: 91, Loss: 0.8428809642791748, Accuracy: 0.72509765625\n",
      "Batch: 92, Loss: 0.9789259433746338, Accuracy: 0.68359375\n",
      "Batch: 93, Loss: 0.9206128120422363, Accuracy: 0.705078125\n",
      "Batch: 94, Loss: 0.9234304428100586, Accuracy: 0.7080078125\n",
      "Batch: 95, Loss: 0.9435533881187439, Accuracy: 0.70458984375\n",
      "Batch: 96, Loss: 0.8952678442001343, Accuracy: 0.71923828125\n",
      "Batch: 97, Loss: 0.8680550456047058, Accuracy: 0.73095703125\n",
      "Batch: 98, Loss: 0.9818506836891174, Accuracy: 0.69091796875\n",
      "Batch: 99, Loss: 0.8569540977478027, Accuracy: 0.72998046875\n",
      "Batch: 100, Loss: 0.9539615511894226, Accuracy: 0.697265625\n",
      "Batch: 101, Loss: 0.9669620990753174, Accuracy: 0.70263671875\n",
      "Batch: 102, Loss: 0.8495473861694336, Accuracy: 0.71923828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 103, Loss: 0.9203579425811768, Accuracy: 0.7060546875\n",
      "Batch: 104, Loss: 0.8775196075439453, Accuracy: 0.7158203125\n",
      "Batch: 105, Loss: 0.927739143371582, Accuracy: 0.70263671875\n",
      "Batch: 106, Loss: 0.8884224891662598, Accuracy: 0.71533203125\n",
      "Batch: 107, Loss: 0.9109084010124207, Accuracy: 0.7119140625\n",
      "Batch: 108, Loss: 0.8769640922546387, Accuracy: 0.71240234375\n",
      "Batch: 109, Loss: 0.8740979433059692, Accuracy: 0.71533203125\n",
      "Batch: 110, Loss: 0.8458744287490845, Accuracy: 0.72509765625\n",
      "Batch: 111, Loss: 0.8103445768356323, Accuracy: 0.73828125\n",
      "Batch: 112, Loss: 0.8535194396972656, Accuracy: 0.73046875\n",
      "Batch: 113, Loss: 0.9002503156661987, Accuracy: 0.70751953125\n",
      "Batch: 114, Loss: 0.8725202083587646, Accuracy: 0.7216796875\n",
      "Batch: 115, Loss: 0.8852306008338928, Accuracy: 0.72412109375\n",
      "Batch: 116, Loss: 0.8715102076530457, Accuracy: 0.71630859375\n",
      "Batch: 117, Loss: 0.8653274774551392, Accuracy: 0.7138671875\n",
      "Batch: 118, Loss: 0.8771571516990662, Accuracy: 0.70458984375\n",
      "Batch: 119, Loss: 0.8856425285339355, Accuracy: 0.71142578125\n",
      "Batch: 120, Loss: 0.8638753890991211, Accuracy: 0.716796875\n",
      "Batch: 121, Loss: 0.8850407600402832, Accuracy: 0.71484375\n",
      "Batch: 122, Loss: 0.8410425186157227, Accuracy: 0.72216796875\n",
      "Batch: 123, Loss: 0.8733586072921753, Accuracy: 0.7275390625\n",
      "Batch: 124, Loss: 0.8306869864463806, Accuracy: 0.72998046875\n",
      "Batch: 125, Loss: 0.8653606176376343, Accuracy: 0.7216796875\n",
      "Batch: 126, Loss: 0.8319203853607178, Accuracy: 0.72216796875\n",
      "Batch: 127, Loss: 0.8028829097747803, Accuracy: 0.7451171875\n",
      "Batch: 128, Loss: 0.9634810090065002, Accuracy: 0.70361328125\n",
      "Batch: 129, Loss: 0.99370938539505, Accuracy: 0.68701171875\n",
      "Batch: 130, Loss: 0.985281765460968, Accuracy: 0.67822265625\n",
      "Batch: 131, Loss: 0.9282525181770325, Accuracy: 0.69970703125\n",
      "Batch: 132, Loss: 0.8393245935440063, Accuracy: 0.7353515625\n",
      "Batch: 133, Loss: 0.8075792789459229, Accuracy: 0.7490234375\n",
      "Batch: 134, Loss: 0.9204093217849731, Accuracy: 0.69580078125\n",
      "Batch: 135, Loss: 0.8753169775009155, Accuracy: 0.7060546875\n",
      "Batch: 136, Loss: 0.8190921545028687, Accuracy: 0.7294921875\n",
      "Batch: 137, Loss: 0.891350269317627, Accuracy: 0.72509765625\n",
      "Batch: 138, Loss: 0.7833610773086548, Accuracy: 0.755859375\n",
      "Batch: 139, Loss: 0.8517690896987915, Accuracy: 0.72412109375\n",
      "Batch: 140, Loss: 0.801501989364624, Accuracy: 0.74267578125\n",
      "Batch: 141, Loss: 0.9114620089530945, Accuracy: 0.69970703125\n",
      "Batch: 142, Loss: 0.8202692270278931, Accuracy: 0.73681640625\n",
      "Batch: 143, Loss: 0.8227076530456543, Accuracy: 0.7470703125\n",
      "Batch: 144, Loss: 0.9248865842819214, Accuracy: 0.71533203125\n",
      "Batch: 145, Loss: 0.8854638934135437, Accuracy: 0.72412109375\n",
      "Batch: 146, Loss: 0.9230143427848816, Accuracy: 0.7041015625\n",
      "Batch: 147, Loss: 0.8932418823242188, Accuracy: 0.7138671875\n",
      "Batch: 148, Loss: 0.8999505043029785, Accuracy: 0.70849609375\n",
      "Batch: 149, Loss: 0.8897143006324768, Accuracy: 0.7158203125\n",
      "Batch: 150, Loss: 0.7622525095939636, Accuracy: 0.75\n",
      "Batch: 151, Loss: 0.7757182121276855, Accuracy: 0.75244140625\n",
      "Batch: 152, Loss: 0.8138649463653564, Accuracy: 0.7451171875\n",
      "Batch: 153, Loss: 0.7892366647720337, Accuracy: 0.73828125\n",
      "Batch: 154, Loss: 0.7917898893356323, Accuracy: 0.7421875\n",
      "Batch: 155, Loss: 0.8783115744590759, Accuracy: 0.71435546875\n",
      "Batch: 156, Loss: 0.791714608669281, Accuracy: 0.73974609375\n",
      "Batch: 157, Loss: 0.7779350280761719, Accuracy: 0.73828125\n",
      "Batch: 158, Loss: 0.7788553833961487, Accuracy: 0.7587890625\n",
      "Batch: 159, Loss: 0.781665563583374, Accuracy: 0.75\n",
      "Batch: 160, Loss: 0.8229278326034546, Accuracy: 0.72509765625\n",
      "Batch: 161, Loss: 0.8365458250045776, Accuracy: 0.724609375\n",
      "Batch: 162, Loss: 0.8098711967468262, Accuracy: 0.74560546875\n",
      "Batch: 163, Loss: 0.9023331999778748, Accuracy: 0.70849609375\n",
      "Batch: 164, Loss: 0.9336305856704712, Accuracy: 0.6953125\n",
      "Batch: 165, Loss: 0.8443763256072998, Accuracy: 0.73876953125\n",
      "Batch: 166, Loss: 0.8373449444770813, Accuracy: 0.73974609375\n",
      "Batch: 167, Loss: 0.8245267868041992, Accuracy: 0.734375\n",
      "Batch: 168, Loss: 0.7832918763160706, Accuracy: 0.74951171875\n",
      "Batch: 169, Loss: 0.8459967970848083, Accuracy: 0.7294921875\n",
      "Batch: 170, Loss: 0.8949117660522461, Accuracy: 0.7138671875\n",
      "Batch: 171, Loss: 0.8225720524787903, Accuracy: 0.736328125\n",
      "Batch: 172, Loss: 0.8158897161483765, Accuracy: 0.72802734375\n",
      "Batch: 173, Loss: 0.8747528791427612, Accuracy: 0.72705078125\n",
      "Batch: 174, Loss: 0.7221694588661194, Accuracy: 0.7666015625\n",
      "Batch: 175, Loss: 0.8837569952011108, Accuracy: 0.708984375\n",
      "Batch: 176, Loss: 0.9122763872146606, Accuracy: 0.703125\n",
      "Batch: 177, Loss: 0.8409260511398315, Accuracy: 0.73681640625\n",
      "Batch: 178, Loss: 0.8066660165786743, Accuracy: 0.74365234375\n",
      "Batch: 179, Loss: 0.8331692218780518, Accuracy: 0.7294921875\n",
      "Batch: 180, Loss: 0.922702968120575, Accuracy: 0.71337890625\n",
      "Saved Weights at epoch 30 to file Weights_30.h5\n",
      "Epoch 31/200\n",
      "Batch: 1, Loss: 1.2245737314224243, Accuracy: 0.65478515625\n",
      "Batch: 2, Loss: 0.852185845375061, Accuracy: 0.71337890625\n",
      "Batch: 3, Loss: 0.8471957445144653, Accuracy: 0.73046875\n",
      "Batch: 4, Loss: 0.9016788601875305, Accuracy: 0.712890625\n",
      "Batch: 5, Loss: 0.8843502998352051, Accuracy: 0.7255859375\n",
      "Batch: 6, Loss: 0.8898892402648926, Accuracy: 0.7099609375\n",
      "Batch: 7, Loss: 0.8227550387382507, Accuracy: 0.7275390625\n",
      "Batch: 8, Loss: 0.8580265045166016, Accuracy: 0.7099609375\n",
      "Batch: 9, Loss: 0.9210059642791748, Accuracy: 0.70751953125\n",
      "Batch: 10, Loss: 0.8600553274154663, Accuracy: 0.720703125\n",
      "Batch: 11, Loss: 0.9220445156097412, Accuracy: 0.703125\n",
      "Batch: 12, Loss: 0.8197582364082336, Accuracy: 0.73974609375\n",
      "Batch: 13, Loss: 0.8748606443405151, Accuracy: 0.71826171875\n",
      "Batch: 14, Loss: 0.8507062792778015, Accuracy: 0.732421875\n",
      "Batch: 15, Loss: 0.8565454483032227, Accuracy: 0.72607421875\n",
      "Batch: 16, Loss: 0.9302771091461182, Accuracy: 0.70849609375\n",
      "Batch: 17, Loss: 0.8561275005340576, Accuracy: 0.7353515625\n",
      "Batch: 18, Loss: 0.9103788137435913, Accuracy: 0.70947265625\n",
      "Batch: 19, Loss: 0.8971502780914307, Accuracy: 0.7216796875\n",
      "Batch: 20, Loss: 0.798477053642273, Accuracy: 0.7412109375\n",
      "Batch: 21, Loss: 0.9768092632293701, Accuracy: 0.69775390625\n",
      "Batch: 22, Loss: 0.8468978404998779, Accuracy: 0.7236328125\n",
      "Batch: 23, Loss: 0.8145376443862915, Accuracy: 0.7412109375\n",
      "Batch: 24, Loss: 0.8496618270874023, Accuracy: 0.71875\n",
      "Batch: 25, Loss: 0.8067584037780762, Accuracy: 0.73876953125\n",
      "Batch: 26, Loss: 0.8472877144813538, Accuracy: 0.72802734375\n",
      "Batch: 27, Loss: 0.8892046213150024, Accuracy: 0.7001953125\n",
      "Batch: 28, Loss: 0.8322845101356506, Accuracy: 0.7392578125\n",
      "Batch: 29, Loss: 0.9206994771957397, Accuracy: 0.70263671875\n",
      "Batch: 30, Loss: 0.8741227388381958, Accuracy: 0.72509765625\n",
      "Batch: 31, Loss: 0.9930870532989502, Accuracy: 0.68994140625\n",
      "Batch: 32, Loss: 0.9021257758140564, Accuracy: 0.7158203125\n",
      "Batch: 33, Loss: 0.931594967842102, Accuracy: 0.697265625\n",
      "Batch: 34, Loss: 0.9506593942642212, Accuracy: 0.6953125\n",
      "Batch: 35, Loss: 0.9759018421173096, Accuracy: 0.69189453125\n",
      "Batch: 36, Loss: 0.9308435916900635, Accuracy: 0.7099609375\n",
      "Batch: 37, Loss: 0.9069399833679199, Accuracy: 0.70703125\n",
      "Batch: 38, Loss: 0.9483919143676758, Accuracy: 0.68505859375\n",
      "Batch: 39, Loss: 0.9017159342765808, Accuracy: 0.71337890625\n",
      "Batch: 40, Loss: 0.9452470541000366, Accuracy: 0.70751953125\n",
      "Batch: 41, Loss: 0.8913057446479797, Accuracy: 0.70458984375\n",
      "Batch: 42, Loss: 0.882048487663269, Accuracy: 0.70703125\n",
      "Batch: 43, Loss: 0.8517289161682129, Accuracy: 0.73486328125\n",
      "Batch: 44, Loss: 0.76548171043396, Accuracy: 0.75341796875\n",
      "Batch: 45, Loss: 0.820476770401001, Accuracy: 0.7412109375\n",
      "Batch: 46, Loss: 0.814823567867279, Accuracy: 0.72802734375\n",
      "Batch: 47, Loss: 0.8603718280792236, Accuracy: 0.72998046875\n",
      "Batch: 48, Loss: 0.8270469903945923, Accuracy: 0.734375\n",
      "Batch: 49, Loss: 0.8091895580291748, Accuracy: 0.73974609375\n",
      "Batch: 50, Loss: 0.8710155487060547, Accuracy: 0.72119140625\n",
      "Batch: 51, Loss: 0.8481252193450928, Accuracy: 0.72314453125\n",
      "Batch: 52, Loss: 0.8135817050933838, Accuracy: 0.73193359375\n",
      "Batch: 53, Loss: 0.841637134552002, Accuracy: 0.7158203125\n",
      "Batch: 54, Loss: 0.8690290451049805, Accuracy: 0.71533203125\n",
      "Batch: 55, Loss: 0.8389438390731812, Accuracy: 0.7314453125\n",
      "Batch: 56, Loss: 0.8157294988632202, Accuracy: 0.74072265625\n",
      "Batch: 57, Loss: 0.9044018387794495, Accuracy: 0.7197265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 58, Loss: 0.853355884552002, Accuracy: 0.72119140625\n",
      "Batch: 59, Loss: 0.9568333625793457, Accuracy: 0.6884765625\n",
      "Batch: 60, Loss: 0.8486157655715942, Accuracy: 0.734375\n",
      "Batch: 61, Loss: 0.7966738343238831, Accuracy: 0.74267578125\n",
      "Batch: 62, Loss: 0.8217698931694031, Accuracy: 0.748046875\n",
      "Batch: 63, Loss: 0.8304871916770935, Accuracy: 0.73095703125\n",
      "Batch: 64, Loss: 0.8712960481643677, Accuracy: 0.708984375\n",
      "Batch: 65, Loss: 0.9193311929702759, Accuracy: 0.70849609375\n",
      "Batch: 66, Loss: 0.8856971263885498, Accuracy: 0.72265625\n",
      "Batch: 67, Loss: 0.9010839462280273, Accuracy: 0.70947265625\n",
      "Batch: 68, Loss: 0.8124855756759644, Accuracy: 0.73193359375\n",
      "Batch: 69, Loss: 0.8665818572044373, Accuracy: 0.71240234375\n",
      "Batch: 70, Loss: 0.8614706993103027, Accuracy: 0.71923828125\n",
      "Batch: 71, Loss: 0.8582751750946045, Accuracy: 0.720703125\n",
      "Batch: 72, Loss: 0.8879247903823853, Accuracy: 0.69384765625\n",
      "Batch: 73, Loss: 0.904281497001648, Accuracy: 0.6982421875\n",
      "Batch: 74, Loss: 0.897027313709259, Accuracy: 0.72216796875\n",
      "Batch: 75, Loss: 0.8229620456695557, Accuracy: 0.7275390625\n",
      "Batch: 76, Loss: 0.8055343627929688, Accuracy: 0.73681640625\n",
      "Batch: 77, Loss: 0.8140831589698792, Accuracy: 0.73779296875\n",
      "Batch: 78, Loss: 0.8495574593544006, Accuracy: 0.72998046875\n",
      "Batch: 79, Loss: 0.8532395958900452, Accuracy: 0.72265625\n",
      "Batch: 80, Loss: 0.8729667663574219, Accuracy: 0.71435546875\n",
      "Batch: 81, Loss: 0.8867038488388062, Accuracy: 0.72802734375\n",
      "Batch: 82, Loss: 0.8274550437927246, Accuracy: 0.73095703125\n",
      "Batch: 83, Loss: 0.812773585319519, Accuracy: 0.7353515625\n",
      "Batch: 84, Loss: 0.8103035688400269, Accuracy: 0.7392578125\n",
      "Batch: 85, Loss: 0.8129639625549316, Accuracy: 0.73779296875\n",
      "Batch: 86, Loss: 0.9440338015556335, Accuracy: 0.70166015625\n",
      "Batch: 87, Loss: 0.8191162347793579, Accuracy: 0.7373046875\n",
      "Batch: 88, Loss: 0.8857465982437134, Accuracy: 0.72509765625\n",
      "Batch: 89, Loss: 0.8771102428436279, Accuracy: 0.72412109375\n",
      "Batch: 90, Loss: 0.9237630367279053, Accuracy: 0.6904296875\n",
      "Batch: 91, Loss: 0.8420690894126892, Accuracy: 0.7353515625\n",
      "Batch: 92, Loss: 0.9596863389015198, Accuracy: 0.69287109375\n",
      "Batch: 93, Loss: 0.9068639278411865, Accuracy: 0.70361328125\n",
      "Batch: 94, Loss: 0.9027383327484131, Accuracy: 0.72265625\n",
      "Batch: 95, Loss: 0.9443955421447754, Accuracy: 0.70361328125\n",
      "Batch: 96, Loss: 0.8700383901596069, Accuracy: 0.71875\n",
      "Batch: 97, Loss: 0.8573391437530518, Accuracy: 0.7373046875\n",
      "Batch: 98, Loss: 0.9495381116867065, Accuracy: 0.69775390625\n",
      "Batch: 99, Loss: 0.8540035486221313, Accuracy: 0.7353515625\n",
      "Batch: 100, Loss: 0.9400399923324585, Accuracy: 0.70068359375\n",
      "Batch: 101, Loss: 0.9840087890625, Accuracy: 0.685546875\n",
      "Batch: 102, Loss: 0.8481419682502747, Accuracy: 0.7294921875\n",
      "Batch: 103, Loss: 0.9045981764793396, Accuracy: 0.71044921875\n",
      "Batch: 104, Loss: 0.8775097131729126, Accuracy: 0.7197265625\n",
      "Batch: 105, Loss: 0.9059908390045166, Accuracy: 0.7080078125\n",
      "Batch: 106, Loss: 0.8829898238182068, Accuracy: 0.71435546875\n",
      "Batch: 107, Loss: 0.8896329998970032, Accuracy: 0.7080078125\n",
      "Batch: 108, Loss: 0.8673890829086304, Accuracy: 0.72412109375\n",
      "Batch: 109, Loss: 0.8629269599914551, Accuracy: 0.7265625\n",
      "Batch: 110, Loss: 0.8533774614334106, Accuracy: 0.72607421875\n",
      "Batch: 111, Loss: 0.7952154278755188, Accuracy: 0.74609375\n",
      "Batch: 112, Loss: 0.8612573146820068, Accuracy: 0.72119140625\n",
      "Batch: 113, Loss: 0.8866158723831177, Accuracy: 0.70751953125\n",
      "Batch: 114, Loss: 0.8641633987426758, Accuracy: 0.7216796875\n",
      "Batch: 115, Loss: 0.8775626420974731, Accuracy: 0.72802734375\n",
      "Batch: 116, Loss: 0.8882999420166016, Accuracy: 0.7119140625\n",
      "Batch: 117, Loss: 0.8629273176193237, Accuracy: 0.71533203125\n",
      "Batch: 118, Loss: 0.8722789287567139, Accuracy: 0.7099609375\n",
      "Batch: 119, Loss: 0.868165910243988, Accuracy: 0.71826171875\n",
      "Batch: 120, Loss: 0.8475674390792847, Accuracy: 0.720703125\n",
      "Batch: 121, Loss: 0.8757022619247437, Accuracy: 0.716796875\n",
      "Batch: 122, Loss: 0.8131921887397766, Accuracy: 0.73828125\n",
      "Batch: 123, Loss: 0.841509997844696, Accuracy: 0.7392578125\n",
      "Batch: 124, Loss: 0.8204924464225769, Accuracy: 0.7294921875\n",
      "Batch: 125, Loss: 0.8554598093032837, Accuracy: 0.7265625\n",
      "Batch: 126, Loss: 0.8293342590332031, Accuracy: 0.72802734375\n",
      "Batch: 127, Loss: 0.7954972386360168, Accuracy: 0.751953125\n",
      "Batch: 128, Loss: 0.9393652677536011, Accuracy: 0.7099609375\n",
      "Batch: 129, Loss: 0.9685449004173279, Accuracy: 0.69873046875\n",
      "Batch: 130, Loss: 0.9824249744415283, Accuracy: 0.68505859375\n",
      "Batch: 131, Loss: 0.9131500720977783, Accuracy: 0.71923828125\n",
      "Batch: 132, Loss: 0.8070200681686401, Accuracy: 0.7431640625\n",
      "Batch: 133, Loss: 0.8139407634735107, Accuracy: 0.7470703125\n",
      "Batch: 134, Loss: 0.8864879608154297, Accuracy: 0.72216796875\n",
      "Batch: 135, Loss: 0.8730304837226868, Accuracy: 0.71630859375\n",
      "Batch: 136, Loss: 0.8074974417686462, Accuracy: 0.72265625\n",
      "Batch: 137, Loss: 0.8565471172332764, Accuracy: 0.7255859375\n",
      "Batch: 138, Loss: 0.7720680236816406, Accuracy: 0.7607421875\n",
      "Batch: 139, Loss: 0.8413463234901428, Accuracy: 0.73828125\n",
      "Batch: 140, Loss: 0.7848601341247559, Accuracy: 0.7529296875\n",
      "Batch: 141, Loss: 0.9025585651397705, Accuracy: 0.70703125\n",
      "Batch: 142, Loss: 0.8042209148406982, Accuracy: 0.7421875\n",
      "Batch: 143, Loss: 0.8172476291656494, Accuracy: 0.73681640625\n",
      "Batch: 144, Loss: 0.8966522216796875, Accuracy: 0.71728515625\n",
      "Batch: 145, Loss: 0.8729162812232971, Accuracy: 0.724609375\n",
      "Batch: 146, Loss: 0.9172734022140503, Accuracy: 0.69482421875\n",
      "Batch: 147, Loss: 0.8759530782699585, Accuracy: 0.7275390625\n",
      "Batch: 148, Loss: 0.8895980715751648, Accuracy: 0.7119140625\n",
      "Batch: 149, Loss: 0.8839069604873657, Accuracy: 0.7265625\n",
      "Batch: 150, Loss: 0.7530578374862671, Accuracy: 0.7578125\n",
      "Batch: 151, Loss: 0.7610825300216675, Accuracy: 0.7490234375\n",
      "Batch: 152, Loss: 0.7972685098648071, Accuracy: 0.74072265625\n",
      "Batch: 153, Loss: 0.7858842611312866, Accuracy: 0.74658203125\n",
      "Batch: 154, Loss: 0.8117231130599976, Accuracy: 0.73095703125\n",
      "Batch: 155, Loss: 0.8906069993972778, Accuracy: 0.7177734375\n",
      "Batch: 156, Loss: 0.7693189382553101, Accuracy: 0.75048828125\n",
      "Batch: 157, Loss: 0.7669312953948975, Accuracy: 0.74462890625\n",
      "Batch: 158, Loss: 0.7747260332107544, Accuracy: 0.7626953125\n",
      "Batch: 159, Loss: 0.7525349855422974, Accuracy: 0.76171875\n",
      "Batch: 160, Loss: 0.8037038445472717, Accuracy: 0.73095703125\n",
      "Batch: 161, Loss: 0.8488583564758301, Accuracy: 0.728515625\n",
      "Batch: 162, Loss: 0.7974791526794434, Accuracy: 0.740234375\n",
      "Batch: 163, Loss: 0.8826655745506287, Accuracy: 0.71142578125\n",
      "Batch: 164, Loss: 0.9181758761405945, Accuracy: 0.71435546875\n",
      "Batch: 165, Loss: 0.8432941436767578, Accuracy: 0.74072265625\n",
      "Batch: 166, Loss: 0.844357430934906, Accuracy: 0.74072265625\n",
      "Batch: 167, Loss: 0.8277833461761475, Accuracy: 0.732421875\n",
      "Batch: 168, Loss: 0.762959361076355, Accuracy: 0.75634765625\n",
      "Batch: 169, Loss: 0.8279668092727661, Accuracy: 0.72265625\n",
      "Batch: 170, Loss: 0.8931286931037903, Accuracy: 0.71728515625\n",
      "Batch: 171, Loss: 0.822034478187561, Accuracy: 0.73291015625\n",
      "Batch: 172, Loss: 0.8048899173736572, Accuracy: 0.73583984375\n",
      "Batch: 173, Loss: 0.8648847937583923, Accuracy: 0.72900390625\n",
      "Batch: 174, Loss: 0.7257646918296814, Accuracy: 0.7626953125\n",
      "Batch: 175, Loss: 0.8715806603431702, Accuracy: 0.701171875\n",
      "Batch: 176, Loss: 0.9083516597747803, Accuracy: 0.71142578125\n",
      "Batch: 177, Loss: 0.8219408392906189, Accuracy: 0.73876953125\n",
      "Batch: 178, Loss: 0.8101683855056763, Accuracy: 0.732421875\n",
      "Batch: 179, Loss: 0.8294023275375366, Accuracy: 0.732421875\n",
      "Batch: 180, Loss: 0.8978983163833618, Accuracy: 0.716796875\n",
      "Epoch 32/200\n",
      "Batch: 1, Loss: 1.2136133909225464, Accuracy: 0.65478515625\n",
      "Batch: 2, Loss: 0.8486114144325256, Accuracy: 0.71875\n",
      "Batch: 3, Loss: 0.8636546730995178, Accuracy: 0.71728515625\n",
      "Batch: 4, Loss: 0.8891431093215942, Accuracy: 0.7109375\n",
      "Batch: 5, Loss: 0.8712595701217651, Accuracy: 0.72265625\n",
      "Batch: 6, Loss: 0.8802506923675537, Accuracy: 0.71630859375\n",
      "Batch: 7, Loss: 0.807607889175415, Accuracy: 0.73828125\n",
      "Batch: 8, Loss: 0.8472761511802673, Accuracy: 0.7197265625\n",
      "Batch: 9, Loss: 0.9153705835342407, Accuracy: 0.7109375\n",
      "Batch: 10, Loss: 0.8598589897155762, Accuracy: 0.72412109375\n",
      "Batch: 11, Loss: 0.9117559194564819, Accuracy: 0.69775390625\n",
      "Batch: 12, Loss: 0.7799647450447083, Accuracy: 0.74560546875\n",
      "Batch: 13, Loss: 0.8598421812057495, Accuracy: 0.72119140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14, Loss: 0.8493093252182007, Accuracy: 0.74365234375\n",
      "Batch: 15, Loss: 0.8635358810424805, Accuracy: 0.72900390625\n",
      "Batch: 16, Loss: 0.9244864583015442, Accuracy: 0.70751953125\n",
      "Batch: 17, Loss: 0.8482325077056885, Accuracy: 0.736328125\n",
      "Batch: 18, Loss: 0.9112378358840942, Accuracy: 0.71044921875\n",
      "Batch: 19, Loss: 0.8910567164421082, Accuracy: 0.72265625\n",
      "Batch: 20, Loss: 0.7975432276725769, Accuracy: 0.74365234375\n",
      "Batch: 21, Loss: 0.940104067325592, Accuracy: 0.71435546875\n",
      "Batch: 22, Loss: 0.8322470188140869, Accuracy: 0.73291015625\n",
      "Batch: 23, Loss: 0.8133599758148193, Accuracy: 0.734375\n",
      "Batch: 24, Loss: 0.8410513401031494, Accuracy: 0.72412109375\n",
      "Batch: 25, Loss: 0.8117275834083557, Accuracy: 0.74609375\n",
      "Batch: 26, Loss: 0.8215864896774292, Accuracy: 0.72802734375\n",
      "Batch: 27, Loss: 0.8803367018699646, Accuracy: 0.71826171875\n",
      "Batch: 28, Loss: 0.8225475549697876, Accuracy: 0.7314453125\n",
      "Batch: 29, Loss: 0.9038845300674438, Accuracy: 0.7119140625\n",
      "Batch: 30, Loss: 0.8676035404205322, Accuracy: 0.7255859375\n",
      "Batch: 31, Loss: 0.9731870293617249, Accuracy: 0.701171875\n",
      "Batch: 32, Loss: 0.9031676054000854, Accuracy: 0.72021484375\n",
      "Batch: 33, Loss: 0.9111542105674744, Accuracy: 0.70556640625\n",
      "Batch: 34, Loss: 0.9422587752342224, Accuracy: 0.7001953125\n",
      "Batch: 35, Loss: 0.9649659991264343, Accuracy: 0.703125\n",
      "Batch: 36, Loss: 0.9201701283454895, Accuracy: 0.70849609375\n",
      "Batch: 37, Loss: 0.8914243578910828, Accuracy: 0.70654296875\n",
      "Batch: 38, Loss: 0.9338102340698242, Accuracy: 0.69775390625\n",
      "Batch: 39, Loss: 0.8779674172401428, Accuracy: 0.72509765625\n",
      "Batch: 40, Loss: 0.9313225150108337, Accuracy: 0.70361328125\n",
      "Batch: 41, Loss: 0.9009920358657837, Accuracy: 0.708984375\n",
      "Batch: 42, Loss: 0.8651019334793091, Accuracy: 0.71044921875\n",
      "Batch: 43, Loss: 0.8364801406860352, Accuracy: 0.73388671875\n",
      "Batch: 44, Loss: 0.7624980807304382, Accuracy: 0.7587890625\n",
      "Batch: 45, Loss: 0.8293616771697998, Accuracy: 0.73046875\n",
      "Batch: 46, Loss: 0.79571932554245, Accuracy: 0.7275390625\n",
      "Batch: 47, Loss: 0.8358954191207886, Accuracy: 0.73388671875\n",
      "Batch: 48, Loss: 0.8332475423812866, Accuracy: 0.73291015625\n",
      "Batch: 49, Loss: 0.8139325976371765, Accuracy: 0.7412109375\n",
      "Batch: 50, Loss: 0.845378041267395, Accuracy: 0.724609375\n",
      "Batch: 51, Loss: 0.8310862183570862, Accuracy: 0.736328125\n",
      "Batch: 52, Loss: 0.8019331693649292, Accuracy: 0.74169921875\n",
      "Batch: 53, Loss: 0.811927080154419, Accuracy: 0.72314453125\n",
      "Batch: 54, Loss: 0.8551395535469055, Accuracy: 0.71435546875\n",
      "Batch: 55, Loss: 0.8173702955245972, Accuracy: 0.73583984375\n",
      "Batch: 56, Loss: 0.8314445614814758, Accuracy: 0.7333984375\n",
      "Batch: 57, Loss: 0.9006615877151489, Accuracy: 0.71533203125\n",
      "Batch: 58, Loss: 0.8448442220687866, Accuracy: 0.716796875\n",
      "Batch: 59, Loss: 0.951561450958252, Accuracy: 0.69921875\n",
      "Batch: 60, Loss: 0.8438832759857178, Accuracy: 0.7294921875\n",
      "Batch: 61, Loss: 0.7864600419998169, Accuracy: 0.74365234375\n",
      "Batch: 62, Loss: 0.8187422156333923, Accuracy: 0.7431640625\n",
      "Batch: 63, Loss: 0.8242055177688599, Accuracy: 0.72705078125\n",
      "Batch: 64, Loss: 0.8716177940368652, Accuracy: 0.708984375\n",
      "Batch: 65, Loss: 0.9241032600402832, Accuracy: 0.70654296875\n",
      "Batch: 66, Loss: 0.8972792625427246, Accuracy: 0.71533203125\n",
      "Batch: 67, Loss: 0.8812050819396973, Accuracy: 0.7109375\n",
      "Batch: 68, Loss: 0.8153331875801086, Accuracy: 0.7353515625\n",
      "Batch: 69, Loss: 0.8398603200912476, Accuracy: 0.7109375\n",
      "Batch: 70, Loss: 0.8457239270210266, Accuracy: 0.72265625\n",
      "Batch: 71, Loss: 0.8523725867271423, Accuracy: 0.72265625\n",
      "Batch: 72, Loss: 0.8836302161216736, Accuracy: 0.71435546875\n",
      "Batch: 73, Loss: 0.8798186779022217, Accuracy: 0.71044921875\n",
      "Batch: 74, Loss: 0.8994045257568359, Accuracy: 0.7060546875\n",
      "Batch: 75, Loss: 0.8188912868499756, Accuracy: 0.73095703125\n",
      "Batch: 76, Loss: 0.7795724868774414, Accuracy: 0.748046875\n",
      "Batch: 77, Loss: 0.8004807233810425, Accuracy: 0.74755859375\n",
      "Batch: 78, Loss: 0.8194035291671753, Accuracy: 0.736328125\n",
      "Batch: 79, Loss: 0.8539255857467651, Accuracy: 0.72216796875\n",
      "Batch: 80, Loss: 0.8632743954658508, Accuracy: 0.71240234375\n",
      "Batch: 81, Loss: 0.8869524002075195, Accuracy: 0.72412109375\n",
      "Batch: 82, Loss: 0.8287146687507629, Accuracy: 0.7236328125\n",
      "Batch: 83, Loss: 0.7871446013450623, Accuracy: 0.7412109375\n",
      "Batch: 84, Loss: 0.8011800646781921, Accuracy: 0.744140625\n",
      "Batch: 85, Loss: 0.8136827945709229, Accuracy: 0.7392578125\n",
      "Batch: 86, Loss: 0.912320077419281, Accuracy: 0.712890625\n",
      "Batch: 87, Loss: 0.7958648204803467, Accuracy: 0.74365234375\n",
      "Batch: 88, Loss: 0.8741111755371094, Accuracy: 0.72705078125\n",
      "Batch: 89, Loss: 0.8602315187454224, Accuracy: 0.72021484375\n",
      "Batch: 90, Loss: 0.9251957535743713, Accuracy: 0.69873046875\n",
      "Batch: 91, Loss: 0.8392171859741211, Accuracy: 0.73193359375\n",
      "Batch: 92, Loss: 0.9602029919624329, Accuracy: 0.6875\n",
      "Batch: 93, Loss: 0.9155761003494263, Accuracy: 0.68603515625\n",
      "Batch: 94, Loss: 0.9093283414840698, Accuracy: 0.7119140625\n",
      "Batch: 95, Loss: 0.9286273717880249, Accuracy: 0.7021484375\n",
      "Batch: 96, Loss: 0.8592451810836792, Accuracy: 0.7333984375\n",
      "Batch: 97, Loss: 0.8509055376052856, Accuracy: 0.74169921875\n",
      "Batch: 98, Loss: 0.9610792398452759, Accuracy: 0.69921875\n",
      "Batch: 99, Loss: 0.8481640815734863, Accuracy: 0.73291015625\n",
      "Batch: 100, Loss: 0.9378815293312073, Accuracy: 0.70166015625\n",
      "Batch: 101, Loss: 0.9721624851226807, Accuracy: 0.70458984375\n",
      "Batch: 102, Loss: 0.8345926403999329, Accuracy: 0.73046875\n",
      "Batch: 103, Loss: 0.9010494947433472, Accuracy: 0.703125\n",
      "Batch: 104, Loss: 0.8515841960906982, Accuracy: 0.72607421875\n",
      "Batch: 105, Loss: 0.8969219326972961, Accuracy: 0.71533203125\n",
      "Batch: 106, Loss: 0.8726317882537842, Accuracy: 0.71240234375\n",
      "Batch: 107, Loss: 0.892753541469574, Accuracy: 0.7099609375\n",
      "Batch: 108, Loss: 0.8569365739822388, Accuracy: 0.720703125\n",
      "Batch: 109, Loss: 0.8639360666275024, Accuracy: 0.72216796875\n",
      "Batch: 110, Loss: 0.8271992206573486, Accuracy: 0.724609375\n",
      "Batch: 111, Loss: 0.7779358625411987, Accuracy: 0.7431640625\n",
      "Batch: 112, Loss: 0.8393173813819885, Accuracy: 0.7373046875\n",
      "Batch: 113, Loss: 0.8793079853057861, Accuracy: 0.7099609375\n",
      "Batch: 114, Loss: 0.8463648557662964, Accuracy: 0.72900390625\n",
      "Batch: 115, Loss: 0.8603532910346985, Accuracy: 0.732421875\n",
      "Batch: 116, Loss: 0.8461943864822388, Accuracy: 0.72216796875\n",
      "Batch: 117, Loss: 0.8619105815887451, Accuracy: 0.7236328125\n",
      "Batch: 118, Loss: 0.8420109748840332, Accuracy: 0.7333984375\n",
      "Batch: 119, Loss: 0.86571204662323, Accuracy: 0.712890625\n",
      "Batch: 120, Loss: 0.8369534015655518, Accuracy: 0.7255859375\n",
      "Batch: 121, Loss: 0.8551280498504639, Accuracy: 0.71923828125\n",
      "Batch: 122, Loss: 0.8212262392044067, Accuracy: 0.736328125\n",
      "Batch: 123, Loss: 0.8231897354125977, Accuracy: 0.7431640625\n",
      "Batch: 124, Loss: 0.8120254874229431, Accuracy: 0.7294921875\n",
      "Batch: 125, Loss: 0.8598729372024536, Accuracy: 0.71630859375\n",
      "Batch: 126, Loss: 0.8009731769561768, Accuracy: 0.744140625\n",
      "Batch: 127, Loss: 0.7852781414985657, Accuracy: 0.7470703125\n",
      "Batch: 128, Loss: 0.9313468933105469, Accuracy: 0.697265625\n",
      "Batch: 129, Loss: 0.9471279382705688, Accuracy: 0.68798828125\n",
      "Batch: 130, Loss: 0.9627513885498047, Accuracy: 0.69287109375\n",
      "Batch: 131, Loss: 0.8927098512649536, Accuracy: 0.71728515625\n",
      "Batch: 132, Loss: 0.8203462362289429, Accuracy: 0.73876953125\n",
      "Batch: 133, Loss: 0.8195546865463257, Accuracy: 0.74560546875\n",
      "Batch: 134, Loss: 0.8730305433273315, Accuracy: 0.716796875\n",
      "Batch: 135, Loss: 0.8568301200866699, Accuracy: 0.7294921875\n",
      "Batch: 136, Loss: 0.8083767890930176, Accuracy: 0.7236328125\n",
      "Batch: 137, Loss: 0.8600795865058899, Accuracy: 0.73193359375\n",
      "Batch: 138, Loss: 0.7534421682357788, Accuracy: 0.77392578125\n",
      "Batch: 139, Loss: 0.8360210657119751, Accuracy: 0.732421875\n",
      "Batch: 140, Loss: 0.7766589522361755, Accuracy: 0.75146484375\n",
      "Batch: 141, Loss: 0.8768219947814941, Accuracy: 0.71044921875\n",
      "Batch: 142, Loss: 0.8014756441116333, Accuracy: 0.7333984375\n",
      "Batch: 143, Loss: 0.8149844408035278, Accuracy: 0.74267578125\n",
      "Batch: 144, Loss: 0.8997922539710999, Accuracy: 0.716796875\n",
      "Batch: 145, Loss: 0.8719483017921448, Accuracy: 0.71826171875\n",
      "Batch: 146, Loss: 0.8980151414871216, Accuracy: 0.71337890625\n",
      "Batch: 147, Loss: 0.8637303113937378, Accuracy: 0.7265625\n",
      "Batch: 148, Loss: 0.8880058526992798, Accuracy: 0.70458984375\n",
      "Batch: 149, Loss: 0.8706817626953125, Accuracy: 0.7138671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 150, Loss: 0.7515275478363037, Accuracy: 0.75927734375\n",
      "Batch: 151, Loss: 0.7557163834571838, Accuracy: 0.75634765625\n",
      "Batch: 152, Loss: 0.8046451807022095, Accuracy: 0.75\n",
      "Batch: 153, Loss: 0.7904697060585022, Accuracy: 0.744140625\n",
      "Batch: 154, Loss: 0.805706262588501, Accuracy: 0.74267578125\n",
      "Batch: 155, Loss: 0.8601987361907959, Accuracy: 0.71533203125\n",
      "Batch: 156, Loss: 0.7757266759872437, Accuracy: 0.74609375\n",
      "Batch: 157, Loss: 0.7511867880821228, Accuracy: 0.75048828125\n",
      "Batch: 158, Loss: 0.7593289613723755, Accuracy: 0.76611328125\n",
      "Batch: 159, Loss: 0.7696515917778015, Accuracy: 0.751953125\n",
      "Batch: 160, Loss: 0.8015754222869873, Accuracy: 0.74169921875\n",
      "Batch: 161, Loss: 0.8341377973556519, Accuracy: 0.72998046875\n",
      "Batch: 162, Loss: 0.8077194094657898, Accuracy: 0.75\n",
      "Batch: 163, Loss: 0.8824868202209473, Accuracy: 0.7099609375\n",
      "Batch: 164, Loss: 0.9124906063079834, Accuracy: 0.70703125\n",
      "Batch: 165, Loss: 0.8346646428108215, Accuracy: 0.7470703125\n",
      "Batch: 166, Loss: 0.8350989818572998, Accuracy: 0.73046875\n",
      "Batch: 167, Loss: 0.8086707592010498, Accuracy: 0.73828125\n",
      "Batch: 168, Loss: 0.7667136192321777, Accuracy: 0.75634765625\n",
      "Batch: 169, Loss: 0.8272203803062439, Accuracy: 0.7431640625\n",
      "Batch: 170, Loss: 0.870357871055603, Accuracy: 0.72509765625\n",
      "Batch: 171, Loss: 0.8151481747627258, Accuracy: 0.74365234375\n",
      "Batch: 172, Loss: 0.7962557077407837, Accuracy: 0.7373046875\n",
      "Batch: 173, Loss: 0.8476399183273315, Accuracy: 0.7373046875\n",
      "Batch: 174, Loss: 0.7217344641685486, Accuracy: 0.7607421875\n",
      "Batch: 175, Loss: 0.8615567684173584, Accuracy: 0.71728515625\n",
      "Batch: 176, Loss: 0.8893353939056396, Accuracy: 0.71923828125\n",
      "Batch: 177, Loss: 0.8201777935028076, Accuracy: 0.7373046875\n",
      "Batch: 178, Loss: 0.7889511585235596, Accuracy: 0.7509765625\n",
      "Batch: 179, Loss: 0.8200324773788452, Accuracy: 0.73388671875\n",
      "Batch: 180, Loss: 0.896263837814331, Accuracy: 0.72314453125\n",
      "Epoch 33/200\n",
      "Batch: 1, Loss: 1.209991216659546, Accuracy: 0.6591796875\n",
      "Batch: 2, Loss: 0.8433524370193481, Accuracy: 0.7119140625\n",
      "Batch: 3, Loss: 0.8388592004776001, Accuracy: 0.73828125\n",
      "Batch: 4, Loss: 0.8623455166816711, Accuracy: 0.72119140625\n",
      "Batch: 5, Loss: 0.8757143020629883, Accuracy: 0.716796875\n",
      "Batch: 6, Loss: 0.8681950569152832, Accuracy: 0.72119140625\n",
      "Batch: 7, Loss: 0.8057848811149597, Accuracy: 0.7373046875\n",
      "Batch: 8, Loss: 0.8415886163711548, Accuracy: 0.7294921875\n",
      "Batch: 9, Loss: 0.8929450511932373, Accuracy: 0.71142578125\n",
      "Batch: 10, Loss: 0.8454951047897339, Accuracy: 0.7373046875\n",
      "Batch: 11, Loss: 0.8955115675926208, Accuracy: 0.70654296875\n",
      "Batch: 12, Loss: 0.786353588104248, Accuracy: 0.74267578125\n",
      "Batch: 13, Loss: 0.8426629304885864, Accuracy: 0.7294921875\n",
      "Batch: 14, Loss: 0.8165544867515564, Accuracy: 0.734375\n",
      "Batch: 15, Loss: 0.8476431369781494, Accuracy: 0.72412109375\n",
      "Batch: 16, Loss: 0.9018270969390869, Accuracy: 0.7109375\n",
      "Batch: 17, Loss: 0.831891655921936, Accuracy: 0.73974609375\n",
      "Batch: 18, Loss: 0.8799176216125488, Accuracy: 0.720703125\n",
      "Batch: 19, Loss: 0.8927815556526184, Accuracy: 0.72314453125\n",
      "Batch: 20, Loss: 0.7860241532325745, Accuracy: 0.7509765625\n",
      "Batch: 21, Loss: 0.930637538433075, Accuracy: 0.716796875\n",
      "Batch: 22, Loss: 0.8078673481941223, Accuracy: 0.7470703125\n",
      "Batch: 23, Loss: 0.8088849186897278, Accuracy: 0.740234375\n",
      "Batch: 24, Loss: 0.829811692237854, Accuracy: 0.73828125\n",
      "Batch: 25, Loss: 0.806835412979126, Accuracy: 0.748046875\n",
      "Batch: 26, Loss: 0.8266567587852478, Accuracy: 0.744140625\n",
      "Batch: 27, Loss: 0.8874472379684448, Accuracy: 0.71240234375\n",
      "Batch: 28, Loss: 0.8181712031364441, Accuracy: 0.7275390625\n",
      "Batch: 29, Loss: 0.9045441150665283, Accuracy: 0.712890625\n",
      "Batch: 30, Loss: 0.8640678524971008, Accuracy: 0.724609375\n",
      "Batch: 31, Loss: 0.9796750545501709, Accuracy: 0.68896484375\n",
      "Batch: 32, Loss: 0.8744430541992188, Accuracy: 0.7177734375\n",
      "Batch: 33, Loss: 0.9127639532089233, Accuracy: 0.70068359375\n",
      "Batch: 34, Loss: 0.9222856760025024, Accuracy: 0.70361328125\n",
      "Batch: 35, Loss: 0.9482780694961548, Accuracy: 0.69482421875\n",
      "Batch: 36, Loss: 0.9046688079833984, Accuracy: 0.71484375\n",
      "Batch: 37, Loss: 0.8892585635185242, Accuracy: 0.71728515625\n",
      "Batch: 38, Loss: 0.9378886222839355, Accuracy: 0.697265625\n",
      "Batch: 39, Loss: 0.8587092757225037, Accuracy: 0.73486328125\n",
      "Batch: 40, Loss: 0.9103662967681885, Accuracy: 0.720703125\n",
      "Batch: 41, Loss: 0.8783646821975708, Accuracy: 0.71337890625\n",
      "Batch: 42, Loss: 0.8532779216766357, Accuracy: 0.716796875\n",
      "Batch: 43, Loss: 0.8257404565811157, Accuracy: 0.7421875\n",
      "Batch: 44, Loss: 0.7404786348342896, Accuracy: 0.76025390625\n",
      "Batch: 45, Loss: 0.8220732808113098, Accuracy: 0.73583984375\n",
      "Batch: 46, Loss: 0.7733851671218872, Accuracy: 0.7392578125\n",
      "Batch: 47, Loss: 0.8503233194351196, Accuracy: 0.728515625\n",
      "Batch: 48, Loss: 0.8140786290168762, Accuracy: 0.74267578125\n",
      "Batch: 49, Loss: 0.8132888078689575, Accuracy: 0.744140625\n",
      "Batch: 50, Loss: 0.8575462102890015, Accuracy: 0.72216796875\n",
      "Batch: 51, Loss: 0.8244792222976685, Accuracy: 0.7373046875\n",
      "Batch: 52, Loss: 0.7996058464050293, Accuracy: 0.740234375\n",
      "Batch: 53, Loss: 0.8056142926216125, Accuracy: 0.72509765625\n",
      "Batch: 54, Loss: 0.8599514961242676, Accuracy: 0.7109375\n",
      "Batch: 55, Loss: 0.8135409355163574, Accuracy: 0.7236328125\n",
      "Batch: 56, Loss: 0.8018743991851807, Accuracy: 0.73974609375\n",
      "Batch: 57, Loss: 0.8860260248184204, Accuracy: 0.71923828125\n",
      "Batch: 58, Loss: 0.8450646996498108, Accuracy: 0.7236328125\n",
      "Batch: 59, Loss: 0.928826093673706, Accuracy: 0.70361328125\n",
      "Batch: 60, Loss: 0.8363720774650574, Accuracy: 0.71826171875\n",
      "Batch: 61, Loss: 0.7693338394165039, Accuracy: 0.7490234375\n",
      "Batch: 62, Loss: 0.8085033297538757, Accuracy: 0.736328125\n",
      "Batch: 63, Loss: 0.8178768754005432, Accuracy: 0.7236328125\n",
      "Batch: 64, Loss: 0.8466833829879761, Accuracy: 0.732421875\n",
      "Batch: 65, Loss: 0.911063551902771, Accuracy: 0.72412109375\n",
      "Batch: 66, Loss: 0.8793056011199951, Accuracy: 0.72021484375\n",
      "Batch: 67, Loss: 0.888954758644104, Accuracy: 0.70458984375\n",
      "Batch: 68, Loss: 0.8021555542945862, Accuracy: 0.72900390625\n",
      "Batch: 69, Loss: 0.8656955361366272, Accuracy: 0.7099609375\n",
      "Batch: 70, Loss: 0.8258826732635498, Accuracy: 0.73095703125\n",
      "Batch: 71, Loss: 0.8410079479217529, Accuracy: 0.7255859375\n",
      "Batch: 72, Loss: 0.8742886781692505, Accuracy: 0.69482421875\n",
      "Batch: 73, Loss: 0.8704968690872192, Accuracy: 0.70703125\n",
      "Batch: 74, Loss: 0.8832302689552307, Accuracy: 0.71337890625\n",
      "Batch: 75, Loss: 0.7961157560348511, Accuracy: 0.73779296875\n",
      "Batch: 76, Loss: 0.7878867387771606, Accuracy: 0.748046875\n",
      "Batch: 77, Loss: 0.7959155440330505, Accuracy: 0.7431640625\n",
      "Batch: 78, Loss: 0.8222358226776123, Accuracy: 0.73828125\n",
      "Batch: 79, Loss: 0.8186885118484497, Accuracy: 0.736328125\n",
      "Batch: 80, Loss: 0.8694058656692505, Accuracy: 0.724609375\n",
      "Batch: 81, Loss: 0.864068865776062, Accuracy: 0.72314453125\n",
      "Batch: 82, Loss: 0.8181781768798828, Accuracy: 0.732421875\n",
      "Batch: 83, Loss: 0.7929104566574097, Accuracy: 0.7392578125\n",
      "Batch: 84, Loss: 0.7789515256881714, Accuracy: 0.759765625\n",
      "Batch: 85, Loss: 0.7963718175888062, Accuracy: 0.73828125\n",
      "Batch: 86, Loss: 0.9104880690574646, Accuracy: 0.72119140625\n",
      "Batch: 87, Loss: 0.78825443983078, Accuracy: 0.751953125\n",
      "Batch: 88, Loss: 0.878248929977417, Accuracy: 0.72412109375\n",
      "Batch: 89, Loss: 0.8590284585952759, Accuracy: 0.7216796875\n",
      "Batch: 90, Loss: 0.8943551778793335, Accuracy: 0.69970703125\n",
      "Batch: 91, Loss: 0.8049097061157227, Accuracy: 0.73388671875\n",
      "Batch: 92, Loss: 0.9423580169677734, Accuracy: 0.6943359375\n",
      "Batch: 93, Loss: 0.9024204611778259, Accuracy: 0.70068359375\n",
      "Batch: 94, Loss: 0.896660327911377, Accuracy: 0.716796875\n",
      "Batch: 95, Loss: 0.919874906539917, Accuracy: 0.6982421875\n",
      "Batch: 96, Loss: 0.8610931038856506, Accuracy: 0.73291015625\n",
      "Batch: 97, Loss: 0.8356188535690308, Accuracy: 0.74169921875\n",
      "Batch: 98, Loss: 0.9424406290054321, Accuracy: 0.703125\n",
      "Batch: 99, Loss: 0.8313283920288086, Accuracy: 0.73486328125\n",
      "Batch: 100, Loss: 0.9315019249916077, Accuracy: 0.7041015625\n",
      "Batch: 101, Loss: 0.9369674921035767, Accuracy: 0.705078125\n",
      "Batch: 102, Loss: 0.820448637008667, Accuracy: 0.74365234375\n",
      "Batch: 103, Loss: 0.870885968208313, Accuracy: 0.724609375\n",
      "Batch: 104, Loss: 0.8542475700378418, Accuracy: 0.736328125\n",
      "Batch: 105, Loss: 0.8915576934814453, Accuracy: 0.72021484375\n",
      "Batch: 106, Loss: 0.8591005802154541, Accuracy: 0.7275390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 107, Loss: 0.888122022151947, Accuracy: 0.71728515625\n",
      "Batch: 108, Loss: 0.8376911878585815, Accuracy: 0.72509765625\n",
      "Batch: 109, Loss: 0.8327506184577942, Accuracy: 0.7353515625\n",
      "Batch: 110, Loss: 0.8139278292655945, Accuracy: 0.72509765625\n",
      "Batch: 111, Loss: 0.775227427482605, Accuracy: 0.75048828125\n",
      "Batch: 112, Loss: 0.8311213254928589, Accuracy: 0.73779296875\n",
      "Batch: 113, Loss: 0.8661139011383057, Accuracy: 0.72705078125\n",
      "Batch: 114, Loss: 0.834735631942749, Accuracy: 0.7314453125\n",
      "Batch: 115, Loss: 0.8557637929916382, Accuracy: 0.7294921875\n",
      "Batch: 116, Loss: 0.8704137206077576, Accuracy: 0.7216796875\n",
      "Batch: 117, Loss: 0.8417941331863403, Accuracy: 0.732421875\n",
      "Batch: 118, Loss: 0.8466355800628662, Accuracy: 0.72705078125\n",
      "Batch: 119, Loss: 0.840105414390564, Accuracy: 0.72607421875\n",
      "Batch: 120, Loss: 0.8198156356811523, Accuracy: 0.736328125\n",
      "Batch: 121, Loss: 0.8600647449493408, Accuracy: 0.71630859375\n",
      "Batch: 122, Loss: 0.8064669370651245, Accuracy: 0.74072265625\n",
      "Batch: 123, Loss: 0.8253098130226135, Accuracy: 0.74267578125\n",
      "Batch: 124, Loss: 0.7906764149665833, Accuracy: 0.73828125\n",
      "Batch: 125, Loss: 0.8314776420593262, Accuracy: 0.73095703125\n",
      "Batch: 126, Loss: 0.8073818683624268, Accuracy: 0.7353515625\n",
      "Batch: 127, Loss: 0.7765896320343018, Accuracy: 0.744140625\n",
      "Batch: 128, Loss: 0.9329565167427063, Accuracy: 0.70068359375\n",
      "Batch: 129, Loss: 0.9559047222137451, Accuracy: 0.69580078125\n",
      "Batch: 130, Loss: 0.940636157989502, Accuracy: 0.68994140625\n",
      "Batch: 131, Loss: 0.8738783597946167, Accuracy: 0.72021484375\n",
      "Batch: 132, Loss: 0.7875832319259644, Accuracy: 0.75341796875\n",
      "Batch: 133, Loss: 0.7851786613464355, Accuracy: 0.7646484375\n",
      "Batch: 134, Loss: 0.8681505918502808, Accuracy: 0.71630859375\n",
      "Batch: 135, Loss: 0.8564648628234863, Accuracy: 0.72509765625\n",
      "Batch: 136, Loss: 0.8070980906486511, Accuracy: 0.7373046875\n",
      "Batch: 137, Loss: 0.8250421285629272, Accuracy: 0.73828125\n",
      "Batch: 138, Loss: 0.7393621206283569, Accuracy: 0.77734375\n",
      "Batch: 139, Loss: 0.8144738674163818, Accuracy: 0.7392578125\n",
      "Batch: 140, Loss: 0.7593228816986084, Accuracy: 0.759765625\n",
      "Batch: 141, Loss: 0.8999776840209961, Accuracy: 0.716796875\n",
      "Batch: 142, Loss: 0.792968213558197, Accuracy: 0.74267578125\n",
      "Batch: 143, Loss: 0.8040405511856079, Accuracy: 0.744140625\n",
      "Batch: 144, Loss: 0.8832271099090576, Accuracy: 0.72021484375\n",
      "Batch: 145, Loss: 0.8453444242477417, Accuracy: 0.72705078125\n",
      "Batch: 146, Loss: 0.8808611631393433, Accuracy: 0.7138671875\n",
      "Batch: 147, Loss: 0.8488420844078064, Accuracy: 0.72607421875\n",
      "Batch: 148, Loss: 0.8838869333267212, Accuracy: 0.71142578125\n",
      "Batch: 149, Loss: 0.8450756669044495, Accuracy: 0.73095703125\n",
      "Batch: 150, Loss: 0.7401074171066284, Accuracy: 0.76611328125\n",
      "Batch: 151, Loss: 0.7443157434463501, Accuracy: 0.75341796875\n",
      "Batch: 152, Loss: 0.7794109582901001, Accuracy: 0.7490234375\n",
      "Batch: 153, Loss: 0.7821553349494934, Accuracy: 0.751953125\n",
      "Batch: 154, Loss: 0.7730445861816406, Accuracy: 0.74267578125\n",
      "Batch: 155, Loss: 0.8687493801116943, Accuracy: 0.7275390625\n",
      "Batch: 156, Loss: 0.7672585248947144, Accuracy: 0.74951171875\n",
      "Batch: 157, Loss: 0.7419162392616272, Accuracy: 0.74853515625\n",
      "Batch: 158, Loss: 0.7509505748748779, Accuracy: 0.76318359375\n",
      "Batch: 159, Loss: 0.754212498664856, Accuracy: 0.7666015625\n",
      "Batch: 160, Loss: 0.7854024171829224, Accuracy: 0.74169921875\n",
      "Batch: 161, Loss: 0.8137497305870056, Accuracy: 0.73876953125\n",
      "Batch: 162, Loss: 0.7817111015319824, Accuracy: 0.75\n",
      "Batch: 163, Loss: 0.8570755124092102, Accuracy: 0.7275390625\n",
      "Batch: 164, Loss: 0.9102599620819092, Accuracy: 0.71142578125\n",
      "Batch: 165, Loss: 0.8038651943206787, Accuracy: 0.7490234375\n",
      "Batch: 166, Loss: 0.8493118286132812, Accuracy: 0.73486328125\n",
      "Batch: 167, Loss: 0.7976272106170654, Accuracy: 0.74462890625\n",
      "Batch: 168, Loss: 0.7442601919174194, Accuracy: 0.759765625\n",
      "Batch: 169, Loss: 0.7936173677444458, Accuracy: 0.7373046875\n",
      "Batch: 170, Loss: 0.8795357346534729, Accuracy: 0.7236328125\n",
      "Batch: 171, Loss: 0.7870473265647888, Accuracy: 0.74365234375\n",
      "Batch: 172, Loss: 0.7834274768829346, Accuracy: 0.74609375\n",
      "Batch: 173, Loss: 0.8450698256492615, Accuracy: 0.7314453125\n",
      "Batch: 174, Loss: 0.7297723293304443, Accuracy: 0.7607421875\n",
      "Batch: 175, Loss: 0.8537217378616333, Accuracy: 0.71337890625\n",
      "Batch: 176, Loss: 0.8833865523338318, Accuracy: 0.724609375\n",
      "Batch: 177, Loss: 0.8052029609680176, Accuracy: 0.74951171875\n",
      "Batch: 178, Loss: 0.7917114496231079, Accuracy: 0.7451171875\n",
      "Batch: 179, Loss: 0.8152353167533875, Accuracy: 0.73388671875\n",
      "Batch: 180, Loss: 0.8786624670028687, Accuracy: 0.716796875\n",
      "Epoch 34/200\n",
      "Batch: 1, Loss: 1.2092885971069336, Accuracy: 0.65185546875\n",
      "Batch: 2, Loss: 0.8247300386428833, Accuracy: 0.724609375\n",
      "Batch: 3, Loss: 0.8245078325271606, Accuracy: 0.7314453125\n",
      "Batch: 4, Loss: 0.8874557018280029, Accuracy: 0.70849609375\n",
      "Batch: 5, Loss: 0.8592126369476318, Accuracy: 0.7255859375\n",
      "Batch: 6, Loss: 0.8678379058837891, Accuracy: 0.71875\n",
      "Batch: 7, Loss: 0.8004235029220581, Accuracy: 0.74609375\n",
      "Batch: 8, Loss: 0.8347793817520142, Accuracy: 0.72607421875\n",
      "Batch: 9, Loss: 0.8704195022583008, Accuracy: 0.7294921875\n",
      "Batch: 10, Loss: 0.8253633975982666, Accuracy: 0.736328125\n",
      "Batch: 11, Loss: 0.8852468729019165, Accuracy: 0.71484375\n",
      "Batch: 12, Loss: 0.7769879698753357, Accuracy: 0.7529296875\n",
      "Batch: 13, Loss: 0.8445999622344971, Accuracy: 0.73193359375\n",
      "Batch: 14, Loss: 0.8105295300483704, Accuracy: 0.74365234375\n",
      "Batch: 15, Loss: 0.8544416427612305, Accuracy: 0.72607421875\n",
      "Batch: 16, Loss: 0.896638035774231, Accuracy: 0.71142578125\n",
      "Batch: 17, Loss: 0.8271081447601318, Accuracy: 0.740234375\n",
      "Batch: 18, Loss: 0.8831666707992554, Accuracy: 0.724609375\n",
      "Batch: 19, Loss: 0.8697707653045654, Accuracy: 0.7314453125\n",
      "Batch: 20, Loss: 0.7643876075744629, Accuracy: 0.751953125\n",
      "Batch: 21, Loss: 0.9124619960784912, Accuracy: 0.70556640625\n",
      "Batch: 22, Loss: 0.811668872833252, Accuracy: 0.744140625\n",
      "Batch: 23, Loss: 0.7906175851821899, Accuracy: 0.74755859375\n",
      "Batch: 24, Loss: 0.8097336292266846, Accuracy: 0.7451171875\n",
      "Batch: 25, Loss: 0.7879117727279663, Accuracy: 0.7509765625\n",
      "Batch: 26, Loss: 0.8141798973083496, Accuracy: 0.7412109375\n",
      "Batch: 27, Loss: 0.8678141236305237, Accuracy: 0.70703125\n",
      "Batch: 28, Loss: 0.8053669929504395, Accuracy: 0.73486328125\n",
      "Batch: 29, Loss: 0.8757342100143433, Accuracy: 0.71923828125\n",
      "Batch: 30, Loss: 0.840693473815918, Accuracy: 0.724609375\n",
      "Batch: 31, Loss: 0.9626360535621643, Accuracy: 0.6953125\n",
      "Batch: 32, Loss: 0.8645350933074951, Accuracy: 0.71435546875\n",
      "Batch: 33, Loss: 0.8873324394226074, Accuracy: 0.71630859375\n",
      "Batch: 34, Loss: 0.9148560762405396, Accuracy: 0.712890625\n",
      "Batch: 35, Loss: 0.9135904908180237, Accuracy: 0.7158203125\n",
      "Batch: 36, Loss: 0.8885804414749146, Accuracy: 0.72509765625\n",
      "Batch: 37, Loss: 0.8723680973052979, Accuracy: 0.71875\n",
      "Batch: 38, Loss: 0.915114164352417, Accuracy: 0.7041015625\n",
      "Batch: 39, Loss: 0.8591231107711792, Accuracy: 0.72802734375\n",
      "Batch: 40, Loss: 0.9064035415649414, Accuracy: 0.7236328125\n",
      "Batch: 41, Loss: 0.8812613487243652, Accuracy: 0.7109375\n",
      "Batch: 42, Loss: 0.855721116065979, Accuracy: 0.7138671875\n",
      "Batch: 43, Loss: 0.8093549013137817, Accuracy: 0.744140625\n",
      "Batch: 44, Loss: 0.7541350722312927, Accuracy: 0.76416015625\n",
      "Batch: 45, Loss: 0.8090170621871948, Accuracy: 0.7412109375\n",
      "Batch: 46, Loss: 0.7841640710830688, Accuracy: 0.72900390625\n",
      "Batch: 47, Loss: 0.8323333263397217, Accuracy: 0.73828125\n",
      "Batch: 48, Loss: 0.8082177639007568, Accuracy: 0.74609375\n",
      "Batch: 49, Loss: 0.7921085953712463, Accuracy: 0.7392578125\n",
      "Batch: 50, Loss: 0.834036111831665, Accuracy: 0.72998046875\n",
      "Batch: 51, Loss: 0.8300723433494568, Accuracy: 0.7353515625\n",
      "Batch: 52, Loss: 0.7913751602172852, Accuracy: 0.73583984375\n",
      "Batch: 53, Loss: 0.8004180192947388, Accuracy: 0.73388671875\n",
      "Batch: 54, Loss: 0.8517979979515076, Accuracy: 0.71875\n",
      "Batch: 55, Loss: 0.8022416234016418, Accuracy: 0.7314453125\n",
      "Batch: 56, Loss: 0.8055357336997986, Accuracy: 0.7392578125\n",
      "Batch: 57, Loss: 0.8605910539627075, Accuracy: 0.72802734375\n",
      "Batch: 58, Loss: 0.8362759947776794, Accuracy: 0.7275390625\n",
      "Batch: 59, Loss: 0.9399408102035522, Accuracy: 0.6982421875\n",
      "Batch: 60, Loss: 0.8033114075660706, Accuracy: 0.74560546875\n",
      "Batch: 61, Loss: 0.7710534334182739, Accuracy: 0.75\n",
      "Batch: 62, Loss: 0.8096703290939331, Accuracy: 0.75048828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 63, Loss: 0.8097817301750183, Accuracy: 0.73095703125\n",
      "Batch: 64, Loss: 0.8323615789413452, Accuracy: 0.73046875\n",
      "Batch: 65, Loss: 0.8888223171234131, Accuracy: 0.72265625\n",
      "Batch: 66, Loss: 0.8741378784179688, Accuracy: 0.7216796875\n",
      "Batch: 67, Loss: 0.8684972524642944, Accuracy: 0.71826171875\n",
      "Batch: 68, Loss: 0.7816587090492249, Accuracy: 0.73828125\n",
      "Batch: 69, Loss: 0.8465350866317749, Accuracy: 0.7177734375\n",
      "Batch: 70, Loss: 0.8315180540084839, Accuracy: 0.7236328125\n",
      "Batch: 71, Loss: 0.8224459886550903, Accuracy: 0.734375\n",
      "Batch: 72, Loss: 0.8545238971710205, Accuracy: 0.7041015625\n",
      "Batch: 73, Loss: 0.8727073669433594, Accuracy: 0.7119140625\n",
      "Batch: 74, Loss: 0.8796243071556091, Accuracy: 0.72509765625\n",
      "Batch: 75, Loss: 0.7877126932144165, Accuracy: 0.7421875\n",
      "Batch: 76, Loss: 0.7697024345397949, Accuracy: 0.74658203125\n",
      "Batch: 77, Loss: 0.7891387343406677, Accuracy: 0.755859375\n",
      "Batch: 78, Loss: 0.8124065399169922, Accuracy: 0.736328125\n",
      "Batch: 79, Loss: 0.8204667568206787, Accuracy: 0.73388671875\n",
      "Batch: 80, Loss: 0.8559631109237671, Accuracy: 0.71240234375\n",
      "Batch: 81, Loss: 0.8645275235176086, Accuracy: 0.72216796875\n",
      "Batch: 82, Loss: 0.8106639981269836, Accuracy: 0.7255859375\n",
      "Batch: 83, Loss: 0.7618012428283691, Accuracy: 0.74560546875\n",
      "Batch: 84, Loss: 0.7686079740524292, Accuracy: 0.75634765625\n",
      "Batch: 85, Loss: 0.7941792011260986, Accuracy: 0.7353515625\n",
      "Batch: 86, Loss: 0.9023705720901489, Accuracy: 0.71435546875\n",
      "Batch: 87, Loss: 0.7891494035720825, Accuracy: 0.744140625\n",
      "Batch: 88, Loss: 0.8544872999191284, Accuracy: 0.7275390625\n",
      "Batch: 89, Loss: 0.8351516723632812, Accuracy: 0.7314453125\n",
      "Batch: 90, Loss: 0.8980076313018799, Accuracy: 0.69580078125\n",
      "Batch: 91, Loss: 0.820833146572113, Accuracy: 0.73583984375\n",
      "Batch: 92, Loss: 0.9487526416778564, Accuracy: 0.68896484375\n",
      "Batch: 93, Loss: 0.9005141258239746, Accuracy: 0.71044921875\n",
      "Batch: 94, Loss: 0.8599729537963867, Accuracy: 0.72802734375\n",
      "Batch: 95, Loss: 0.8973680734634399, Accuracy: 0.72216796875\n",
      "Batch: 96, Loss: 0.8464322090148926, Accuracy: 0.73291015625\n",
      "Batch: 97, Loss: 0.8264098167419434, Accuracy: 0.740234375\n",
      "Batch: 98, Loss: 0.9095386862754822, Accuracy: 0.71435546875\n",
      "Batch: 99, Loss: 0.8316968679428101, Accuracy: 0.73046875\n",
      "Batch: 100, Loss: 0.9130270481109619, Accuracy: 0.71240234375\n",
      "Batch: 101, Loss: 0.9520594477653503, Accuracy: 0.69482421875\n",
      "Batch: 102, Loss: 0.8117901682853699, Accuracy: 0.73388671875\n",
      "Batch: 103, Loss: 0.8865417242050171, Accuracy: 0.7119140625\n",
      "Batch: 104, Loss: 0.8589436411857605, Accuracy: 0.728515625\n",
      "Batch: 105, Loss: 0.882689356803894, Accuracy: 0.7177734375\n",
      "Batch: 106, Loss: 0.8526378870010376, Accuracy: 0.7294921875\n",
      "Batch: 107, Loss: 0.8677854537963867, Accuracy: 0.72900390625\n",
      "Batch: 108, Loss: 0.8360803723335266, Accuracy: 0.72509765625\n",
      "Batch: 109, Loss: 0.8495280742645264, Accuracy: 0.72509765625\n",
      "Batch: 110, Loss: 0.8006348013877869, Accuracy: 0.73681640625\n",
      "Batch: 111, Loss: 0.7661010026931763, Accuracy: 0.76220703125\n",
      "Batch: 112, Loss: 0.8083206415176392, Accuracy: 0.7470703125\n",
      "Batch: 113, Loss: 0.864958643913269, Accuracy: 0.71630859375\n",
      "Batch: 114, Loss: 0.8347932696342468, Accuracy: 0.73193359375\n",
      "Batch: 115, Loss: 0.851527214050293, Accuracy: 0.73046875\n",
      "Batch: 116, Loss: 0.846640944480896, Accuracy: 0.724609375\n",
      "Batch: 117, Loss: 0.8196936845779419, Accuracy: 0.73193359375\n",
      "Batch: 118, Loss: 0.837465763092041, Accuracy: 0.72802734375\n",
      "Batch: 119, Loss: 0.8225750923156738, Accuracy: 0.72705078125\n",
      "Batch: 120, Loss: 0.811072826385498, Accuracy: 0.7412109375\n",
      "Batch: 121, Loss: 0.8217511177062988, Accuracy: 0.732421875\n",
      "Batch: 122, Loss: 0.7895963191986084, Accuracy: 0.748046875\n",
      "Batch: 123, Loss: 0.8024747371673584, Accuracy: 0.75341796875\n",
      "Batch: 124, Loss: 0.781700849533081, Accuracy: 0.75\n",
      "Batch: 125, Loss: 0.8317850828170776, Accuracy: 0.736328125\n",
      "Batch: 126, Loss: 0.7839396595954895, Accuracy: 0.732421875\n",
      "Batch: 127, Loss: 0.7684131860733032, Accuracy: 0.751953125\n",
      "Batch: 128, Loss: 0.9217595458030701, Accuracy: 0.7138671875\n",
      "Batch: 129, Loss: 0.9519680738449097, Accuracy: 0.705078125\n",
      "Batch: 130, Loss: 0.9339158535003662, Accuracy: 0.70751953125\n",
      "Batch: 131, Loss: 0.8531817197799683, Accuracy: 0.73095703125\n",
      "Batch: 132, Loss: 0.7806353569030762, Accuracy: 0.75048828125\n",
      "Batch: 133, Loss: 0.7881172895431519, Accuracy: 0.7529296875\n",
      "Batch: 134, Loss: 0.8501591086387634, Accuracy: 0.73828125\n",
      "Batch: 135, Loss: 0.8429222106933594, Accuracy: 0.7255859375\n",
      "Batch: 136, Loss: 0.784518837928772, Accuracy: 0.736328125\n",
      "Batch: 137, Loss: 0.8443112373352051, Accuracy: 0.7353515625\n",
      "Batch: 138, Loss: 0.7389923334121704, Accuracy: 0.77294921875\n",
      "Batch: 139, Loss: 0.8066507577896118, Accuracy: 0.73486328125\n",
      "Batch: 140, Loss: 0.7537049055099487, Accuracy: 0.75537109375\n",
      "Batch: 141, Loss: 0.8896907567977905, Accuracy: 0.71044921875\n",
      "Batch: 142, Loss: 0.7916767597198486, Accuracy: 0.74169921875\n",
      "Batch: 143, Loss: 0.8196383714675903, Accuracy: 0.73486328125\n",
      "Batch: 144, Loss: 0.8692180514335632, Accuracy: 0.72607421875\n",
      "Batch: 145, Loss: 0.8368592262268066, Accuracy: 0.7421875\n",
      "Batch: 146, Loss: 0.8882120251655579, Accuracy: 0.71337890625\n",
      "Batch: 147, Loss: 0.8408960103988647, Accuracy: 0.72900390625\n",
      "Batch: 148, Loss: 0.8796181678771973, Accuracy: 0.71728515625\n",
      "Batch: 149, Loss: 0.8563606142997742, Accuracy: 0.7294921875\n",
      "Batch: 150, Loss: 0.7412353754043579, Accuracy: 0.76025390625\n",
      "Batch: 151, Loss: 0.7431420087814331, Accuracy: 0.76513671875\n",
      "Batch: 152, Loss: 0.7888956069946289, Accuracy: 0.7529296875\n",
      "Batch: 153, Loss: 0.7650741338729858, Accuracy: 0.7470703125\n",
      "Batch: 154, Loss: 0.7800010442733765, Accuracy: 0.7431640625\n",
      "Batch: 155, Loss: 0.8753884434700012, Accuracy: 0.71728515625\n",
      "Batch: 156, Loss: 0.7534948587417603, Accuracy: 0.75146484375\n",
      "Batch: 157, Loss: 0.7291967272758484, Accuracy: 0.7568359375\n",
      "Batch: 158, Loss: 0.7495912313461304, Accuracy: 0.76220703125\n",
      "Batch: 159, Loss: 0.7429296374320984, Accuracy: 0.767578125\n",
      "Batch: 160, Loss: 0.7883270382881165, Accuracy: 0.74560546875\n",
      "Batch: 161, Loss: 0.8106732368469238, Accuracy: 0.73828125\n",
      "Batch: 162, Loss: 0.7778576612472534, Accuracy: 0.7548828125\n",
      "Batch: 163, Loss: 0.8522430658340454, Accuracy: 0.72509765625\n",
      "Batch: 164, Loss: 0.8944308161735535, Accuracy: 0.7197265625\n",
      "Batch: 165, Loss: 0.8122778534889221, Accuracy: 0.7451171875\n",
      "Batch: 166, Loss: 0.8346703052520752, Accuracy: 0.736328125\n",
      "Batch: 167, Loss: 0.7945978045463562, Accuracy: 0.748046875\n",
      "Batch: 168, Loss: 0.7426508069038391, Accuracy: 0.7666015625\n",
      "Batch: 169, Loss: 0.7899738550186157, Accuracy: 0.7412109375\n",
      "Batch: 170, Loss: 0.8546812534332275, Accuracy: 0.728515625\n",
      "Batch: 171, Loss: 0.7878279089927673, Accuracy: 0.751953125\n",
      "Batch: 172, Loss: 0.778735876083374, Accuracy: 0.74365234375\n",
      "Batch: 173, Loss: 0.829246997833252, Accuracy: 0.73291015625\n",
      "Batch: 174, Loss: 0.707314133644104, Accuracy: 0.76513671875\n",
      "Batch: 175, Loss: 0.8406049013137817, Accuracy: 0.71923828125\n",
      "Batch: 176, Loss: 0.8529249429702759, Accuracy: 0.73046875\n",
      "Batch: 177, Loss: 0.7990524172782898, Accuracy: 0.740234375\n",
      "Batch: 178, Loss: 0.7666215896606445, Accuracy: 0.75634765625\n",
      "Batch: 179, Loss: 0.8040902018547058, Accuracy: 0.74853515625\n",
      "Batch: 180, Loss: 0.8513867855072021, Accuracy: 0.71875\n",
      "Epoch 35/200\n",
      "Batch: 1, Loss: 1.1964541673660278, Accuracy: 0.66064453125\n",
      "Batch: 2, Loss: 0.8313827514648438, Accuracy: 0.7275390625\n",
      "Batch: 3, Loss: 0.8192334771156311, Accuracy: 0.73095703125\n",
      "Batch: 4, Loss: 0.854364275932312, Accuracy: 0.7294921875\n",
      "Batch: 5, Loss: 0.8282530307769775, Accuracy: 0.73095703125\n",
      "Batch: 6, Loss: 0.8497750759124756, Accuracy: 0.7265625\n",
      "Batch: 7, Loss: 0.7783873677253723, Accuracy: 0.7470703125\n",
      "Batch: 8, Loss: 0.8379050493240356, Accuracy: 0.71826171875\n",
      "Batch: 9, Loss: 0.8984800577163696, Accuracy: 0.72021484375\n",
      "Batch: 10, Loss: 0.818321704864502, Accuracy: 0.74072265625\n",
      "Batch: 11, Loss: 0.8608403205871582, Accuracy: 0.7177734375\n",
      "Batch: 12, Loss: 0.7638533115386963, Accuracy: 0.74658203125\n",
      "Batch: 13, Loss: 0.8306550979614258, Accuracy: 0.73974609375\n",
      "Batch: 14, Loss: 0.8157296180725098, Accuracy: 0.73876953125\n",
      "Batch: 15, Loss: 0.8208326697349548, Accuracy: 0.73388671875\n",
      "Batch: 16, Loss: 0.8852216005325317, Accuracy: 0.71337890625\n",
      "Batch: 17, Loss: 0.8152917623519897, Accuracy: 0.75146484375\n",
      "Batch: 18, Loss: 0.8653719425201416, Accuracy: 0.71923828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 19, Loss: 0.8673574924468994, Accuracy: 0.7275390625\n",
      "Batch: 20, Loss: 0.7514469027519226, Accuracy: 0.7626953125\n",
      "Batch: 21, Loss: 0.9002983570098877, Accuracy: 0.71826171875\n",
      "Batch: 22, Loss: 0.784170389175415, Accuracy: 0.7412109375\n",
      "Batch: 23, Loss: 0.7797897458076477, Accuracy: 0.744140625\n",
      "Batch: 24, Loss: 0.8239381313323975, Accuracy: 0.73291015625\n",
      "Batch: 25, Loss: 0.781998872756958, Accuracy: 0.76123046875\n",
      "Batch: 26, Loss: 0.7995261549949646, Accuracy: 0.75048828125\n",
      "Batch: 27, Loss: 0.8485323190689087, Accuracy: 0.7255859375\n",
      "Batch: 28, Loss: 0.7998148798942566, Accuracy: 0.73291015625\n",
      "Batch: 29, Loss: 0.8698610067367554, Accuracy: 0.72119140625\n",
      "Batch: 30, Loss: 0.836808443069458, Accuracy: 0.73681640625\n",
      "Batch: 31, Loss: 0.9400938749313354, Accuracy: 0.7080078125\n",
      "Batch: 32, Loss: 0.8711431622505188, Accuracy: 0.7158203125\n",
      "Batch: 33, Loss: 0.8680309057235718, Accuracy: 0.71533203125\n",
      "Batch: 34, Loss: 0.898151159286499, Accuracy: 0.70361328125\n",
      "Batch: 35, Loss: 0.9260687828063965, Accuracy: 0.69140625\n",
      "Batch: 36, Loss: 0.8914084434509277, Accuracy: 0.7138671875\n",
      "Batch: 37, Loss: 0.8780988454818726, Accuracy: 0.71728515625\n",
      "Batch: 38, Loss: 0.9041814804077148, Accuracy: 0.70654296875\n",
      "Batch: 39, Loss: 0.852750301361084, Accuracy: 0.73486328125\n",
      "Batch: 40, Loss: 0.9121218919754028, Accuracy: 0.72314453125\n",
      "Batch: 41, Loss: 0.8610187768936157, Accuracy: 0.71875\n",
      "Batch: 42, Loss: 0.839944064617157, Accuracy: 0.72314453125\n",
      "Batch: 43, Loss: 0.8234029412269592, Accuracy: 0.74267578125\n",
      "Batch: 44, Loss: 0.7410131692886353, Accuracy: 0.763671875\n",
      "Batch: 45, Loss: 0.791039228439331, Accuracy: 0.74462890625\n",
      "Batch: 46, Loss: 0.7798314094543457, Accuracy: 0.73095703125\n",
      "Batch: 47, Loss: 0.8140219449996948, Accuracy: 0.73681640625\n",
      "Batch: 48, Loss: 0.803423285484314, Accuracy: 0.74267578125\n",
      "Batch: 49, Loss: 0.7908754348754883, Accuracy: 0.74658203125\n",
      "Batch: 50, Loss: 0.8469306230545044, Accuracy: 0.73193359375\n",
      "Batch: 51, Loss: 0.8160429000854492, Accuracy: 0.734375\n",
      "Batch: 52, Loss: 0.7778083086013794, Accuracy: 0.7490234375\n",
      "Batch: 53, Loss: 0.8017561435699463, Accuracy: 0.728515625\n",
      "Batch: 54, Loss: 0.833471417427063, Accuracy: 0.72119140625\n",
      "Batch: 55, Loss: 0.7986794114112854, Accuracy: 0.73486328125\n",
      "Batch: 56, Loss: 0.8111226558685303, Accuracy: 0.7353515625\n",
      "Batch: 57, Loss: 0.8846783638000488, Accuracy: 0.71435546875\n",
      "Batch: 58, Loss: 0.8256983757019043, Accuracy: 0.73193359375\n",
      "Batch: 59, Loss: 0.9222370386123657, Accuracy: 0.70556640625\n",
      "Batch: 60, Loss: 0.8251569271087646, Accuracy: 0.740234375\n",
      "Batch: 61, Loss: 0.7670488357543945, Accuracy: 0.75439453125\n",
      "Batch: 62, Loss: 0.7917093634605408, Accuracy: 0.75048828125\n",
      "Batch: 63, Loss: 0.8032729625701904, Accuracy: 0.73486328125\n",
      "Batch: 64, Loss: 0.8235600590705872, Accuracy: 0.72607421875\n",
      "Batch: 65, Loss: 0.8887733817100525, Accuracy: 0.72119140625\n",
      "Batch: 66, Loss: 0.8626511096954346, Accuracy: 0.72802734375\n",
      "Batch: 67, Loss: 0.8590899705886841, Accuracy: 0.724609375\n",
      "Batch: 68, Loss: 0.7765152454376221, Accuracy: 0.74609375\n",
      "Batch: 69, Loss: 0.8444162607192993, Accuracy: 0.7119140625\n",
      "Batch: 70, Loss: 0.8176127076148987, Accuracy: 0.72802734375\n",
      "Batch: 71, Loss: 0.8058216571807861, Accuracy: 0.734375\n",
      "Batch: 72, Loss: 0.8583287000656128, Accuracy: 0.70751953125\n",
      "Batch: 73, Loss: 0.8679056167602539, Accuracy: 0.71435546875\n",
      "Batch: 74, Loss: 0.8764618635177612, Accuracy: 0.72705078125\n",
      "Batch: 75, Loss: 0.7793294191360474, Accuracy: 0.74560546875\n",
      "Batch: 76, Loss: 0.7653325796127319, Accuracy: 0.7529296875\n",
      "Batch: 77, Loss: 0.7926188707351685, Accuracy: 0.7490234375\n",
      "Batch: 78, Loss: 0.8234754800796509, Accuracy: 0.7470703125\n",
      "Batch: 79, Loss: 0.8195410370826721, Accuracy: 0.7412109375\n",
      "Batch: 80, Loss: 0.8358423709869385, Accuracy: 0.724609375\n",
      "Batch: 81, Loss: 0.8508341312408447, Accuracy: 0.73291015625\n",
      "Batch: 82, Loss: 0.797892153263092, Accuracy: 0.740234375\n",
      "Batch: 83, Loss: 0.7714232206344604, Accuracy: 0.7529296875\n",
      "Batch: 84, Loss: 0.7602448463439941, Accuracy: 0.7568359375\n",
      "Batch: 85, Loss: 0.799903929233551, Accuracy: 0.74462890625\n",
      "Batch: 86, Loss: 0.8822193741798401, Accuracy: 0.728515625\n",
      "Batch: 87, Loss: 0.773144006729126, Accuracy: 0.75244140625\n",
      "Batch: 88, Loss: 0.8404555320739746, Accuracy: 0.73828125\n",
      "Batch: 89, Loss: 0.8305051922798157, Accuracy: 0.7373046875\n",
      "Batch: 90, Loss: 0.8706476092338562, Accuracy: 0.7138671875\n",
      "Batch: 91, Loss: 0.8157600164413452, Accuracy: 0.73681640625\n",
      "Batch: 92, Loss: 0.9411913752555847, Accuracy: 0.70068359375\n",
      "Batch: 93, Loss: 0.8768312335014343, Accuracy: 0.712890625\n",
      "Batch: 94, Loss: 0.8716508746147156, Accuracy: 0.72314453125\n",
      "Batch: 95, Loss: 0.895398736000061, Accuracy: 0.71533203125\n",
      "Batch: 96, Loss: 0.8333734273910522, Accuracy: 0.7333984375\n",
      "Batch: 97, Loss: 0.8124582767486572, Accuracy: 0.75048828125\n",
      "Batch: 98, Loss: 0.9119515419006348, Accuracy: 0.71240234375\n",
      "Batch: 99, Loss: 0.8097327947616577, Accuracy: 0.74169921875\n",
      "Batch: 100, Loss: 0.9131259322166443, Accuracy: 0.70849609375\n",
      "Batch: 101, Loss: 0.9283124804496765, Accuracy: 0.71142578125\n",
      "Batch: 102, Loss: 0.8133948445320129, Accuracy: 0.7333984375\n",
      "Batch: 103, Loss: 0.8648275136947632, Accuracy: 0.728515625\n",
      "Batch: 104, Loss: 0.8469706773757935, Accuracy: 0.73193359375\n",
      "Batch: 105, Loss: 0.863447904586792, Accuracy: 0.72509765625\n",
      "Batch: 106, Loss: 0.8476343154907227, Accuracy: 0.72998046875\n",
      "Batch: 107, Loss: 0.8622474074363708, Accuracy: 0.72998046875\n",
      "Batch: 108, Loss: 0.8275717496871948, Accuracy: 0.7373046875\n",
      "Batch: 109, Loss: 0.8239492177963257, Accuracy: 0.7392578125\n",
      "Batch: 110, Loss: 0.8099053502082825, Accuracy: 0.72705078125\n",
      "Batch: 111, Loss: 0.7582096457481384, Accuracy: 0.74951171875\n",
      "Batch: 112, Loss: 0.8092001080513, Accuracy: 0.74169921875\n",
      "Batch: 113, Loss: 0.8540942668914795, Accuracy: 0.71630859375\n",
      "Batch: 114, Loss: 0.8209213018417358, Accuracy: 0.73046875\n",
      "Batch: 115, Loss: 0.8297602534294128, Accuracy: 0.74072265625\n",
      "Batch: 116, Loss: 0.83455491065979, Accuracy: 0.724609375\n",
      "Batch: 117, Loss: 0.8391393423080444, Accuracy: 0.7265625\n",
      "Batch: 118, Loss: 0.8428864479064941, Accuracy: 0.7236328125\n",
      "Batch: 119, Loss: 0.8265143632888794, Accuracy: 0.7216796875\n",
      "Batch: 120, Loss: 0.8151692748069763, Accuracy: 0.7392578125\n",
      "Batch: 121, Loss: 0.812799870967865, Accuracy: 0.73974609375\n",
      "Batch: 122, Loss: 0.791517972946167, Accuracy: 0.74365234375\n",
      "Batch: 123, Loss: 0.7903119325637817, Accuracy: 0.75537109375\n",
      "Batch: 124, Loss: 0.7859309911727905, Accuracy: 0.736328125\n",
      "Batch: 125, Loss: 0.8246769905090332, Accuracy: 0.73388671875\n",
      "Batch: 126, Loss: 0.773100733757019, Accuracy: 0.74658203125\n",
      "Batch: 127, Loss: 0.7565933465957642, Accuracy: 0.75634765625\n",
      "Batch: 128, Loss: 0.9085816144943237, Accuracy: 0.7080078125\n",
      "Batch: 129, Loss: 0.9352654218673706, Accuracy: 0.7021484375\n",
      "Batch: 130, Loss: 0.9294093251228333, Accuracy: 0.70849609375\n",
      "Batch: 131, Loss: 0.8727855086326599, Accuracy: 0.7255859375\n",
      "Batch: 132, Loss: 0.7845533490180969, Accuracy: 0.74951171875\n",
      "Batch: 133, Loss: 0.7828987240791321, Accuracy: 0.76611328125\n",
      "Batch: 134, Loss: 0.853589653968811, Accuracy: 0.7265625\n",
      "Batch: 135, Loss: 0.8210538625717163, Accuracy: 0.734375\n",
      "Batch: 136, Loss: 0.7906529903411865, Accuracy: 0.7353515625\n",
      "Batch: 137, Loss: 0.8382877111434937, Accuracy: 0.72900390625\n",
      "Batch: 138, Loss: 0.7449947595596313, Accuracy: 0.77099609375\n",
      "Batch: 139, Loss: 0.8000441193580627, Accuracy: 0.7470703125\n",
      "Batch: 140, Loss: 0.7581030130386353, Accuracy: 0.7490234375\n",
      "Batch: 141, Loss: 0.8806765079498291, Accuracy: 0.70849609375\n",
      "Batch: 142, Loss: 0.7795141935348511, Accuracy: 0.7470703125\n",
      "Batch: 143, Loss: 0.7997140884399414, Accuracy: 0.748046875\n",
      "Batch: 144, Loss: 0.8643697500228882, Accuracy: 0.73046875\n",
      "Batch: 145, Loss: 0.8303737044334412, Accuracy: 0.73779296875\n",
      "Batch: 146, Loss: 0.880244255065918, Accuracy: 0.71875\n",
      "Batch: 147, Loss: 0.8412423729896545, Accuracy: 0.73486328125\n",
      "Batch: 148, Loss: 0.8612650632858276, Accuracy: 0.7197265625\n",
      "Batch: 149, Loss: 0.8455474376678467, Accuracy: 0.73046875\n",
      "Batch: 150, Loss: 0.7092933654785156, Accuracy: 0.7763671875\n",
      "Batch: 151, Loss: 0.7433288097381592, Accuracy: 0.755859375\n",
      "Batch: 152, Loss: 0.7634415030479431, Accuracy: 0.76123046875\n",
      "Batch: 153, Loss: 0.7521296143531799, Accuracy: 0.76220703125\n",
      "Batch: 154, Loss: 0.7725954651832581, Accuracy: 0.74072265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 155, Loss: 0.8461353778839111, Accuracy: 0.72607421875\n",
      "Batch: 156, Loss: 0.7564986944198608, Accuracy: 0.75927734375\n",
      "Batch: 157, Loss: 0.7339504957199097, Accuracy: 0.75537109375\n",
      "Batch: 158, Loss: 0.7251421809196472, Accuracy: 0.76953125\n",
      "Batch: 159, Loss: 0.7314119338989258, Accuracy: 0.7705078125\n",
      "Batch: 160, Loss: 0.7683638334274292, Accuracy: 0.751953125\n",
      "Batch: 161, Loss: 0.7958179712295532, Accuracy: 0.74267578125\n",
      "Batch: 162, Loss: 0.7672562599182129, Accuracy: 0.755859375\n",
      "Batch: 163, Loss: 0.8400946855545044, Accuracy: 0.72705078125\n",
      "Batch: 164, Loss: 0.8830862641334534, Accuracy: 0.712890625\n",
      "Batch: 165, Loss: 0.798261821269989, Accuracy: 0.75244140625\n",
      "Batch: 166, Loss: 0.8142791986465454, Accuracy: 0.73974609375\n",
      "Batch: 167, Loss: 0.7914155721664429, Accuracy: 0.7421875\n",
      "Batch: 168, Loss: 0.7293782234191895, Accuracy: 0.76611328125\n",
      "Batch: 169, Loss: 0.7884247303009033, Accuracy: 0.7529296875\n",
      "Batch: 170, Loss: 0.8441373109817505, Accuracy: 0.728515625\n",
      "Batch: 171, Loss: 0.775050938129425, Accuracy: 0.748046875\n",
      "Batch: 172, Loss: 0.7620182037353516, Accuracy: 0.7509765625\n",
      "Batch: 173, Loss: 0.8335716128349304, Accuracy: 0.74072265625\n",
      "Batch: 174, Loss: 0.7165763974189758, Accuracy: 0.7666015625\n",
      "Batch: 175, Loss: 0.8332257270812988, Accuracy: 0.72265625\n",
      "Batch: 176, Loss: 0.8629812598228455, Accuracy: 0.728515625\n",
      "Batch: 177, Loss: 0.79050612449646, Accuracy: 0.7421875\n",
      "Batch: 178, Loss: 0.7558858394622803, Accuracy: 0.75732421875\n",
      "Batch: 179, Loss: 0.7764805555343628, Accuracy: 0.7607421875\n",
      "Batch: 180, Loss: 0.8450497388839722, Accuracy: 0.73046875\n",
      "Epoch 36/200\n",
      "Batch: 1, Loss: 1.2010776996612549, Accuracy: 0.666015625\n",
      "Batch: 2, Loss: 0.81953364610672, Accuracy: 0.72119140625\n",
      "Batch: 3, Loss: 0.8247082233428955, Accuracy: 0.7275390625\n",
      "Batch: 4, Loss: 0.8550313711166382, Accuracy: 0.72314453125\n",
      "Batch: 5, Loss: 0.8460355997085571, Accuracy: 0.7216796875\n",
      "Batch: 6, Loss: 0.8229920864105225, Accuracy: 0.7314453125\n",
      "Batch: 7, Loss: 0.7708163857460022, Accuracy: 0.75341796875\n",
      "Batch: 8, Loss: 0.8290708065032959, Accuracy: 0.7333984375\n",
      "Batch: 9, Loss: 0.8681169748306274, Accuracy: 0.72509765625\n",
      "Batch: 10, Loss: 0.7971218228340149, Accuracy: 0.7490234375\n",
      "Batch: 11, Loss: 0.8697638511657715, Accuracy: 0.7236328125\n",
      "Batch: 12, Loss: 0.7662125825881958, Accuracy: 0.7568359375\n",
      "Batch: 13, Loss: 0.822636604309082, Accuracy: 0.72802734375\n",
      "Batch: 14, Loss: 0.7909066677093506, Accuracy: 0.75341796875\n",
      "Batch: 15, Loss: 0.8230862617492676, Accuracy: 0.7314453125\n",
      "Batch: 16, Loss: 0.872063398361206, Accuracy: 0.7197265625\n",
      "Batch: 17, Loss: 0.7948509454727173, Accuracy: 0.75244140625\n",
      "Batch: 18, Loss: 0.8609700798988342, Accuracy: 0.72265625\n",
      "Batch: 19, Loss: 0.8631686568260193, Accuracy: 0.7275390625\n",
      "Batch: 20, Loss: 0.7453546524047852, Accuracy: 0.75732421875\n",
      "Batch: 21, Loss: 0.8905534744262695, Accuracy: 0.72607421875\n",
      "Batch: 22, Loss: 0.7799574136734009, Accuracy: 0.74462890625\n",
      "Batch: 23, Loss: 0.7711273431777954, Accuracy: 0.7587890625\n",
      "Batch: 24, Loss: 0.802753746509552, Accuracy: 0.73974609375\n",
      "Batch: 25, Loss: 0.7616236209869385, Accuracy: 0.7587890625\n",
      "Batch: 26, Loss: 0.802099347114563, Accuracy: 0.74462890625\n",
      "Batch: 27, Loss: 0.8264111280441284, Accuracy: 0.7294921875\n",
      "Batch: 28, Loss: 0.779798150062561, Accuracy: 0.74609375\n",
      "Batch: 29, Loss: 0.8772954344749451, Accuracy: 0.7275390625\n",
      "Batch: 30, Loss: 0.825223445892334, Accuracy: 0.73583984375\n",
      "Batch: 31, Loss: 0.9376854300498962, Accuracy: 0.701171875\n",
      "Batch: 32, Loss: 0.8443208932876587, Accuracy: 0.7294921875\n",
      "Batch: 33, Loss: 0.8709263205528259, Accuracy: 0.71435546875\n",
      "Batch: 34, Loss: 0.8896818161010742, Accuracy: 0.7138671875\n",
      "Batch: 35, Loss: 0.9149143099784851, Accuracy: 0.7099609375\n",
      "Batch: 36, Loss: 0.8793659210205078, Accuracy: 0.724609375\n",
      "Batch: 37, Loss: 0.847953736782074, Accuracy: 0.72900390625\n",
      "Batch: 38, Loss: 0.88759446144104, Accuracy: 0.71630859375\n",
      "Batch: 39, Loss: 0.8535662889480591, Accuracy: 0.732421875\n",
      "Batch: 40, Loss: 0.8739032745361328, Accuracy: 0.72314453125\n",
      "Batch: 41, Loss: 0.8347989320755005, Accuracy: 0.73095703125\n",
      "Batch: 42, Loss: 0.8378064632415771, Accuracy: 0.71337890625\n",
      "Batch: 43, Loss: 0.8049197196960449, Accuracy: 0.7529296875\n",
      "Batch: 44, Loss: 0.7196987271308899, Accuracy: 0.76806640625\n",
      "Batch: 45, Loss: 0.800491213798523, Accuracy: 0.748046875\n",
      "Batch: 46, Loss: 0.779647707939148, Accuracy: 0.7392578125\n",
      "Batch: 47, Loss: 0.8114787340164185, Accuracy: 0.7412109375\n",
      "Batch: 48, Loss: 0.7921749949455261, Accuracy: 0.74951171875\n",
      "Batch: 49, Loss: 0.7687831521034241, Accuracy: 0.7529296875\n",
      "Batch: 50, Loss: 0.8088182210922241, Accuracy: 0.7294921875\n",
      "Batch: 51, Loss: 0.7970113158226013, Accuracy: 0.73583984375\n",
      "Batch: 52, Loss: 0.7747253179550171, Accuracy: 0.7412109375\n",
      "Batch: 53, Loss: 0.7859551310539246, Accuracy: 0.73046875\n",
      "Batch: 54, Loss: 0.8435677289962769, Accuracy: 0.7216796875\n",
      "Batch: 55, Loss: 0.7886413335800171, Accuracy: 0.73876953125\n",
      "Batch: 56, Loss: 0.7705420255661011, Accuracy: 0.7470703125\n",
      "Batch: 57, Loss: 0.8568347692489624, Accuracy: 0.72412109375\n",
      "Batch: 58, Loss: 0.8120701313018799, Accuracy: 0.72607421875\n",
      "Batch: 59, Loss: 0.9115360975265503, Accuracy: 0.71484375\n",
      "Batch: 60, Loss: 0.8084416389465332, Accuracy: 0.74560546875\n",
      "Batch: 61, Loss: 0.7547633647918701, Accuracy: 0.75439453125\n",
      "Batch: 62, Loss: 0.7791323661804199, Accuracy: 0.76025390625\n",
      "Batch: 63, Loss: 0.7955561876296997, Accuracy: 0.734375\n",
      "Batch: 64, Loss: 0.8212796449661255, Accuracy: 0.73291015625\n",
      "Batch: 65, Loss: 0.8818068504333496, Accuracy: 0.72998046875\n",
      "Batch: 66, Loss: 0.8525835871696472, Accuracy: 0.73095703125\n",
      "Batch: 67, Loss: 0.8707681894302368, Accuracy: 0.71435546875\n",
      "Batch: 68, Loss: 0.7748194336891174, Accuracy: 0.744140625\n",
      "Batch: 69, Loss: 0.8305469751358032, Accuracy: 0.72265625\n",
      "Batch: 70, Loss: 0.8255643844604492, Accuracy: 0.72802734375\n",
      "Batch: 71, Loss: 0.8183019757270813, Accuracy: 0.74169921875\n",
      "Batch: 72, Loss: 0.8357264399528503, Accuracy: 0.72509765625\n",
      "Batch: 73, Loss: 0.8403096795082092, Accuracy: 0.7265625\n",
      "Batch: 74, Loss: 0.8612136840820312, Accuracy: 0.7236328125\n",
      "Batch: 75, Loss: 0.7753087282180786, Accuracy: 0.74609375\n",
      "Batch: 76, Loss: 0.7504456639289856, Accuracy: 0.765625\n",
      "Batch: 77, Loss: 0.7701049447059631, Accuracy: 0.76611328125\n",
      "Batch: 78, Loss: 0.7967748641967773, Accuracy: 0.74560546875\n",
      "Batch: 79, Loss: 0.8112469911575317, Accuracy: 0.74072265625\n",
      "Batch: 80, Loss: 0.8603948950767517, Accuracy: 0.71923828125\n",
      "Batch: 81, Loss: 0.8540113568305969, Accuracy: 0.7294921875\n",
      "Batch: 82, Loss: 0.7948381304740906, Accuracy: 0.7353515625\n",
      "Batch: 83, Loss: 0.7627309560775757, Accuracy: 0.76318359375\n",
      "Batch: 84, Loss: 0.7644089460372925, Accuracy: 0.759765625\n",
      "Batch: 85, Loss: 0.7809080481529236, Accuracy: 0.7509765625\n",
      "Batch: 86, Loss: 0.882087230682373, Accuracy: 0.73046875\n",
      "Batch: 87, Loss: 0.7699112892150879, Accuracy: 0.74755859375\n",
      "Batch: 88, Loss: 0.8416577577590942, Accuracy: 0.74560546875\n",
      "Batch: 89, Loss: 0.8258204460144043, Accuracy: 0.73681640625\n",
      "Batch: 90, Loss: 0.8876529932022095, Accuracy: 0.70703125\n",
      "Batch: 91, Loss: 0.7868760824203491, Accuracy: 0.7470703125\n",
      "Batch: 92, Loss: 0.9212356805801392, Accuracy: 0.69189453125\n",
      "Batch: 93, Loss: 0.8698092699050903, Accuracy: 0.7119140625\n",
      "Batch: 94, Loss: 0.854692816734314, Accuracy: 0.72021484375\n",
      "Batch: 95, Loss: 0.8785467743873596, Accuracy: 0.72509765625\n",
      "Batch: 96, Loss: 0.8118009567260742, Accuracy: 0.7392578125\n",
      "Batch: 97, Loss: 0.7922906875610352, Accuracy: 0.751953125\n",
      "Batch: 98, Loss: 0.8918776512145996, Accuracy: 0.7158203125\n",
      "Batch: 99, Loss: 0.799005389213562, Accuracy: 0.748046875\n",
      "Batch: 100, Loss: 0.9018258452415466, Accuracy: 0.71923828125\n",
      "Batch: 101, Loss: 0.9279811382293701, Accuracy: 0.7041015625\n",
      "Batch: 102, Loss: 0.7747554779052734, Accuracy: 0.74853515625\n",
      "Batch: 103, Loss: 0.8494899868965149, Accuracy: 0.73095703125\n",
      "Batch: 104, Loss: 0.8179045915603638, Accuracy: 0.73828125\n",
      "Batch: 105, Loss: 0.8513902425765991, Accuracy: 0.72900390625\n",
      "Batch: 106, Loss: 0.8039917349815369, Accuracy: 0.7421875\n",
      "Batch: 107, Loss: 0.8389869928359985, Accuracy: 0.7265625\n",
      "Batch: 108, Loss: 0.8009255528450012, Accuracy: 0.74462890625\n",
      "Batch: 109, Loss: 0.8128937482833862, Accuracy: 0.74560546875\n",
      "Batch: 110, Loss: 0.7958046197891235, Accuracy: 0.7353515625\n",
      "Batch: 111, Loss: 0.7389859557151794, Accuracy: 0.76220703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 112, Loss: 0.8018397688865662, Accuracy: 0.7451171875\n",
      "Batch: 113, Loss: 0.8461339473724365, Accuracy: 0.72900390625\n",
      "Batch: 114, Loss: 0.8232607245445251, Accuracy: 0.72607421875\n",
      "Batch: 115, Loss: 0.8094568252563477, Accuracy: 0.73779296875\n",
      "Batch: 116, Loss: 0.8156654834747314, Accuracy: 0.7333984375\n",
      "Batch: 117, Loss: 0.8158284425735474, Accuracy: 0.7392578125\n",
      "Batch: 118, Loss: 0.8240563273429871, Accuracy: 0.728515625\n",
      "Batch: 119, Loss: 0.8109849691390991, Accuracy: 0.732421875\n",
      "Batch: 120, Loss: 0.79752516746521, Accuracy: 0.7392578125\n",
      "Batch: 121, Loss: 0.8120306730270386, Accuracy: 0.73779296875\n",
      "Batch: 122, Loss: 0.7716286182403564, Accuracy: 0.75146484375\n",
      "Batch: 123, Loss: 0.769289493560791, Accuracy: 0.7646484375\n",
      "Batch: 124, Loss: 0.7742679119110107, Accuracy: 0.74853515625\n",
      "Batch: 125, Loss: 0.8158309459686279, Accuracy: 0.74072265625\n",
      "Batch: 126, Loss: 0.7700760364532471, Accuracy: 0.75830078125\n",
      "Batch: 127, Loss: 0.7466988563537598, Accuracy: 0.76171875\n",
      "Batch: 128, Loss: 0.8825801610946655, Accuracy: 0.71728515625\n",
      "Batch: 129, Loss: 0.9146886467933655, Accuracy: 0.7109375\n",
      "Batch: 130, Loss: 0.9066393375396729, Accuracy: 0.70458984375\n",
      "Batch: 131, Loss: 0.855660080909729, Accuracy: 0.73095703125\n",
      "Batch: 132, Loss: 0.7604590654373169, Accuracy: 0.75927734375\n",
      "Batch: 133, Loss: 0.7496646642684937, Accuracy: 0.76806640625\n",
      "Batch: 134, Loss: 0.8316729068756104, Accuracy: 0.73388671875\n",
      "Batch: 135, Loss: 0.8191115856170654, Accuracy: 0.7314453125\n",
      "Batch: 136, Loss: 0.7570958137512207, Accuracy: 0.7509765625\n",
      "Batch: 137, Loss: 0.8220251202583313, Accuracy: 0.7333984375\n",
      "Batch: 138, Loss: 0.7252193689346313, Accuracy: 0.7744140625\n",
      "Batch: 139, Loss: 0.7923492193222046, Accuracy: 0.74560546875\n",
      "Batch: 140, Loss: 0.738885760307312, Accuracy: 0.7587890625\n",
      "Batch: 141, Loss: 0.8671882152557373, Accuracy: 0.72021484375\n",
      "Batch: 142, Loss: 0.7554091215133667, Accuracy: 0.74072265625\n",
      "Batch: 143, Loss: 0.7798022627830505, Accuracy: 0.7568359375\n",
      "Batch: 144, Loss: 0.872448205947876, Accuracy: 0.7255859375\n",
      "Batch: 145, Loss: 0.8171385526657104, Accuracy: 0.74365234375\n",
      "Batch: 146, Loss: 0.8519498705863953, Accuracy: 0.71533203125\n",
      "Batch: 147, Loss: 0.8261495232582092, Accuracy: 0.73583984375\n",
      "Batch: 148, Loss: 0.857914924621582, Accuracy: 0.72314453125\n",
      "Batch: 149, Loss: 0.836955726146698, Accuracy: 0.7333984375\n",
      "Batch: 150, Loss: 0.711898148059845, Accuracy: 0.77783203125\n",
      "Batch: 151, Loss: 0.7171146869659424, Accuracy: 0.77294921875\n",
      "Batch: 152, Loss: 0.7495696544647217, Accuracy: 0.765625\n",
      "Batch: 153, Loss: 0.746151864528656, Accuracy: 0.76318359375\n",
      "Batch: 154, Loss: 0.747101366519928, Accuracy: 0.75439453125\n",
      "Batch: 155, Loss: 0.859099268913269, Accuracy: 0.7255859375\n",
      "Batch: 156, Loss: 0.7455624341964722, Accuracy: 0.755859375\n",
      "Batch: 157, Loss: 0.7270799875259399, Accuracy: 0.75927734375\n",
      "Batch: 158, Loss: 0.7224189043045044, Accuracy: 0.771484375\n",
      "Batch: 159, Loss: 0.7375884652137756, Accuracy: 0.7685546875\n",
      "Batch: 160, Loss: 0.7513583302497864, Accuracy: 0.755859375\n",
      "Batch: 161, Loss: 0.7924046516418457, Accuracy: 0.73828125\n",
      "Batch: 162, Loss: 0.74783855676651, Accuracy: 0.7578125\n",
      "Batch: 163, Loss: 0.8347432613372803, Accuracy: 0.728515625\n",
      "Batch: 164, Loss: 0.8832442760467529, Accuracy: 0.71435546875\n",
      "Batch: 165, Loss: 0.7981278896331787, Accuracy: 0.75537109375\n",
      "Batch: 166, Loss: 0.8055207133293152, Accuracy: 0.74560546875\n",
      "Batch: 167, Loss: 0.7748494148254395, Accuracy: 0.75244140625\n",
      "Batch: 168, Loss: 0.7223913669586182, Accuracy: 0.76708984375\n",
      "Batch: 169, Loss: 0.7731387615203857, Accuracy: 0.74951171875\n",
      "Batch: 170, Loss: 0.8540841341018677, Accuracy: 0.7255859375\n",
      "Batch: 171, Loss: 0.776183009147644, Accuracy: 0.7509765625\n",
      "Batch: 172, Loss: 0.7567688226699829, Accuracy: 0.75439453125\n",
      "Batch: 173, Loss: 0.8112103939056396, Accuracy: 0.73876953125\n",
      "Batch: 174, Loss: 0.6815507411956787, Accuracy: 0.78662109375\n",
      "Batch: 175, Loss: 0.8103660345077515, Accuracy: 0.7236328125\n",
      "Batch: 176, Loss: 0.8522956967353821, Accuracy: 0.7177734375\n",
      "Batch: 177, Loss: 0.7909858822822571, Accuracy: 0.75537109375\n",
      "Batch: 178, Loss: 0.7467465400695801, Accuracy: 0.7626953125\n",
      "Batch: 179, Loss: 0.782758891582489, Accuracy: 0.74951171875\n",
      "Batch: 180, Loss: 0.8457671403884888, Accuracy: 0.72998046875\n",
      "Epoch 37/200\n",
      "Batch: 1, Loss: 1.1657078266143799, Accuracy: 0.666015625\n",
      "Batch: 2, Loss: 0.8253383636474609, Accuracy: 0.71728515625\n",
      "Batch: 3, Loss: 0.8224847912788391, Accuracy: 0.740234375\n",
      "Batch: 4, Loss: 0.8405547142028809, Accuracy: 0.7236328125\n",
      "Batch: 5, Loss: 0.8302432298660278, Accuracy: 0.74365234375\n",
      "Batch: 6, Loss: 0.8205264806747437, Accuracy: 0.7333984375\n",
      "Batch: 7, Loss: 0.7675926685333252, Accuracy: 0.75\n",
      "Batch: 8, Loss: 0.807786762714386, Accuracy: 0.7353515625\n",
      "Batch: 9, Loss: 0.8667365908622742, Accuracy: 0.72705078125\n",
      "Batch: 10, Loss: 0.8083570599555969, Accuracy: 0.74169921875\n",
      "Batch: 11, Loss: 0.8465592265129089, Accuracy: 0.728515625\n",
      "Batch: 12, Loss: 0.7451517581939697, Accuracy: 0.76416015625\n",
      "Batch: 13, Loss: 0.8207270503044128, Accuracy: 0.734375\n",
      "Batch: 14, Loss: 0.7948734760284424, Accuracy: 0.75634765625\n",
      "Batch: 15, Loss: 0.8072256445884705, Accuracy: 0.7412109375\n",
      "Batch: 16, Loss: 0.8651729822158813, Accuracy: 0.72265625\n",
      "Batch: 17, Loss: 0.7750203013420105, Accuracy: 0.75390625\n",
      "Batch: 18, Loss: 0.8429837226867676, Accuracy: 0.734375\n",
      "Batch: 19, Loss: 0.8483405709266663, Accuracy: 0.7353515625\n",
      "Batch: 20, Loss: 0.7306416034698486, Accuracy: 0.7685546875\n",
      "Batch: 21, Loss: 0.9001632928848267, Accuracy: 0.71044921875\n",
      "Batch: 22, Loss: 0.7532261610031128, Accuracy: 0.75732421875\n",
      "Batch: 23, Loss: 0.7542590498924255, Accuracy: 0.75927734375\n",
      "Batch: 24, Loss: 0.778199315071106, Accuracy: 0.74853515625\n",
      "Batch: 25, Loss: 0.7523950338363647, Accuracy: 0.76904296875\n",
      "Batch: 26, Loss: 0.7886232137680054, Accuracy: 0.751953125\n",
      "Batch: 27, Loss: 0.832086443901062, Accuracy: 0.72802734375\n",
      "Batch: 28, Loss: 0.7739156484603882, Accuracy: 0.7529296875\n",
      "Batch: 29, Loss: 0.8721564412117004, Accuracy: 0.71240234375\n",
      "Batch: 30, Loss: 0.8195546269416809, Accuracy: 0.7470703125\n",
      "Batch: 31, Loss: 0.9406508207321167, Accuracy: 0.70068359375\n",
      "Batch: 32, Loss: 0.8296833038330078, Accuracy: 0.73583984375\n",
      "Batch: 33, Loss: 0.8658791780471802, Accuracy: 0.7099609375\n",
      "Batch: 34, Loss: 0.896316409111023, Accuracy: 0.7119140625\n",
      "Batch: 35, Loss: 0.9047931432723999, Accuracy: 0.7119140625\n",
      "Batch: 36, Loss: 0.8736770749092102, Accuracy: 0.72265625\n",
      "Batch: 37, Loss: 0.8643925189971924, Accuracy: 0.7177734375\n",
      "Batch: 38, Loss: 0.8937222361564636, Accuracy: 0.7119140625\n",
      "Batch: 39, Loss: 0.8358311653137207, Accuracy: 0.73876953125\n",
      "Batch: 40, Loss: 0.8932693004608154, Accuracy: 0.7158203125\n",
      "Batch: 41, Loss: 0.853796124458313, Accuracy: 0.71923828125\n",
      "Batch: 42, Loss: 0.8053588271141052, Accuracy: 0.72900390625\n",
      "Batch: 43, Loss: 0.7827573418617249, Accuracy: 0.74609375\n",
      "Batch: 44, Loss: 0.7334052920341492, Accuracy: 0.76611328125\n",
      "Batch: 45, Loss: 0.7755544185638428, Accuracy: 0.75537109375\n",
      "Batch: 46, Loss: 0.7514181137084961, Accuracy: 0.7373046875\n",
      "Batch: 47, Loss: 0.8194994330406189, Accuracy: 0.74072265625\n",
      "Batch: 48, Loss: 0.7819509506225586, Accuracy: 0.74609375\n",
      "Batch: 49, Loss: 0.79558265209198, Accuracy: 0.744140625\n",
      "Batch: 50, Loss: 0.799191951751709, Accuracy: 0.73388671875\n",
      "Batch: 51, Loss: 0.8071038722991943, Accuracy: 0.73828125\n",
      "Batch: 52, Loss: 0.7653409242630005, Accuracy: 0.74267578125\n",
      "Batch: 53, Loss: 0.7829612493515015, Accuracy: 0.73681640625\n",
      "Batch: 54, Loss: 0.8427154421806335, Accuracy: 0.712890625\n",
      "Batch: 55, Loss: 0.7768968343734741, Accuracy: 0.75048828125\n",
      "Batch: 56, Loss: 0.7629272937774658, Accuracy: 0.7529296875\n",
      "Batch: 57, Loss: 0.8623015880584717, Accuracy: 0.72216796875\n",
      "Batch: 58, Loss: 0.7963132858276367, Accuracy: 0.72802734375\n",
      "Batch: 59, Loss: 0.9108521938323975, Accuracy: 0.7158203125\n",
      "Batch: 60, Loss: 0.8004052639007568, Accuracy: 0.75146484375\n",
      "Batch: 61, Loss: 0.7422715425491333, Accuracy: 0.75927734375\n",
      "Batch: 62, Loss: 0.7936519384384155, Accuracy: 0.7529296875\n",
      "Batch: 63, Loss: 0.7804172039031982, Accuracy: 0.7412109375\n",
      "Batch: 64, Loss: 0.8294169902801514, Accuracy: 0.72705078125\n",
      "Batch: 65, Loss: 0.8813929557800293, Accuracy: 0.7314453125\n",
      "Batch: 66, Loss: 0.8274250626564026, Accuracy: 0.7333984375\n",
      "Batch: 67, Loss: 0.8621642589569092, Accuracy: 0.71875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 68, Loss: 0.7660294771194458, Accuracy: 0.74560546875\n",
      "Batch: 69, Loss: 0.8072347044944763, Accuracy: 0.73291015625\n",
      "Batch: 70, Loss: 0.8012322187423706, Accuracy: 0.748046875\n",
      "Batch: 71, Loss: 0.780434787273407, Accuracy: 0.74853515625\n",
      "Batch: 72, Loss: 0.829118549823761, Accuracy: 0.716796875\n",
      "Batch: 73, Loss: 0.8475942015647888, Accuracy: 0.72265625\n",
      "Batch: 74, Loss: 0.8484141230583191, Accuracy: 0.732421875\n",
      "Batch: 75, Loss: 0.7721981406211853, Accuracy: 0.732421875\n",
      "Batch: 76, Loss: 0.7484197020530701, Accuracy: 0.7666015625\n",
      "Batch: 77, Loss: 0.7696821093559265, Accuracy: 0.7509765625\n",
      "Batch: 78, Loss: 0.7911451458930969, Accuracy: 0.75341796875\n",
      "Batch: 79, Loss: 0.8205022215843201, Accuracy: 0.73681640625\n",
      "Batch: 80, Loss: 0.8169376850128174, Accuracy: 0.73291015625\n",
      "Batch: 81, Loss: 0.8306909799575806, Accuracy: 0.74169921875\n",
      "Batch: 82, Loss: 0.7671868205070496, Accuracy: 0.73779296875\n",
      "Batch: 83, Loss: 0.7492525577545166, Accuracy: 0.75244140625\n",
      "Batch: 84, Loss: 0.7538820505142212, Accuracy: 0.76318359375\n",
      "Batch: 85, Loss: 0.7779794335365295, Accuracy: 0.7431640625\n",
      "Batch: 86, Loss: 0.8568200469017029, Accuracy: 0.72705078125\n",
      "Batch: 87, Loss: 0.7568801045417786, Accuracy: 0.7509765625\n",
      "Batch: 88, Loss: 0.8332113027572632, Accuracy: 0.7373046875\n",
      "Batch: 89, Loss: 0.8102455139160156, Accuracy: 0.732421875\n",
      "Batch: 90, Loss: 0.857896089553833, Accuracy: 0.7138671875\n",
      "Batch: 91, Loss: 0.7825023531913757, Accuracy: 0.748046875\n",
      "Batch: 92, Loss: 0.9242885708808899, Accuracy: 0.69921875\n",
      "Batch: 93, Loss: 0.860468864440918, Accuracy: 0.72412109375\n",
      "Batch: 94, Loss: 0.8479503393173218, Accuracy: 0.73193359375\n",
      "Batch: 95, Loss: 0.8794618844985962, Accuracy: 0.71728515625\n",
      "Batch: 96, Loss: 0.816368818283081, Accuracy: 0.740234375\n",
      "Batch: 97, Loss: 0.7958561182022095, Accuracy: 0.75244140625\n",
      "Batch: 98, Loss: 0.8813111782073975, Accuracy: 0.724609375\n",
      "Batch: 99, Loss: 0.8032176494598389, Accuracy: 0.75244140625\n",
      "Batch: 100, Loss: 0.9060924053192139, Accuracy: 0.71142578125\n",
      "Batch: 101, Loss: 0.8954229950904846, Accuracy: 0.7158203125\n",
      "Batch: 102, Loss: 0.8101204633712769, Accuracy: 0.74853515625\n",
      "Batch: 103, Loss: 0.8439205288887024, Accuracy: 0.728515625\n",
      "Batch: 104, Loss: 0.8342544436454773, Accuracy: 0.7255859375\n",
      "Batch: 105, Loss: 0.8635419607162476, Accuracy: 0.7197265625\n",
      "Batch: 106, Loss: 0.8096427917480469, Accuracy: 0.73291015625\n",
      "Batch: 107, Loss: 0.8409650325775146, Accuracy: 0.73388671875\n",
      "Batch: 108, Loss: 0.807390570640564, Accuracy: 0.73095703125\n",
      "Batch: 109, Loss: 0.8235347270965576, Accuracy: 0.7373046875\n",
      "Batch: 110, Loss: 0.7920612692832947, Accuracy: 0.73828125\n",
      "Batch: 111, Loss: 0.7306898832321167, Accuracy: 0.7587890625\n",
      "Batch: 112, Loss: 0.8157202005386353, Accuracy: 0.74462890625\n",
      "Batch: 113, Loss: 0.8416478633880615, Accuracy: 0.732421875\n",
      "Batch: 114, Loss: 0.8156587481498718, Accuracy: 0.7373046875\n",
      "Batch: 115, Loss: 0.8282983303070068, Accuracy: 0.73779296875\n",
      "Batch: 116, Loss: 0.8064030408859253, Accuracy: 0.74072265625\n",
      "Batch: 117, Loss: 0.8052719235420227, Accuracy: 0.73828125\n",
      "Batch: 118, Loss: 0.8132152557373047, Accuracy: 0.7392578125\n",
      "Batch: 119, Loss: 0.803118109703064, Accuracy: 0.7392578125\n",
      "Batch: 120, Loss: 0.7757604122161865, Accuracy: 0.7470703125\n",
      "Batch: 121, Loss: 0.7893576622009277, Accuracy: 0.74169921875\n",
      "Batch: 122, Loss: 0.7560414671897888, Accuracy: 0.75048828125\n",
      "Batch: 123, Loss: 0.7663930058479309, Accuracy: 0.759765625\n",
      "Batch: 124, Loss: 0.7516376972198486, Accuracy: 0.75439453125\n",
      "Batch: 125, Loss: 0.8157656192779541, Accuracy: 0.736328125\n",
      "Batch: 126, Loss: 0.7664581537246704, Accuracy: 0.7470703125\n",
      "Batch: 127, Loss: 0.7368685007095337, Accuracy: 0.76171875\n",
      "Batch: 128, Loss: 0.8954549431800842, Accuracy: 0.72216796875\n",
      "Batch: 129, Loss: 0.9206653237342834, Accuracy: 0.70556640625\n",
      "Batch: 130, Loss: 0.8964184522628784, Accuracy: 0.7197265625\n",
      "Batch: 131, Loss: 0.8352161645889282, Accuracy: 0.73388671875\n",
      "Batch: 132, Loss: 0.7523685693740845, Accuracy: 0.759765625\n",
      "Batch: 133, Loss: 0.760529637336731, Accuracy: 0.76513671875\n",
      "Batch: 134, Loss: 0.8500335216522217, Accuracy: 0.7197265625\n",
      "Batch: 135, Loss: 0.8195256590843201, Accuracy: 0.73291015625\n",
      "Batch: 136, Loss: 0.744027853012085, Accuracy: 0.74951171875\n",
      "Batch: 137, Loss: 0.8079644441604614, Accuracy: 0.73681640625\n",
      "Batch: 138, Loss: 0.7156187891960144, Accuracy: 0.78955078125\n",
      "Batch: 139, Loss: 0.7925697565078735, Accuracy: 0.74609375\n",
      "Batch: 140, Loss: 0.7354930639266968, Accuracy: 0.765625\n",
      "Batch: 141, Loss: 0.8452826142311096, Accuracy: 0.72705078125\n",
      "Batch: 142, Loss: 0.7659865617752075, Accuracy: 0.7451171875\n",
      "Batch: 143, Loss: 0.7689551711082458, Accuracy: 0.748046875\n",
      "Batch: 144, Loss: 0.850252091884613, Accuracy: 0.72802734375\n",
      "Batch: 145, Loss: 0.8166545629501343, Accuracy: 0.74169921875\n",
      "Batch: 146, Loss: 0.8532676696777344, Accuracy: 0.72607421875\n",
      "Batch: 147, Loss: 0.8089487552642822, Accuracy: 0.7431640625\n",
      "Batch: 148, Loss: 0.8559477925300598, Accuracy: 0.72265625\n",
      "Batch: 149, Loss: 0.8274946808815002, Accuracy: 0.72900390625\n",
      "Batch: 150, Loss: 0.7052263021469116, Accuracy: 0.77783203125\n",
      "Batch: 151, Loss: 0.7261475324630737, Accuracy: 0.76220703125\n",
      "Batch: 152, Loss: 0.7425780892372131, Accuracy: 0.75146484375\n",
      "Batch: 153, Loss: 0.745890200138092, Accuracy: 0.7626953125\n",
      "Batch: 154, Loss: 0.747409462928772, Accuracy: 0.7490234375\n",
      "Batch: 155, Loss: 0.8371931314468384, Accuracy: 0.7333984375\n",
      "Batch: 156, Loss: 0.7300821542739868, Accuracy: 0.76904296875\n",
      "Batch: 157, Loss: 0.7157434821128845, Accuracy: 0.76025390625\n",
      "Batch: 158, Loss: 0.71067214012146, Accuracy: 0.77783203125\n",
      "Batch: 159, Loss: 0.727148711681366, Accuracy: 0.767578125\n",
      "Batch: 160, Loss: 0.754133403301239, Accuracy: 0.74609375\n",
      "Batch: 161, Loss: 0.7820521593093872, Accuracy: 0.7451171875\n",
      "Batch: 162, Loss: 0.7522304654121399, Accuracy: 0.75732421875\n",
      "Batch: 163, Loss: 0.8167248964309692, Accuracy: 0.74609375\n",
      "Batch: 164, Loss: 0.8692291975021362, Accuracy: 0.7138671875\n",
      "Batch: 165, Loss: 0.7874869108200073, Accuracy: 0.74951171875\n",
      "Batch: 166, Loss: 0.8076810240745544, Accuracy: 0.74951171875\n",
      "Batch: 167, Loss: 0.7795950174331665, Accuracy: 0.75\n",
      "Batch: 168, Loss: 0.7212120294570923, Accuracy: 0.77392578125\n",
      "Batch: 169, Loss: 0.7685474157333374, Accuracy: 0.7548828125\n",
      "Batch: 170, Loss: 0.8335036039352417, Accuracy: 0.740234375\n",
      "Batch: 171, Loss: 0.7571380734443665, Accuracy: 0.759765625\n",
      "Batch: 172, Loss: 0.7554545402526855, Accuracy: 0.75146484375\n",
      "Batch: 173, Loss: 0.8244754672050476, Accuracy: 0.744140625\n",
      "Batch: 174, Loss: 0.6744799613952637, Accuracy: 0.7802734375\n",
      "Batch: 175, Loss: 0.7941614389419556, Accuracy: 0.73486328125\n",
      "Batch: 176, Loss: 0.8346124887466431, Accuracy: 0.748046875\n",
      "Batch: 177, Loss: 0.7790676951408386, Accuracy: 0.74853515625\n",
      "Batch: 178, Loss: 0.73829585313797, Accuracy: 0.7607421875\n",
      "Batch: 179, Loss: 0.7800505757331848, Accuracy: 0.7529296875\n",
      "Batch: 180, Loss: 0.8272690773010254, Accuracy: 0.73828125\n",
      "Epoch 38/200\n",
      "Batch: 1, Loss: 1.1329455375671387, Accuracy: 0.67724609375\n",
      "Batch: 2, Loss: 0.802725076675415, Accuracy: 0.7236328125\n",
      "Batch: 3, Loss: 0.7899013757705688, Accuracy: 0.7431640625\n",
      "Batch: 4, Loss: 0.8270246982574463, Accuracy: 0.72900390625\n",
      "Batch: 5, Loss: 0.8163105249404907, Accuracy: 0.73974609375\n",
      "Batch: 6, Loss: 0.8152844905853271, Accuracy: 0.7392578125\n",
      "Batch: 7, Loss: 0.7521697282791138, Accuracy: 0.75390625\n",
      "Batch: 8, Loss: 0.8063359260559082, Accuracy: 0.7353515625\n",
      "Batch: 9, Loss: 0.8505038619041443, Accuracy: 0.74365234375\n",
      "Batch: 10, Loss: 0.7939685583114624, Accuracy: 0.75146484375\n",
      "Batch: 11, Loss: 0.8401684761047363, Accuracy: 0.72998046875\n",
      "Batch: 12, Loss: 0.7568432688713074, Accuracy: 0.75830078125\n",
      "Batch: 13, Loss: 0.8125855922698975, Accuracy: 0.734375\n",
      "Batch: 14, Loss: 0.7781180739402771, Accuracy: 0.75927734375\n",
      "Batch: 15, Loss: 0.8009161949157715, Accuracy: 0.74853515625\n",
      "Batch: 16, Loss: 0.8350238800048828, Accuracy: 0.7255859375\n",
      "Batch: 17, Loss: 0.7716277837753296, Accuracy: 0.7529296875\n",
      "Batch: 18, Loss: 0.8445725440979004, Accuracy: 0.7314453125\n",
      "Batch: 19, Loss: 0.8367078304290771, Accuracy: 0.73046875\n",
      "Batch: 20, Loss: 0.7230571508407593, Accuracy: 0.7685546875\n",
      "Batch: 21, Loss: 0.8783657550811768, Accuracy: 0.72265625\n",
      "Batch: 22, Loss: 0.7642743587493896, Accuracy: 0.75390625\n",
      "Batch: 23, Loss: 0.7703441977500916, Accuracy: 0.7548828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 24, Loss: 0.7783691883087158, Accuracy: 0.7529296875\n",
      "Batch: 25, Loss: 0.7540953755378723, Accuracy: 0.7646484375\n",
      "Batch: 26, Loss: 0.7732203602790833, Accuracy: 0.7548828125\n",
      "Batch: 27, Loss: 0.834166407585144, Accuracy: 0.72705078125\n",
      "Batch: 28, Loss: 0.7855889797210693, Accuracy: 0.74609375\n",
      "Batch: 29, Loss: 0.8358876705169678, Accuracy: 0.73046875\n",
      "Batch: 30, Loss: 0.8037785291671753, Accuracy: 0.7490234375\n",
      "Batch: 31, Loss: 0.916429340839386, Accuracy: 0.71044921875\n",
      "Batch: 32, Loss: 0.8266968727111816, Accuracy: 0.7353515625\n",
      "Batch: 33, Loss: 0.8495901226997375, Accuracy: 0.7265625\n",
      "Batch: 34, Loss: 0.8805902004241943, Accuracy: 0.71435546875\n",
      "Batch: 35, Loss: 0.8742695450782776, Accuracy: 0.7177734375\n",
      "Batch: 36, Loss: 0.8635482788085938, Accuracy: 0.728515625\n",
      "Batch: 37, Loss: 0.8657916188240051, Accuracy: 0.7265625\n",
      "Batch: 38, Loss: 0.877028226852417, Accuracy: 0.71630859375\n",
      "Batch: 39, Loss: 0.8205949068069458, Accuracy: 0.732421875\n",
      "Batch: 40, Loss: 0.8753058910369873, Accuracy: 0.72412109375\n",
      "Batch: 41, Loss: 0.8313803672790527, Accuracy: 0.728515625\n",
      "Batch: 42, Loss: 0.8121351599693298, Accuracy: 0.7294921875\n",
      "Batch: 43, Loss: 0.7698313593864441, Accuracy: 0.75390625\n",
      "Batch: 44, Loss: 0.7071713209152222, Accuracy: 0.77490234375\n",
      "Batch: 45, Loss: 0.7766768336296082, Accuracy: 0.75830078125\n",
      "Batch: 46, Loss: 0.7458587288856506, Accuracy: 0.74755859375\n",
      "Batch: 47, Loss: 0.8137902021408081, Accuracy: 0.74658203125\n",
      "Batch: 48, Loss: 0.7725306153297424, Accuracy: 0.75439453125\n",
      "Batch: 49, Loss: 0.7682523131370544, Accuracy: 0.75390625\n",
      "Batch: 50, Loss: 0.8105750679969788, Accuracy: 0.7392578125\n",
      "Batch: 51, Loss: 0.7842038869857788, Accuracy: 0.74560546875\n",
      "Batch: 52, Loss: 0.7511165738105774, Accuracy: 0.75439453125\n",
      "Batch: 53, Loss: 0.7620493173599243, Accuracy: 0.7490234375\n",
      "Batch: 54, Loss: 0.8193470239639282, Accuracy: 0.7275390625\n",
      "Batch: 55, Loss: 0.7652513980865479, Accuracy: 0.748046875\n",
      "Batch: 56, Loss: 0.7665531039237976, Accuracy: 0.75341796875\n",
      "Batch: 57, Loss: 0.8422666788101196, Accuracy: 0.73388671875\n",
      "Batch: 58, Loss: 0.7965325117111206, Accuracy: 0.73291015625\n",
      "Batch: 59, Loss: 0.906792938709259, Accuracy: 0.7177734375\n",
      "Batch: 60, Loss: 0.8043522834777832, Accuracy: 0.7451171875\n",
      "Batch: 61, Loss: 0.7452647089958191, Accuracy: 0.7578125\n",
      "Batch: 62, Loss: 0.7600418925285339, Accuracy: 0.76171875\n",
      "Batch: 63, Loss: 0.7760183811187744, Accuracy: 0.74365234375\n",
      "Batch: 64, Loss: 0.8068917393684387, Accuracy: 0.73291015625\n",
      "Batch: 65, Loss: 0.8503748178482056, Accuracy: 0.73876953125\n",
      "Batch: 66, Loss: 0.836902379989624, Accuracy: 0.72998046875\n",
      "Batch: 67, Loss: 0.8425527811050415, Accuracy: 0.7265625\n",
      "Batch: 68, Loss: 0.7714669704437256, Accuracy: 0.7392578125\n",
      "Batch: 69, Loss: 0.8094844222068787, Accuracy: 0.7392578125\n",
      "Batch: 70, Loss: 0.7976794242858887, Accuracy: 0.7275390625\n",
      "Batch: 71, Loss: 0.8009468913078308, Accuracy: 0.73828125\n",
      "Batch: 72, Loss: 0.8205980062484741, Accuracy: 0.7236328125\n",
      "Batch: 73, Loss: 0.8354921936988831, Accuracy: 0.72802734375\n",
      "Batch: 74, Loss: 0.8315290212631226, Accuracy: 0.73486328125\n",
      "Batch: 75, Loss: 0.7429748177528381, Accuracy: 0.7568359375\n",
      "Batch: 76, Loss: 0.7333967685699463, Accuracy: 0.7587890625\n",
      "Batch: 77, Loss: 0.7528290748596191, Accuracy: 0.765625\n",
      "Batch: 78, Loss: 0.7909911274909973, Accuracy: 0.7470703125\n",
      "Batch: 79, Loss: 0.7927894592285156, Accuracy: 0.74462890625\n",
      "Batch: 80, Loss: 0.8126616477966309, Accuracy: 0.7314453125\n",
      "Batch: 81, Loss: 0.8226157426834106, Accuracy: 0.74462890625\n",
      "Batch: 82, Loss: 0.7825227379798889, Accuracy: 0.7451171875\n",
      "Batch: 83, Loss: 0.730816662311554, Accuracy: 0.7568359375\n",
      "Batch: 84, Loss: 0.7476190328598022, Accuracy: 0.76708984375\n",
      "Batch: 85, Loss: 0.768044114112854, Accuracy: 0.74951171875\n",
      "Batch: 86, Loss: 0.8612366914749146, Accuracy: 0.73193359375\n",
      "Batch: 87, Loss: 0.7684599161148071, Accuracy: 0.7529296875\n",
      "Batch: 88, Loss: 0.8178592324256897, Accuracy: 0.75048828125\n",
      "Batch: 89, Loss: 0.7882117033004761, Accuracy: 0.7451171875\n",
      "Batch: 90, Loss: 0.8690112829208374, Accuracy: 0.7158203125\n",
      "Batch: 91, Loss: 0.7636380195617676, Accuracy: 0.75439453125\n",
      "Batch: 92, Loss: 0.8799852132797241, Accuracy: 0.712890625\n",
      "Batch: 93, Loss: 0.8558131456375122, Accuracy: 0.72021484375\n",
      "Batch: 94, Loss: 0.8449897766113281, Accuracy: 0.7255859375\n",
      "Batch: 95, Loss: 0.8691336512565613, Accuracy: 0.7294921875\n",
      "Batch: 96, Loss: 0.7932006120681763, Accuracy: 0.7431640625\n",
      "Batch: 97, Loss: 0.7759343981742859, Accuracy: 0.75927734375\n",
      "Batch: 98, Loss: 0.8712618947029114, Accuracy: 0.7265625\n",
      "Batch: 99, Loss: 0.7754935026168823, Accuracy: 0.7529296875\n",
      "Batch: 100, Loss: 0.8729114532470703, Accuracy: 0.71923828125\n",
      "Batch: 101, Loss: 0.8964381814002991, Accuracy: 0.71337890625\n",
      "Batch: 102, Loss: 0.7823045253753662, Accuracy: 0.74169921875\n",
      "Batch: 103, Loss: 0.8294791579246521, Accuracy: 0.72509765625\n",
      "Batch: 104, Loss: 0.8252558708190918, Accuracy: 0.73828125\n",
      "Batch: 105, Loss: 0.8376606702804565, Accuracy: 0.7265625\n",
      "Batch: 106, Loss: 0.799201488494873, Accuracy: 0.74951171875\n",
      "Batch: 107, Loss: 0.8268274068832397, Accuracy: 0.73583984375\n",
      "Batch: 108, Loss: 0.800057590007782, Accuracy: 0.74365234375\n",
      "Batch: 109, Loss: 0.8114403486251831, Accuracy: 0.73583984375\n",
      "Batch: 110, Loss: 0.7661659121513367, Accuracy: 0.755859375\n",
      "Batch: 111, Loss: 0.7311401963233948, Accuracy: 0.76708984375\n",
      "Batch: 112, Loss: 0.7820143103599548, Accuracy: 0.76025390625\n",
      "Batch: 113, Loss: 0.8189164400100708, Accuracy: 0.72802734375\n",
      "Batch: 114, Loss: 0.8000507354736328, Accuracy: 0.73974609375\n",
      "Batch: 115, Loss: 0.7889351844787598, Accuracy: 0.765625\n",
      "Batch: 116, Loss: 0.8021028637886047, Accuracy: 0.74072265625\n",
      "Batch: 117, Loss: 0.7946770191192627, Accuracy: 0.74365234375\n",
      "Batch: 118, Loss: 0.8216903805732727, Accuracy: 0.73291015625\n",
      "Batch: 119, Loss: 0.7981871366500854, Accuracy: 0.73095703125\n",
      "Batch: 120, Loss: 0.784748375415802, Accuracy: 0.73974609375\n",
      "Batch: 121, Loss: 0.7958194017410278, Accuracy: 0.74560546875\n",
      "Batch: 122, Loss: 0.7500810623168945, Accuracy: 0.76318359375\n",
      "Batch: 123, Loss: 0.7658622860908508, Accuracy: 0.7646484375\n",
      "Batch: 124, Loss: 0.7631354331970215, Accuracy: 0.74951171875\n",
      "Batch: 125, Loss: 0.7996816635131836, Accuracy: 0.740234375\n",
      "Batch: 126, Loss: 0.7580885291099548, Accuracy: 0.74755859375\n",
      "Batch: 127, Loss: 0.7317948341369629, Accuracy: 0.76708984375\n",
      "Batch: 128, Loss: 0.878422200679779, Accuracy: 0.72265625\n",
      "Batch: 129, Loss: 0.9023649096488953, Accuracy: 0.712890625\n",
      "Batch: 130, Loss: 0.8787859082221985, Accuracy: 0.7255859375\n",
      "Batch: 131, Loss: 0.83229660987854, Accuracy: 0.73046875\n",
      "Batch: 132, Loss: 0.7551392912864685, Accuracy: 0.7578125\n",
      "Batch: 133, Loss: 0.7384248971939087, Accuracy: 0.76953125\n",
      "Batch: 134, Loss: 0.8156396150588989, Accuracy: 0.7294921875\n",
      "Batch: 135, Loss: 0.8061288595199585, Accuracy: 0.744140625\n",
      "Batch: 136, Loss: 0.7553607225418091, Accuracy: 0.75048828125\n",
      "Batch: 137, Loss: 0.8134228587150574, Accuracy: 0.7421875\n",
      "Batch: 138, Loss: 0.7163745164871216, Accuracy: 0.7841796875\n",
      "Batch: 139, Loss: 0.7672082185745239, Accuracy: 0.755859375\n",
      "Batch: 140, Loss: 0.7301584482192993, Accuracy: 0.76220703125\n",
      "Batch: 141, Loss: 0.8450202941894531, Accuracy: 0.7236328125\n",
      "Batch: 142, Loss: 0.7451866269111633, Accuracy: 0.7578125\n",
      "Batch: 143, Loss: 0.7644866704940796, Accuracy: 0.75927734375\n",
      "Batch: 144, Loss: 0.860188364982605, Accuracy: 0.72314453125\n",
      "Batch: 145, Loss: 0.7943313121795654, Accuracy: 0.7451171875\n",
      "Batch: 146, Loss: 0.8440683484077454, Accuracy: 0.7236328125\n",
      "Batch: 147, Loss: 0.8094147443771362, Accuracy: 0.74169921875\n",
      "Batch: 148, Loss: 0.824785053730011, Accuracy: 0.73046875\n",
      "Batch: 149, Loss: 0.8152637481689453, Accuracy: 0.73583984375\n",
      "Batch: 150, Loss: 0.7124178409576416, Accuracy: 0.77099609375\n",
      "Batch: 151, Loss: 0.7083216905593872, Accuracy: 0.76806640625\n",
      "Batch: 152, Loss: 0.7588526010513306, Accuracy: 0.7548828125\n",
      "Batch: 153, Loss: 0.7413222789764404, Accuracy: 0.75927734375\n",
      "Batch: 154, Loss: 0.7440053224563599, Accuracy: 0.75341796875\n",
      "Batch: 155, Loss: 0.8344986438751221, Accuracy: 0.732421875\n",
      "Batch: 156, Loss: 0.715330958366394, Accuracy: 0.75927734375\n",
      "Batch: 157, Loss: 0.716392993927002, Accuracy: 0.75048828125\n",
      "Batch: 158, Loss: 0.7008944749832153, Accuracy: 0.7783203125\n",
      "Batch: 159, Loss: 0.7137495279312134, Accuracy: 0.76611328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 160, Loss: 0.7464348077774048, Accuracy: 0.75927734375\n",
      "Batch: 161, Loss: 0.7790177464485168, Accuracy: 0.74658203125\n",
      "Batch: 162, Loss: 0.7258516550064087, Accuracy: 0.76220703125\n",
      "Batch: 163, Loss: 0.8171097040176392, Accuracy: 0.7265625\n",
      "Batch: 164, Loss: 0.8635408282279968, Accuracy: 0.72998046875\n",
      "Batch: 165, Loss: 0.7792121171951294, Accuracy: 0.75732421875\n",
      "Batch: 166, Loss: 0.7861509919166565, Accuracy: 0.74951171875\n",
      "Batch: 167, Loss: 0.7682737112045288, Accuracy: 0.75439453125\n",
      "Batch: 168, Loss: 0.6996620893478394, Accuracy: 0.77685546875\n",
      "Batch: 169, Loss: 0.7639480233192444, Accuracy: 0.7412109375\n",
      "Batch: 170, Loss: 0.8088738918304443, Accuracy: 0.7353515625\n",
      "Batch: 171, Loss: 0.757061243057251, Accuracy: 0.767578125\n",
      "Batch: 172, Loss: 0.7492251396179199, Accuracy: 0.7509765625\n",
      "Batch: 173, Loss: 0.8142359256744385, Accuracy: 0.74853515625\n",
      "Batch: 174, Loss: 0.6850026249885559, Accuracy: 0.77685546875\n",
      "Batch: 175, Loss: 0.8000391125679016, Accuracy: 0.73974609375\n",
      "Batch: 176, Loss: 0.8257151246070862, Accuracy: 0.7265625\n",
      "Batch: 177, Loss: 0.7639755010604858, Accuracy: 0.75048828125\n",
      "Batch: 178, Loss: 0.7447406649589539, Accuracy: 0.76416015625\n",
      "Batch: 179, Loss: 0.7639610767364502, Accuracy: 0.755859375\n",
      "Batch: 180, Loss: 0.8315554857254028, Accuracy: 0.73388671875\n",
      "Epoch 39/200\n",
      "Batch: 1, Loss: 1.1589531898498535, Accuracy: 0.68115234375\n",
      "Batch: 2, Loss: 0.8060808181762695, Accuracy: 0.728515625\n",
      "Batch: 3, Loss: 0.7816458940505981, Accuracy: 0.75146484375\n",
      "Batch: 4, Loss: 0.8244317770004272, Accuracy: 0.7236328125\n",
      "Batch: 5, Loss: 0.7999346256256104, Accuracy: 0.74365234375\n",
      "Batch: 6, Loss: 0.8170208930969238, Accuracy: 0.73583984375\n",
      "Batch: 7, Loss: 0.7623543739318848, Accuracy: 0.755859375\n",
      "Batch: 8, Loss: 0.7984902858734131, Accuracy: 0.7373046875\n",
      "Batch: 9, Loss: 0.8480767607688904, Accuracy: 0.73291015625\n",
      "Batch: 10, Loss: 0.7735096216201782, Accuracy: 0.75244140625\n",
      "Batch: 11, Loss: 0.8409073352813721, Accuracy: 0.732421875\n",
      "Batch: 12, Loss: 0.7307032346725464, Accuracy: 0.76513671875\n",
      "Batch: 13, Loss: 0.7980208396911621, Accuracy: 0.7470703125\n",
      "Batch: 14, Loss: 0.7759841680526733, Accuracy: 0.7578125\n",
      "Batch: 15, Loss: 0.7895976305007935, Accuracy: 0.75244140625\n",
      "Batch: 16, Loss: 0.8485044240951538, Accuracy: 0.72998046875\n",
      "Batch: 17, Loss: 0.7604022026062012, Accuracy: 0.7646484375\n",
      "Batch: 18, Loss: 0.8340352773666382, Accuracy: 0.7353515625\n",
      "Batch: 19, Loss: 0.8203238844871521, Accuracy: 0.74365234375\n",
      "Batch: 20, Loss: 0.7041639685630798, Accuracy: 0.7763671875\n",
      "Batch: 21, Loss: 0.8709319829940796, Accuracy: 0.73193359375\n",
      "Batch: 22, Loss: 0.7423450350761414, Accuracy: 0.75390625\n",
      "Batch: 23, Loss: 0.7375936508178711, Accuracy: 0.763671875\n",
      "Batch: 24, Loss: 0.7714961767196655, Accuracy: 0.75244140625\n",
      "Batch: 25, Loss: 0.749047040939331, Accuracy: 0.767578125\n",
      "Batch: 26, Loss: 0.7552332282066345, Accuracy: 0.75537109375\n",
      "Batch: 27, Loss: 0.80207359790802, Accuracy: 0.73583984375\n",
      "Batch: 28, Loss: 0.7673740386962891, Accuracy: 0.75244140625\n",
      "Batch: 29, Loss: 0.8475114703178406, Accuracy: 0.736328125\n",
      "Batch: 30, Loss: 0.7916557192802429, Accuracy: 0.7470703125\n",
      "Batch: 31, Loss: 0.911302387714386, Accuracy: 0.71044921875\n",
      "Batch: 32, Loss: 0.8173060417175293, Accuracy: 0.732421875\n",
      "Batch: 33, Loss: 0.8394511342048645, Accuracy: 0.72509765625\n",
      "Batch: 34, Loss: 0.8573951721191406, Accuracy: 0.7294921875\n",
      "Batch: 35, Loss: 0.8731069564819336, Accuracy: 0.716796875\n",
      "Batch: 36, Loss: 0.8483269214630127, Accuracy: 0.72998046875\n",
      "Batch: 37, Loss: 0.8479623794555664, Accuracy: 0.73095703125\n",
      "Batch: 38, Loss: 0.8560096025466919, Accuracy: 0.71875\n",
      "Batch: 39, Loss: 0.830664873123169, Accuracy: 0.732421875\n",
      "Batch: 40, Loss: 0.8538756370544434, Accuracy: 0.73583984375\n",
      "Batch: 41, Loss: 0.8540025949478149, Accuracy: 0.72021484375\n",
      "Batch: 42, Loss: 0.8008620142936707, Accuracy: 0.72802734375\n",
      "Batch: 43, Loss: 0.764624297618866, Accuracy: 0.75537109375\n",
      "Batch: 44, Loss: 0.7047024369239807, Accuracy: 0.767578125\n",
      "Batch: 45, Loss: 0.7596924304962158, Accuracy: 0.75390625\n",
      "Batch: 46, Loss: 0.7447310090065002, Accuracy: 0.74951171875\n",
      "Batch: 47, Loss: 0.8019542694091797, Accuracy: 0.7431640625\n",
      "Batch: 48, Loss: 0.7684025764465332, Accuracy: 0.75390625\n",
      "Batch: 49, Loss: 0.7687183618545532, Accuracy: 0.75439453125\n",
      "Batch: 50, Loss: 0.7980177402496338, Accuracy: 0.73681640625\n",
      "Batch: 51, Loss: 0.7753317356109619, Accuracy: 0.75048828125\n",
      "Batch: 52, Loss: 0.7409892082214355, Accuracy: 0.75634765625\n",
      "Batch: 53, Loss: 0.7658171057701111, Accuracy: 0.74560546875\n",
      "Batch: 54, Loss: 0.7925984859466553, Accuracy: 0.73779296875\n",
      "Batch: 55, Loss: 0.7626450657844543, Accuracy: 0.75634765625\n",
      "Batch: 56, Loss: 0.7604823708534241, Accuracy: 0.74609375\n",
      "Batch: 57, Loss: 0.8273928165435791, Accuracy: 0.74365234375\n",
      "Batch: 58, Loss: 0.8040586113929749, Accuracy: 0.728515625\n",
      "Batch: 59, Loss: 0.886760950088501, Accuracy: 0.72119140625\n",
      "Batch: 60, Loss: 0.7949119806289673, Accuracy: 0.74365234375\n",
      "Batch: 61, Loss: 0.7263567447662354, Accuracy: 0.765625\n",
      "Batch: 62, Loss: 0.7637938261032104, Accuracy: 0.759765625\n",
      "Batch: 63, Loss: 0.7879826426506042, Accuracy: 0.7333984375\n",
      "Batch: 64, Loss: 0.8285988569259644, Accuracy: 0.73486328125\n",
      "Batch: 65, Loss: 0.8429400324821472, Accuracy: 0.72998046875\n",
      "Batch: 66, Loss: 0.8237179517745972, Accuracy: 0.74072265625\n",
      "Batch: 67, Loss: 0.847316324710846, Accuracy: 0.728515625\n",
      "Batch: 68, Loss: 0.7469087243080139, Accuracy: 0.75634765625\n",
      "Batch: 69, Loss: 0.8022987842559814, Accuracy: 0.732421875\n",
      "Batch: 70, Loss: 0.7697550058364868, Accuracy: 0.74072265625\n",
      "Batch: 71, Loss: 0.7900282144546509, Accuracy: 0.74169921875\n",
      "Batch: 72, Loss: 0.8028308153152466, Accuracy: 0.72705078125\n",
      "Batch: 73, Loss: 0.8208281397819519, Accuracy: 0.72900390625\n",
      "Batch: 74, Loss: 0.8245800137519836, Accuracy: 0.736328125\n",
      "Batch: 75, Loss: 0.7514340281486511, Accuracy: 0.7509765625\n",
      "Batch: 76, Loss: 0.7251031994819641, Accuracy: 0.77294921875\n",
      "Batch: 77, Loss: 0.7440086007118225, Accuracy: 0.76806640625\n",
      "Batch: 78, Loss: 0.75980544090271, Accuracy: 0.76025390625\n",
      "Batch: 79, Loss: 0.7913510203361511, Accuracy: 0.7373046875\n",
      "Batch: 80, Loss: 0.8002660274505615, Accuracy: 0.73876953125\n",
      "Batch: 81, Loss: 0.7959030866622925, Accuracy: 0.751953125\n",
      "Batch: 82, Loss: 0.7582252621650696, Accuracy: 0.74755859375\n",
      "Batch: 83, Loss: 0.7335798740386963, Accuracy: 0.7568359375\n",
      "Batch: 84, Loss: 0.7390792965888977, Accuracy: 0.7685546875\n",
      "Batch: 85, Loss: 0.7720403075218201, Accuracy: 0.74365234375\n",
      "Batch: 86, Loss: 0.8441759347915649, Accuracy: 0.72802734375\n",
      "Batch: 87, Loss: 0.7402061223983765, Accuracy: 0.76123046875\n",
      "Batch: 88, Loss: 0.8132287263870239, Accuracy: 0.74658203125\n",
      "Batch: 89, Loss: 0.7745968699455261, Accuracy: 0.75634765625\n",
      "Batch: 90, Loss: 0.8465616703033447, Accuracy: 0.72216796875\n",
      "Batch: 91, Loss: 0.7768532633781433, Accuracy: 0.75146484375\n",
      "Batch: 92, Loss: 0.8831557035446167, Accuracy: 0.7109375\n",
      "Batch: 93, Loss: 0.8456056118011475, Accuracy: 0.72265625\n",
      "Batch: 94, Loss: 0.8457409143447876, Accuracy: 0.72900390625\n",
      "Batch: 95, Loss: 0.8583121299743652, Accuracy: 0.72998046875\n",
      "Batch: 96, Loss: 0.7931656241416931, Accuracy: 0.75244140625\n",
      "Batch: 97, Loss: 0.7691463232040405, Accuracy: 0.7548828125\n",
      "Batch: 98, Loss: 0.8627626895904541, Accuracy: 0.7265625\n",
      "Batch: 99, Loss: 0.781673789024353, Accuracy: 0.7509765625\n",
      "Batch: 100, Loss: 0.8723158240318298, Accuracy: 0.7216796875\n",
      "Batch: 101, Loss: 0.8874591588973999, Accuracy: 0.72216796875\n",
      "Batch: 102, Loss: 0.7552396655082703, Accuracy: 0.75\n",
      "Batch: 103, Loss: 0.8064514398574829, Accuracy: 0.74462890625\n",
      "Batch: 104, Loss: 0.7890483140945435, Accuracy: 0.74169921875\n",
      "Batch: 105, Loss: 0.8312404155731201, Accuracy: 0.7294921875\n",
      "Batch: 106, Loss: 0.8008800745010376, Accuracy: 0.73779296875\n",
      "Batch: 107, Loss: 0.8226372003555298, Accuracy: 0.74560546875\n",
      "Batch: 108, Loss: 0.7810813188552856, Accuracy: 0.74609375\n",
      "Batch: 109, Loss: 0.7775142192840576, Accuracy: 0.74072265625\n",
      "Batch: 110, Loss: 0.7760564684867859, Accuracy: 0.7470703125\n",
      "Batch: 111, Loss: 0.7152690291404724, Accuracy: 0.77978515625\n",
      "Batch: 112, Loss: 0.7890676259994507, Accuracy: 0.74853515625\n",
      "Batch: 113, Loss: 0.819935142993927, Accuracy: 0.7294921875\n",
      "Batch: 114, Loss: 0.7978516817092896, Accuracy: 0.7373046875\n",
      "Batch: 115, Loss: 0.8010455965995789, Accuracy: 0.74853515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 116, Loss: 0.7902199029922485, Accuracy: 0.74072265625\n",
      "Batch: 117, Loss: 0.7883903980255127, Accuracy: 0.74169921875\n",
      "Batch: 118, Loss: 0.7953976392745972, Accuracy: 0.74365234375\n",
      "Batch: 119, Loss: 0.7847691774368286, Accuracy: 0.73828125\n",
      "Batch: 120, Loss: 0.7619383335113525, Accuracy: 0.751953125\n",
      "Batch: 121, Loss: 0.7821493148803711, Accuracy: 0.7412109375\n",
      "Batch: 122, Loss: 0.7522596120834351, Accuracy: 0.7607421875\n",
      "Batch: 123, Loss: 0.7528161406517029, Accuracy: 0.76513671875\n",
      "Batch: 124, Loss: 0.7402231693267822, Accuracy: 0.75732421875\n",
      "Batch: 125, Loss: 0.7844874858856201, Accuracy: 0.74609375\n",
      "Batch: 126, Loss: 0.7544803619384766, Accuracy: 0.7490234375\n",
      "Batch: 127, Loss: 0.7052263021469116, Accuracy: 0.771484375\n",
      "Batch: 128, Loss: 0.8479967713356018, Accuracy: 0.728515625\n",
      "Batch: 129, Loss: 0.8832679390907288, Accuracy: 0.71826171875\n",
      "Batch: 130, Loss: 0.9093482494354248, Accuracy: 0.70654296875\n",
      "Batch: 131, Loss: 0.8107799887657166, Accuracy: 0.74951171875\n",
      "Batch: 132, Loss: 0.7452588081359863, Accuracy: 0.76318359375\n",
      "Batch: 133, Loss: 0.7297977805137634, Accuracy: 0.7724609375\n",
      "Batch: 134, Loss: 0.803638219833374, Accuracy: 0.74267578125\n",
      "Batch: 135, Loss: 0.7816148996353149, Accuracy: 0.755859375\n",
      "Batch: 136, Loss: 0.7521631717681885, Accuracy: 0.7451171875\n",
      "Batch: 137, Loss: 0.7878710031509399, Accuracy: 0.75341796875\n",
      "Batch: 138, Loss: 0.7100021243095398, Accuracy: 0.78173828125\n",
      "Batch: 139, Loss: 0.7679460048675537, Accuracy: 0.75146484375\n",
      "Batch: 140, Loss: 0.7362880110740662, Accuracy: 0.76953125\n",
      "Batch: 141, Loss: 0.8336406350135803, Accuracy: 0.72900390625\n",
      "Batch: 142, Loss: 0.743834376335144, Accuracy: 0.75244140625\n",
      "Batch: 143, Loss: 0.7531367540359497, Accuracy: 0.76806640625\n",
      "Batch: 144, Loss: 0.8156344890594482, Accuracy: 0.74169921875\n",
      "Batch: 145, Loss: 0.8044416308403015, Accuracy: 0.75634765625\n",
      "Batch: 146, Loss: 0.8352341651916504, Accuracy: 0.732421875\n",
      "Batch: 147, Loss: 0.7806951403617859, Accuracy: 0.7568359375\n",
      "Batch: 148, Loss: 0.8191239237785339, Accuracy: 0.7236328125\n",
      "Batch: 149, Loss: 0.800434947013855, Accuracy: 0.744140625\n",
      "Batch: 150, Loss: 0.7022668719291687, Accuracy: 0.77490234375\n",
      "Batch: 151, Loss: 0.7056096792221069, Accuracy: 0.77734375\n",
      "Batch: 152, Loss: 0.735292911529541, Accuracy: 0.76220703125\n",
      "Batch: 153, Loss: 0.7479335069656372, Accuracy: 0.7548828125\n",
      "Batch: 154, Loss: 0.7300900220870972, Accuracy: 0.7587890625\n",
      "Batch: 155, Loss: 0.8130178451538086, Accuracy: 0.7421875\n",
      "Batch: 156, Loss: 0.7196217775344849, Accuracy: 0.763671875\n",
      "Batch: 157, Loss: 0.716469407081604, Accuracy: 0.75390625\n",
      "Batch: 158, Loss: 0.6930871605873108, Accuracy: 0.77490234375\n",
      "Batch: 159, Loss: 0.7089549899101257, Accuracy: 0.775390625\n",
      "Batch: 160, Loss: 0.7464264631271362, Accuracy: 0.75\n",
      "Batch: 161, Loss: 0.7769138813018799, Accuracy: 0.74951171875\n",
      "Batch: 162, Loss: 0.753666877746582, Accuracy: 0.75830078125\n",
      "Batch: 163, Loss: 0.8179371356964111, Accuracy: 0.73388671875\n",
      "Batch: 164, Loss: 0.8495792150497437, Accuracy: 0.7275390625\n",
      "Batch: 165, Loss: 0.767479419708252, Accuracy: 0.75830078125\n",
      "Batch: 166, Loss: 0.7762188911437988, Accuracy: 0.7421875\n",
      "Batch: 167, Loss: 0.7514686584472656, Accuracy: 0.7568359375\n",
      "Batch: 168, Loss: 0.6914650201797485, Accuracy: 0.78173828125\n",
      "Batch: 169, Loss: 0.7553632259368896, Accuracy: 0.75439453125\n",
      "Batch: 170, Loss: 0.8148975372314453, Accuracy: 0.73876953125\n",
      "Batch: 171, Loss: 0.7427659034729004, Accuracy: 0.7509765625\n",
      "Batch: 172, Loss: 0.7380021810531616, Accuracy: 0.76025390625\n",
      "Batch: 173, Loss: 0.8083527088165283, Accuracy: 0.740234375\n",
      "Batch: 174, Loss: 0.6724961400032043, Accuracy: 0.767578125\n",
      "Batch: 175, Loss: 0.796148955821991, Accuracy: 0.73681640625\n",
      "Batch: 176, Loss: 0.8381307721138, Accuracy: 0.7333984375\n",
      "Batch: 177, Loss: 0.7630258798599243, Accuracy: 0.7548828125\n",
      "Batch: 178, Loss: 0.7331277132034302, Accuracy: 0.76708984375\n",
      "Batch: 179, Loss: 0.7629506587982178, Accuracy: 0.75927734375\n",
      "Batch: 180, Loss: 0.8195981979370117, Accuracy: 0.73876953125\n",
      "Epoch 40/200\n",
      "Batch: 1, Loss: 1.1150015592575073, Accuracy: 0.68017578125\n",
      "Batch: 2, Loss: 0.7848862409591675, Accuracy: 0.73388671875\n",
      "Batch: 3, Loss: 0.7678240537643433, Accuracy: 0.76220703125\n",
      "Batch: 4, Loss: 0.7970020771026611, Accuracy: 0.74462890625\n",
      "Batch: 5, Loss: 0.8003724813461304, Accuracy: 0.7470703125\n",
      "Batch: 6, Loss: 0.812894344329834, Accuracy: 0.73486328125\n",
      "Batch: 7, Loss: 0.7484884858131409, Accuracy: 0.75634765625\n",
      "Batch: 8, Loss: 0.801209032535553, Accuracy: 0.72900390625\n",
      "Batch: 9, Loss: 0.8229482769966125, Accuracy: 0.73876953125\n",
      "Batch: 10, Loss: 0.7645152807235718, Accuracy: 0.75830078125\n",
      "Batch: 11, Loss: 0.8096337914466858, Accuracy: 0.73291015625\n",
      "Batch: 12, Loss: 0.7347144484519958, Accuracy: 0.76220703125\n",
      "Batch: 13, Loss: 0.7866736650466919, Accuracy: 0.74951171875\n",
      "Batch: 14, Loss: 0.7620446681976318, Accuracy: 0.7763671875\n",
      "Batch: 15, Loss: 0.795965313911438, Accuracy: 0.7451171875\n",
      "Batch: 16, Loss: 0.8447316288948059, Accuracy: 0.72607421875\n",
      "Batch: 17, Loss: 0.7470563650131226, Accuracy: 0.75927734375\n",
      "Batch: 18, Loss: 0.8182398080825806, Accuracy: 0.74072265625\n",
      "Batch: 19, Loss: 0.8144527673721313, Accuracy: 0.73974609375\n",
      "Batch: 20, Loss: 0.7203981876373291, Accuracy: 0.77685546875\n",
      "Batch: 21, Loss: 0.8554031848907471, Accuracy: 0.7333984375\n",
      "Batch: 22, Loss: 0.7440881133079529, Accuracy: 0.75927734375\n",
      "Batch: 23, Loss: 0.7279860973358154, Accuracy: 0.7646484375\n",
      "Batch: 24, Loss: 0.7671878933906555, Accuracy: 0.751953125\n",
      "Batch: 25, Loss: 0.7316228747367859, Accuracy: 0.765625\n",
      "Batch: 26, Loss: 0.7645333409309387, Accuracy: 0.7578125\n",
      "Batch: 27, Loss: 0.8184499740600586, Accuracy: 0.7373046875\n",
      "Batch: 28, Loss: 0.7745227813720703, Accuracy: 0.7509765625\n",
      "Batch: 29, Loss: 0.8297480344772339, Accuracy: 0.7314453125\n",
      "Batch: 30, Loss: 0.7878850698471069, Accuracy: 0.74658203125\n",
      "Batch: 31, Loss: 0.900719165802002, Accuracy: 0.71923828125\n",
      "Batch: 32, Loss: 0.8274009823799133, Accuracy: 0.73095703125\n",
      "Batch: 33, Loss: 0.824246346950531, Accuracy: 0.734375\n",
      "Batch: 34, Loss: 0.8469667434692383, Accuracy: 0.7275390625\n",
      "Batch: 35, Loss: 0.8523418307304382, Accuracy: 0.7255859375\n",
      "Batch: 36, Loss: 0.8249543309211731, Accuracy: 0.73388671875\n",
      "Batch: 37, Loss: 0.8075869679450989, Accuracy: 0.74072265625\n",
      "Batch: 38, Loss: 0.8623601198196411, Accuracy: 0.7236328125\n",
      "Batch: 39, Loss: 0.8109302520751953, Accuracy: 0.74658203125\n",
      "Batch: 40, Loss: 0.8524783849716187, Accuracy: 0.7255859375\n",
      "Batch: 41, Loss: 0.8159105777740479, Accuracy: 0.7314453125\n",
      "Batch: 42, Loss: 0.8068017363548279, Accuracy: 0.73486328125\n",
      "Batch: 43, Loss: 0.762593150138855, Accuracy: 0.7626953125\n",
      "Batch: 44, Loss: 0.6937326192855835, Accuracy: 0.7734375\n",
      "Batch: 45, Loss: 0.7580370903015137, Accuracy: 0.7646484375\n",
      "Batch: 46, Loss: 0.7427428364753723, Accuracy: 0.74853515625\n",
      "Batch: 47, Loss: 0.7976105213165283, Accuracy: 0.74560546875\n",
      "Batch: 48, Loss: 0.7553651928901672, Accuracy: 0.75634765625\n",
      "Batch: 49, Loss: 0.7352650761604309, Accuracy: 0.7626953125\n",
      "Batch: 50, Loss: 0.7936539649963379, Accuracy: 0.7373046875\n",
      "Batch: 51, Loss: 0.7663779258728027, Accuracy: 0.74462890625\n",
      "Batch: 52, Loss: 0.7414015531539917, Accuracy: 0.75390625\n",
      "Batch: 53, Loss: 0.7601953744888306, Accuracy: 0.7392578125\n",
      "Batch: 54, Loss: 0.7917552590370178, Accuracy: 0.734375\n",
      "Batch: 55, Loss: 0.7630453109741211, Accuracy: 0.74853515625\n",
      "Batch: 56, Loss: 0.7601712942123413, Accuracy: 0.74609375\n",
      "Batch: 57, Loss: 0.8403856754302979, Accuracy: 0.732421875\n",
      "Batch: 58, Loss: 0.7884929180145264, Accuracy: 0.74267578125\n",
      "Batch: 59, Loss: 0.8750135898590088, Accuracy: 0.7265625\n",
      "Batch: 60, Loss: 0.7877945899963379, Accuracy: 0.74951171875\n",
      "Batch: 61, Loss: 0.7299776077270508, Accuracy: 0.763671875\n",
      "Batch: 62, Loss: 0.7589819431304932, Accuracy: 0.75927734375\n",
      "Batch: 63, Loss: 0.7631132006645203, Accuracy: 0.74462890625\n",
      "Batch: 64, Loss: 0.8034704923629761, Accuracy: 0.72802734375\n",
      "Batch: 65, Loss: 0.8387997150421143, Accuracy: 0.72900390625\n",
      "Batch: 66, Loss: 0.8164525032043457, Accuracy: 0.740234375\n",
      "Batch: 67, Loss: 0.8135083913803101, Accuracy: 0.7373046875\n",
      "Batch: 68, Loss: 0.7527529001235962, Accuracy: 0.75244140625\n",
      "Batch: 69, Loss: 0.7855255603790283, Accuracy: 0.755859375\n",
      "Batch: 70, Loss: 0.7925945520401001, Accuracy: 0.74462890625\n",
      "Batch: 71, Loss: 0.777298092842102, Accuracy: 0.7548828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 72, Loss: 0.817292332649231, Accuracy: 0.7294921875\n",
      "Batch: 73, Loss: 0.8055840730667114, Accuracy: 0.73779296875\n",
      "Batch: 74, Loss: 0.819078803062439, Accuracy: 0.7353515625\n",
      "Batch: 75, Loss: 0.728225588798523, Accuracy: 0.765625\n",
      "Batch: 76, Loss: 0.7166002988815308, Accuracy: 0.7763671875\n",
      "Batch: 77, Loss: 0.7401928305625916, Accuracy: 0.76953125\n",
      "Batch: 78, Loss: 0.770234227180481, Accuracy: 0.76171875\n",
      "Batch: 79, Loss: 0.7708609104156494, Accuracy: 0.7470703125\n",
      "Batch: 80, Loss: 0.8164892196655273, Accuracy: 0.7412109375\n",
      "Batch: 81, Loss: 0.8004738092422485, Accuracy: 0.75\n",
      "Batch: 82, Loss: 0.7653013467788696, Accuracy: 0.74609375\n",
      "Batch: 83, Loss: 0.7316730618476868, Accuracy: 0.7666015625\n",
      "Batch: 84, Loss: 0.7319618463516235, Accuracy: 0.7744140625\n",
      "Batch: 85, Loss: 0.7484724521636963, Accuracy: 0.75927734375\n",
      "Batch: 86, Loss: 0.8229755759239197, Accuracy: 0.7353515625\n",
      "Batch: 87, Loss: 0.7363013029098511, Accuracy: 0.76416015625\n",
      "Batch: 88, Loss: 0.7895735502243042, Accuracy: 0.75244140625\n",
      "Batch: 89, Loss: 0.7756742835044861, Accuracy: 0.74462890625\n",
      "Batch: 90, Loss: 0.8410271406173706, Accuracy: 0.7265625\n",
      "Batch: 91, Loss: 0.7581120729446411, Accuracy: 0.75146484375\n",
      "Batch: 92, Loss: 0.875328779220581, Accuracy: 0.71337890625\n",
      "Batch: 93, Loss: 0.8400149345397949, Accuracy: 0.7255859375\n",
      "Batch: 94, Loss: 0.8201941847801208, Accuracy: 0.7333984375\n",
      "Batch: 95, Loss: 0.8444333076477051, Accuracy: 0.732421875\n",
      "Batch: 96, Loss: 0.7671838998794556, Accuracy: 0.744140625\n",
      "Batch: 97, Loss: 0.7678619623184204, Accuracy: 0.75439453125\n",
      "Batch: 98, Loss: 0.843866765499115, Accuracy: 0.73681640625\n",
      "Batch: 99, Loss: 0.7688534259796143, Accuracy: 0.7607421875\n",
      "Batch: 100, Loss: 0.8544409275054932, Accuracy: 0.732421875\n",
      "Batch: 101, Loss: 0.8832526206970215, Accuracy: 0.7236328125\n",
      "Batch: 102, Loss: 0.7738489508628845, Accuracy: 0.73779296875\n",
      "Batch: 103, Loss: 0.8430107831954956, Accuracy: 0.7353515625\n",
      "Batch: 104, Loss: 0.7890002131462097, Accuracy: 0.751953125\n",
      "Batch: 105, Loss: 0.8295513391494751, Accuracy: 0.7314453125\n",
      "Batch: 106, Loss: 0.7813483476638794, Accuracy: 0.7548828125\n",
      "Batch: 107, Loss: 0.8147858381271362, Accuracy: 0.74658203125\n",
      "Batch: 108, Loss: 0.7827102541923523, Accuracy: 0.7509765625\n",
      "Batch: 109, Loss: 0.7836892604827881, Accuracy: 0.74169921875\n",
      "Batch: 110, Loss: 0.7618098855018616, Accuracy: 0.748046875\n",
      "Batch: 111, Loss: 0.709175705909729, Accuracy: 0.7685546875\n",
      "Batch: 112, Loss: 0.7786048650741577, Accuracy: 0.7451171875\n",
      "Batch: 113, Loss: 0.7991686463356018, Accuracy: 0.73291015625\n",
      "Batch: 114, Loss: 0.7652236223220825, Accuracy: 0.75048828125\n",
      "Batch: 115, Loss: 0.7864081859588623, Accuracy: 0.75537109375\n",
      "Batch: 116, Loss: 0.8017548322677612, Accuracy: 0.7412109375\n",
      "Batch: 117, Loss: 0.7710453271865845, Accuracy: 0.7509765625\n",
      "Batch: 118, Loss: 0.7874242067337036, Accuracy: 0.732421875\n",
      "Batch: 119, Loss: 0.7705757021903992, Accuracy: 0.7451171875\n",
      "Batch: 120, Loss: 0.7689963579177856, Accuracy: 0.748046875\n",
      "Batch: 121, Loss: 0.7617868185043335, Accuracy: 0.74658203125\n",
      "Batch: 122, Loss: 0.7243831157684326, Accuracy: 0.7646484375\n",
      "Batch: 123, Loss: 0.7602100372314453, Accuracy: 0.75927734375\n",
      "Batch: 124, Loss: 0.7228862643241882, Accuracy: 0.763671875\n",
      "Batch: 125, Loss: 0.7961036562919617, Accuracy: 0.73681640625\n",
      "Batch: 126, Loss: 0.7408747673034668, Accuracy: 0.7548828125\n",
      "Batch: 127, Loss: 0.7079954147338867, Accuracy: 0.78173828125\n",
      "Batch: 128, Loss: 0.863492488861084, Accuracy: 0.72509765625\n",
      "Batch: 129, Loss: 0.8907045125961304, Accuracy: 0.712890625\n",
      "Batch: 130, Loss: 0.8902236223220825, Accuracy: 0.70458984375\n",
      "Batch: 131, Loss: 0.8110774755477905, Accuracy: 0.73876953125\n",
      "Batch: 132, Loss: 0.7360939979553223, Accuracy: 0.76953125\n",
      "Batch: 133, Loss: 0.7422715425491333, Accuracy: 0.771484375\n",
      "Batch: 134, Loss: 0.8042763471603394, Accuracy: 0.7451171875\n",
      "Batch: 135, Loss: 0.7975257635116577, Accuracy: 0.7412109375\n",
      "Batch: 136, Loss: 0.7341634631156921, Accuracy: 0.76025390625\n",
      "Batch: 137, Loss: 0.7942211627960205, Accuracy: 0.74755859375\n",
      "Batch: 138, Loss: 0.7075268030166626, Accuracy: 0.78662109375\n",
      "Batch: 139, Loss: 0.7685451507568359, Accuracy: 0.7470703125\n",
      "Batch: 140, Loss: 0.7037901878356934, Accuracy: 0.77001953125\n",
      "Batch: 141, Loss: 0.8200727701187134, Accuracy: 0.73681640625\n",
      "Batch: 142, Loss: 0.7332577109336853, Accuracy: 0.76220703125\n",
      "Batch: 143, Loss: 0.7537702322006226, Accuracy: 0.7490234375\n",
      "Batch: 144, Loss: 0.8150944709777832, Accuracy: 0.736328125\n",
      "Batch: 145, Loss: 0.7861710786819458, Accuracy: 0.74609375\n",
      "Batch: 146, Loss: 0.8366492986679077, Accuracy: 0.7236328125\n",
      "Batch: 147, Loss: 0.7781360149383545, Accuracy: 0.7548828125\n",
      "Batch: 148, Loss: 0.8123095631599426, Accuracy: 0.73291015625\n",
      "Batch: 149, Loss: 0.7836959958076477, Accuracy: 0.74755859375\n",
      "Batch: 150, Loss: 0.6980005502700806, Accuracy: 0.775390625\n",
      "Batch: 151, Loss: 0.6916418075561523, Accuracy: 0.77734375\n",
      "Batch: 152, Loss: 0.7286585569381714, Accuracy: 0.77783203125\n",
      "Batch: 153, Loss: 0.7247056365013123, Accuracy: 0.76806640625\n",
      "Batch: 154, Loss: 0.727074146270752, Accuracy: 0.75146484375\n",
      "Batch: 155, Loss: 0.8059976100921631, Accuracy: 0.744140625\n",
      "Batch: 156, Loss: 0.7160288095474243, Accuracy: 0.76611328125\n",
      "Batch: 157, Loss: 0.6759899854660034, Accuracy: 0.77783203125\n",
      "Batch: 158, Loss: 0.6978893280029297, Accuracy: 0.78173828125\n",
      "Batch: 159, Loss: 0.7221949100494385, Accuracy: 0.78466796875\n",
      "Batch: 160, Loss: 0.7448620796203613, Accuracy: 0.7587890625\n",
      "Batch: 161, Loss: 0.7561312317848206, Accuracy: 0.75927734375\n",
      "Batch: 162, Loss: 0.7303661108016968, Accuracy: 0.75830078125\n",
      "Batch: 163, Loss: 0.7898968458175659, Accuracy: 0.736328125\n",
      "Batch: 164, Loss: 0.8332480788230896, Accuracy: 0.74169921875\n",
      "Batch: 165, Loss: 0.7559468746185303, Accuracy: 0.76416015625\n",
      "Batch: 166, Loss: 0.7789519429206848, Accuracy: 0.74560546875\n",
      "Batch: 167, Loss: 0.7523330450057983, Accuracy: 0.7587890625\n",
      "Batch: 168, Loss: 0.6709589958190918, Accuracy: 0.787109375\n",
      "Batch: 169, Loss: 0.7649710178375244, Accuracy: 0.7470703125\n",
      "Batch: 170, Loss: 0.7976366877555847, Accuracy: 0.74365234375\n",
      "Batch: 171, Loss: 0.7459647059440613, Accuracy: 0.76953125\n",
      "Batch: 172, Loss: 0.7448000907897949, Accuracy: 0.751953125\n",
      "Batch: 173, Loss: 0.7885400056838989, Accuracy: 0.75\n",
      "Batch: 174, Loss: 0.6697301268577576, Accuracy: 0.77783203125\n",
      "Batch: 175, Loss: 0.7720979452133179, Accuracy: 0.74169921875\n",
      "Batch: 176, Loss: 0.8160346746444702, Accuracy: 0.7353515625\n",
      "Batch: 177, Loss: 0.7559989094734192, Accuracy: 0.7587890625\n",
      "Batch: 178, Loss: 0.7271516919136047, Accuracy: 0.77001953125\n",
      "Batch: 179, Loss: 0.755450963973999, Accuracy: 0.76171875\n",
      "Batch: 180, Loss: 0.8007581830024719, Accuracy: 0.74609375\n",
      "Saved Weights at epoch 40 to file Weights_40.h5\n",
      "Epoch 41/200\n",
      "Batch: 1, Loss: 1.1432030200958252, Accuracy: 0.67919921875\n",
      "Batch: 2, Loss: 0.7698047161102295, Accuracy: 0.74951171875\n",
      "Batch: 3, Loss: 0.7630488872528076, Accuracy: 0.748046875\n",
      "Batch: 4, Loss: 0.8012250661849976, Accuracy: 0.74755859375\n",
      "Batch: 5, Loss: 0.7919756174087524, Accuracy: 0.74658203125\n",
      "Batch: 6, Loss: 0.7921644449234009, Accuracy: 0.740234375\n",
      "Batch: 7, Loss: 0.741652250289917, Accuracy: 0.7578125\n",
      "Batch: 8, Loss: 0.7699039578437805, Accuracy: 0.74072265625\n",
      "Batch: 9, Loss: 0.8260717391967773, Accuracy: 0.72802734375\n",
      "Batch: 10, Loss: 0.7528719902038574, Accuracy: 0.74853515625\n",
      "Batch: 11, Loss: 0.8173779249191284, Accuracy: 0.73046875\n",
      "Batch: 12, Loss: 0.7161763310432434, Accuracy: 0.77099609375\n",
      "Batch: 13, Loss: 0.7808341383934021, Accuracy: 0.74560546875\n",
      "Batch: 14, Loss: 0.7602365016937256, Accuracy: 0.76513671875\n",
      "Batch: 15, Loss: 0.7875597476959229, Accuracy: 0.7568359375\n",
      "Batch: 16, Loss: 0.827843427658081, Accuracy: 0.7373046875\n",
      "Batch: 17, Loss: 0.7675435543060303, Accuracy: 0.75439453125\n",
      "Batch: 18, Loss: 0.807769238948822, Accuracy: 0.744140625\n",
      "Batch: 19, Loss: 0.8353750705718994, Accuracy: 0.73486328125\n",
      "Batch: 20, Loss: 0.704623281955719, Accuracy: 0.77685546875\n",
      "Batch: 21, Loss: 0.8390016555786133, Accuracy: 0.72900390625\n",
      "Batch: 22, Loss: 0.7377223968505859, Accuracy: 0.76416015625\n",
      "Batch: 23, Loss: 0.7249903678894043, Accuracy: 0.76513671875\n",
      "Batch: 24, Loss: 0.765836238861084, Accuracy: 0.7509765625\n",
      "Batch: 25, Loss: 0.7294262647628784, Accuracy: 0.771484375\n",
      "Batch: 26, Loss: 0.7268064618110657, Accuracy: 0.76220703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 27, Loss: 0.7928811311721802, Accuracy: 0.74462890625\n",
      "Batch: 28, Loss: 0.7573283314704895, Accuracy: 0.76025390625\n",
      "Batch: 29, Loss: 0.8351287841796875, Accuracy: 0.7509765625\n",
      "Batch: 30, Loss: 0.7894409894943237, Accuracy: 0.74853515625\n",
      "Batch: 31, Loss: 0.9077019691467285, Accuracy: 0.71923828125\n",
      "Batch: 32, Loss: 0.8094485402107239, Accuracy: 0.74072265625\n",
      "Batch: 33, Loss: 0.7958517074584961, Accuracy: 0.7451171875\n",
      "Batch: 34, Loss: 0.8423279523849487, Accuracy: 0.72607421875\n",
      "Batch: 35, Loss: 0.8568874597549438, Accuracy: 0.72705078125\n",
      "Batch: 36, Loss: 0.83406001329422, Accuracy: 0.7392578125\n",
      "Batch: 37, Loss: 0.8127954006195068, Accuracy: 0.72900390625\n",
      "Batch: 38, Loss: 0.8511354923248291, Accuracy: 0.72265625\n",
      "Batch: 39, Loss: 0.7943546772003174, Accuracy: 0.7421875\n",
      "Batch: 40, Loss: 0.824770450592041, Accuracy: 0.74462890625\n",
      "Batch: 41, Loss: 0.8234494924545288, Accuracy: 0.736328125\n",
      "Batch: 42, Loss: 0.7699413299560547, Accuracy: 0.74462890625\n",
      "Batch: 43, Loss: 0.7670972347259521, Accuracy: 0.751953125\n",
      "Batch: 44, Loss: 0.6876060962677002, Accuracy: 0.78369140625\n",
      "Batch: 45, Loss: 0.7509926557540894, Accuracy: 0.7646484375\n",
      "Batch: 46, Loss: 0.7393514513969421, Accuracy: 0.74365234375\n",
      "Batch: 47, Loss: 0.7700172662734985, Accuracy: 0.7490234375\n",
      "Batch: 48, Loss: 0.7628263831138611, Accuracy: 0.7529296875\n",
      "Batch: 49, Loss: 0.7447782754898071, Accuracy: 0.763671875\n",
      "Batch: 50, Loss: 0.7791089415550232, Accuracy: 0.7470703125\n",
      "Batch: 51, Loss: 0.7548692226409912, Accuracy: 0.74560546875\n",
      "Batch: 52, Loss: 0.7418147325515747, Accuracy: 0.74658203125\n",
      "Batch: 53, Loss: 0.7611145377159119, Accuracy: 0.74560546875\n",
      "Batch: 54, Loss: 0.7922338247299194, Accuracy: 0.74072265625\n",
      "Batch: 55, Loss: 0.7643696069717407, Accuracy: 0.75341796875\n",
      "Batch: 56, Loss: 0.744631290435791, Accuracy: 0.74951171875\n",
      "Batch: 57, Loss: 0.8282673954963684, Accuracy: 0.7451171875\n",
      "Batch: 58, Loss: 0.7757668495178223, Accuracy: 0.73779296875\n",
      "Batch: 59, Loss: 0.8752331733703613, Accuracy: 0.72216796875\n",
      "Batch: 60, Loss: 0.7752549648284912, Accuracy: 0.76123046875\n",
      "Batch: 61, Loss: 0.7185414433479309, Accuracy: 0.76904296875\n",
      "Batch: 62, Loss: 0.732980489730835, Accuracy: 0.77587890625\n",
      "Batch: 63, Loss: 0.7549636363983154, Accuracy: 0.74658203125\n",
      "Batch: 64, Loss: 0.7930610179901123, Accuracy: 0.74267578125\n",
      "Batch: 65, Loss: 0.8310195803642273, Accuracy: 0.73583984375\n",
      "Batch: 66, Loss: 0.8161846399307251, Accuracy: 0.73486328125\n",
      "Batch: 67, Loss: 0.81341952085495, Accuracy: 0.7314453125\n",
      "Batch: 68, Loss: 0.7446613311767578, Accuracy: 0.7529296875\n",
      "Batch: 69, Loss: 0.7780650854110718, Accuracy: 0.7490234375\n",
      "Batch: 70, Loss: 0.7742429375648499, Accuracy: 0.73681640625\n",
      "Batch: 71, Loss: 0.781277060508728, Accuracy: 0.7470703125\n",
      "Batch: 72, Loss: 0.7951360940933228, Accuracy: 0.73046875\n",
      "Batch: 73, Loss: 0.7880420684814453, Accuracy: 0.7490234375\n",
      "Batch: 74, Loss: 0.8198809623718262, Accuracy: 0.73681640625\n",
      "Batch: 75, Loss: 0.72550368309021, Accuracy: 0.75732421875\n",
      "Batch: 76, Loss: 0.7020879983901978, Accuracy: 0.77099609375\n",
      "Batch: 77, Loss: 0.7160123586654663, Accuracy: 0.7705078125\n",
      "Batch: 78, Loss: 0.7531744241714478, Accuracy: 0.7626953125\n",
      "Batch: 79, Loss: 0.772854208946228, Accuracy: 0.7490234375\n",
      "Batch: 80, Loss: 0.7961036562919617, Accuracy: 0.73974609375\n",
      "Batch: 81, Loss: 0.7836859226226807, Accuracy: 0.75390625\n",
      "Batch: 82, Loss: 0.7466878294944763, Accuracy: 0.7509765625\n",
      "Batch: 83, Loss: 0.7111848592758179, Accuracy: 0.7822265625\n",
      "Batch: 84, Loss: 0.7140557765960693, Accuracy: 0.775390625\n",
      "Batch: 85, Loss: 0.7527106404304504, Accuracy: 0.759765625\n",
      "Batch: 86, Loss: 0.8114418387413025, Accuracy: 0.74658203125\n",
      "Batch: 87, Loss: 0.7118357419967651, Accuracy: 0.7724609375\n",
      "Batch: 88, Loss: 0.7893353700637817, Accuracy: 0.75537109375\n",
      "Batch: 89, Loss: 0.7669435739517212, Accuracy: 0.7529296875\n",
      "Batch: 90, Loss: 0.8115638494491577, Accuracy: 0.73193359375\n",
      "Batch: 91, Loss: 0.7389522790908813, Accuracy: 0.77294921875\n",
      "Batch: 92, Loss: 0.8789352178573608, Accuracy: 0.71630859375\n",
      "Batch: 93, Loss: 0.8235971927642822, Accuracy: 0.73046875\n",
      "Batch: 94, Loss: 0.7939447164535522, Accuracy: 0.74267578125\n",
      "Batch: 95, Loss: 0.8351483345031738, Accuracy: 0.73828125\n",
      "Batch: 96, Loss: 0.7766396999359131, Accuracy: 0.75\n",
      "Batch: 97, Loss: 0.7475355863571167, Accuracy: 0.76611328125\n",
      "Batch: 98, Loss: 0.8428709506988525, Accuracy: 0.73876953125\n",
      "Batch: 99, Loss: 0.7574960589408875, Accuracy: 0.7529296875\n",
      "Batch: 100, Loss: 0.8405609130859375, Accuracy: 0.7431640625\n",
      "Batch: 101, Loss: 0.8590606451034546, Accuracy: 0.73046875\n",
      "Batch: 102, Loss: 0.7386119365692139, Accuracy: 0.76416015625\n",
      "Batch: 103, Loss: 0.7897018194198608, Accuracy: 0.7509765625\n",
      "Batch: 104, Loss: 0.7858348488807678, Accuracy: 0.73828125\n",
      "Batch: 105, Loss: 0.8034341335296631, Accuracy: 0.75537109375\n",
      "Batch: 106, Loss: 0.7622730731964111, Accuracy: 0.75830078125\n",
      "Batch: 107, Loss: 0.8033322095870972, Accuracy: 0.7431640625\n",
      "Batch: 108, Loss: 0.7631251215934753, Accuracy: 0.75\n",
      "Batch: 109, Loss: 0.7625393271446228, Accuracy: 0.755859375\n",
      "Batch: 110, Loss: 0.755456805229187, Accuracy: 0.7490234375\n",
      "Batch: 111, Loss: 0.7011908292770386, Accuracy: 0.7666015625\n",
      "Batch: 112, Loss: 0.7711527943611145, Accuracy: 0.7578125\n",
      "Batch: 113, Loss: 0.7902437448501587, Accuracy: 0.7373046875\n",
      "Batch: 114, Loss: 0.7676196694374084, Accuracy: 0.74951171875\n",
      "Batch: 115, Loss: 0.7885868549346924, Accuracy: 0.75146484375\n",
      "Batch: 116, Loss: 0.7758680582046509, Accuracy: 0.75244140625\n",
      "Batch: 117, Loss: 0.7842810750007629, Accuracy: 0.751953125\n",
      "Batch: 118, Loss: 0.7823874950408936, Accuracy: 0.74267578125\n",
      "Batch: 119, Loss: 0.7748169898986816, Accuracy: 0.748046875\n",
      "Batch: 120, Loss: 0.7284454703330994, Accuracy: 0.7646484375\n",
      "Batch: 121, Loss: 0.757860004901886, Accuracy: 0.75048828125\n",
      "Batch: 122, Loss: 0.7363488674163818, Accuracy: 0.7587890625\n",
      "Batch: 123, Loss: 0.7335915565490723, Accuracy: 0.771484375\n",
      "Batch: 124, Loss: 0.7408435344696045, Accuracy: 0.7587890625\n",
      "Batch: 125, Loss: 0.7864511013031006, Accuracy: 0.74462890625\n",
      "Batch: 126, Loss: 0.7196508646011353, Accuracy: 0.7607421875\n",
      "Batch: 127, Loss: 0.7136253714561462, Accuracy: 0.763671875\n",
      "Batch: 128, Loss: 0.8602794408798218, Accuracy: 0.7275390625\n",
      "Batch: 129, Loss: 0.8685826063156128, Accuracy: 0.728515625\n",
      "Batch: 130, Loss: 0.8654383420944214, Accuracy: 0.716796875\n",
      "Batch: 131, Loss: 0.7978829145431519, Accuracy: 0.7451171875\n",
      "Batch: 132, Loss: 0.7170861959457397, Accuracy: 0.7783203125\n",
      "Batch: 133, Loss: 0.7078914046287537, Accuracy: 0.78369140625\n",
      "Batch: 134, Loss: 0.7919207811355591, Accuracy: 0.73876953125\n",
      "Batch: 135, Loss: 0.7899062037467957, Accuracy: 0.74462890625\n",
      "Batch: 136, Loss: 0.7288724184036255, Accuracy: 0.7587890625\n",
      "Batch: 137, Loss: 0.7876801490783691, Accuracy: 0.7578125\n",
      "Batch: 138, Loss: 0.697504997253418, Accuracy: 0.78369140625\n",
      "Batch: 139, Loss: 0.7348158359527588, Accuracy: 0.76513671875\n",
      "Batch: 140, Loss: 0.6989703178405762, Accuracy: 0.7744140625\n",
      "Batch: 141, Loss: 0.8030552864074707, Accuracy: 0.73681640625\n",
      "Batch: 142, Loss: 0.7236745357513428, Accuracy: 0.771484375\n",
      "Batch: 143, Loss: 0.7556732892990112, Accuracy: 0.75927734375\n",
      "Batch: 144, Loss: 0.7998961210250854, Accuracy: 0.7421875\n",
      "Batch: 145, Loss: 0.7798032760620117, Accuracy: 0.76171875\n",
      "Batch: 146, Loss: 0.8237005472183228, Accuracy: 0.74169921875\n",
      "Batch: 147, Loss: 0.78779137134552, Accuracy: 0.74462890625\n",
      "Batch: 148, Loss: 0.8081631064414978, Accuracy: 0.73388671875\n",
      "Batch: 149, Loss: 0.7848557233810425, Accuracy: 0.74267578125\n",
      "Batch: 150, Loss: 0.6763854026794434, Accuracy: 0.783203125\n",
      "Batch: 151, Loss: 0.6842182874679565, Accuracy: 0.7802734375\n",
      "Batch: 152, Loss: 0.7282649278640747, Accuracy: 0.767578125\n",
      "Batch: 153, Loss: 0.7179856896400452, Accuracy: 0.77490234375\n",
      "Batch: 154, Loss: 0.713725209236145, Accuracy: 0.755859375\n",
      "Batch: 155, Loss: 0.8147995471954346, Accuracy: 0.74609375\n",
      "Batch: 156, Loss: 0.692901611328125, Accuracy: 0.77587890625\n",
      "Batch: 157, Loss: 0.6860845685005188, Accuracy: 0.76708984375\n",
      "Batch: 158, Loss: 0.6955730319023132, Accuracy: 0.78271484375\n",
      "Batch: 159, Loss: 0.7116670608520508, Accuracy: 0.78173828125\n",
      "Batch: 160, Loss: 0.7463065385818481, Accuracy: 0.759765625\n",
      "Batch: 161, Loss: 0.7578529715538025, Accuracy: 0.75146484375\n",
      "Batch: 162, Loss: 0.7305627465248108, Accuracy: 0.76513671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 163, Loss: 0.7814548015594482, Accuracy: 0.74267578125\n",
      "Batch: 164, Loss: 0.8395079374313354, Accuracy: 0.7333984375\n",
      "Batch: 165, Loss: 0.759488582611084, Accuracy: 0.765625\n",
      "Batch: 166, Loss: 0.7546234130859375, Accuracy: 0.76123046875\n",
      "Batch: 167, Loss: 0.7529990673065186, Accuracy: 0.7529296875\n",
      "Batch: 168, Loss: 0.683224618434906, Accuracy: 0.7841796875\n",
      "Batch: 169, Loss: 0.7490510940551758, Accuracy: 0.7587890625\n",
      "Batch: 170, Loss: 0.7734482288360596, Accuracy: 0.7548828125\n",
      "Batch: 171, Loss: 0.7318746447563171, Accuracy: 0.76904296875\n",
      "Batch: 172, Loss: 0.7319692373275757, Accuracy: 0.7568359375\n",
      "Batch: 173, Loss: 0.7879568338394165, Accuracy: 0.74609375\n",
      "Batch: 174, Loss: 0.6486756205558777, Accuracy: 0.7919921875\n",
      "Batch: 175, Loss: 0.7791265249252319, Accuracy: 0.74951171875\n",
      "Batch: 176, Loss: 0.816396176815033, Accuracy: 0.7412109375\n",
      "Batch: 177, Loss: 0.7452669739723206, Accuracy: 0.76953125\n",
      "Batch: 178, Loss: 0.7110567688941956, Accuracy: 0.76708984375\n",
      "Batch: 179, Loss: 0.7484807968139648, Accuracy: 0.763671875\n",
      "Batch: 180, Loss: 0.8020161390304565, Accuracy: 0.751953125\n",
      "Epoch 42/200\n",
      "Batch: 1, Loss: 1.1299926042556763, Accuracy: 0.68603515625\n",
      "Batch: 2, Loss: 0.7798289656639099, Accuracy: 0.73828125\n",
      "Batch: 3, Loss: 0.7567306756973267, Accuracy: 0.75537109375\n",
      "Batch: 4, Loss: 0.7906724214553833, Accuracy: 0.73681640625\n",
      "Batch: 5, Loss: 0.7705720663070679, Accuracy: 0.7470703125\n",
      "Batch: 6, Loss: 0.8034188747406006, Accuracy: 0.74951171875\n",
      "Batch: 7, Loss: 0.7389662861824036, Accuracy: 0.75732421875\n",
      "Batch: 8, Loss: 0.7711681127548218, Accuracy: 0.7529296875\n",
      "Batch: 9, Loss: 0.8127272129058838, Accuracy: 0.74169921875\n",
      "Batch: 10, Loss: 0.7406740784645081, Accuracy: 0.75732421875\n",
      "Batch: 11, Loss: 0.8121451139450073, Accuracy: 0.74462890625\n",
      "Batch: 12, Loss: 0.7204501032829285, Accuracy: 0.77587890625\n",
      "Batch: 13, Loss: 0.7761657238006592, Accuracy: 0.73828125\n",
      "Batch: 14, Loss: 0.7675516605377197, Accuracy: 0.763671875\n",
      "Batch: 15, Loss: 0.7646843791007996, Accuracy: 0.75146484375\n",
      "Batch: 16, Loss: 0.8342387676239014, Accuracy: 0.732421875\n",
      "Batch: 17, Loss: 0.7429758310317993, Accuracy: 0.76123046875\n",
      "Batch: 18, Loss: 0.802139937877655, Accuracy: 0.7451171875\n",
      "Batch: 19, Loss: 0.7909495830535889, Accuracy: 0.75390625\n",
      "Batch: 20, Loss: 0.6892490386962891, Accuracy: 0.77880859375\n",
      "Batch: 21, Loss: 0.8361086845397949, Accuracy: 0.73388671875\n",
      "Batch: 22, Loss: 0.7270423173904419, Accuracy: 0.76123046875\n",
      "Batch: 23, Loss: 0.7188593149185181, Accuracy: 0.76025390625\n",
      "Batch: 24, Loss: 0.7600032091140747, Accuracy: 0.75146484375\n",
      "Batch: 25, Loss: 0.7318090796470642, Accuracy: 0.763671875\n",
      "Batch: 26, Loss: 0.750880777835846, Accuracy: 0.76123046875\n",
      "Batch: 27, Loss: 0.7825319170951843, Accuracy: 0.7470703125\n",
      "Batch: 28, Loss: 0.741701602935791, Accuracy: 0.76123046875\n",
      "Batch: 29, Loss: 0.8173562288284302, Accuracy: 0.7431640625\n",
      "Batch: 30, Loss: 0.794031023979187, Accuracy: 0.75048828125\n",
      "Batch: 31, Loss: 0.8841179609298706, Accuracy: 0.72119140625\n",
      "Batch: 32, Loss: 0.8235211372375488, Accuracy: 0.7392578125\n",
      "Batch: 33, Loss: 0.7945103645324707, Accuracy: 0.74462890625\n",
      "Batch: 34, Loss: 0.8445779085159302, Accuracy: 0.72412109375\n",
      "Batch: 35, Loss: 0.8318401575088501, Accuracy: 0.74169921875\n",
      "Batch: 36, Loss: 0.8343285322189331, Accuracy: 0.73974609375\n",
      "Batch: 37, Loss: 0.8176205158233643, Accuracy: 0.7412109375\n",
      "Batch: 38, Loss: 0.8287686109542847, Accuracy: 0.73486328125\n",
      "Batch: 39, Loss: 0.7827973365783691, Accuracy: 0.74609375\n",
      "Batch: 40, Loss: 0.8541287183761597, Accuracy: 0.73095703125\n",
      "Batch: 41, Loss: 0.804520845413208, Accuracy: 0.7373046875\n",
      "Batch: 42, Loss: 0.7890470027923584, Accuracy: 0.73828125\n",
      "Batch: 43, Loss: 0.7620683908462524, Accuracy: 0.75830078125\n",
      "Batch: 44, Loss: 0.6797793507575989, Accuracy: 0.78173828125\n",
      "Batch: 45, Loss: 0.7420926690101624, Accuracy: 0.76171875\n",
      "Batch: 46, Loss: 0.7319146990776062, Accuracy: 0.74951171875\n",
      "Batch: 47, Loss: 0.7608286142349243, Accuracy: 0.75537109375\n",
      "Batch: 48, Loss: 0.7404276132583618, Accuracy: 0.76171875\n",
      "Batch: 49, Loss: 0.744155764579773, Accuracy: 0.759765625\n",
      "Batch: 50, Loss: 0.7845344543457031, Accuracy: 0.74267578125\n",
      "Batch: 51, Loss: 0.7505215406417847, Accuracy: 0.75732421875\n",
      "Batch: 52, Loss: 0.7313868999481201, Accuracy: 0.7548828125\n",
      "Batch: 53, Loss: 0.7257180213928223, Accuracy: 0.75439453125\n",
      "Batch: 54, Loss: 0.786677360534668, Accuracy: 0.73828125\n",
      "Batch: 55, Loss: 0.7457955479621887, Accuracy: 0.755859375\n",
      "Batch: 56, Loss: 0.7242279052734375, Accuracy: 0.76611328125\n",
      "Batch: 57, Loss: 0.8085458874702454, Accuracy: 0.75146484375\n",
      "Batch: 58, Loss: 0.7615736722946167, Accuracy: 0.759765625\n",
      "Batch: 59, Loss: 0.8661453127861023, Accuracy: 0.7294921875\n",
      "Batch: 60, Loss: 0.7650229930877686, Accuracy: 0.7626953125\n",
      "Batch: 61, Loss: 0.6939883828163147, Accuracy: 0.7763671875\n",
      "Batch: 62, Loss: 0.7371330261230469, Accuracy: 0.7685546875\n",
      "Batch: 63, Loss: 0.7489524483680725, Accuracy: 0.74755859375\n",
      "Batch: 64, Loss: 0.7741019129753113, Accuracy: 0.74267578125\n",
      "Batch: 65, Loss: 0.8219801783561707, Accuracy: 0.7373046875\n",
      "Batch: 66, Loss: 0.8044367432594299, Accuracy: 0.748046875\n",
      "Batch: 67, Loss: 0.8245373964309692, Accuracy: 0.72998046875\n",
      "Batch: 68, Loss: 0.7180799841880798, Accuracy: 0.76220703125\n",
      "Batch: 69, Loss: 0.7784442901611328, Accuracy: 0.7451171875\n",
      "Batch: 70, Loss: 0.7555884718894958, Accuracy: 0.751953125\n",
      "Batch: 71, Loss: 0.7779794931411743, Accuracy: 0.74951171875\n",
      "Batch: 72, Loss: 0.7900333404541016, Accuracy: 0.734375\n",
      "Batch: 73, Loss: 0.779499351978302, Accuracy: 0.736328125\n",
      "Batch: 74, Loss: 0.79041588306427, Accuracy: 0.7392578125\n",
      "Batch: 75, Loss: 0.7230621576309204, Accuracy: 0.76513671875\n",
      "Batch: 76, Loss: 0.6891337633132935, Accuracy: 0.78125\n",
      "Batch: 77, Loss: 0.7166188955307007, Accuracy: 0.7783203125\n",
      "Batch: 78, Loss: 0.741568386554718, Accuracy: 0.77001953125\n",
      "Batch: 79, Loss: 0.7677439451217651, Accuracy: 0.75439453125\n",
      "Batch: 80, Loss: 0.7867757081985474, Accuracy: 0.74365234375\n",
      "Batch: 81, Loss: 0.7633950710296631, Accuracy: 0.76220703125\n",
      "Batch: 82, Loss: 0.7276458740234375, Accuracy: 0.76513671875\n",
      "Batch: 83, Loss: 0.6947766542434692, Accuracy: 0.7685546875\n",
      "Batch: 84, Loss: 0.6959539651870728, Accuracy: 0.7880859375\n",
      "Batch: 85, Loss: 0.7496473789215088, Accuracy: 0.7529296875\n",
      "Batch: 86, Loss: 0.8151800632476807, Accuracy: 0.74853515625\n",
      "Batch: 87, Loss: 0.7075652480125427, Accuracy: 0.76904296875\n",
      "Batch: 88, Loss: 0.7982994318008423, Accuracy: 0.7529296875\n",
      "Batch: 89, Loss: 0.7478756904602051, Accuracy: 0.76318359375\n",
      "Batch: 90, Loss: 0.8113728165626526, Accuracy: 0.72216796875\n",
      "Batch: 91, Loss: 0.7542651295661926, Accuracy: 0.7568359375\n",
      "Batch: 92, Loss: 0.8727079629898071, Accuracy: 0.7109375\n",
      "Batch: 93, Loss: 0.819176197052002, Accuracy: 0.72216796875\n",
      "Batch: 94, Loss: 0.7786630988121033, Accuracy: 0.74658203125\n",
      "Batch: 95, Loss: 0.8186743855476379, Accuracy: 0.74755859375\n",
      "Batch: 96, Loss: 0.7638823986053467, Accuracy: 0.75830078125\n",
      "Batch: 97, Loss: 0.734892725944519, Accuracy: 0.7646484375\n",
      "Batch: 98, Loss: 0.8241614103317261, Accuracy: 0.74462890625\n",
      "Batch: 99, Loss: 0.7503579258918762, Accuracy: 0.76123046875\n",
      "Batch: 100, Loss: 0.8469699025154114, Accuracy: 0.732421875\n",
      "Batch: 101, Loss: 0.8672193288803101, Accuracy: 0.71728515625\n",
      "Batch: 102, Loss: 0.7294252514839172, Accuracy: 0.75927734375\n",
      "Batch: 103, Loss: 0.8047411441802979, Accuracy: 0.73779296875\n",
      "Batch: 104, Loss: 0.7670271992683411, Accuracy: 0.75732421875\n",
      "Batch: 105, Loss: 0.8067127466201782, Accuracy: 0.74072265625\n",
      "Batch: 106, Loss: 0.7649955749511719, Accuracy: 0.755859375\n",
      "Batch: 107, Loss: 0.7937597036361694, Accuracy: 0.74462890625\n",
      "Batch: 108, Loss: 0.7478094100952148, Accuracy: 0.76123046875\n",
      "Batch: 109, Loss: 0.7382172346115112, Accuracy: 0.75732421875\n",
      "Batch: 110, Loss: 0.746271014213562, Accuracy: 0.75\n",
      "Batch: 111, Loss: 0.7010752558708191, Accuracy: 0.7744140625\n",
      "Batch: 112, Loss: 0.7626053094863892, Accuracy: 0.75732421875\n",
      "Batch: 113, Loss: 0.7920307517051697, Accuracy: 0.732421875\n",
      "Batch: 114, Loss: 0.7646410465240479, Accuracy: 0.75341796875\n",
      "Batch: 115, Loss: 0.7570051550865173, Accuracy: 0.76611328125\n",
      "Batch: 116, Loss: 0.7541216611862183, Accuracy: 0.7607421875\n",
      "Batch: 117, Loss: 0.765107274055481, Accuracy: 0.7509765625\n",
      "Batch: 118, Loss: 0.7576402425765991, Accuracy: 0.7490234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 119, Loss: 0.7607307434082031, Accuracy: 0.75927734375\n",
      "Batch: 120, Loss: 0.7339502573013306, Accuracy: 0.76513671875\n",
      "Batch: 121, Loss: 0.7684736847877502, Accuracy: 0.748046875\n",
      "Batch: 122, Loss: 0.7281308174133301, Accuracy: 0.76904296875\n",
      "Batch: 123, Loss: 0.7272822856903076, Accuracy: 0.767578125\n",
      "Batch: 124, Loss: 0.7212504744529724, Accuracy: 0.7646484375\n",
      "Batch: 125, Loss: 0.7597041130065918, Accuracy: 0.751953125\n",
      "Batch: 126, Loss: 0.7197012901306152, Accuracy: 0.76806640625\n",
      "Batch: 127, Loss: 0.6980962753295898, Accuracy: 0.7705078125\n",
      "Batch: 128, Loss: 0.8385692834854126, Accuracy: 0.7294921875\n",
      "Batch: 129, Loss: 0.8729212880134583, Accuracy: 0.71630859375\n",
      "Batch: 130, Loss: 0.863675594329834, Accuracy: 0.7177734375\n",
      "Batch: 131, Loss: 0.8039307594299316, Accuracy: 0.75439453125\n",
      "Batch: 132, Loss: 0.7000042796134949, Accuracy: 0.78271484375\n",
      "Batch: 133, Loss: 0.7082505226135254, Accuracy: 0.7724609375\n",
      "Batch: 134, Loss: 0.7756213545799255, Accuracy: 0.7509765625\n",
      "Batch: 135, Loss: 0.7827813625335693, Accuracy: 0.744140625\n",
      "Batch: 136, Loss: 0.7271429300308228, Accuracy: 0.76318359375\n",
      "Batch: 137, Loss: 0.7649411559104919, Accuracy: 0.76025390625\n",
      "Batch: 138, Loss: 0.6774246096611023, Accuracy: 0.78955078125\n",
      "Batch: 139, Loss: 0.7299032211303711, Accuracy: 0.7646484375\n",
      "Batch: 140, Loss: 0.6830284595489502, Accuracy: 0.77783203125\n",
      "Batch: 141, Loss: 0.8074606657028198, Accuracy: 0.73974609375\n",
      "Batch: 142, Loss: 0.7152400016784668, Accuracy: 0.765625\n",
      "Batch: 143, Loss: 0.7302410006523132, Accuracy: 0.76123046875\n",
      "Batch: 144, Loss: 0.7986172437667847, Accuracy: 0.7431640625\n",
      "Batch: 145, Loss: 0.7791088819503784, Accuracy: 0.7578125\n",
      "Batch: 146, Loss: 0.822807252407074, Accuracy: 0.72802734375\n",
      "Batch: 147, Loss: 0.7621558308601379, Accuracy: 0.76171875\n",
      "Batch: 148, Loss: 0.7945107221603394, Accuracy: 0.74169921875\n",
      "Batch: 149, Loss: 0.7789002060890198, Accuracy: 0.75\n",
      "Batch: 150, Loss: 0.6807039380073547, Accuracy: 0.78369140625\n",
      "Batch: 151, Loss: 0.6842496991157532, Accuracy: 0.783203125\n",
      "Batch: 152, Loss: 0.7234784364700317, Accuracy: 0.76318359375\n",
      "Batch: 153, Loss: 0.7280808687210083, Accuracy: 0.775390625\n",
      "Batch: 154, Loss: 0.7264857292175293, Accuracy: 0.7568359375\n",
      "Batch: 155, Loss: 0.8071500062942505, Accuracy: 0.73486328125\n",
      "Batch: 156, Loss: 0.6949760913848877, Accuracy: 0.76953125\n",
      "Batch: 157, Loss: 0.691152811050415, Accuracy: 0.77099609375\n",
      "Batch: 158, Loss: 0.7010657787322998, Accuracy: 0.779296875\n",
      "Batch: 159, Loss: 0.6803386211395264, Accuracy: 0.78271484375\n",
      "Batch: 160, Loss: 0.7222979068756104, Accuracy: 0.76708984375\n",
      "Batch: 161, Loss: 0.75527024269104, Accuracy: 0.75634765625\n",
      "Batch: 162, Loss: 0.721223771572113, Accuracy: 0.7626953125\n",
      "Batch: 163, Loss: 0.7767354249954224, Accuracy: 0.74462890625\n",
      "Batch: 164, Loss: 0.8268203735351562, Accuracy: 0.73388671875\n",
      "Batch: 165, Loss: 0.717645525932312, Accuracy: 0.77099609375\n",
      "Batch: 166, Loss: 0.7846345901489258, Accuracy: 0.7509765625\n",
      "Batch: 167, Loss: 0.7354130744934082, Accuracy: 0.7626953125\n",
      "Batch: 168, Loss: 0.6671277284622192, Accuracy: 0.78857421875\n",
      "Batch: 169, Loss: 0.7486363053321838, Accuracy: 0.7626953125\n",
      "Batch: 170, Loss: 0.7825264930725098, Accuracy: 0.751953125\n",
      "Batch: 171, Loss: 0.7051822543144226, Accuracy: 0.78466796875\n",
      "Batch: 172, Loss: 0.6933501958847046, Accuracy: 0.76806640625\n",
      "Batch: 173, Loss: 0.7790470123291016, Accuracy: 0.75048828125\n",
      "Batch: 174, Loss: 0.6518293619155884, Accuracy: 0.787109375\n",
      "Batch: 175, Loss: 0.7623656988143921, Accuracy: 0.7412109375\n",
      "Batch: 176, Loss: 0.7979412078857422, Accuracy: 0.748046875\n",
      "Batch: 177, Loss: 0.7359273433685303, Accuracy: 0.755859375\n",
      "Batch: 178, Loss: 0.7136005759239197, Accuracy: 0.7724609375\n",
      "Batch: 179, Loss: 0.7247253656387329, Accuracy: 0.76953125\n",
      "Batch: 180, Loss: 0.7849621772766113, Accuracy: 0.74951171875\n",
      "Epoch 43/200\n",
      "Batch: 1, Loss: 1.1159741878509521, Accuracy: 0.6787109375\n",
      "Batch: 2, Loss: 0.7429837584495544, Accuracy: 0.740234375\n",
      "Batch: 3, Loss: 0.7524043321609497, Accuracy: 0.75\n",
      "Batch: 4, Loss: 0.7896201610565186, Accuracy: 0.74365234375\n",
      "Batch: 5, Loss: 0.7787750959396362, Accuracy: 0.75341796875\n",
      "Batch: 6, Loss: 0.7789807319641113, Accuracy: 0.7353515625\n",
      "Batch: 7, Loss: 0.7175998687744141, Accuracy: 0.765625\n",
      "Batch: 8, Loss: 0.7480235695838928, Accuracy: 0.755859375\n",
      "Batch: 9, Loss: 0.806399941444397, Accuracy: 0.74951171875\n",
      "Batch: 10, Loss: 0.7294700145721436, Accuracy: 0.775390625\n",
      "Batch: 11, Loss: 0.7980132102966309, Accuracy: 0.74853515625\n",
      "Batch: 12, Loss: 0.692629337310791, Accuracy: 0.77294921875\n",
      "Batch: 13, Loss: 0.7466978430747986, Accuracy: 0.755859375\n",
      "Batch: 14, Loss: 0.7566463947296143, Accuracy: 0.765625\n",
      "Batch: 15, Loss: 0.7720537185668945, Accuracy: 0.7587890625\n",
      "Batch: 16, Loss: 0.7965606451034546, Accuracy: 0.7470703125\n",
      "Batch: 17, Loss: 0.7373710870742798, Accuracy: 0.765625\n",
      "Batch: 18, Loss: 0.7952151298522949, Accuracy: 0.75048828125\n",
      "Batch: 19, Loss: 0.7976424694061279, Accuracy: 0.7470703125\n",
      "Batch: 20, Loss: 0.6804127097129822, Accuracy: 0.77783203125\n",
      "Batch: 21, Loss: 0.8248693943023682, Accuracy: 0.73779296875\n",
      "Batch: 22, Loss: 0.7094506025314331, Accuracy: 0.7646484375\n",
      "Batch: 23, Loss: 0.7109252214431763, Accuracy: 0.767578125\n",
      "Batch: 24, Loss: 0.7772611379623413, Accuracy: 0.74755859375\n",
      "Batch: 25, Loss: 0.7257168889045715, Accuracy: 0.77734375\n",
      "Batch: 26, Loss: 0.7345801591873169, Accuracy: 0.7705078125\n",
      "Batch: 27, Loss: 0.7977181673049927, Accuracy: 0.736328125\n",
      "Batch: 28, Loss: 0.7333095073699951, Accuracy: 0.75341796875\n",
      "Batch: 29, Loss: 0.8171529769897461, Accuracy: 0.7392578125\n",
      "Batch: 30, Loss: 0.792630672454834, Accuracy: 0.74755859375\n",
      "Batch: 31, Loss: 0.8804836273193359, Accuracy: 0.72412109375\n",
      "Batch: 32, Loss: 0.8123329877853394, Accuracy: 0.73876953125\n",
      "Batch: 33, Loss: 0.801170825958252, Accuracy: 0.73779296875\n",
      "Batch: 34, Loss: 0.8227345943450928, Accuracy: 0.7314453125\n",
      "Batch: 35, Loss: 0.8237941861152649, Accuracy: 0.72607421875\n",
      "Batch: 36, Loss: 0.8097759485244751, Accuracy: 0.74072265625\n",
      "Batch: 37, Loss: 0.8003580570220947, Accuracy: 0.7353515625\n",
      "Batch: 38, Loss: 0.8576736450195312, Accuracy: 0.72314453125\n",
      "Batch: 39, Loss: 0.7794535160064697, Accuracy: 0.7568359375\n",
      "Batch: 40, Loss: 0.8345241546630859, Accuracy: 0.73779296875\n",
      "Batch: 41, Loss: 0.8154749870300293, Accuracy: 0.7333984375\n",
      "Batch: 42, Loss: 0.7843831777572632, Accuracy: 0.73779296875\n",
      "Batch: 43, Loss: 0.7724473476409912, Accuracy: 0.7548828125\n",
      "Batch: 44, Loss: 0.6676970720291138, Accuracy: 0.78173828125\n",
      "Batch: 45, Loss: 0.7596018314361572, Accuracy: 0.7587890625\n",
      "Batch: 46, Loss: 0.7340875864028931, Accuracy: 0.75146484375\n",
      "Batch: 47, Loss: 0.7584414482116699, Accuracy: 0.759765625\n",
      "Batch: 48, Loss: 0.7499106526374817, Accuracy: 0.76025390625\n",
      "Batch: 49, Loss: 0.7238852381706238, Accuracy: 0.76806640625\n",
      "Batch: 50, Loss: 0.7736346125602722, Accuracy: 0.75537109375\n",
      "Batch: 51, Loss: 0.7489432096481323, Accuracy: 0.75830078125\n",
      "Batch: 52, Loss: 0.7166851758956909, Accuracy: 0.75830078125\n",
      "Batch: 53, Loss: 0.7551437616348267, Accuracy: 0.7607421875\n",
      "Batch: 54, Loss: 0.7837892770767212, Accuracy: 0.73828125\n",
      "Batch: 55, Loss: 0.7400115132331848, Accuracy: 0.76123046875\n",
      "Batch: 56, Loss: 0.7400970458984375, Accuracy: 0.75927734375\n",
      "Batch: 57, Loss: 0.8027108311653137, Accuracy: 0.74169921875\n",
      "Batch: 58, Loss: 0.7748632431030273, Accuracy: 0.74169921875\n",
      "Batch: 59, Loss: 0.8612513542175293, Accuracy: 0.724609375\n",
      "Batch: 60, Loss: 0.7454025745391846, Accuracy: 0.76416015625\n",
      "Batch: 61, Loss: 0.7043113708496094, Accuracy: 0.77001953125\n",
      "Batch: 62, Loss: 0.7283241748809814, Accuracy: 0.76904296875\n",
      "Batch: 63, Loss: 0.751418948173523, Accuracy: 0.75244140625\n",
      "Batch: 64, Loss: 0.7782765626907349, Accuracy: 0.7392578125\n",
      "Batch: 65, Loss: 0.8120112419128418, Accuracy: 0.736328125\n",
      "Batch: 66, Loss: 0.7959843277931213, Accuracy: 0.7421875\n",
      "Batch: 67, Loss: 0.819354772567749, Accuracy: 0.73779296875\n",
      "Batch: 68, Loss: 0.7155373096466064, Accuracy: 0.7685546875\n",
      "Batch: 69, Loss: 0.7844376564025879, Accuracy: 0.74462890625\n",
      "Batch: 70, Loss: 0.7447714805603027, Accuracy: 0.74951171875\n",
      "Batch: 71, Loss: 0.7595144510269165, Accuracy: 0.75390625\n",
      "Batch: 72, Loss: 0.7905998229980469, Accuracy: 0.73046875\n",
      "Batch: 73, Loss: 0.7816301584243774, Accuracy: 0.74560546875\n",
      "Batch: 74, Loss: 0.7941187620162964, Accuracy: 0.74267578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 75, Loss: 0.7005741000175476, Accuracy: 0.76513671875\n",
      "Batch: 76, Loss: 0.6835812926292419, Accuracy: 0.77197265625\n",
      "Batch: 77, Loss: 0.7163962125778198, Accuracy: 0.77490234375\n",
      "Batch: 78, Loss: 0.7492672801017761, Accuracy: 0.76904296875\n",
      "Batch: 79, Loss: 0.7526001930236816, Accuracy: 0.75927734375\n",
      "Batch: 80, Loss: 0.786001443862915, Accuracy: 0.7529296875\n",
      "Batch: 81, Loss: 0.7856615781784058, Accuracy: 0.7568359375\n",
      "Batch: 82, Loss: 0.7180390357971191, Accuracy: 0.767578125\n",
      "Batch: 83, Loss: 0.696086585521698, Accuracy: 0.77587890625\n",
      "Batch: 84, Loss: 0.7131294012069702, Accuracy: 0.77490234375\n",
      "Batch: 85, Loss: 0.7372266054153442, Accuracy: 0.75439453125\n",
      "Batch: 86, Loss: 0.7963418960571289, Accuracy: 0.7548828125\n",
      "Batch: 87, Loss: 0.7078028321266174, Accuracy: 0.78076171875\n",
      "Batch: 88, Loss: 0.7779702544212341, Accuracy: 0.76171875\n",
      "Batch: 89, Loss: 0.7328914403915405, Accuracy: 0.76171875\n",
      "Batch: 90, Loss: 0.8112776875495911, Accuracy: 0.73095703125\n",
      "Batch: 91, Loss: 0.7264055609703064, Accuracy: 0.76806640625\n",
      "Batch: 92, Loss: 0.8591153025627136, Accuracy: 0.70361328125\n",
      "Batch: 93, Loss: 0.8046567440032959, Accuracy: 0.740234375\n",
      "Batch: 94, Loss: 0.7919085025787354, Accuracy: 0.74462890625\n",
      "Batch: 95, Loss: 0.8334175944328308, Accuracy: 0.73046875\n",
      "Batch: 96, Loss: 0.7516428232192993, Accuracy: 0.7529296875\n",
      "Batch: 97, Loss: 0.7279430031776428, Accuracy: 0.76806640625\n",
      "Batch: 98, Loss: 0.8214082717895508, Accuracy: 0.744140625\n",
      "Batch: 99, Loss: 0.742716372013092, Accuracy: 0.763671875\n",
      "Batch: 100, Loss: 0.814979076385498, Accuracy: 0.74072265625\n",
      "Batch: 101, Loss: 0.8581860065460205, Accuracy: 0.732421875\n",
      "Batch: 102, Loss: 0.7460674047470093, Accuracy: 0.759765625\n",
      "Batch: 103, Loss: 0.8001848459243774, Accuracy: 0.7431640625\n",
      "Batch: 104, Loss: 0.7586531043052673, Accuracy: 0.751953125\n",
      "Batch: 105, Loss: 0.7908276915550232, Accuracy: 0.74169921875\n",
      "Batch: 106, Loss: 0.7474864721298218, Accuracy: 0.751953125\n",
      "Batch: 107, Loss: 0.7803872227668762, Accuracy: 0.74560546875\n",
      "Batch: 108, Loss: 0.745309591293335, Accuracy: 0.763671875\n",
      "Batch: 109, Loss: 0.7383112907409668, Accuracy: 0.7607421875\n",
      "Batch: 110, Loss: 0.7301305532455444, Accuracy: 0.7626953125\n",
      "Batch: 111, Loss: 0.6953582763671875, Accuracy: 0.77783203125\n",
      "Batch: 112, Loss: 0.7462928295135498, Accuracy: 0.7626953125\n",
      "Batch: 113, Loss: 0.7842026352882385, Accuracy: 0.73486328125\n",
      "Batch: 114, Loss: 0.7442436218261719, Accuracy: 0.75\n",
      "Batch: 115, Loss: 0.7656985521316528, Accuracy: 0.75146484375\n",
      "Batch: 116, Loss: 0.7716434597969055, Accuracy: 0.7529296875\n",
      "Batch: 117, Loss: 0.7605592012405396, Accuracy: 0.75146484375\n",
      "Batch: 118, Loss: 0.76923006772995, Accuracy: 0.75244140625\n",
      "Batch: 119, Loss: 0.7506226301193237, Accuracy: 0.75244140625\n",
      "Batch: 120, Loss: 0.74852055311203, Accuracy: 0.76171875\n",
      "Batch: 121, Loss: 0.7505331039428711, Accuracy: 0.75048828125\n",
      "Batch: 122, Loss: 0.7100898027420044, Accuracy: 0.76171875\n",
      "Batch: 123, Loss: 0.7216807007789612, Accuracy: 0.77001953125\n",
      "Batch: 124, Loss: 0.7046831846237183, Accuracy: 0.76806640625\n",
      "Batch: 125, Loss: 0.7531623244285583, Accuracy: 0.7568359375\n",
      "Batch: 126, Loss: 0.7108297944068909, Accuracy: 0.76416015625\n",
      "Batch: 127, Loss: 0.6887184977531433, Accuracy: 0.7763671875\n",
      "Batch: 128, Loss: 0.8136913180351257, Accuracy: 0.74365234375\n",
      "Batch: 129, Loss: 0.8648122549057007, Accuracy: 0.72021484375\n",
      "Batch: 130, Loss: 0.8645633459091187, Accuracy: 0.73193359375\n",
      "Batch: 131, Loss: 0.7763421535491943, Accuracy: 0.75537109375\n",
      "Batch: 132, Loss: 0.7010208368301392, Accuracy: 0.77783203125\n",
      "Batch: 133, Loss: 0.7145070433616638, Accuracy: 0.78173828125\n",
      "Batch: 134, Loss: 0.7616685628890991, Accuracy: 0.75390625\n",
      "Batch: 135, Loss: 0.7788352370262146, Accuracy: 0.748046875\n",
      "Batch: 136, Loss: 0.7306368350982666, Accuracy: 0.76123046875\n",
      "Batch: 137, Loss: 0.7601410150527954, Accuracy: 0.7568359375\n",
      "Batch: 138, Loss: 0.6732751131057739, Accuracy: 0.79345703125\n",
      "Batch: 139, Loss: 0.7278848886489868, Accuracy: 0.75830078125\n",
      "Batch: 140, Loss: 0.7132494449615479, Accuracy: 0.76171875\n",
      "Batch: 141, Loss: 0.7992991209030151, Accuracy: 0.74853515625\n",
      "Batch: 142, Loss: 0.7035320401191711, Accuracy: 0.7666015625\n",
      "Batch: 143, Loss: 0.7365967035293579, Accuracy: 0.76708984375\n",
      "Batch: 144, Loss: 0.7972900867462158, Accuracy: 0.75732421875\n",
      "Batch: 145, Loss: 0.756882905960083, Accuracy: 0.75830078125\n",
      "Batch: 146, Loss: 0.80642169713974, Accuracy: 0.740234375\n",
      "Batch: 147, Loss: 0.7553929686546326, Accuracy: 0.751953125\n",
      "Batch: 148, Loss: 0.7992624044418335, Accuracy: 0.7333984375\n",
      "Batch: 149, Loss: 0.7585228085517883, Accuracy: 0.75732421875\n",
      "Batch: 150, Loss: 0.6672008633613586, Accuracy: 0.78955078125\n",
      "Batch: 151, Loss: 0.6773195266723633, Accuracy: 0.78515625\n",
      "Batch: 152, Loss: 0.7099877595901489, Accuracy: 0.76513671875\n",
      "Batch: 153, Loss: 0.7035164833068848, Accuracy: 0.77880859375\n",
      "Batch: 154, Loss: 0.7002971172332764, Accuracy: 0.76220703125\n",
      "Batch: 155, Loss: 0.7865984439849854, Accuracy: 0.74609375\n",
      "Batch: 156, Loss: 0.6937267780303955, Accuracy: 0.767578125\n",
      "Batch: 157, Loss: 0.6642106771469116, Accuracy: 0.77197265625\n",
      "Batch: 158, Loss: 0.6731725931167603, Accuracy: 0.7890625\n",
      "Batch: 159, Loss: 0.6773670315742493, Accuracy: 0.7880859375\n",
      "Batch: 160, Loss: 0.7220927476882935, Accuracy: 0.75830078125\n",
      "Batch: 161, Loss: 0.7253124713897705, Accuracy: 0.76806640625\n",
      "Batch: 162, Loss: 0.7085843682289124, Accuracy: 0.76611328125\n",
      "Batch: 163, Loss: 0.7680243253707886, Accuracy: 0.75244140625\n",
      "Batch: 164, Loss: 0.8155606985092163, Accuracy: 0.73779296875\n",
      "Batch: 165, Loss: 0.721173882484436, Accuracy: 0.7744140625\n",
      "Batch: 166, Loss: 0.7583969235420227, Accuracy: 0.75927734375\n",
      "Batch: 167, Loss: 0.7484458684921265, Accuracy: 0.75927734375\n",
      "Batch: 168, Loss: 0.6716472506523132, Accuracy: 0.78125\n",
      "Batch: 169, Loss: 0.7307097911834717, Accuracy: 0.76171875\n",
      "Batch: 170, Loss: 0.7664123177528381, Accuracy: 0.75634765625\n",
      "Batch: 171, Loss: 0.7114209532737732, Accuracy: 0.771484375\n",
      "Batch: 172, Loss: 0.7039515972137451, Accuracy: 0.7705078125\n",
      "Batch: 173, Loss: 0.7544082403182983, Accuracy: 0.7568359375\n",
      "Batch: 174, Loss: 0.6429457664489746, Accuracy: 0.7841796875\n",
      "Batch: 175, Loss: 0.7607150077819824, Accuracy: 0.74658203125\n",
      "Batch: 176, Loss: 0.8024408221244812, Accuracy: 0.740234375\n",
      "Batch: 177, Loss: 0.7254871129989624, Accuracy: 0.7744140625\n",
      "Batch: 178, Loss: 0.6966586709022522, Accuracy: 0.7744140625\n",
      "Batch: 179, Loss: 0.7203150391578674, Accuracy: 0.77294921875\n",
      "Batch: 180, Loss: 0.7843181490898132, Accuracy: 0.74755859375\n",
      "Epoch 44/200\n",
      "Batch: 1, Loss: 1.0769457817077637, Accuracy: 0.70263671875\n",
      "Batch: 2, Loss: 0.7467040419578552, Accuracy: 0.74658203125\n",
      "Batch: 3, Loss: 0.7521934509277344, Accuracy: 0.75244140625\n",
      "Batch: 4, Loss: 0.7916308641433716, Accuracy: 0.736328125\n",
      "Batch: 5, Loss: 0.7560899257659912, Accuracy: 0.74853515625\n",
      "Batch: 6, Loss: 0.7717441320419312, Accuracy: 0.7587890625\n",
      "Batch: 7, Loss: 0.7301205992698669, Accuracy: 0.7626953125\n",
      "Batch: 8, Loss: 0.7492120265960693, Accuracy: 0.75048828125\n",
      "Batch: 9, Loss: 0.7972785234451294, Accuracy: 0.73974609375\n",
      "Batch: 10, Loss: 0.7389385104179382, Accuracy: 0.7685546875\n",
      "Batch: 11, Loss: 0.7885469794273376, Accuracy: 0.74365234375\n",
      "Batch: 12, Loss: 0.6952654123306274, Accuracy: 0.7705078125\n",
      "Batch: 13, Loss: 0.7649078369140625, Accuracy: 0.75830078125\n",
      "Batch: 14, Loss: 0.7366588115692139, Accuracy: 0.775390625\n",
      "Batch: 15, Loss: 0.7558709383010864, Accuracy: 0.76416015625\n",
      "Batch: 16, Loss: 0.795681357383728, Accuracy: 0.73779296875\n",
      "Batch: 17, Loss: 0.7191467881202698, Accuracy: 0.77490234375\n",
      "Batch: 18, Loss: 0.7775489687919617, Accuracy: 0.7529296875\n",
      "Batch: 19, Loss: 0.7833727598190308, Accuracy: 0.75634765625\n",
      "Batch: 20, Loss: 0.6803793907165527, Accuracy: 0.787109375\n",
      "Batch: 21, Loss: 0.80561763048172, Accuracy: 0.74072265625\n",
      "Batch: 22, Loss: 0.7066128253936768, Accuracy: 0.76806640625\n",
      "Batch: 23, Loss: 0.6961984634399414, Accuracy: 0.77001953125\n",
      "Batch: 24, Loss: 0.7323828339576721, Accuracy: 0.77001953125\n",
      "Batch: 25, Loss: 0.6975789070129395, Accuracy: 0.7724609375\n",
      "Batch: 26, Loss: 0.7259522676467896, Accuracy: 0.76611328125\n",
      "Batch: 27, Loss: 0.7679806351661682, Accuracy: 0.75\n",
      "Batch: 28, Loss: 0.7373300790786743, Accuracy: 0.7578125\n",
      "Batch: 29, Loss: 0.797101616859436, Accuracy: 0.75\n",
      "Batch: 30, Loss: 0.7558594942092896, Accuracy: 0.76953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 31, Loss: 0.8680847883224487, Accuracy: 0.71337890625\n",
      "Batch: 32, Loss: 0.7934327125549316, Accuracy: 0.7431640625\n",
      "Batch: 33, Loss: 0.7881799936294556, Accuracy: 0.74267578125\n",
      "Batch: 34, Loss: 0.7979840040206909, Accuracy: 0.73779296875\n",
      "Batch: 35, Loss: 0.8250980377197266, Accuracy: 0.7294921875\n",
      "Batch: 36, Loss: 0.8066790103912354, Accuracy: 0.75439453125\n",
      "Batch: 37, Loss: 0.792097806930542, Accuracy: 0.7412109375\n",
      "Batch: 38, Loss: 0.8178622722625732, Accuracy: 0.734375\n",
      "Batch: 39, Loss: 0.7689342498779297, Accuracy: 0.751953125\n",
      "Batch: 40, Loss: 0.8176648616790771, Accuracy: 0.744140625\n",
      "Batch: 41, Loss: 0.7971958518028259, Accuracy: 0.7470703125\n",
      "Batch: 42, Loss: 0.7848309874534607, Accuracy: 0.7412109375\n",
      "Batch: 43, Loss: 0.7302781343460083, Accuracy: 0.763671875\n",
      "Batch: 44, Loss: 0.670417845249176, Accuracy: 0.78759765625\n",
      "Batch: 45, Loss: 0.7143921852111816, Accuracy: 0.7666015625\n",
      "Batch: 46, Loss: 0.7178138494491577, Accuracy: 0.7548828125\n",
      "Batch: 47, Loss: 0.7718164920806885, Accuracy: 0.75146484375\n",
      "Batch: 48, Loss: 0.7210690379142761, Accuracy: 0.76708984375\n",
      "Batch: 49, Loss: 0.7237882018089294, Accuracy: 0.76611328125\n",
      "Batch: 50, Loss: 0.7641854286193848, Accuracy: 0.7490234375\n",
      "Batch: 51, Loss: 0.7324815392494202, Accuracy: 0.76318359375\n",
      "Batch: 52, Loss: 0.7113991975784302, Accuracy: 0.7587890625\n",
      "Batch: 53, Loss: 0.7327334880828857, Accuracy: 0.75634765625\n",
      "Batch: 54, Loss: 0.7715494632720947, Accuracy: 0.74658203125\n",
      "Batch: 55, Loss: 0.7338869571685791, Accuracy: 0.75732421875\n",
      "Batch: 56, Loss: 0.7190303206443787, Accuracy: 0.7705078125\n",
      "Batch: 57, Loss: 0.8010410666465759, Accuracy: 0.75146484375\n",
      "Batch: 58, Loss: 0.7567326426506042, Accuracy: 0.74267578125\n",
      "Batch: 59, Loss: 0.8579392433166504, Accuracy: 0.7265625\n",
      "Batch: 60, Loss: 0.7497799396514893, Accuracy: 0.7548828125\n",
      "Batch: 61, Loss: 0.6927593946456909, Accuracy: 0.7724609375\n",
      "Batch: 62, Loss: 0.7204023599624634, Accuracy: 0.77099609375\n",
      "Batch: 63, Loss: 0.7346690893173218, Accuracy: 0.76220703125\n",
      "Batch: 64, Loss: 0.7573094964027405, Accuracy: 0.755859375\n",
      "Batch: 65, Loss: 0.7966495752334595, Accuracy: 0.7431640625\n",
      "Batch: 66, Loss: 0.7856266498565674, Accuracy: 0.7529296875\n",
      "Batch: 67, Loss: 0.7926942110061646, Accuracy: 0.744140625\n",
      "Batch: 68, Loss: 0.7033694386482239, Accuracy: 0.77685546875\n",
      "Batch: 69, Loss: 0.7595469951629639, Accuracy: 0.75439453125\n",
      "Batch: 70, Loss: 0.7364147901535034, Accuracy: 0.76123046875\n",
      "Batch: 71, Loss: 0.7316786050796509, Accuracy: 0.76416015625\n",
      "Batch: 72, Loss: 0.7881391048431396, Accuracy: 0.72509765625\n",
      "Batch: 73, Loss: 0.7803428769111633, Accuracy: 0.73779296875\n",
      "Batch: 74, Loss: 0.7917285561561584, Accuracy: 0.7509765625\n",
      "Batch: 75, Loss: 0.706541895866394, Accuracy: 0.767578125\n",
      "Batch: 76, Loss: 0.7039507031440735, Accuracy: 0.77099609375\n",
      "Batch: 77, Loss: 0.6842048764228821, Accuracy: 0.78564453125\n",
      "Batch: 78, Loss: 0.7309712767601013, Accuracy: 0.767578125\n",
      "Batch: 79, Loss: 0.736922025680542, Accuracy: 0.767578125\n",
      "Batch: 80, Loss: 0.7777271866798401, Accuracy: 0.74267578125\n",
      "Batch: 81, Loss: 0.7531411647796631, Accuracy: 0.76611328125\n",
      "Batch: 82, Loss: 0.7457599639892578, Accuracy: 0.75244140625\n",
      "Batch: 83, Loss: 0.6962235569953918, Accuracy: 0.7734375\n",
      "Batch: 84, Loss: 0.716855525970459, Accuracy: 0.775390625\n",
      "Batch: 85, Loss: 0.7265492677688599, Accuracy: 0.75927734375\n",
      "Batch: 86, Loss: 0.7937697172164917, Accuracy: 0.75244140625\n",
      "Batch: 87, Loss: 0.6854685544967651, Accuracy: 0.78271484375\n",
      "Batch: 88, Loss: 0.7829915285110474, Accuracy: 0.76025390625\n",
      "Batch: 89, Loss: 0.7323291301727295, Accuracy: 0.76513671875\n",
      "Batch: 90, Loss: 0.7926163673400879, Accuracy: 0.73681640625\n",
      "Batch: 91, Loss: 0.7235519886016846, Accuracy: 0.77197265625\n",
      "Batch: 92, Loss: 0.856170117855072, Accuracy: 0.71875\n",
      "Batch: 93, Loss: 0.8130877614021301, Accuracy: 0.7353515625\n",
      "Batch: 94, Loss: 0.7726714611053467, Accuracy: 0.74267578125\n",
      "Batch: 95, Loss: 0.8213560581207275, Accuracy: 0.73974609375\n",
      "Batch: 96, Loss: 0.7455155253410339, Accuracy: 0.7646484375\n",
      "Batch: 97, Loss: 0.7264138460159302, Accuracy: 0.77099609375\n",
      "Batch: 98, Loss: 0.7999216318130493, Accuracy: 0.74658203125\n",
      "Batch: 99, Loss: 0.7429250478744507, Accuracy: 0.763671875\n",
      "Batch: 100, Loss: 0.8315082788467407, Accuracy: 0.73681640625\n",
      "Batch: 101, Loss: 0.8329976201057434, Accuracy: 0.73046875\n",
      "Batch: 102, Loss: 0.7229540348052979, Accuracy: 0.76953125\n",
      "Batch: 103, Loss: 0.7831708788871765, Accuracy: 0.740234375\n",
      "Batch: 104, Loss: 0.7655245065689087, Accuracy: 0.7548828125\n",
      "Batch: 105, Loss: 0.7863380908966064, Accuracy: 0.7568359375\n",
      "Batch: 106, Loss: 0.738723635673523, Accuracy: 0.76171875\n",
      "Batch: 107, Loss: 0.7864269018173218, Accuracy: 0.755859375\n",
      "Batch: 108, Loss: 0.7353837490081787, Accuracy: 0.763671875\n",
      "Batch: 109, Loss: 0.7406225800514221, Accuracy: 0.75732421875\n",
      "Batch: 110, Loss: 0.7396646738052368, Accuracy: 0.75732421875\n",
      "Batch: 111, Loss: 0.685228705406189, Accuracy: 0.7890625\n",
      "Batch: 112, Loss: 0.7320860028266907, Accuracy: 0.7734375\n",
      "Batch: 113, Loss: 0.7796524167060852, Accuracy: 0.74462890625\n",
      "Batch: 114, Loss: 0.7593384385108948, Accuracy: 0.75634765625\n",
      "Batch: 115, Loss: 0.761841893196106, Accuracy: 0.76025390625\n",
      "Batch: 116, Loss: 0.7325029373168945, Accuracy: 0.7626953125\n",
      "Batch: 117, Loss: 0.7269325256347656, Accuracy: 0.75830078125\n",
      "Batch: 118, Loss: 0.7576362490653992, Accuracy: 0.74658203125\n",
      "Batch: 119, Loss: 0.7339082956314087, Accuracy: 0.76318359375\n",
      "Batch: 120, Loss: 0.7400169372558594, Accuracy: 0.75146484375\n",
      "Batch: 121, Loss: 0.7375313639640808, Accuracy: 0.75830078125\n",
      "Batch: 122, Loss: 0.7087953686714172, Accuracy: 0.7705078125\n",
      "Batch: 123, Loss: 0.7077703475952148, Accuracy: 0.783203125\n",
      "Batch: 124, Loss: 0.7003028392791748, Accuracy: 0.77490234375\n",
      "Batch: 125, Loss: 0.7393295168876648, Accuracy: 0.76025390625\n",
      "Batch: 126, Loss: 0.701389491558075, Accuracy: 0.76318359375\n",
      "Batch: 127, Loss: 0.7090116739273071, Accuracy: 0.7587890625\n",
      "Batch: 128, Loss: 0.8333723545074463, Accuracy: 0.73046875\n",
      "Batch: 129, Loss: 0.8501977920532227, Accuracy: 0.72998046875\n",
      "Batch: 130, Loss: 0.8597409725189209, Accuracy: 0.712890625\n",
      "Batch: 131, Loss: 0.7811559438705444, Accuracy: 0.74169921875\n",
      "Batch: 132, Loss: 0.7129155397415161, Accuracy: 0.77880859375\n",
      "Batch: 133, Loss: 0.70737224817276, Accuracy: 0.77587890625\n",
      "Batch: 134, Loss: 0.7558461427688599, Accuracy: 0.7451171875\n",
      "Batch: 135, Loss: 0.747855544090271, Accuracy: 0.755859375\n",
      "Batch: 136, Loss: 0.70445317029953, Accuracy: 0.7705078125\n",
      "Batch: 137, Loss: 0.7485370635986328, Accuracy: 0.76318359375\n",
      "Batch: 138, Loss: 0.6779266595840454, Accuracy: 0.791015625\n",
      "Batch: 139, Loss: 0.7295166254043579, Accuracy: 0.7685546875\n",
      "Batch: 140, Loss: 0.6877799034118652, Accuracy: 0.77099609375\n",
      "Batch: 141, Loss: 0.8059127926826477, Accuracy: 0.74267578125\n",
      "Batch: 142, Loss: 0.6993650794029236, Accuracy: 0.76123046875\n",
      "Batch: 143, Loss: 0.7176403403282166, Accuracy: 0.76513671875\n",
      "Batch: 144, Loss: 0.7748937606811523, Accuracy: 0.7587890625\n",
      "Batch: 145, Loss: 0.7385019659996033, Accuracy: 0.7724609375\n",
      "Batch: 146, Loss: 0.7869142293930054, Accuracy: 0.74072265625\n",
      "Batch: 147, Loss: 0.7465405464172363, Accuracy: 0.76611328125\n",
      "Batch: 148, Loss: 0.7868561744689941, Accuracy: 0.744140625\n",
      "Batch: 149, Loss: 0.7642051577568054, Accuracy: 0.7548828125\n",
      "Batch: 150, Loss: 0.6718524694442749, Accuracy: 0.78369140625\n",
      "Batch: 151, Loss: 0.6602768898010254, Accuracy: 0.787109375\n",
      "Batch: 152, Loss: 0.7031532526016235, Accuracy: 0.77392578125\n",
      "Batch: 153, Loss: 0.7065303325653076, Accuracy: 0.7763671875\n",
      "Batch: 154, Loss: 0.7130051851272583, Accuracy: 0.7646484375\n",
      "Batch: 155, Loss: 0.7992546558380127, Accuracy: 0.7490234375\n",
      "Batch: 156, Loss: 0.6963433027267456, Accuracy: 0.77685546875\n",
      "Batch: 157, Loss: 0.6725434064865112, Accuracy: 0.7724609375\n",
      "Batch: 158, Loss: 0.6669269800186157, Accuracy: 0.7998046875\n",
      "Batch: 159, Loss: 0.6932616233825684, Accuracy: 0.791015625\n",
      "Batch: 160, Loss: 0.7174142599105835, Accuracy: 0.7587890625\n",
      "Batch: 161, Loss: 0.7445563077926636, Accuracy: 0.76513671875\n",
      "Batch: 162, Loss: 0.709702730178833, Accuracy: 0.77587890625\n",
      "Batch: 163, Loss: 0.7675983905792236, Accuracy: 0.744140625\n",
      "Batch: 164, Loss: 0.8120726346969604, Accuracy: 0.7392578125\n",
      "Batch: 165, Loss: 0.7312535643577576, Accuracy: 0.7666015625\n",
      "Batch: 166, Loss: 0.7428779602050781, Accuracy: 0.77099609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 167, Loss: 0.739132821559906, Accuracy: 0.7568359375\n",
      "Batch: 168, Loss: 0.6614797115325928, Accuracy: 0.7890625\n",
      "Batch: 169, Loss: 0.7308846116065979, Accuracy: 0.76806640625\n",
      "Batch: 170, Loss: 0.7590781450271606, Accuracy: 0.7568359375\n",
      "Batch: 171, Loss: 0.7071436643600464, Accuracy: 0.775390625\n",
      "Batch: 172, Loss: 0.7077244520187378, Accuracy: 0.76904296875\n",
      "Batch: 173, Loss: 0.7457290887832642, Accuracy: 0.7666015625\n",
      "Batch: 174, Loss: 0.6452399492263794, Accuracy: 0.7880859375\n",
      "Batch: 175, Loss: 0.7494896054267883, Accuracy: 0.748046875\n",
      "Batch: 176, Loss: 0.7816511392593384, Accuracy: 0.7529296875\n",
      "Batch: 177, Loss: 0.714889407157898, Accuracy: 0.76904296875\n",
      "Batch: 178, Loss: 0.683577835559845, Accuracy: 0.77294921875\n",
      "Batch: 179, Loss: 0.7168700695037842, Accuracy: 0.76611328125\n",
      "Batch: 180, Loss: 0.7806745171546936, Accuracy: 0.7587890625\n",
      "Epoch 45/200\n",
      "Batch: 1, Loss: 1.0708086490631104, Accuracy: 0.70166015625\n",
      "Batch: 2, Loss: 0.7483986616134644, Accuracy: 0.75439453125\n",
      "Batch: 3, Loss: 0.761357307434082, Accuracy: 0.7568359375\n",
      "Batch: 4, Loss: 0.7673516869544983, Accuracy: 0.744140625\n",
      "Batch: 5, Loss: 0.7411891222000122, Accuracy: 0.76220703125\n",
      "Batch: 6, Loss: 0.7566702365875244, Accuracy: 0.7578125\n",
      "Batch: 7, Loss: 0.7202849984169006, Accuracy: 0.7607421875\n",
      "Batch: 8, Loss: 0.7366576194763184, Accuracy: 0.75439453125\n",
      "Batch: 9, Loss: 0.7858593463897705, Accuracy: 0.7421875\n",
      "Batch: 10, Loss: 0.7273620963096619, Accuracy: 0.76806640625\n",
      "Batch: 11, Loss: 0.7931731939315796, Accuracy: 0.74169921875\n",
      "Batch: 12, Loss: 0.6780389547348022, Accuracy: 0.78515625\n",
      "Batch: 13, Loss: 0.7471773624420166, Accuracy: 0.74609375\n",
      "Batch: 14, Loss: 0.7286962270736694, Accuracy: 0.77099609375\n",
      "Batch: 15, Loss: 0.751724362373352, Accuracy: 0.76416015625\n",
      "Batch: 16, Loss: 0.7830540537834167, Accuracy: 0.74462890625\n",
      "Batch: 17, Loss: 0.7363375425338745, Accuracy: 0.77197265625\n",
      "Batch: 18, Loss: 0.7742023468017578, Accuracy: 0.74267578125\n",
      "Batch: 19, Loss: 0.7872830629348755, Accuracy: 0.748046875\n",
      "Batch: 20, Loss: 0.6735357642173767, Accuracy: 0.78662109375\n",
      "Batch: 21, Loss: 0.7975109219551086, Accuracy: 0.74169921875\n",
      "Batch: 22, Loss: 0.7250062227249146, Accuracy: 0.76123046875\n",
      "Batch: 23, Loss: 0.7098960280418396, Accuracy: 0.7744140625\n",
      "Batch: 24, Loss: 0.7535310983657837, Accuracy: 0.75537109375\n",
      "Batch: 25, Loss: 0.6951850056648254, Accuracy: 0.7802734375\n",
      "Batch: 26, Loss: 0.7359236478805542, Accuracy: 0.763671875\n",
      "Batch: 27, Loss: 0.7677900195121765, Accuracy: 0.74609375\n",
      "Batch: 28, Loss: 0.735023021697998, Accuracy: 0.75146484375\n",
      "Batch: 29, Loss: 0.8023737668991089, Accuracy: 0.74072265625\n",
      "Batch: 30, Loss: 0.7587692141532898, Accuracy: 0.7685546875\n",
      "Batch: 31, Loss: 0.8592148423194885, Accuracy: 0.72998046875\n",
      "Batch: 32, Loss: 0.7787044048309326, Accuracy: 0.74609375\n",
      "Batch: 33, Loss: 0.7784656286239624, Accuracy: 0.7353515625\n",
      "Batch: 34, Loss: 0.813135027885437, Accuracy: 0.73583984375\n",
      "Batch: 35, Loss: 0.8217048645019531, Accuracy: 0.73193359375\n",
      "Batch: 36, Loss: 0.7916581034660339, Accuracy: 0.74951171875\n",
      "Batch: 37, Loss: 0.7791669368743896, Accuracy: 0.748046875\n",
      "Batch: 38, Loss: 0.8130800724029541, Accuracy: 0.732421875\n",
      "Batch: 39, Loss: 0.7664322853088379, Accuracy: 0.7548828125\n",
      "Batch: 40, Loss: 0.808106005191803, Accuracy: 0.748046875\n",
      "Batch: 41, Loss: 0.7713186740875244, Accuracy: 0.75048828125\n",
      "Batch: 42, Loss: 0.7831673622131348, Accuracy: 0.7451171875\n",
      "Batch: 43, Loss: 0.734445333480835, Accuracy: 0.7685546875\n",
      "Batch: 44, Loss: 0.6603723168373108, Accuracy: 0.7861328125\n",
      "Batch: 45, Loss: 0.7276473045349121, Accuracy: 0.76513671875\n",
      "Batch: 46, Loss: 0.7047744989395142, Accuracy: 0.7607421875\n",
      "Batch: 47, Loss: 0.7641991376876831, Accuracy: 0.759765625\n",
      "Batch: 48, Loss: 0.7276107668876648, Accuracy: 0.77099609375\n",
      "Batch: 49, Loss: 0.7175761461257935, Accuracy: 0.765625\n",
      "Batch: 50, Loss: 0.7522033452987671, Accuracy: 0.75341796875\n",
      "Batch: 51, Loss: 0.7411849498748779, Accuracy: 0.7607421875\n",
      "Batch: 52, Loss: 0.7032811641693115, Accuracy: 0.76708984375\n",
      "Batch: 53, Loss: 0.7058367729187012, Accuracy: 0.76416015625\n",
      "Batch: 54, Loss: 0.768555760383606, Accuracy: 0.7373046875\n",
      "Batch: 55, Loss: 0.7220640182495117, Accuracy: 0.7607421875\n",
      "Batch: 56, Loss: 0.7214937210083008, Accuracy: 0.77294921875\n",
      "Batch: 57, Loss: 0.807794451713562, Accuracy: 0.744140625\n",
      "Batch: 58, Loss: 0.7511767148971558, Accuracy: 0.74755859375\n",
      "Batch: 59, Loss: 0.8482470512390137, Accuracy: 0.7314453125\n",
      "Batch: 60, Loss: 0.741050124168396, Accuracy: 0.7685546875\n",
      "Batch: 61, Loss: 0.6764758825302124, Accuracy: 0.78466796875\n",
      "Batch: 62, Loss: 0.727656900882721, Accuracy: 0.77294921875\n",
      "Batch: 63, Loss: 0.7273937463760376, Accuracy: 0.7607421875\n",
      "Batch: 64, Loss: 0.7663826942443848, Accuracy: 0.7431640625\n",
      "Batch: 65, Loss: 0.8151044845581055, Accuracy: 0.744140625\n",
      "Batch: 66, Loss: 0.7795916795730591, Accuracy: 0.751953125\n",
      "Batch: 67, Loss: 0.783126711845398, Accuracy: 0.7470703125\n",
      "Batch: 68, Loss: 0.6955363750457764, Accuracy: 0.775390625\n",
      "Batch: 69, Loss: 0.7552590370178223, Accuracy: 0.75439453125\n",
      "Batch: 70, Loss: 0.7254450917243958, Accuracy: 0.763671875\n",
      "Batch: 71, Loss: 0.7429184913635254, Accuracy: 0.76025390625\n",
      "Batch: 72, Loss: 0.7513030171394348, Accuracy: 0.744140625\n",
      "Batch: 73, Loss: 0.7707747220993042, Accuracy: 0.744140625\n",
      "Batch: 74, Loss: 0.7740090489387512, Accuracy: 0.75048828125\n",
      "Batch: 75, Loss: 0.6985020637512207, Accuracy: 0.7685546875\n",
      "Batch: 76, Loss: 0.671209454536438, Accuracy: 0.7880859375\n",
      "Batch: 77, Loss: 0.6903671026229858, Accuracy: 0.7802734375\n",
      "Batch: 78, Loss: 0.7539554238319397, Accuracy: 0.75390625\n",
      "Batch: 79, Loss: 0.7365155816078186, Accuracy: 0.771484375\n",
      "Batch: 80, Loss: 0.7636088132858276, Accuracy: 0.7548828125\n",
      "Batch: 81, Loss: 0.7746541500091553, Accuracy: 0.7490234375\n",
      "Batch: 82, Loss: 0.7231515645980835, Accuracy: 0.76318359375\n",
      "Batch: 83, Loss: 0.6986696720123291, Accuracy: 0.7705078125\n",
      "Batch: 84, Loss: 0.6959395408630371, Accuracy: 0.7724609375\n",
      "Batch: 85, Loss: 0.7293139696121216, Accuracy: 0.7587890625\n",
      "Batch: 86, Loss: 0.8000887632369995, Accuracy: 0.751953125\n",
      "Batch: 87, Loss: 0.6868600845336914, Accuracy: 0.7763671875\n",
      "Batch: 88, Loss: 0.7437129020690918, Accuracy: 0.7685546875\n",
      "Batch: 89, Loss: 0.7437202334403992, Accuracy: 0.759765625\n",
      "Batch: 90, Loss: 0.7816624641418457, Accuracy: 0.7470703125\n",
      "Batch: 91, Loss: 0.7244452238082886, Accuracy: 0.7744140625\n",
      "Batch: 92, Loss: 0.8358940482139587, Accuracy: 0.72265625\n",
      "Batch: 93, Loss: 0.7990221381187439, Accuracy: 0.7412109375\n",
      "Batch: 94, Loss: 0.7694441080093384, Accuracy: 0.7509765625\n",
      "Batch: 95, Loss: 0.793938159942627, Accuracy: 0.75439453125\n",
      "Batch: 96, Loss: 0.7428671717643738, Accuracy: 0.76953125\n",
      "Batch: 97, Loss: 0.7219570279121399, Accuracy: 0.771484375\n",
      "Batch: 98, Loss: 0.795235276222229, Accuracy: 0.7490234375\n",
      "Batch: 99, Loss: 0.7365350127220154, Accuracy: 0.76708984375\n",
      "Batch: 100, Loss: 0.8199632167816162, Accuracy: 0.73828125\n",
      "Batch: 101, Loss: 0.8451486825942993, Accuracy: 0.7333984375\n",
      "Batch: 102, Loss: 0.7023485898971558, Accuracy: 0.7734375\n",
      "Batch: 103, Loss: 0.7683166861534119, Accuracy: 0.75\n",
      "Batch: 104, Loss: 0.7434698343276978, Accuracy: 0.76904296875\n",
      "Batch: 105, Loss: 0.7625752687454224, Accuracy: 0.75830078125\n",
      "Batch: 106, Loss: 0.7261465191841125, Accuracy: 0.76611328125\n",
      "Batch: 107, Loss: 0.7557646036148071, Accuracy: 0.75732421875\n",
      "Batch: 108, Loss: 0.7186608910560608, Accuracy: 0.7685546875\n",
      "Batch: 109, Loss: 0.7470251321792603, Accuracy: 0.76318359375\n",
      "Batch: 110, Loss: 0.7144455313682556, Accuracy: 0.7587890625\n",
      "Batch: 111, Loss: 0.6844196915626526, Accuracy: 0.78173828125\n",
      "Batch: 112, Loss: 0.7274359464645386, Accuracy: 0.76904296875\n",
      "Batch: 113, Loss: 0.7608879208564758, Accuracy: 0.75146484375\n",
      "Batch: 114, Loss: 0.7426042556762695, Accuracy: 0.759765625\n",
      "Batch: 115, Loss: 0.7351999878883362, Accuracy: 0.76611328125\n",
      "Batch: 116, Loss: 0.7483142614364624, Accuracy: 0.7578125\n",
      "Batch: 117, Loss: 0.7225483059883118, Accuracy: 0.77197265625\n",
      "Batch: 118, Loss: 0.745737612247467, Accuracy: 0.7568359375\n",
      "Batch: 119, Loss: 0.7221455574035645, Accuracy: 0.7607421875\n",
      "Batch: 120, Loss: 0.7179006338119507, Accuracy: 0.775390625\n",
      "Batch: 121, Loss: 0.7355762720108032, Accuracy: 0.75439453125\n",
      "Batch: 122, Loss: 0.6909363269805908, Accuracy: 0.76611328125\n",
      "Batch: 123, Loss: 0.6957296133041382, Accuracy: 0.78466796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 124, Loss: 0.692220151424408, Accuracy: 0.76708984375\n",
      "Batch: 125, Loss: 0.7346259951591492, Accuracy: 0.75927734375\n",
      "Batch: 126, Loss: 0.6939315795898438, Accuracy: 0.77392578125\n",
      "Batch: 127, Loss: 0.68406081199646, Accuracy: 0.78369140625\n",
      "Batch: 128, Loss: 0.801501989364624, Accuracy: 0.75146484375\n",
      "Batch: 129, Loss: 0.8406583070755005, Accuracy: 0.72998046875\n",
      "Batch: 130, Loss: 0.8386359214782715, Accuracy: 0.73388671875\n",
      "Batch: 131, Loss: 0.7644717693328857, Accuracy: 0.75830078125\n",
      "Batch: 132, Loss: 0.6893174648284912, Accuracy: 0.78564453125\n",
      "Batch: 133, Loss: 0.6884298920631409, Accuracy: 0.78515625\n",
      "Batch: 134, Loss: 0.7579189538955688, Accuracy: 0.75634765625\n",
      "Batch: 135, Loss: 0.7522212266921997, Accuracy: 0.759765625\n",
      "Batch: 136, Loss: 0.6944496631622314, Accuracy: 0.76611328125\n",
      "Batch: 137, Loss: 0.7456562519073486, Accuracy: 0.76025390625\n",
      "Batch: 138, Loss: 0.6542675495147705, Accuracy: 0.79443359375\n",
      "Batch: 139, Loss: 0.7081500291824341, Accuracy: 0.77880859375\n",
      "Batch: 140, Loss: 0.6733307242393494, Accuracy: 0.77685546875\n",
      "Batch: 141, Loss: 0.7723705172538757, Accuracy: 0.7412109375\n",
      "Batch: 142, Loss: 0.6899294853210449, Accuracy: 0.7763671875\n",
      "Batch: 143, Loss: 0.7003763914108276, Accuracy: 0.77734375\n",
      "Batch: 144, Loss: 0.7488120198249817, Accuracy: 0.751953125\n",
      "Batch: 145, Loss: 0.7533639669418335, Accuracy: 0.76953125\n",
      "Batch: 146, Loss: 0.7886908054351807, Accuracy: 0.74365234375\n",
      "Batch: 147, Loss: 0.725031852722168, Accuracy: 0.76171875\n",
      "Batch: 148, Loss: 0.7726892828941345, Accuracy: 0.74560546875\n",
      "Batch: 149, Loss: 0.7520129680633545, Accuracy: 0.76708984375\n",
      "Batch: 150, Loss: 0.6432088613510132, Accuracy: 0.7978515625\n",
      "Batch: 151, Loss: 0.6585440635681152, Accuracy: 0.78564453125\n",
      "Batch: 152, Loss: 0.7065635323524475, Accuracy: 0.771484375\n",
      "Batch: 153, Loss: 0.7051064968109131, Accuracy: 0.77685546875\n",
      "Batch: 154, Loss: 0.6855694055557251, Accuracy: 0.7705078125\n",
      "Batch: 155, Loss: 0.7828328013420105, Accuracy: 0.748046875\n",
      "Batch: 156, Loss: 0.6727553606033325, Accuracy: 0.78564453125\n",
      "Batch: 157, Loss: 0.6589866876602173, Accuracy: 0.77734375\n",
      "Batch: 158, Loss: 0.6672745943069458, Accuracy: 0.7880859375\n",
      "Batch: 159, Loss: 0.7029765844345093, Accuracy: 0.78125\n",
      "Batch: 160, Loss: 0.6948857307434082, Accuracy: 0.7802734375\n",
      "Batch: 161, Loss: 0.740318775177002, Accuracy: 0.7626953125\n",
      "Batch: 162, Loss: 0.6961137056350708, Accuracy: 0.7724609375\n",
      "Batch: 163, Loss: 0.7433788776397705, Accuracy: 0.76318359375\n",
      "Batch: 164, Loss: 0.8066303730010986, Accuracy: 0.744140625\n",
      "Batch: 165, Loss: 0.7155007123947144, Accuracy: 0.77734375\n",
      "Batch: 166, Loss: 0.7351411581039429, Accuracy: 0.76025390625\n",
      "Batch: 167, Loss: 0.7037255764007568, Accuracy: 0.76953125\n",
      "Batch: 168, Loss: 0.6577386856079102, Accuracy: 0.79345703125\n",
      "Batch: 169, Loss: 0.7204833030700684, Accuracy: 0.76904296875\n",
      "Batch: 170, Loss: 0.7717830538749695, Accuracy: 0.74853515625\n",
      "Batch: 171, Loss: 0.7024674415588379, Accuracy: 0.78515625\n",
      "Batch: 172, Loss: 0.6955493688583374, Accuracy: 0.76708984375\n",
      "Batch: 173, Loss: 0.7433110475540161, Accuracy: 0.7646484375\n",
      "Batch: 174, Loss: 0.6260579824447632, Accuracy: 0.7900390625\n",
      "Batch: 175, Loss: 0.7550562620162964, Accuracy: 0.75390625\n",
      "Batch: 176, Loss: 0.7790006995201111, Accuracy: 0.74365234375\n",
      "Batch: 177, Loss: 0.7199702262878418, Accuracy: 0.77734375\n",
      "Batch: 178, Loss: 0.6912170648574829, Accuracy: 0.78271484375\n",
      "Batch: 179, Loss: 0.7017084360122681, Accuracy: 0.779296875\n",
      "Batch: 180, Loss: 0.7716997861862183, Accuracy: 0.7568359375\n",
      "Epoch 46/200\n",
      "Batch: 1, Loss: 1.0591950416564941, Accuracy: 0.70556640625\n",
      "Batch: 2, Loss: 0.7079979181289673, Accuracy: 0.76123046875\n",
      "Batch: 3, Loss: 0.7270649075508118, Accuracy: 0.76513671875\n",
      "Batch: 4, Loss: 0.755041241645813, Accuracy: 0.7568359375\n",
      "Batch: 5, Loss: 0.71925950050354, Accuracy: 0.76806640625\n",
      "Batch: 6, Loss: 0.7564074397087097, Accuracy: 0.75244140625\n",
      "Batch: 7, Loss: 0.7209959030151367, Accuracy: 0.763671875\n",
      "Batch: 8, Loss: 0.7481364607810974, Accuracy: 0.7626953125\n",
      "Batch: 9, Loss: 0.7571027874946594, Accuracy: 0.76220703125\n",
      "Batch: 10, Loss: 0.7172956466674805, Accuracy: 0.77001953125\n",
      "Batch: 11, Loss: 0.780979573726654, Accuracy: 0.7412109375\n",
      "Batch: 12, Loss: 0.6651445031166077, Accuracy: 0.78369140625\n",
      "Batch: 13, Loss: 0.7393589019775391, Accuracy: 0.75830078125\n",
      "Batch: 14, Loss: 0.7073584198951721, Accuracy: 0.7802734375\n",
      "Batch: 15, Loss: 0.7564775943756104, Accuracy: 0.76318359375\n",
      "Batch: 16, Loss: 0.7804473638534546, Accuracy: 0.7451171875\n",
      "Batch: 17, Loss: 0.7139281034469604, Accuracy: 0.77783203125\n",
      "Batch: 18, Loss: 0.7745358347892761, Accuracy: 0.748046875\n",
      "Batch: 19, Loss: 0.771665096282959, Accuracy: 0.76123046875\n",
      "Batch: 20, Loss: 0.6577394604682922, Accuracy: 0.79248046875\n",
      "Batch: 21, Loss: 0.8062826991081238, Accuracy: 0.74609375\n",
      "Batch: 22, Loss: 0.6828206777572632, Accuracy: 0.775390625\n",
      "Batch: 23, Loss: 0.6956930160522461, Accuracy: 0.7763671875\n",
      "Batch: 24, Loss: 0.7263069152832031, Accuracy: 0.7666015625\n",
      "Batch: 25, Loss: 0.6823091506958008, Accuracy: 0.779296875\n",
      "Batch: 26, Loss: 0.7297617197036743, Accuracy: 0.7666015625\n",
      "Batch: 27, Loss: 0.7649831771850586, Accuracy: 0.75390625\n",
      "Batch: 28, Loss: 0.728280782699585, Accuracy: 0.76123046875\n",
      "Batch: 29, Loss: 0.7957615852355957, Accuracy: 0.74560546875\n",
      "Batch: 30, Loss: 0.748786985874176, Accuracy: 0.7568359375\n",
      "Batch: 31, Loss: 0.8451634645462036, Accuracy: 0.73779296875\n",
      "Batch: 32, Loss: 0.7815101742744446, Accuracy: 0.7490234375\n",
      "Batch: 33, Loss: 0.7823657989501953, Accuracy: 0.7490234375\n",
      "Batch: 34, Loss: 0.7978569269180298, Accuracy: 0.73974609375\n",
      "Batch: 35, Loss: 0.8077993392944336, Accuracy: 0.7421875\n",
      "Batch: 36, Loss: 0.7902553677558899, Accuracy: 0.74951171875\n",
      "Batch: 37, Loss: 0.7676485776901245, Accuracy: 0.740234375\n",
      "Batch: 38, Loss: 0.8095218539237976, Accuracy: 0.7421875\n",
      "Batch: 39, Loss: 0.7633678913116455, Accuracy: 0.75341796875\n",
      "Batch: 40, Loss: 0.8155231475830078, Accuracy: 0.74462890625\n",
      "Batch: 41, Loss: 0.7643037438392639, Accuracy: 0.751953125\n",
      "Batch: 42, Loss: 0.7676966190338135, Accuracy: 0.744140625\n",
      "Batch: 43, Loss: 0.7339498400688171, Accuracy: 0.76904296875\n",
      "Batch: 44, Loss: 0.6813423037528992, Accuracy: 0.78466796875\n",
      "Batch: 45, Loss: 0.7253780364990234, Accuracy: 0.7666015625\n",
      "Batch: 46, Loss: 0.7001149654388428, Accuracy: 0.76123046875\n",
      "Batch: 47, Loss: 0.7752897143363953, Accuracy: 0.75146484375\n",
      "Batch: 48, Loss: 0.7326257228851318, Accuracy: 0.759765625\n",
      "Batch: 49, Loss: 0.7138277292251587, Accuracy: 0.77392578125\n",
      "Batch: 50, Loss: 0.7393968105316162, Accuracy: 0.7587890625\n",
      "Batch: 51, Loss: 0.7294673919677734, Accuracy: 0.76513671875\n",
      "Batch: 52, Loss: 0.7082794904708862, Accuracy: 0.77001953125\n",
      "Batch: 53, Loss: 0.7187140583992004, Accuracy: 0.763671875\n",
      "Batch: 54, Loss: 0.7641235589981079, Accuracy: 0.74951171875\n",
      "Batch: 55, Loss: 0.7246241569519043, Accuracy: 0.7607421875\n",
      "Batch: 56, Loss: 0.7066805958747864, Accuracy: 0.76416015625\n",
      "Batch: 57, Loss: 0.7824856638908386, Accuracy: 0.7529296875\n",
      "Batch: 58, Loss: 0.7505818009376526, Accuracy: 0.7587890625\n",
      "Batch: 59, Loss: 0.8343230485916138, Accuracy: 0.73583984375\n",
      "Batch: 60, Loss: 0.7280004024505615, Accuracy: 0.7744140625\n",
      "Batch: 61, Loss: 0.6937684416770935, Accuracy: 0.7744140625\n",
      "Batch: 62, Loss: 0.7070357799530029, Accuracy: 0.77685546875\n",
      "Batch: 63, Loss: 0.7355725765228271, Accuracy: 0.7607421875\n",
      "Batch: 64, Loss: 0.7608828544616699, Accuracy: 0.74658203125\n",
      "Batch: 65, Loss: 0.7849503755569458, Accuracy: 0.74658203125\n",
      "Batch: 66, Loss: 0.7810121774673462, Accuracy: 0.7509765625\n",
      "Batch: 67, Loss: 0.7721958160400391, Accuracy: 0.75\n",
      "Batch: 68, Loss: 0.700762152671814, Accuracy: 0.77392578125\n",
      "Batch: 69, Loss: 0.7474938631057739, Accuracy: 0.75390625\n",
      "Batch: 70, Loss: 0.7356655597686768, Accuracy: 0.75537109375\n",
      "Batch: 71, Loss: 0.720372200012207, Accuracy: 0.76318359375\n",
      "Batch: 72, Loss: 0.7483526468276978, Accuracy: 0.73681640625\n",
      "Batch: 73, Loss: 0.7467396259307861, Accuracy: 0.75\n",
      "Batch: 74, Loss: 0.7508202791213989, Accuracy: 0.76171875\n",
      "Batch: 75, Loss: 0.6964179277420044, Accuracy: 0.7626953125\n",
      "Batch: 76, Loss: 0.6740894317626953, Accuracy: 0.78857421875\n",
      "Batch: 77, Loss: 0.6806538105010986, Accuracy: 0.783203125\n",
      "Batch: 78, Loss: 0.7391250133514404, Accuracy: 0.76806640625\n",
      "Batch: 79, Loss: 0.7256567478179932, Accuracy: 0.7607421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 80, Loss: 0.7532397508621216, Accuracy: 0.74658203125\n",
      "Batch: 81, Loss: 0.7585118412971497, Accuracy: 0.75830078125\n",
      "Batch: 82, Loss: 0.7183173298835754, Accuracy: 0.76611328125\n",
      "Batch: 83, Loss: 0.6933928728103638, Accuracy: 0.77001953125\n",
      "Batch: 84, Loss: 0.6863903999328613, Accuracy: 0.77490234375\n",
      "Batch: 85, Loss: 0.7194180488586426, Accuracy: 0.763671875\n",
      "Batch: 86, Loss: 0.7800997495651245, Accuracy: 0.76025390625\n",
      "Batch: 87, Loss: 0.6875801682472229, Accuracy: 0.78076171875\n",
      "Batch: 88, Loss: 0.7438819408416748, Accuracy: 0.76318359375\n",
      "Batch: 89, Loss: 0.7279021739959717, Accuracy: 0.7734375\n",
      "Batch: 90, Loss: 0.7915592789649963, Accuracy: 0.7353515625\n",
      "Batch: 91, Loss: 0.6967617869377136, Accuracy: 0.76953125\n",
      "Batch: 92, Loss: 0.8142368793487549, Accuracy: 0.73046875\n",
      "Batch: 93, Loss: 0.7682503461837769, Accuracy: 0.75048828125\n",
      "Batch: 94, Loss: 0.7617524862289429, Accuracy: 0.75048828125\n",
      "Batch: 95, Loss: 0.7914834022521973, Accuracy: 0.748046875\n",
      "Batch: 96, Loss: 0.7487738728523254, Accuracy: 0.75830078125\n",
      "Batch: 97, Loss: 0.7007190585136414, Accuracy: 0.779296875\n",
      "Batch: 98, Loss: 0.7785300016403198, Accuracy: 0.75439453125\n",
      "Batch: 99, Loss: 0.7141989469528198, Accuracy: 0.7724609375\n",
      "Batch: 100, Loss: 0.7904930710792542, Accuracy: 0.7470703125\n",
      "Batch: 101, Loss: 0.8346226215362549, Accuracy: 0.7373046875\n",
      "Batch: 102, Loss: 0.7037723660469055, Accuracy: 0.77197265625\n",
      "Batch: 103, Loss: 0.7707573175430298, Accuracy: 0.75732421875\n",
      "Batch: 104, Loss: 0.7411401271820068, Accuracy: 0.76171875\n",
      "Batch: 105, Loss: 0.7821987867355347, Accuracy: 0.74560546875\n",
      "Batch: 106, Loss: 0.7179629802703857, Accuracy: 0.77197265625\n",
      "Batch: 107, Loss: 0.7414873242378235, Accuracy: 0.76318359375\n",
      "Batch: 108, Loss: 0.7196481227874756, Accuracy: 0.77490234375\n",
      "Batch: 109, Loss: 0.734899640083313, Accuracy: 0.763671875\n",
      "Batch: 110, Loss: 0.7149101495742798, Accuracy: 0.76123046875\n",
      "Batch: 111, Loss: 0.6690806746482849, Accuracy: 0.79052734375\n",
      "Batch: 112, Loss: 0.7338883876800537, Accuracy: 0.76611328125\n",
      "Batch: 113, Loss: 0.7477052211761475, Accuracy: 0.75439453125\n",
      "Batch: 114, Loss: 0.7390097975730896, Accuracy: 0.763671875\n",
      "Batch: 115, Loss: 0.7325973510742188, Accuracy: 0.7646484375\n",
      "Batch: 116, Loss: 0.7372562885284424, Accuracy: 0.765625\n",
      "Batch: 117, Loss: 0.7142137289047241, Accuracy: 0.7646484375\n",
      "Batch: 118, Loss: 0.7348135709762573, Accuracy: 0.7587890625\n",
      "Batch: 119, Loss: 0.7194632291793823, Accuracy: 0.76123046875\n",
      "Batch: 120, Loss: 0.690653383731842, Accuracy: 0.77197265625\n",
      "Batch: 121, Loss: 0.7291351556777954, Accuracy: 0.767578125\n",
      "Batch: 122, Loss: 0.6782078742980957, Accuracy: 0.7763671875\n",
      "Batch: 123, Loss: 0.6886720061302185, Accuracy: 0.78466796875\n",
      "Batch: 124, Loss: 0.6782423257827759, Accuracy: 0.77685546875\n",
      "Batch: 125, Loss: 0.7350358963012695, Accuracy: 0.76123046875\n",
      "Batch: 126, Loss: 0.7011580467224121, Accuracy: 0.76416015625\n",
      "Batch: 127, Loss: 0.6651683449745178, Accuracy: 0.7890625\n",
      "Batch: 128, Loss: 0.8126637935638428, Accuracy: 0.7431640625\n",
      "Batch: 129, Loss: 0.8350543975830078, Accuracy: 0.7294921875\n",
      "Batch: 130, Loss: 0.8309968113899231, Accuracy: 0.73779296875\n",
      "Batch: 131, Loss: 0.7651112675666809, Accuracy: 0.74951171875\n",
      "Batch: 132, Loss: 0.6964117884635925, Accuracy: 0.77490234375\n",
      "Batch: 133, Loss: 0.6826493740081787, Accuracy: 0.7822265625\n",
      "Batch: 134, Loss: 0.7557684183120728, Accuracy: 0.75634765625\n",
      "Batch: 135, Loss: 0.7339752316474915, Accuracy: 0.759765625\n",
      "Batch: 136, Loss: 0.6898376941680908, Accuracy: 0.78173828125\n",
      "Batch: 137, Loss: 0.7426348924636841, Accuracy: 0.76220703125\n",
      "Batch: 138, Loss: 0.6584973931312561, Accuracy: 0.7978515625\n",
      "Batch: 139, Loss: 0.7181518077850342, Accuracy: 0.76904296875\n",
      "Batch: 140, Loss: 0.6607644557952881, Accuracy: 0.7958984375\n",
      "Batch: 141, Loss: 0.7625901103019714, Accuracy: 0.75\n",
      "Batch: 142, Loss: 0.68715900182724, Accuracy: 0.77880859375\n",
      "Batch: 143, Loss: 0.7064131498336792, Accuracy: 0.779296875\n",
      "Batch: 144, Loss: 0.767897367477417, Accuracy: 0.76416015625\n",
      "Batch: 145, Loss: 0.728529691696167, Accuracy: 0.7763671875\n",
      "Batch: 146, Loss: 0.7712531089782715, Accuracy: 0.75439453125\n",
      "Batch: 147, Loss: 0.7279248237609863, Accuracy: 0.7607421875\n",
      "Batch: 148, Loss: 0.7519108057022095, Accuracy: 0.75439453125\n",
      "Batch: 149, Loss: 0.7646021842956543, Accuracy: 0.75244140625\n",
      "Batch: 150, Loss: 0.6468780040740967, Accuracy: 0.7919921875\n",
      "Batch: 151, Loss: 0.6575274467468262, Accuracy: 0.78662109375\n",
      "Batch: 152, Loss: 0.6797177195549011, Accuracy: 0.77685546875\n",
      "Batch: 153, Loss: 0.6939960718154907, Accuracy: 0.7822265625\n",
      "Batch: 154, Loss: 0.7021273374557495, Accuracy: 0.7666015625\n",
      "Batch: 155, Loss: 0.7545276880264282, Accuracy: 0.7548828125\n",
      "Batch: 156, Loss: 0.6602733135223389, Accuracy: 0.78515625\n",
      "Batch: 157, Loss: 0.6379260420799255, Accuracy: 0.78515625\n",
      "Batch: 158, Loss: 0.6812347173690796, Accuracy: 0.787109375\n",
      "Batch: 159, Loss: 0.65962815284729, Accuracy: 0.796875\n",
      "Batch: 160, Loss: 0.701696515083313, Accuracy: 0.7734375\n",
      "Batch: 161, Loss: 0.726151704788208, Accuracy: 0.76220703125\n",
      "Batch: 162, Loss: 0.6740066409111023, Accuracy: 0.77587890625\n",
      "Batch: 163, Loss: 0.7432391047477722, Accuracy: 0.7509765625\n",
      "Batch: 164, Loss: 0.7977575063705444, Accuracy: 0.7431640625\n",
      "Batch: 165, Loss: 0.7140343189239502, Accuracy: 0.77734375\n",
      "Batch: 166, Loss: 0.7297008037567139, Accuracy: 0.77294921875\n",
      "Batch: 167, Loss: 0.7023538947105408, Accuracy: 0.775390625\n",
      "Batch: 168, Loss: 0.6324412226676941, Accuracy: 0.8017578125\n",
      "Batch: 169, Loss: 0.7259483337402344, Accuracy: 0.763671875\n",
      "Batch: 170, Loss: 0.7602724432945251, Accuracy: 0.7529296875\n",
      "Batch: 171, Loss: 0.7018795013427734, Accuracy: 0.779296875\n",
      "Batch: 172, Loss: 0.6880471706390381, Accuracy: 0.7705078125\n",
      "Batch: 173, Loss: 0.7521615028381348, Accuracy: 0.755859375\n",
      "Batch: 174, Loss: 0.6214701533317566, Accuracy: 0.794921875\n",
      "Batch: 175, Loss: 0.7380647659301758, Accuracy: 0.75927734375\n",
      "Batch: 176, Loss: 0.7821938395500183, Accuracy: 0.7587890625\n",
      "Batch: 177, Loss: 0.6955291032791138, Accuracy: 0.771484375\n",
      "Batch: 178, Loss: 0.6763328313827515, Accuracy: 0.77734375\n",
      "Batch: 179, Loss: 0.7141468524932861, Accuracy: 0.77197265625\n",
      "Batch: 180, Loss: 0.7511624097824097, Accuracy: 0.75830078125\n",
      "Epoch 47/200\n",
      "Batch: 1, Loss: 1.0638701915740967, Accuracy: 0.70361328125\n",
      "Batch: 2, Loss: 0.720883846282959, Accuracy: 0.7568359375\n",
      "Batch: 3, Loss: 0.7290099859237671, Accuracy: 0.7578125\n",
      "Batch: 4, Loss: 0.7512087821960449, Accuracy: 0.7509765625\n",
      "Batch: 5, Loss: 0.7317857146263123, Accuracy: 0.765625\n",
      "Batch: 6, Loss: 0.7443729043006897, Accuracy: 0.7587890625\n",
      "Batch: 7, Loss: 0.6900964379310608, Accuracy: 0.7734375\n",
      "Batch: 8, Loss: 0.7235527634620667, Accuracy: 0.767578125\n",
      "Batch: 9, Loss: 0.7828815579414368, Accuracy: 0.74853515625\n",
      "Batch: 10, Loss: 0.719739556312561, Accuracy: 0.76806640625\n",
      "Batch: 11, Loss: 0.7760601043701172, Accuracy: 0.75\n",
      "Batch: 12, Loss: 0.6630533933639526, Accuracy: 0.78369140625\n",
      "Batch: 13, Loss: 0.7083010673522949, Accuracy: 0.77294921875\n",
      "Batch: 14, Loss: 0.7149140238761902, Accuracy: 0.77490234375\n",
      "Batch: 15, Loss: 0.7433878779411316, Accuracy: 0.767578125\n",
      "Batch: 16, Loss: 0.7772800922393799, Accuracy: 0.74853515625\n",
      "Batch: 17, Loss: 0.7105597257614136, Accuracy: 0.78125\n",
      "Batch: 18, Loss: 0.7642465829849243, Accuracy: 0.76025390625\n",
      "Batch: 19, Loss: 0.7712439298629761, Accuracy: 0.75146484375\n",
      "Batch: 20, Loss: 0.6519525051116943, Accuracy: 0.78857421875\n",
      "Batch: 21, Loss: 0.7697321176528931, Accuracy: 0.751953125\n",
      "Batch: 22, Loss: 0.6853396892547607, Accuracy: 0.77978515625\n",
      "Batch: 23, Loss: 0.6753811836242676, Accuracy: 0.7861328125\n",
      "Batch: 24, Loss: 0.723275899887085, Accuracy: 0.77001953125\n",
      "Batch: 25, Loss: 0.6870710849761963, Accuracy: 0.783203125\n",
      "Batch: 26, Loss: 0.7282719612121582, Accuracy: 0.75634765625\n",
      "Batch: 27, Loss: 0.7624622583389282, Accuracy: 0.75634765625\n",
      "Batch: 28, Loss: 0.7191051244735718, Accuracy: 0.765625\n",
      "Batch: 29, Loss: 0.7717479467391968, Accuracy: 0.755859375\n",
      "Batch: 30, Loss: 0.7343264818191528, Accuracy: 0.7705078125\n",
      "Batch: 31, Loss: 0.840615451335907, Accuracy: 0.73876953125\n",
      "Batch: 32, Loss: 0.7704137563705444, Accuracy: 0.76611328125\n",
      "Batch: 33, Loss: 0.759211540222168, Accuracy: 0.7578125\n",
      "Batch: 34, Loss: 0.803209662437439, Accuracy: 0.75146484375\n",
      "Batch: 35, Loss: 0.8164066672325134, Accuracy: 0.73828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 36, Loss: 0.7712670564651489, Accuracy: 0.759765625\n",
      "Batch: 37, Loss: 0.7709318399429321, Accuracy: 0.7529296875\n",
      "Batch: 38, Loss: 0.7897757887840271, Accuracy: 0.751953125\n",
      "Batch: 39, Loss: 0.7531865239143372, Accuracy: 0.75830078125\n",
      "Batch: 40, Loss: 0.8135113716125488, Accuracy: 0.734375\n",
      "Batch: 41, Loss: 0.7836508750915527, Accuracy: 0.74609375\n",
      "Batch: 42, Loss: 0.7566258907318115, Accuracy: 0.75341796875\n",
      "Batch: 43, Loss: 0.7175951600074768, Accuracy: 0.775390625\n",
      "Batch: 44, Loss: 0.652151346206665, Accuracy: 0.7939453125\n",
      "Batch: 45, Loss: 0.7211318016052246, Accuracy: 0.76953125\n",
      "Batch: 46, Loss: 0.6970471143722534, Accuracy: 0.76123046875\n",
      "Batch: 47, Loss: 0.7485445737838745, Accuracy: 0.763671875\n",
      "Batch: 48, Loss: 0.7190911173820496, Accuracy: 0.77001953125\n",
      "Batch: 49, Loss: 0.6961835622787476, Accuracy: 0.7763671875\n",
      "Batch: 50, Loss: 0.743064284324646, Accuracy: 0.75732421875\n",
      "Batch: 51, Loss: 0.7262719869613647, Accuracy: 0.76220703125\n",
      "Batch: 52, Loss: 0.7070227861404419, Accuracy: 0.77001953125\n",
      "Batch: 53, Loss: 0.7048842906951904, Accuracy: 0.77001953125\n",
      "Batch: 54, Loss: 0.7431897521018982, Accuracy: 0.75341796875\n",
      "Batch: 55, Loss: 0.7028701305389404, Accuracy: 0.7744140625\n",
      "Batch: 56, Loss: 0.7029181718826294, Accuracy: 0.77099609375\n",
      "Batch: 57, Loss: 0.7725877165794373, Accuracy: 0.76416015625\n",
      "Batch: 58, Loss: 0.7328101396560669, Accuracy: 0.74658203125\n",
      "Batch: 59, Loss: 0.8317523002624512, Accuracy: 0.74658203125\n",
      "Batch: 60, Loss: 0.717340350151062, Accuracy: 0.77587890625\n",
      "Batch: 61, Loss: 0.6949071288108826, Accuracy: 0.76806640625\n",
      "Batch: 62, Loss: 0.7020193934440613, Accuracy: 0.7724609375\n",
      "Batch: 63, Loss: 0.7160651683807373, Accuracy: 0.76171875\n",
      "Batch: 64, Loss: 0.7420438528060913, Accuracy: 0.76318359375\n",
      "Batch: 65, Loss: 0.7895535230636597, Accuracy: 0.74072265625\n",
      "Batch: 66, Loss: 0.7455101013183594, Accuracy: 0.7529296875\n",
      "Batch: 67, Loss: 0.7539255023002625, Accuracy: 0.75634765625\n",
      "Batch: 68, Loss: 0.6694468259811401, Accuracy: 0.7734375\n",
      "Batch: 69, Loss: 0.7420617938041687, Accuracy: 0.7568359375\n",
      "Batch: 70, Loss: 0.7274531126022339, Accuracy: 0.7607421875\n",
      "Batch: 71, Loss: 0.7323033809661865, Accuracy: 0.75634765625\n",
      "Batch: 72, Loss: 0.7520059943199158, Accuracy: 0.75048828125\n",
      "Batch: 73, Loss: 0.7678256034851074, Accuracy: 0.748046875\n",
      "Batch: 74, Loss: 0.7560769319534302, Accuracy: 0.75830078125\n",
      "Batch: 75, Loss: 0.6777516007423401, Accuracy: 0.77783203125\n",
      "Batch: 76, Loss: 0.6627368927001953, Accuracy: 0.78564453125\n",
      "Batch: 77, Loss: 0.6715611815452576, Accuracy: 0.783203125\n",
      "Batch: 78, Loss: 0.7163188457489014, Accuracy: 0.77294921875\n",
      "Batch: 79, Loss: 0.7193528413772583, Accuracy: 0.7646484375\n",
      "Batch: 80, Loss: 0.7609987258911133, Accuracy: 0.7587890625\n",
      "Batch: 81, Loss: 0.7519339919090271, Accuracy: 0.76220703125\n",
      "Batch: 82, Loss: 0.6899930238723755, Accuracy: 0.77392578125\n",
      "Batch: 83, Loss: 0.6748124361038208, Accuracy: 0.779296875\n",
      "Batch: 84, Loss: 0.680759608745575, Accuracy: 0.794921875\n",
      "Batch: 85, Loss: 0.7230827808380127, Accuracy: 0.76123046875\n",
      "Batch: 86, Loss: 0.7669471502304077, Accuracy: 0.77099609375\n",
      "Batch: 87, Loss: 0.6774698495864868, Accuracy: 0.78271484375\n",
      "Batch: 88, Loss: 0.7431041598320007, Accuracy: 0.7705078125\n",
      "Batch: 89, Loss: 0.7286479473114014, Accuracy: 0.76220703125\n",
      "Batch: 90, Loss: 0.776607096195221, Accuracy: 0.74169921875\n",
      "Batch: 91, Loss: 0.7089294195175171, Accuracy: 0.7763671875\n",
      "Batch: 92, Loss: 0.8220615386962891, Accuracy: 0.72998046875\n",
      "Batch: 93, Loss: 0.7616585493087769, Accuracy: 0.74853515625\n",
      "Batch: 94, Loss: 0.7499881386756897, Accuracy: 0.75634765625\n",
      "Batch: 95, Loss: 0.78229820728302, Accuracy: 0.7529296875\n",
      "Batch: 96, Loss: 0.7342696189880371, Accuracy: 0.76025390625\n",
      "Batch: 97, Loss: 0.7038077116012573, Accuracy: 0.78076171875\n",
      "Batch: 98, Loss: 0.7752900123596191, Accuracy: 0.755859375\n",
      "Batch: 99, Loss: 0.7174897193908691, Accuracy: 0.76416015625\n",
      "Batch: 100, Loss: 0.7895038723945618, Accuracy: 0.74853515625\n",
      "Batch: 101, Loss: 0.8151775002479553, Accuracy: 0.74169921875\n",
      "Batch: 102, Loss: 0.694720447063446, Accuracy: 0.77490234375\n",
      "Batch: 103, Loss: 0.7453532218933105, Accuracy: 0.759765625\n",
      "Batch: 104, Loss: 0.7186849117279053, Accuracy: 0.7646484375\n",
      "Batch: 105, Loss: 0.7639197111129761, Accuracy: 0.75537109375\n",
      "Batch: 106, Loss: 0.7055324912071228, Accuracy: 0.7666015625\n",
      "Batch: 107, Loss: 0.7479661703109741, Accuracy: 0.75634765625\n",
      "Batch: 108, Loss: 0.7219412326812744, Accuracy: 0.759765625\n",
      "Batch: 109, Loss: 0.7072888612747192, Accuracy: 0.77001953125\n",
      "Batch: 110, Loss: 0.7100109457969666, Accuracy: 0.7626953125\n",
      "Batch: 111, Loss: 0.6453943252563477, Accuracy: 0.7998046875\n",
      "Batch: 112, Loss: 0.7165623903274536, Accuracy: 0.76953125\n",
      "Batch: 113, Loss: 0.7685719132423401, Accuracy: 0.74560546875\n",
      "Batch: 114, Loss: 0.7255216836929321, Accuracy: 0.75830078125\n",
      "Batch: 115, Loss: 0.7422976493835449, Accuracy: 0.763671875\n",
      "Batch: 116, Loss: 0.7125396728515625, Accuracy: 0.76220703125\n",
      "Batch: 117, Loss: 0.724976122379303, Accuracy: 0.7724609375\n",
      "Batch: 118, Loss: 0.7248315811157227, Accuracy: 0.75732421875\n",
      "Batch: 119, Loss: 0.7190281748771667, Accuracy: 0.76904296875\n",
      "Batch: 120, Loss: 0.7239606976509094, Accuracy: 0.76025390625\n",
      "Batch: 121, Loss: 0.7196918725967407, Accuracy: 0.76953125\n",
      "Batch: 122, Loss: 0.6796698570251465, Accuracy: 0.76904296875\n",
      "Batch: 123, Loss: 0.6901906728744507, Accuracy: 0.78125\n",
      "Batch: 124, Loss: 0.6862852573394775, Accuracy: 0.7666015625\n",
      "Batch: 125, Loss: 0.7202409505844116, Accuracy: 0.76953125\n",
      "Batch: 126, Loss: 0.6986038684844971, Accuracy: 0.77099609375\n",
      "Batch: 127, Loss: 0.6576049327850342, Accuracy: 0.78759765625\n",
      "Batch: 128, Loss: 0.7817344069480896, Accuracy: 0.751953125\n",
      "Batch: 129, Loss: 0.832680344581604, Accuracy: 0.73388671875\n",
      "Batch: 130, Loss: 0.8167121410369873, Accuracy: 0.73974609375\n",
      "Batch: 131, Loss: 0.7498292922973633, Accuracy: 0.75830078125\n",
      "Batch: 132, Loss: 0.6876791715621948, Accuracy: 0.779296875\n",
      "Batch: 133, Loss: 0.6717069149017334, Accuracy: 0.78955078125\n",
      "Batch: 134, Loss: 0.7545239329338074, Accuracy: 0.7548828125\n",
      "Batch: 135, Loss: 0.741575300693512, Accuracy: 0.75830078125\n",
      "Batch: 136, Loss: 0.6765202879905701, Accuracy: 0.77880859375\n",
      "Batch: 137, Loss: 0.733817458152771, Accuracy: 0.76416015625\n",
      "Batch: 138, Loss: 0.6641440987586975, Accuracy: 0.80224609375\n",
      "Batch: 139, Loss: 0.7040660381317139, Accuracy: 0.76806640625\n",
      "Batch: 140, Loss: 0.6665788292884827, Accuracy: 0.7783203125\n",
      "Batch: 141, Loss: 0.7647727131843567, Accuracy: 0.7509765625\n",
      "Batch: 142, Loss: 0.6778520941734314, Accuracy: 0.76611328125\n",
      "Batch: 143, Loss: 0.7004494667053223, Accuracy: 0.779296875\n",
      "Batch: 144, Loss: 0.7723476886749268, Accuracy: 0.75927734375\n",
      "Batch: 145, Loss: 0.7255027294158936, Accuracy: 0.76806640625\n",
      "Batch: 146, Loss: 0.7733514308929443, Accuracy: 0.74365234375\n",
      "Batch: 147, Loss: 0.7403491735458374, Accuracy: 0.7626953125\n",
      "Batch: 148, Loss: 0.776588499546051, Accuracy: 0.7412109375\n",
      "Batch: 149, Loss: 0.7396194934844971, Accuracy: 0.76318359375\n",
      "Batch: 150, Loss: 0.6448543071746826, Accuracy: 0.7890625\n",
      "Batch: 151, Loss: 0.6467815041542053, Accuracy: 0.791015625\n",
      "Batch: 152, Loss: 0.6786278486251831, Accuracy: 0.7783203125\n",
      "Batch: 153, Loss: 0.6845604777336121, Accuracy: 0.779296875\n",
      "Batch: 154, Loss: 0.6760306358337402, Accuracy: 0.77734375\n",
      "Batch: 155, Loss: 0.7606310248374939, Accuracy: 0.76025390625\n",
      "Batch: 156, Loss: 0.648777961730957, Accuracy: 0.78662109375\n",
      "Batch: 157, Loss: 0.6335488557815552, Accuracy: 0.79052734375\n",
      "Batch: 158, Loss: 0.6634678244590759, Accuracy: 0.78955078125\n",
      "Batch: 159, Loss: 0.6677024364471436, Accuracy: 0.79443359375\n",
      "Batch: 160, Loss: 0.7022029161453247, Accuracy: 0.77685546875\n",
      "Batch: 161, Loss: 0.7169715166091919, Accuracy: 0.77001953125\n",
      "Batch: 162, Loss: 0.6787445545196533, Accuracy: 0.78173828125\n",
      "Batch: 163, Loss: 0.7310702800750732, Accuracy: 0.75244140625\n",
      "Batch: 164, Loss: 0.7933844327926636, Accuracy: 0.75341796875\n",
      "Batch: 165, Loss: 0.7076418399810791, Accuracy: 0.77783203125\n",
      "Batch: 166, Loss: 0.7207028269767761, Accuracy: 0.7734375\n",
      "Batch: 167, Loss: 0.7049412131309509, Accuracy: 0.77685546875\n",
      "Batch: 168, Loss: 0.645675539970398, Accuracy: 0.78662109375\n",
      "Batch: 169, Loss: 0.7144532799720764, Accuracy: 0.76611328125\n",
      "Batch: 170, Loss: 0.7407389283180237, Accuracy: 0.7607421875\n",
      "Batch: 171, Loss: 0.6857579350471497, Accuracy: 0.78076171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 172, Loss: 0.6689009666442871, Accuracy: 0.7685546875\n",
      "Batch: 173, Loss: 0.7502893209457397, Accuracy: 0.75927734375\n",
      "Batch: 174, Loss: 0.6180506944656372, Accuracy: 0.7919921875\n",
      "Batch: 175, Loss: 0.7376747727394104, Accuracy: 0.76220703125\n",
      "Batch: 176, Loss: 0.7513211965560913, Accuracy: 0.7587890625\n",
      "Batch: 177, Loss: 0.7076011300086975, Accuracy: 0.77490234375\n",
      "Batch: 178, Loss: 0.6742662191390991, Accuracy: 0.78125\n",
      "Batch: 179, Loss: 0.7023400068283081, Accuracy: 0.77001953125\n",
      "Batch: 180, Loss: 0.7449214458465576, Accuracy: 0.7666015625\n",
      "Epoch 48/200\n",
      "Batch: 1, Loss: 1.085714340209961, Accuracy: 0.69482421875\n",
      "Batch: 2, Loss: 0.7186189889907837, Accuracy: 0.755859375\n",
      "Batch: 3, Loss: 0.7286950945854187, Accuracy: 0.7646484375\n",
      "Batch: 4, Loss: 0.7345722913742065, Accuracy: 0.7568359375\n",
      "Batch: 5, Loss: 0.7365050911903381, Accuracy: 0.75244140625\n",
      "Batch: 6, Loss: 0.7336474657058716, Accuracy: 0.76416015625\n",
      "Batch: 7, Loss: 0.7181910276412964, Accuracy: 0.76953125\n",
      "Batch: 8, Loss: 0.7122018337249756, Accuracy: 0.7724609375\n",
      "Batch: 9, Loss: 0.7770881652832031, Accuracy: 0.75244140625\n",
      "Batch: 10, Loss: 0.7170469760894775, Accuracy: 0.76953125\n",
      "Batch: 11, Loss: 0.7734572887420654, Accuracy: 0.75146484375\n",
      "Batch: 12, Loss: 0.6679729223251343, Accuracy: 0.78271484375\n",
      "Batch: 13, Loss: 0.7415180206298828, Accuracy: 0.7548828125\n",
      "Batch: 14, Loss: 0.7024503946304321, Accuracy: 0.78173828125\n",
      "Batch: 15, Loss: 0.7241196036338806, Accuracy: 0.7666015625\n",
      "Batch: 16, Loss: 0.7691017389297485, Accuracy: 0.75048828125\n",
      "Batch: 17, Loss: 0.7312180399894714, Accuracy: 0.77001953125\n",
      "Batch: 18, Loss: 0.7429665327072144, Accuracy: 0.75537109375\n",
      "Batch: 19, Loss: 0.7552942633628845, Accuracy: 0.7646484375\n",
      "Batch: 20, Loss: 0.6536269187927246, Accuracy: 0.7880859375\n",
      "Batch: 21, Loss: 0.7600789666175842, Accuracy: 0.7587890625\n",
      "Batch: 22, Loss: 0.6722245216369629, Accuracy: 0.7841796875\n",
      "Batch: 23, Loss: 0.673109769821167, Accuracy: 0.78466796875\n",
      "Batch: 24, Loss: 0.7154019474983215, Accuracy: 0.77392578125\n",
      "Batch: 25, Loss: 0.6910618543624878, Accuracy: 0.787109375\n",
      "Batch: 26, Loss: 0.7052627205848694, Accuracy: 0.7802734375\n",
      "Batch: 27, Loss: 0.7607548832893372, Accuracy: 0.75439453125\n",
      "Batch: 28, Loss: 0.707685649394989, Accuracy: 0.76806640625\n",
      "Batch: 29, Loss: 0.757123589515686, Accuracy: 0.7578125\n",
      "Batch: 30, Loss: 0.734859824180603, Accuracy: 0.7763671875\n",
      "Batch: 31, Loss: 0.8200271129608154, Accuracy: 0.74072265625\n",
      "Batch: 32, Loss: 0.7714478969573975, Accuracy: 0.75\n",
      "Batch: 33, Loss: 0.7571602463722229, Accuracy: 0.7529296875\n",
      "Batch: 34, Loss: 0.802383303642273, Accuracy: 0.7392578125\n",
      "Batch: 35, Loss: 0.7944796085357666, Accuracy: 0.73876953125\n",
      "Batch: 36, Loss: 0.7842969298362732, Accuracy: 0.7548828125\n",
      "Batch: 37, Loss: 0.7667213082313538, Accuracy: 0.75390625\n",
      "Batch: 38, Loss: 0.8122389316558838, Accuracy: 0.73583984375\n",
      "Batch: 39, Loss: 0.7269209623336792, Accuracy: 0.7666015625\n",
      "Batch: 40, Loss: 0.7932966947555542, Accuracy: 0.74560546875\n",
      "Batch: 41, Loss: 0.7639354467391968, Accuracy: 0.75830078125\n",
      "Batch: 42, Loss: 0.7440003156661987, Accuracy: 0.75537109375\n",
      "Batch: 43, Loss: 0.7264288663864136, Accuracy: 0.77587890625\n",
      "Batch: 44, Loss: 0.6336222290992737, Accuracy: 0.7919921875\n",
      "Batch: 45, Loss: 0.7056078910827637, Accuracy: 0.77099609375\n",
      "Batch: 46, Loss: 0.7013328075408936, Accuracy: 0.76513671875\n",
      "Batch: 47, Loss: 0.7146618962287903, Accuracy: 0.77099609375\n",
      "Batch: 48, Loss: 0.7187559008598328, Accuracy: 0.7685546875\n",
      "Batch: 49, Loss: 0.6834226846694946, Accuracy: 0.77392578125\n",
      "Batch: 50, Loss: 0.7311302423477173, Accuracy: 0.75927734375\n",
      "Batch: 51, Loss: 0.705081582069397, Accuracy: 0.77197265625\n",
      "Batch: 52, Loss: 0.6905819773674011, Accuracy: 0.77978515625\n",
      "Batch: 53, Loss: 0.7125265598297119, Accuracy: 0.7568359375\n",
      "Batch: 54, Loss: 0.7483202219009399, Accuracy: 0.74560546875\n",
      "Batch: 55, Loss: 0.6974664926528931, Accuracy: 0.7734375\n",
      "Batch: 56, Loss: 0.6871501207351685, Accuracy: 0.77294921875\n",
      "Batch: 57, Loss: 0.76444411277771, Accuracy: 0.75732421875\n",
      "Batch: 58, Loss: 0.7227123975753784, Accuracy: 0.75830078125\n",
      "Batch: 59, Loss: 0.8207570314407349, Accuracy: 0.74267578125\n",
      "Batch: 60, Loss: 0.7184350490570068, Accuracy: 0.7763671875\n",
      "Batch: 61, Loss: 0.6676634550094604, Accuracy: 0.79150390625\n",
      "Batch: 62, Loss: 0.6970851421356201, Accuracy: 0.77392578125\n",
      "Batch: 63, Loss: 0.7420186996459961, Accuracy: 0.7568359375\n",
      "Batch: 64, Loss: 0.7373101711273193, Accuracy: 0.759765625\n",
      "Batch: 65, Loss: 0.7778171300888062, Accuracy: 0.75634765625\n",
      "Batch: 66, Loss: 0.7500773668289185, Accuracy: 0.74951171875\n",
      "Batch: 67, Loss: 0.7516458034515381, Accuracy: 0.7490234375\n",
      "Batch: 68, Loss: 0.6829649806022644, Accuracy: 0.779296875\n",
      "Batch: 69, Loss: 0.7349866032600403, Accuracy: 0.7587890625\n",
      "Batch: 70, Loss: 0.6968274116516113, Accuracy: 0.7705078125\n",
      "Batch: 71, Loss: 0.7218698263168335, Accuracy: 0.76318359375\n",
      "Batch: 72, Loss: 0.7515701055526733, Accuracy: 0.73828125\n",
      "Batch: 73, Loss: 0.7302401661872864, Accuracy: 0.77099609375\n",
      "Batch: 74, Loss: 0.7432727813720703, Accuracy: 0.76171875\n",
      "Batch: 75, Loss: 0.6578433513641357, Accuracy: 0.7802734375\n",
      "Batch: 76, Loss: 0.6767646074295044, Accuracy: 0.791015625\n",
      "Batch: 77, Loss: 0.6777021288871765, Accuracy: 0.79052734375\n",
      "Batch: 78, Loss: 0.7078666687011719, Accuracy: 0.76708984375\n",
      "Batch: 79, Loss: 0.7057762145996094, Accuracy: 0.7685546875\n",
      "Batch: 80, Loss: 0.737934410572052, Accuracy: 0.76318359375\n",
      "Batch: 81, Loss: 0.745177149772644, Accuracy: 0.77294921875\n",
      "Batch: 82, Loss: 0.7040631175041199, Accuracy: 0.767578125\n",
      "Batch: 83, Loss: 0.6590276956558228, Accuracy: 0.783203125\n",
      "Batch: 84, Loss: 0.6648306846618652, Accuracy: 0.78466796875\n",
      "Batch: 85, Loss: 0.7013000845909119, Accuracy: 0.7705078125\n",
      "Batch: 86, Loss: 0.7821066975593567, Accuracy: 0.7626953125\n",
      "Batch: 87, Loss: 0.6831625699996948, Accuracy: 0.77734375\n",
      "Batch: 88, Loss: 0.7317795753479004, Accuracy: 0.7724609375\n",
      "Batch: 89, Loss: 0.7157906293869019, Accuracy: 0.77783203125\n",
      "Batch: 90, Loss: 0.7496072053909302, Accuracy: 0.7529296875\n",
      "Batch: 91, Loss: 0.6994519233703613, Accuracy: 0.78466796875\n",
      "Batch: 92, Loss: 0.8037169575691223, Accuracy: 0.74609375\n",
      "Batch: 93, Loss: 0.7621979713439941, Accuracy: 0.748046875\n",
      "Batch: 94, Loss: 0.7465839385986328, Accuracy: 0.7578125\n",
      "Batch: 95, Loss: 0.7732106447219849, Accuracy: 0.75146484375\n",
      "Batch: 96, Loss: 0.7137875556945801, Accuracy: 0.77197265625\n",
      "Batch: 97, Loss: 0.7104225158691406, Accuracy: 0.78466796875\n",
      "Batch: 98, Loss: 0.7772787809371948, Accuracy: 0.74853515625\n",
      "Batch: 99, Loss: 0.7016198635101318, Accuracy: 0.77294921875\n",
      "Batch: 100, Loss: 0.7896490097045898, Accuracy: 0.7421875\n",
      "Batch: 101, Loss: 0.8098307847976685, Accuracy: 0.7431640625\n",
      "Batch: 102, Loss: 0.6731611490249634, Accuracy: 0.783203125\n",
      "Batch: 103, Loss: 0.7450814247131348, Accuracy: 0.75537109375\n",
      "Batch: 104, Loss: 0.7072293162345886, Accuracy: 0.77978515625\n",
      "Batch: 105, Loss: 0.7378034591674805, Accuracy: 0.7646484375\n",
      "Batch: 106, Loss: 0.6969149112701416, Accuracy: 0.78369140625\n",
      "Batch: 107, Loss: 0.7447248697280884, Accuracy: 0.7666015625\n",
      "Batch: 108, Loss: 0.7305552363395691, Accuracy: 0.76953125\n",
      "Batch: 109, Loss: 0.700177788734436, Accuracy: 0.779296875\n",
      "Batch: 110, Loss: 0.7081709504127502, Accuracy: 0.767578125\n",
      "Batch: 111, Loss: 0.6505377292633057, Accuracy: 0.7822265625\n",
      "Batch: 112, Loss: 0.7079294919967651, Accuracy: 0.77880859375\n",
      "Batch: 113, Loss: 0.7305238246917725, Accuracy: 0.759765625\n",
      "Batch: 114, Loss: 0.725079357624054, Accuracy: 0.76806640625\n",
      "Batch: 115, Loss: 0.7350949048995972, Accuracy: 0.76708984375\n",
      "Batch: 116, Loss: 0.7061071395874023, Accuracy: 0.77099609375\n",
      "Batch: 117, Loss: 0.7037969827651978, Accuracy: 0.77734375\n",
      "Batch: 118, Loss: 0.7193801403045654, Accuracy: 0.7646484375\n",
      "Batch: 119, Loss: 0.703755795955658, Accuracy: 0.76513671875\n",
      "Batch: 120, Loss: 0.6862263679504395, Accuracy: 0.7802734375\n",
      "Batch: 121, Loss: 0.7126781940460205, Accuracy: 0.7783203125\n",
      "Batch: 122, Loss: 0.6751541495323181, Accuracy: 0.78759765625\n",
      "Batch: 123, Loss: 0.6647903919219971, Accuracy: 0.7900390625\n",
      "Batch: 124, Loss: 0.6696872711181641, Accuracy: 0.77978515625\n",
      "Batch: 125, Loss: 0.7144179344177246, Accuracy: 0.77880859375\n",
      "Batch: 126, Loss: 0.6808128356933594, Accuracy: 0.7744140625\n",
      "Batch: 127, Loss: 0.6537715196609497, Accuracy: 0.78564453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 128, Loss: 0.7819443941116333, Accuracy: 0.748046875\n",
      "Batch: 129, Loss: 0.8044837713241577, Accuracy: 0.73583984375\n",
      "Batch: 130, Loss: 0.8204063177108765, Accuracy: 0.73779296875\n",
      "Batch: 131, Loss: 0.7555453181266785, Accuracy: 0.7568359375\n",
      "Batch: 132, Loss: 0.6905956268310547, Accuracy: 0.78173828125\n",
      "Batch: 133, Loss: 0.6565106511116028, Accuracy: 0.7861328125\n",
      "Batch: 134, Loss: 0.7377870082855225, Accuracy: 0.75537109375\n",
      "Batch: 135, Loss: 0.7296590805053711, Accuracy: 0.77392578125\n",
      "Batch: 136, Loss: 0.6807953715324402, Accuracy: 0.76953125\n",
      "Batch: 137, Loss: 0.7191113829612732, Accuracy: 0.77490234375\n",
      "Batch: 138, Loss: 0.6470531225204468, Accuracy: 0.8017578125\n",
      "Batch: 139, Loss: 0.6979189515113831, Accuracy: 0.76904296875\n",
      "Batch: 140, Loss: 0.623997688293457, Accuracy: 0.79638671875\n",
      "Batch: 141, Loss: 0.7590164542198181, Accuracy: 0.75048828125\n",
      "Batch: 142, Loss: 0.6602543592453003, Accuracy: 0.77734375\n",
      "Batch: 143, Loss: 0.6797972917556763, Accuracy: 0.78515625\n",
      "Batch: 144, Loss: 0.7498637437820435, Accuracy: 0.75537109375\n",
      "Batch: 145, Loss: 0.727159857749939, Accuracy: 0.7763671875\n",
      "Batch: 146, Loss: 0.7654522657394409, Accuracy: 0.7529296875\n",
      "Batch: 147, Loss: 0.7160845994949341, Accuracy: 0.76953125\n",
      "Batch: 148, Loss: 0.7592999935150146, Accuracy: 0.74267578125\n",
      "Batch: 149, Loss: 0.7579334378242493, Accuracy: 0.75\n",
      "Batch: 150, Loss: 0.645723819732666, Accuracy: 0.79296875\n",
      "Batch: 151, Loss: 0.6364156007766724, Accuracy: 0.796875\n",
      "Batch: 152, Loss: 0.6744170188903809, Accuracy: 0.77880859375\n",
      "Batch: 153, Loss: 0.6937988996505737, Accuracy: 0.78076171875\n",
      "Batch: 154, Loss: 0.6904525756835938, Accuracy: 0.77783203125\n",
      "Batch: 155, Loss: 0.7534725069999695, Accuracy: 0.7587890625\n",
      "Batch: 156, Loss: 0.6564194560050964, Accuracy: 0.78955078125\n",
      "Batch: 157, Loss: 0.6321098804473877, Accuracy: 0.80078125\n",
      "Batch: 158, Loss: 0.6470086574554443, Accuracy: 0.79296875\n",
      "Batch: 159, Loss: 0.6827173233032227, Accuracy: 0.7841796875\n",
      "Batch: 160, Loss: 0.6866939663887024, Accuracy: 0.775390625\n",
      "Batch: 161, Loss: 0.69942706823349, Accuracy: 0.771484375\n",
      "Batch: 162, Loss: 0.6715811491012573, Accuracy: 0.78857421875\n",
      "Batch: 163, Loss: 0.7237664461135864, Accuracy: 0.76025390625\n",
      "Batch: 164, Loss: 0.7843520641326904, Accuracy: 0.75146484375\n",
      "Batch: 165, Loss: 0.6921840906143188, Accuracy: 0.7880859375\n",
      "Batch: 166, Loss: 0.7215710282325745, Accuracy: 0.7646484375\n",
      "Batch: 167, Loss: 0.6884225606918335, Accuracy: 0.7783203125\n",
      "Batch: 168, Loss: 0.6392669081687927, Accuracy: 0.79150390625\n",
      "Batch: 169, Loss: 0.7183816432952881, Accuracy: 0.77392578125\n",
      "Batch: 170, Loss: 0.7383054494857788, Accuracy: 0.76220703125\n",
      "Batch: 171, Loss: 0.6906901597976685, Accuracy: 0.78369140625\n",
      "Batch: 172, Loss: 0.67096346616745, Accuracy: 0.77392578125\n",
      "Batch: 173, Loss: 0.7242587208747864, Accuracy: 0.76806640625\n",
      "Batch: 174, Loss: 0.6073075532913208, Accuracy: 0.7978515625\n",
      "Batch: 175, Loss: 0.7335060238838196, Accuracy: 0.75927734375\n",
      "Batch: 176, Loss: 0.7550580501556396, Accuracy: 0.76318359375\n",
      "Batch: 177, Loss: 0.6934535503387451, Accuracy: 0.77587890625\n",
      "Batch: 178, Loss: 0.6736724376678467, Accuracy: 0.78076171875\n",
      "Batch: 179, Loss: 0.6970245838165283, Accuracy: 0.77880859375\n",
      "Batch: 180, Loss: 0.7191346883773804, Accuracy: 0.76904296875\n",
      "Epoch 49/200\n",
      "Batch: 1, Loss: 1.0362449884414673, Accuracy: 0.712890625\n",
      "Batch: 2, Loss: 0.7003344893455505, Accuracy: 0.7646484375\n",
      "Batch: 3, Loss: 0.71238112449646, Accuracy: 0.7685546875\n",
      "Batch: 4, Loss: 0.7239441275596619, Accuracy: 0.76806640625\n",
      "Batch: 5, Loss: 0.7230549454689026, Accuracy: 0.77001953125\n",
      "Batch: 6, Loss: 0.7310645580291748, Accuracy: 0.76171875\n",
      "Batch: 7, Loss: 0.6989012956619263, Accuracy: 0.771484375\n",
      "Batch: 8, Loss: 0.6990947127342224, Accuracy: 0.76513671875\n",
      "Batch: 9, Loss: 0.7632848024368286, Accuracy: 0.75830078125\n",
      "Batch: 10, Loss: 0.6884423494338989, Accuracy: 0.78076171875\n",
      "Batch: 11, Loss: 0.7495976090431213, Accuracy: 0.759765625\n",
      "Batch: 12, Loss: 0.6524248123168945, Accuracy: 0.787109375\n",
      "Batch: 13, Loss: 0.7168283462524414, Accuracy: 0.7626953125\n",
      "Batch: 14, Loss: 0.7054704427719116, Accuracy: 0.77685546875\n",
      "Batch: 15, Loss: 0.7205142974853516, Accuracy: 0.76806640625\n",
      "Batch: 16, Loss: 0.7781760096549988, Accuracy: 0.7431640625\n",
      "Batch: 17, Loss: 0.7172647714614868, Accuracy: 0.77294921875\n",
      "Batch: 18, Loss: 0.7463088035583496, Accuracy: 0.75634765625\n",
      "Batch: 19, Loss: 0.7393182516098022, Accuracy: 0.771484375\n",
      "Batch: 20, Loss: 0.6380758881568909, Accuracy: 0.7978515625\n",
      "Batch: 21, Loss: 0.7570936679840088, Accuracy: 0.751953125\n",
      "Batch: 22, Loss: 0.6558024287223816, Accuracy: 0.79345703125\n",
      "Batch: 23, Loss: 0.6614031791687012, Accuracy: 0.7802734375\n",
      "Batch: 24, Loss: 0.7017537355422974, Accuracy: 0.77685546875\n",
      "Batch: 25, Loss: 0.6705231666564941, Accuracy: 0.79296875\n",
      "Batch: 26, Loss: 0.7017433643341064, Accuracy: 0.7705078125\n",
      "Batch: 27, Loss: 0.7540155053138733, Accuracy: 0.755859375\n",
      "Batch: 28, Loss: 0.7016905546188354, Accuracy: 0.77197265625\n",
      "Batch: 29, Loss: 0.7625783681869507, Accuracy: 0.7529296875\n",
      "Batch: 30, Loss: 0.7117115259170532, Accuracy: 0.77734375\n",
      "Batch: 31, Loss: 0.816286027431488, Accuracy: 0.73828125\n",
      "Batch: 32, Loss: 0.7553378343582153, Accuracy: 0.76123046875\n",
      "Batch: 33, Loss: 0.7600642442703247, Accuracy: 0.75390625\n",
      "Batch: 34, Loss: 0.7893370389938354, Accuracy: 0.74072265625\n",
      "Batch: 35, Loss: 0.7830113172531128, Accuracy: 0.74169921875\n",
      "Batch: 36, Loss: 0.7698227167129517, Accuracy: 0.75439453125\n",
      "Batch: 37, Loss: 0.7690219879150391, Accuracy: 0.7607421875\n",
      "Batch: 38, Loss: 0.7729300856590271, Accuracy: 0.75244140625\n",
      "Batch: 39, Loss: 0.7544050216674805, Accuracy: 0.7626953125\n",
      "Batch: 40, Loss: 0.8019473552703857, Accuracy: 0.7451171875\n",
      "Batch: 41, Loss: 0.7558774948120117, Accuracy: 0.75244140625\n",
      "Batch: 42, Loss: 0.7455223798751831, Accuracy: 0.75\n",
      "Batch: 43, Loss: 0.719362735748291, Accuracy: 0.76708984375\n",
      "Batch: 44, Loss: 0.6454480886459351, Accuracy: 0.791015625\n",
      "Batch: 45, Loss: 0.7169824838638306, Accuracy: 0.76806640625\n",
      "Batch: 46, Loss: 0.6823427677154541, Accuracy: 0.759765625\n",
      "Batch: 47, Loss: 0.7029432058334351, Accuracy: 0.7724609375\n",
      "Batch: 48, Loss: 0.6928830146789551, Accuracy: 0.783203125\n",
      "Batch: 49, Loss: 0.6807683110237122, Accuracy: 0.77734375\n",
      "Batch: 50, Loss: 0.712475061416626, Accuracy: 0.763671875\n",
      "Batch: 51, Loss: 0.7223837375640869, Accuracy: 0.76416015625\n",
      "Batch: 52, Loss: 0.6996098756790161, Accuracy: 0.77099609375\n",
      "Batch: 53, Loss: 0.6970884203910828, Accuracy: 0.77001953125\n",
      "Batch: 54, Loss: 0.7569137811660767, Accuracy: 0.7587890625\n",
      "Batch: 55, Loss: 0.7148363590240479, Accuracy: 0.76416015625\n",
      "Batch: 56, Loss: 0.6980140209197998, Accuracy: 0.7783203125\n",
      "Batch: 57, Loss: 0.7680659294128418, Accuracy: 0.76171875\n",
      "Batch: 58, Loss: 0.7178251147270203, Accuracy: 0.76806640625\n",
      "Batch: 59, Loss: 0.8221962451934814, Accuracy: 0.7373046875\n",
      "Batch: 60, Loss: 0.720981240272522, Accuracy: 0.77294921875\n",
      "Batch: 61, Loss: 0.6807396411895752, Accuracy: 0.78271484375\n",
      "Batch: 62, Loss: 0.6947339773178101, Accuracy: 0.78076171875\n",
      "Batch: 63, Loss: 0.7064938545227051, Accuracy: 0.77197265625\n",
      "Batch: 64, Loss: 0.7329906225204468, Accuracy: 0.763671875\n",
      "Batch: 65, Loss: 0.7711249589920044, Accuracy: 0.7548828125\n",
      "Batch: 66, Loss: 0.7462401390075684, Accuracy: 0.7578125\n",
      "Batch: 67, Loss: 0.7609327435493469, Accuracy: 0.75390625\n",
      "Batch: 68, Loss: 0.6700085401535034, Accuracy: 0.787109375\n",
      "Batch: 69, Loss: 0.7405965328216553, Accuracy: 0.76171875\n",
      "Batch: 70, Loss: 0.7200958728790283, Accuracy: 0.7607421875\n",
      "Batch: 71, Loss: 0.7078948020935059, Accuracy: 0.76806640625\n",
      "Batch: 72, Loss: 0.7418563365936279, Accuracy: 0.7548828125\n",
      "Batch: 73, Loss: 0.726140558719635, Accuracy: 0.76611328125\n",
      "Batch: 74, Loss: 0.7124180197715759, Accuracy: 0.7763671875\n",
      "Batch: 75, Loss: 0.6670960187911987, Accuracy: 0.77490234375\n",
      "Batch: 76, Loss: 0.6650921106338501, Accuracy: 0.7880859375\n",
      "Batch: 77, Loss: 0.6557705402374268, Accuracy: 0.79248046875\n",
      "Batch: 78, Loss: 0.7119717597961426, Accuracy: 0.77001953125\n",
      "Batch: 79, Loss: 0.7091721296310425, Accuracy: 0.7685546875\n",
      "Batch: 80, Loss: 0.740719199180603, Accuracy: 0.76025390625\n",
      "Batch: 81, Loss: 0.7384217977523804, Accuracy: 0.76611328125\n",
      "Batch: 82, Loss: 0.7125296592712402, Accuracy: 0.7646484375\n",
      "Batch: 83, Loss: 0.6721162796020508, Accuracy: 0.7802734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 84, Loss: 0.6746541857719421, Accuracy: 0.7802734375\n",
      "Batch: 85, Loss: 0.709037184715271, Accuracy: 0.76171875\n",
      "Batch: 86, Loss: 0.742400050163269, Accuracy: 0.76904296875\n",
      "Batch: 87, Loss: 0.6555801033973694, Accuracy: 0.78564453125\n",
      "Batch: 88, Loss: 0.7358282208442688, Accuracy: 0.76904296875\n",
      "Batch: 89, Loss: 0.6953064203262329, Accuracy: 0.77587890625\n",
      "Batch: 90, Loss: 0.7512297630310059, Accuracy: 0.7587890625\n",
      "Batch: 91, Loss: 0.6727960705757141, Accuracy: 0.7880859375\n",
      "Batch: 92, Loss: 0.799858570098877, Accuracy: 0.740234375\n",
      "Batch: 93, Loss: 0.7811859846115112, Accuracy: 0.74462890625\n",
      "Batch: 94, Loss: 0.7466238737106323, Accuracy: 0.763671875\n",
      "Batch: 95, Loss: 0.7666237354278564, Accuracy: 0.75244140625\n",
      "Batch: 96, Loss: 0.7114471197128296, Accuracy: 0.77490234375\n",
      "Batch: 97, Loss: 0.6873705387115479, Accuracy: 0.78564453125\n",
      "Batch: 98, Loss: 0.750628650188446, Accuracy: 0.771484375\n",
      "Batch: 99, Loss: 0.7106424570083618, Accuracy: 0.77490234375\n",
      "Batch: 100, Loss: 0.7915828227996826, Accuracy: 0.7451171875\n",
      "Batch: 101, Loss: 0.7955548763275146, Accuracy: 0.75244140625\n",
      "Batch: 102, Loss: 0.6919790506362915, Accuracy: 0.77685546875\n",
      "Batch: 103, Loss: 0.7131484746932983, Accuracy: 0.765625\n",
      "Batch: 104, Loss: 0.7199814319610596, Accuracy: 0.77197265625\n",
      "Batch: 105, Loss: 0.7565428018569946, Accuracy: 0.7578125\n",
      "Batch: 106, Loss: 0.70888352394104, Accuracy: 0.7705078125\n",
      "Batch: 107, Loss: 0.7295135855674744, Accuracy: 0.767578125\n",
      "Batch: 108, Loss: 0.7037014961242676, Accuracy: 0.77294921875\n",
      "Batch: 109, Loss: 0.6966429948806763, Accuracy: 0.7744140625\n",
      "Batch: 110, Loss: 0.683922529220581, Accuracy: 0.76806640625\n",
      "Batch: 111, Loss: 0.6663965582847595, Accuracy: 0.78564453125\n",
      "Batch: 112, Loss: 0.7059756517410278, Accuracy: 0.7685546875\n",
      "Batch: 113, Loss: 0.7332869172096252, Accuracy: 0.76416015625\n",
      "Batch: 114, Loss: 0.700946569442749, Accuracy: 0.77587890625\n",
      "Batch: 115, Loss: 0.7235454320907593, Accuracy: 0.765625\n",
      "Batch: 116, Loss: 0.706281840801239, Accuracy: 0.7734375\n",
      "Batch: 117, Loss: 0.7023535966873169, Accuracy: 0.77685546875\n",
      "Batch: 118, Loss: 0.7096688151359558, Accuracy: 0.76904296875\n",
      "Batch: 119, Loss: 0.6753021478652954, Accuracy: 0.77197265625\n",
      "Batch: 120, Loss: 0.6830303072929382, Accuracy: 0.77587890625\n",
      "Batch: 121, Loss: 0.7003240585327148, Accuracy: 0.77294921875\n",
      "Batch: 122, Loss: 0.6567428112030029, Accuracy: 0.7841796875\n",
      "Batch: 123, Loss: 0.6758587956428528, Accuracy: 0.78759765625\n",
      "Batch: 124, Loss: 0.6596201658248901, Accuracy: 0.77880859375\n",
      "Batch: 125, Loss: 0.7090712785720825, Accuracy: 0.779296875\n",
      "Batch: 126, Loss: 0.6757524013519287, Accuracy: 0.78369140625\n",
      "Batch: 127, Loss: 0.6650144457817078, Accuracy: 0.78125\n",
      "Batch: 128, Loss: 0.7470849752426147, Accuracy: 0.7666015625\n",
      "Batch: 129, Loss: 0.7947027683258057, Accuracy: 0.748046875\n",
      "Batch: 130, Loss: 0.8012694120407104, Accuracy: 0.74755859375\n",
      "Batch: 131, Loss: 0.7187279462814331, Accuracy: 0.77490234375\n",
      "Batch: 132, Loss: 0.6902215480804443, Accuracy: 0.7763671875\n",
      "Batch: 133, Loss: 0.6425948739051819, Accuracy: 0.791015625\n",
      "Batch: 134, Loss: 0.7366777658462524, Accuracy: 0.7607421875\n",
      "Batch: 135, Loss: 0.7230448722839355, Accuracy: 0.75732421875\n",
      "Batch: 136, Loss: 0.6682670712471008, Accuracy: 0.78369140625\n",
      "Batch: 137, Loss: 0.707940936088562, Accuracy: 0.775390625\n",
      "Batch: 138, Loss: 0.635517954826355, Accuracy: 0.80078125\n",
      "Batch: 139, Loss: 0.6846201419830322, Accuracy: 0.7822265625\n",
      "Batch: 140, Loss: 0.654644787311554, Accuracy: 0.791015625\n",
      "Batch: 141, Loss: 0.7530620694160461, Accuracy: 0.7607421875\n",
      "Batch: 142, Loss: 0.6736849546432495, Accuracy: 0.7783203125\n",
      "Batch: 143, Loss: 0.6796471476554871, Accuracy: 0.79248046875\n",
      "Batch: 144, Loss: 0.7464622259140015, Accuracy: 0.7685546875\n",
      "Batch: 145, Loss: 0.7093108296394348, Accuracy: 0.77880859375\n",
      "Batch: 146, Loss: 0.7717499732971191, Accuracy: 0.74462890625\n",
      "Batch: 147, Loss: 0.7246623039245605, Accuracy: 0.76953125\n",
      "Batch: 148, Loss: 0.7562018036842346, Accuracy: 0.748046875\n",
      "Batch: 149, Loss: 0.7363324165344238, Accuracy: 0.759765625\n",
      "Batch: 150, Loss: 0.6314972639083862, Accuracy: 0.8046875\n",
      "Batch: 151, Loss: 0.6245203018188477, Accuracy: 0.794921875\n",
      "Batch: 152, Loss: 0.6808241009712219, Accuracy: 0.78369140625\n",
      "Batch: 153, Loss: 0.6805645227432251, Accuracy: 0.7841796875\n",
      "Batch: 154, Loss: 0.6772652864456177, Accuracy: 0.77587890625\n",
      "Batch: 155, Loss: 0.7506898641586304, Accuracy: 0.76025390625\n",
      "Batch: 156, Loss: 0.6502474546432495, Accuracy: 0.79150390625\n",
      "Batch: 157, Loss: 0.6388037204742432, Accuracy: 0.78759765625\n",
      "Batch: 158, Loss: 0.6320794820785522, Accuracy: 0.80419921875\n",
      "Batch: 159, Loss: 0.6494872570037842, Accuracy: 0.79443359375\n",
      "Batch: 160, Loss: 0.6620863676071167, Accuracy: 0.7841796875\n",
      "Batch: 161, Loss: 0.704981803894043, Accuracy: 0.771484375\n",
      "Batch: 162, Loss: 0.6532805562019348, Accuracy: 0.79052734375\n",
      "Batch: 163, Loss: 0.725827157497406, Accuracy: 0.75732421875\n",
      "Batch: 164, Loss: 0.7820860147476196, Accuracy: 0.7568359375\n",
      "Batch: 165, Loss: 0.6921571493148804, Accuracy: 0.7822265625\n",
      "Batch: 166, Loss: 0.7181180119514465, Accuracy: 0.7685546875\n",
      "Batch: 167, Loss: 0.688949465751648, Accuracy: 0.7822265625\n",
      "Batch: 168, Loss: 0.6203538775444031, Accuracy: 0.7978515625\n",
      "Batch: 169, Loss: 0.6917464733123779, Accuracy: 0.77783203125\n",
      "Batch: 170, Loss: 0.7103956341743469, Accuracy: 0.76904296875\n",
      "Batch: 171, Loss: 0.6649352312088013, Accuracy: 0.78369140625\n",
      "Batch: 172, Loss: 0.6843892335891724, Accuracy: 0.77392578125\n",
      "Batch: 173, Loss: 0.7413721084594727, Accuracy: 0.7548828125\n",
      "Batch: 174, Loss: 0.6101676225662231, Accuracy: 0.79833984375\n",
      "Batch: 175, Loss: 0.7280883193016052, Accuracy: 0.76318359375\n",
      "Batch: 176, Loss: 0.7590564489364624, Accuracy: 0.759765625\n",
      "Batch: 177, Loss: 0.6878551244735718, Accuracy: 0.77685546875\n",
      "Batch: 178, Loss: 0.682776927947998, Accuracy: 0.783203125\n",
      "Batch: 179, Loss: 0.6846777200698853, Accuracy: 0.771484375\n",
      "Batch: 180, Loss: 0.7454854249954224, Accuracy: 0.76318359375\n",
      "Epoch 50/200\n",
      "Batch: 1, Loss: 1.0186078548431396, Accuracy: 0.71435546875\n",
      "Batch: 2, Loss: 0.6999637484550476, Accuracy: 0.76025390625\n",
      "Batch: 3, Loss: 0.7113476991653442, Accuracy: 0.77294921875\n",
      "Batch: 4, Loss: 0.7334880828857422, Accuracy: 0.76025390625\n",
      "Batch: 5, Loss: 0.7068761587142944, Accuracy: 0.76513671875\n",
      "Batch: 6, Loss: 0.7509921193122864, Accuracy: 0.7607421875\n",
      "Batch: 7, Loss: 0.6953715085983276, Accuracy: 0.77978515625\n",
      "Batch: 8, Loss: 0.7189077138900757, Accuracy: 0.7705078125\n",
      "Batch: 9, Loss: 0.7450896501541138, Accuracy: 0.7607421875\n",
      "Batch: 10, Loss: 0.694141149520874, Accuracy: 0.78173828125\n",
      "Batch: 11, Loss: 0.739221453666687, Accuracy: 0.76220703125\n",
      "Batch: 12, Loss: 0.6526464819908142, Accuracy: 0.787109375\n",
      "Batch: 13, Loss: 0.7091861963272095, Accuracy: 0.77001953125\n",
      "Batch: 14, Loss: 0.6881176233291626, Accuracy: 0.7880859375\n",
      "Batch: 15, Loss: 0.7215700745582581, Accuracy: 0.7705078125\n",
      "Batch: 16, Loss: 0.7557169198989868, Accuracy: 0.7548828125\n",
      "Batch: 17, Loss: 0.6865679025650024, Accuracy: 0.78564453125\n",
      "Batch: 18, Loss: 0.746401846408844, Accuracy: 0.7646484375\n",
      "Batch: 19, Loss: 0.7568790912628174, Accuracy: 0.76904296875\n",
      "Batch: 20, Loss: 0.6348252892494202, Accuracy: 0.7939453125\n",
      "Batch: 21, Loss: 0.7594727873802185, Accuracy: 0.7626953125\n",
      "Batch: 22, Loss: 0.6714125871658325, Accuracy: 0.78125\n",
      "Batch: 23, Loss: 0.6569347381591797, Accuracy: 0.7861328125\n",
      "Batch: 24, Loss: 0.6700835824012756, Accuracy: 0.78076171875\n",
      "Batch: 25, Loss: 0.680017352104187, Accuracy: 0.7841796875\n",
      "Batch: 26, Loss: 0.6973652839660645, Accuracy: 0.7685546875\n",
      "Batch: 27, Loss: 0.7313512563705444, Accuracy: 0.755859375\n",
      "Batch: 28, Loss: 0.7123454809188843, Accuracy: 0.7724609375\n",
      "Batch: 29, Loss: 0.7594977021217346, Accuracy: 0.7626953125\n",
      "Batch: 30, Loss: 0.7296863794326782, Accuracy: 0.7646484375\n",
      "Batch: 31, Loss: 0.8057864904403687, Accuracy: 0.7509765625\n",
      "Batch: 32, Loss: 0.7688858509063721, Accuracy: 0.75439453125\n",
      "Batch: 33, Loss: 0.7290315628051758, Accuracy: 0.76611328125\n",
      "Batch: 34, Loss: 0.7659488916397095, Accuracy: 0.74853515625\n",
      "Batch: 35, Loss: 0.7859330177307129, Accuracy: 0.75244140625\n",
      "Batch: 36, Loss: 0.7572511434555054, Accuracy: 0.759765625\n",
      "Batch: 37, Loss: 0.7280413508415222, Accuracy: 0.7607421875\n",
      "Batch: 38, Loss: 0.7788559794425964, Accuracy: 0.7490234375\n",
      "Batch: 39, Loss: 0.730059802532196, Accuracy: 0.76416015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 40, Loss: 0.7839040756225586, Accuracy: 0.7509765625\n",
      "Batch: 41, Loss: 0.7584147453308105, Accuracy: 0.75537109375\n",
      "Batch: 42, Loss: 0.7411967515945435, Accuracy: 0.748046875\n",
      "Batch: 43, Loss: 0.6845271587371826, Accuracy: 0.77978515625\n",
      "Batch: 44, Loss: 0.6482805609703064, Accuracy: 0.8017578125\n",
      "Batch: 45, Loss: 0.6836411356925964, Accuracy: 0.77783203125\n",
      "Batch: 46, Loss: 0.6822313070297241, Accuracy: 0.76318359375\n",
      "Batch: 47, Loss: 0.7101455330848694, Accuracy: 0.7666015625\n",
      "Batch: 48, Loss: 0.695932149887085, Accuracy: 0.77734375\n",
      "Batch: 49, Loss: 0.689582109451294, Accuracy: 0.78369140625\n",
      "Batch: 50, Loss: 0.7127019762992859, Accuracy: 0.76953125\n",
      "Batch: 51, Loss: 0.6969490051269531, Accuracy: 0.77490234375\n",
      "Batch: 52, Loss: 0.6780626773834229, Accuracy: 0.77099609375\n",
      "Batch: 53, Loss: 0.705786406993866, Accuracy: 0.76806640625\n",
      "Batch: 54, Loss: 0.7410346269607544, Accuracy: 0.75439453125\n",
      "Batch: 55, Loss: 0.6881890296936035, Accuracy: 0.779296875\n",
      "Batch: 56, Loss: 0.6904134154319763, Accuracy: 0.76904296875\n",
      "Batch: 57, Loss: 0.7565717697143555, Accuracy: 0.76171875\n",
      "Batch: 58, Loss: 0.7152400016784668, Accuracy: 0.7705078125\n",
      "Batch: 59, Loss: 0.8071416616439819, Accuracy: 0.74755859375\n",
      "Batch: 60, Loss: 0.712248682975769, Accuracy: 0.7783203125\n",
      "Batch: 61, Loss: 0.6714006066322327, Accuracy: 0.787109375\n",
      "Batch: 62, Loss: 0.6940618753433228, Accuracy: 0.7763671875\n",
      "Batch: 63, Loss: 0.7212570905685425, Accuracy: 0.76171875\n",
      "Batch: 64, Loss: 0.7149844169616699, Accuracy: 0.76220703125\n",
      "Batch: 65, Loss: 0.7720922231674194, Accuracy: 0.7451171875\n",
      "Batch: 66, Loss: 0.7367696166038513, Accuracy: 0.765625\n",
      "Batch: 67, Loss: 0.7451163530349731, Accuracy: 0.7470703125\n",
      "Batch: 68, Loss: 0.6702871322631836, Accuracy: 0.78076171875\n",
      "Batch: 69, Loss: 0.7210242748260498, Accuracy: 0.76220703125\n",
      "Batch: 70, Loss: 0.6975377798080444, Accuracy: 0.77294921875\n",
      "Batch: 71, Loss: 0.6995029449462891, Accuracy: 0.7802734375\n",
      "Batch: 72, Loss: 0.7320300936698914, Accuracy: 0.744140625\n",
      "Batch: 73, Loss: 0.7146552801132202, Accuracy: 0.7607421875\n",
      "Batch: 74, Loss: 0.7390923500061035, Accuracy: 0.76806640625\n",
      "Batch: 75, Loss: 0.6660309433937073, Accuracy: 0.7802734375\n",
      "Batch: 76, Loss: 0.6532580256462097, Accuracy: 0.79345703125\n",
      "Batch: 77, Loss: 0.6531224846839905, Accuracy: 0.7978515625\n",
      "Batch: 78, Loss: 0.6984095573425293, Accuracy: 0.7763671875\n",
      "Batch: 79, Loss: 0.7080828547477722, Accuracy: 0.77490234375\n",
      "Batch: 80, Loss: 0.7248815894126892, Accuracy: 0.76416015625\n",
      "Batch: 81, Loss: 0.7270647287368774, Accuracy: 0.7705078125\n",
      "Batch: 82, Loss: 0.7035444974899292, Accuracy: 0.7705078125\n",
      "Batch: 83, Loss: 0.6383752822875977, Accuracy: 0.7880859375\n",
      "Batch: 84, Loss: 0.6625815629959106, Accuracy: 0.7880859375\n",
      "Batch: 85, Loss: 0.7046849727630615, Accuracy: 0.76708984375\n",
      "Batch: 86, Loss: 0.757186770439148, Accuracy: 0.7734375\n",
      "Batch: 87, Loss: 0.6637320518493652, Accuracy: 0.78466796875\n",
      "Batch: 88, Loss: 0.7249922156333923, Accuracy: 0.76806640625\n",
      "Batch: 89, Loss: 0.6805918216705322, Accuracy: 0.77880859375\n",
      "Batch: 90, Loss: 0.7365708351135254, Accuracy: 0.74755859375\n",
      "Batch: 91, Loss: 0.6742548942565918, Accuracy: 0.787109375\n",
      "Batch: 92, Loss: 0.7791988849639893, Accuracy: 0.74267578125\n",
      "Batch: 93, Loss: 0.7612708806991577, Accuracy: 0.7490234375\n",
      "Batch: 94, Loss: 0.7328280806541443, Accuracy: 0.76220703125\n",
      "Batch: 95, Loss: 0.7821507453918457, Accuracy: 0.7470703125\n",
      "Batch: 96, Loss: 0.6981314420700073, Accuracy: 0.7802734375\n",
      "Batch: 97, Loss: 0.6848055720329285, Accuracy: 0.787109375\n",
      "Batch: 98, Loss: 0.7390879392623901, Accuracy: 0.76904296875\n",
      "Batch: 99, Loss: 0.6985740065574646, Accuracy: 0.775390625\n",
      "Batch: 100, Loss: 0.7870181798934937, Accuracy: 0.75830078125\n",
      "Batch: 101, Loss: 0.7843738794326782, Accuracy: 0.744140625\n",
      "Batch: 102, Loss: 0.6649124622344971, Accuracy: 0.77880859375\n",
      "Batch: 103, Loss: 0.7306212186813354, Accuracy: 0.7666015625\n",
      "Batch: 104, Loss: 0.7273845076560974, Accuracy: 0.7705078125\n",
      "Batch: 105, Loss: 0.7369428873062134, Accuracy: 0.763671875\n",
      "Batch: 106, Loss: 0.692612886428833, Accuracy: 0.7734375\n",
      "Batch: 107, Loss: 0.7127970457077026, Accuracy: 0.77685546875\n",
      "Batch: 108, Loss: 0.666478157043457, Accuracy: 0.7802734375\n",
      "Batch: 109, Loss: 0.6928521394729614, Accuracy: 0.77734375\n",
      "Batch: 110, Loss: 0.6812275648117065, Accuracy: 0.7822265625\n",
      "Batch: 111, Loss: 0.6556198000907898, Accuracy: 0.7861328125\n",
      "Batch: 112, Loss: 0.6948400139808655, Accuracy: 0.78173828125\n",
      "Batch: 113, Loss: 0.7236239314079285, Accuracy: 0.76171875\n",
      "Batch: 114, Loss: 0.7004968523979187, Accuracy: 0.7763671875\n",
      "Batch: 115, Loss: 0.7255087494850159, Accuracy: 0.76611328125\n",
      "Batch: 116, Loss: 0.6894142627716064, Accuracy: 0.787109375\n",
      "Batch: 117, Loss: 0.6992313265800476, Accuracy: 0.77392578125\n",
      "Batch: 118, Loss: 0.7127622365951538, Accuracy: 0.76953125\n",
      "Batch: 119, Loss: 0.7008976340293884, Accuracy: 0.7685546875\n",
      "Batch: 120, Loss: 0.6695178747177124, Accuracy: 0.78076171875\n",
      "Batch: 121, Loss: 0.7066271901130676, Accuracy: 0.77587890625\n",
      "Batch: 122, Loss: 0.647292971611023, Accuracy: 0.79052734375\n",
      "Batch: 123, Loss: 0.6643746495246887, Accuracy: 0.78955078125\n",
      "Batch: 124, Loss: 0.6680012345314026, Accuracy: 0.78955078125\n",
      "Batch: 125, Loss: 0.6930806040763855, Accuracy: 0.77392578125\n",
      "Batch: 126, Loss: 0.6612378358840942, Accuracy: 0.78662109375\n",
      "Batch: 127, Loss: 0.6321976184844971, Accuracy: 0.7919921875\n",
      "Batch: 128, Loss: 0.786489725112915, Accuracy: 0.74462890625\n",
      "Batch: 129, Loss: 0.7879636883735657, Accuracy: 0.74365234375\n",
      "Batch: 130, Loss: 0.8097639083862305, Accuracy: 0.73486328125\n",
      "Batch: 131, Loss: 0.7352165579795837, Accuracy: 0.75830078125\n",
      "Batch: 132, Loss: 0.6665743589401245, Accuracy: 0.78662109375\n",
      "Batch: 133, Loss: 0.6621668338775635, Accuracy: 0.78857421875\n",
      "Batch: 134, Loss: 0.7381352186203003, Accuracy: 0.7626953125\n",
      "Batch: 135, Loss: 0.7106125354766846, Accuracy: 0.763671875\n",
      "Batch: 136, Loss: 0.6710128784179688, Accuracy: 0.77783203125\n",
      "Batch: 137, Loss: 0.6954656839370728, Accuracy: 0.78515625\n",
      "Batch: 138, Loss: 0.621962308883667, Accuracy: 0.81298828125\n",
      "Batch: 139, Loss: 0.684909462928772, Accuracy: 0.7783203125\n",
      "Batch: 140, Loss: 0.6407259702682495, Accuracy: 0.79150390625\n",
      "Batch: 141, Loss: 0.7342485785484314, Accuracy: 0.76416015625\n",
      "Batch: 142, Loss: 0.6579052209854126, Accuracy: 0.79638671875\n",
      "Batch: 143, Loss: 0.6794345378875732, Accuracy: 0.78076171875\n",
      "Batch: 144, Loss: 0.7427080273628235, Accuracy: 0.76904296875\n",
      "Batch: 145, Loss: 0.6990633010864258, Accuracy: 0.779296875\n",
      "Batch: 146, Loss: 0.7485671043395996, Accuracy: 0.7548828125\n",
      "Batch: 147, Loss: 0.683883786201477, Accuracy: 0.77587890625\n",
      "Batch: 148, Loss: 0.7467519044876099, Accuracy: 0.763671875\n",
      "Batch: 149, Loss: 0.7369465827941895, Accuracy: 0.759765625\n",
      "Batch: 150, Loss: 0.6239873170852661, Accuracy: 0.79541015625\n",
      "Batch: 151, Loss: 0.6359958648681641, Accuracy: 0.79345703125\n",
      "Batch: 152, Loss: 0.662712037563324, Accuracy: 0.7822265625\n",
      "Batch: 153, Loss: 0.6633800268173218, Accuracy: 0.78271484375\n",
      "Batch: 154, Loss: 0.6635358333587646, Accuracy: 0.78125\n",
      "Batch: 155, Loss: 0.7530803084373474, Accuracy: 0.7509765625\n",
      "Batch: 156, Loss: 0.6400200128555298, Accuracy: 0.7880859375\n",
      "Batch: 157, Loss: 0.6284721493721008, Accuracy: 0.79296875\n",
      "Batch: 158, Loss: 0.6413862705230713, Accuracy: 0.8017578125\n",
      "Batch: 159, Loss: 0.6492130160331726, Accuracy: 0.7919921875\n",
      "Batch: 160, Loss: 0.666504979133606, Accuracy: 0.79150390625\n",
      "Batch: 161, Loss: 0.6821971535682678, Accuracy: 0.77880859375\n",
      "Batch: 162, Loss: 0.6519257426261902, Accuracy: 0.7890625\n",
      "Batch: 163, Loss: 0.7399889230728149, Accuracy: 0.767578125\n",
      "Batch: 164, Loss: 0.7640335559844971, Accuracy: 0.7490234375\n",
      "Batch: 165, Loss: 0.6817376613616943, Accuracy: 0.7802734375\n",
      "Batch: 166, Loss: 0.7096115946769714, Accuracy: 0.77001953125\n",
      "Batch: 167, Loss: 0.6782078742980957, Accuracy: 0.77783203125\n",
      "Batch: 168, Loss: 0.6234257817268372, Accuracy: 0.80419921875\n",
      "Batch: 169, Loss: 0.6974776983261108, Accuracy: 0.77197265625\n",
      "Batch: 170, Loss: 0.7015997171401978, Accuracy: 0.78271484375\n",
      "Batch: 171, Loss: 0.657757043838501, Accuracy: 0.787109375\n",
      "Batch: 172, Loss: 0.6713670492172241, Accuracy: 0.77734375\n",
      "Batch: 173, Loss: 0.7021363973617554, Accuracy: 0.76953125\n",
      "Batch: 174, Loss: 0.5815705060958862, Accuracy: 0.80859375\n",
      "Batch: 175, Loss: 0.7103937268257141, Accuracy: 0.76904296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 176, Loss: 0.7377191781997681, Accuracy: 0.76708984375\n",
      "Batch: 177, Loss: 0.6699398756027222, Accuracy: 0.78759765625\n",
      "Batch: 178, Loss: 0.6478315591812134, Accuracy: 0.78369140625\n",
      "Batch: 179, Loss: 0.6816633939743042, Accuracy: 0.78515625\n",
      "Batch: 180, Loss: 0.7132880687713623, Accuracy: 0.76806640625\n",
      "Saved Weights at epoch 50 to file Weights_50.h5\n",
      "Epoch 51/200\n",
      "Batch: 1, Loss: 0.9979232549667358, Accuracy: 0.708984375\n",
      "Batch: 2, Loss: 0.7125872373580933, Accuracy: 0.7626953125\n",
      "Batch: 3, Loss: 0.6891351938247681, Accuracy: 0.7685546875\n",
      "Batch: 4, Loss: 0.717725396156311, Accuracy: 0.75732421875\n",
      "Batch: 5, Loss: 0.701570987701416, Accuracy: 0.771484375\n",
      "Batch: 6, Loss: 0.7297602891921997, Accuracy: 0.7626953125\n",
      "Batch: 7, Loss: 0.6880083680152893, Accuracy: 0.77587890625\n",
      "Batch: 8, Loss: 0.7022489309310913, Accuracy: 0.765625\n",
      "Batch: 9, Loss: 0.7411562204360962, Accuracy: 0.76953125\n",
      "Batch: 10, Loss: 0.6784321069717407, Accuracy: 0.78076171875\n",
      "Batch: 11, Loss: 0.7373299598693848, Accuracy: 0.7626953125\n",
      "Batch: 12, Loss: 0.6492493152618408, Accuracy: 0.794921875\n",
      "Batch: 13, Loss: 0.6916903257369995, Accuracy: 0.77734375\n",
      "Batch: 14, Loss: 0.6885157227516174, Accuracy: 0.787109375\n",
      "Batch: 15, Loss: 0.70265793800354, Accuracy: 0.77587890625\n",
      "Batch: 16, Loss: 0.7491499185562134, Accuracy: 0.7607421875\n",
      "Batch: 17, Loss: 0.6763870120048523, Accuracy: 0.79248046875\n",
      "Batch: 18, Loss: 0.7323260307312012, Accuracy: 0.7783203125\n",
      "Batch: 19, Loss: 0.719860315322876, Accuracy: 0.7626953125\n",
      "Batch: 20, Loss: 0.6340970993041992, Accuracy: 0.79296875\n",
      "Batch: 21, Loss: 0.7439961433410645, Accuracy: 0.76708984375\n",
      "Batch: 22, Loss: 0.650911808013916, Accuracy: 0.78955078125\n",
      "Batch: 23, Loss: 0.6659416556358337, Accuracy: 0.7890625\n",
      "Batch: 24, Loss: 0.6896175146102905, Accuracy: 0.7685546875\n",
      "Batch: 25, Loss: 0.6751261949539185, Accuracy: 0.77880859375\n",
      "Batch: 26, Loss: 0.6934268474578857, Accuracy: 0.7841796875\n",
      "Batch: 27, Loss: 0.7269103527069092, Accuracy: 0.7607421875\n",
      "Batch: 28, Loss: 0.6944479942321777, Accuracy: 0.7802734375\n",
      "Batch: 29, Loss: 0.7528446912765503, Accuracy: 0.755859375\n",
      "Batch: 30, Loss: 0.717688262462616, Accuracy: 0.77099609375\n",
      "Batch: 31, Loss: 0.8161956071853638, Accuracy: 0.740234375\n",
      "Batch: 32, Loss: 0.7556267976760864, Accuracy: 0.76318359375\n",
      "Batch: 33, Loss: 0.7284241318702698, Accuracy: 0.75732421875\n",
      "Batch: 34, Loss: 0.7552460432052612, Accuracy: 0.75634765625\n",
      "Batch: 35, Loss: 0.7776197195053101, Accuracy: 0.73486328125\n",
      "Batch: 36, Loss: 0.7356958389282227, Accuracy: 0.76220703125\n",
      "Batch: 37, Loss: 0.7339144945144653, Accuracy: 0.76171875\n",
      "Batch: 38, Loss: 0.7505718469619751, Accuracy: 0.74853515625\n",
      "Batch: 39, Loss: 0.7133883237838745, Accuracy: 0.77197265625\n",
      "Batch: 40, Loss: 0.7709294557571411, Accuracy: 0.75537109375\n",
      "Batch: 41, Loss: 0.7518590688705444, Accuracy: 0.7705078125\n",
      "Batch: 42, Loss: 0.735612154006958, Accuracy: 0.75927734375\n",
      "Batch: 43, Loss: 0.6839534044265747, Accuracy: 0.78271484375\n",
      "Batch: 44, Loss: 0.629209041595459, Accuracy: 0.791015625\n",
      "Batch: 45, Loss: 0.7018393278121948, Accuracy: 0.77001953125\n",
      "Batch: 46, Loss: 0.6751838326454163, Accuracy: 0.7802734375\n",
      "Batch: 47, Loss: 0.6986334323883057, Accuracy: 0.77392578125\n",
      "Batch: 48, Loss: 0.6953422427177429, Accuracy: 0.77392578125\n",
      "Batch: 49, Loss: 0.6879773139953613, Accuracy: 0.7724609375\n",
      "Batch: 50, Loss: 0.7161652445793152, Accuracy: 0.771484375\n",
      "Batch: 51, Loss: 0.6858636140823364, Accuracy: 0.7744140625\n",
      "Batch: 52, Loss: 0.6812453269958496, Accuracy: 0.77001953125\n",
      "Batch: 53, Loss: 0.6874840259552002, Accuracy: 0.77734375\n",
      "Batch: 54, Loss: 0.7171843647956848, Accuracy: 0.76318359375\n",
      "Batch: 55, Loss: 0.7033255696296692, Accuracy: 0.76904296875\n",
      "Batch: 56, Loss: 0.6710202097892761, Accuracy: 0.771484375\n",
      "Batch: 57, Loss: 0.7610446810722351, Accuracy: 0.7548828125\n",
      "Batch: 58, Loss: 0.7231200933456421, Accuracy: 0.759765625\n",
      "Batch: 59, Loss: 0.8278319835662842, Accuracy: 0.7412109375\n",
      "Batch: 60, Loss: 0.710509181022644, Accuracy: 0.78125\n",
      "Batch: 61, Loss: 0.6653805375099182, Accuracy: 0.78955078125\n",
      "Batch: 62, Loss: 0.6946265697479248, Accuracy: 0.771484375\n",
      "Batch: 63, Loss: 0.7139628529548645, Accuracy: 0.765625\n",
      "Batch: 64, Loss: 0.7161860466003418, Accuracy: 0.76611328125\n",
      "Batch: 65, Loss: 0.7720189094543457, Accuracy: 0.76025390625\n",
      "Batch: 66, Loss: 0.7300986647605896, Accuracy: 0.75830078125\n",
      "Batch: 67, Loss: 0.7500724792480469, Accuracy: 0.75634765625\n",
      "Batch: 68, Loss: 0.6689842343330383, Accuracy: 0.7880859375\n",
      "Batch: 69, Loss: 0.700089693069458, Accuracy: 0.7705078125\n",
      "Batch: 70, Loss: 0.7017072439193726, Accuracy: 0.76123046875\n",
      "Batch: 71, Loss: 0.7001359462738037, Accuracy: 0.77783203125\n",
      "Batch: 72, Loss: 0.7182526588439941, Accuracy: 0.75244140625\n",
      "Batch: 73, Loss: 0.7292113900184631, Accuracy: 0.7607421875\n",
      "Batch: 74, Loss: 0.7132276296615601, Accuracy: 0.77734375\n",
      "Batch: 75, Loss: 0.6849035024642944, Accuracy: 0.78076171875\n",
      "Batch: 76, Loss: 0.6638069748878479, Accuracy: 0.79345703125\n",
      "Batch: 77, Loss: 0.6517432332038879, Accuracy: 0.796875\n",
      "Batch: 78, Loss: 0.7011883854866028, Accuracy: 0.779296875\n",
      "Batch: 79, Loss: 0.690760612487793, Accuracy: 0.7744140625\n",
      "Batch: 80, Loss: 0.7213571071624756, Accuracy: 0.7666015625\n",
      "Batch: 81, Loss: 0.7085200548171997, Accuracy: 0.77783203125\n",
      "Batch: 82, Loss: 0.6937413811683655, Accuracy: 0.7744140625\n",
      "Batch: 83, Loss: 0.657562255859375, Accuracy: 0.7841796875\n",
      "Batch: 84, Loss: 0.6488359570503235, Accuracy: 0.7861328125\n",
      "Batch: 85, Loss: 0.6897404193878174, Accuracy: 0.7744140625\n",
      "Batch: 86, Loss: 0.7738595008850098, Accuracy: 0.76611328125\n",
      "Batch: 87, Loss: 0.662988007068634, Accuracy: 0.7900390625\n",
      "Batch: 88, Loss: 0.7187746167182922, Accuracy: 0.78125\n",
      "Batch: 89, Loss: 0.6800872087478638, Accuracy: 0.78857421875\n",
      "Batch: 90, Loss: 0.7437523603439331, Accuracy: 0.74951171875\n",
      "Batch: 91, Loss: 0.6741515398025513, Accuracy: 0.78466796875\n",
      "Batch: 92, Loss: 0.7985734343528748, Accuracy: 0.73046875\n",
      "Batch: 93, Loss: 0.7431581616401672, Accuracy: 0.7626953125\n",
      "Batch: 94, Loss: 0.7278139591217041, Accuracy: 0.76318359375\n",
      "Batch: 95, Loss: 0.7613300085067749, Accuracy: 0.7578125\n",
      "Batch: 96, Loss: 0.7042117118835449, Accuracy: 0.7783203125\n",
      "Batch: 97, Loss: 0.6782294511795044, Accuracy: 0.78857421875\n",
      "Batch: 98, Loss: 0.7517716884613037, Accuracy: 0.767578125\n",
      "Batch: 99, Loss: 0.6967766880989075, Accuracy: 0.77734375\n",
      "Batch: 100, Loss: 0.7631120681762695, Accuracy: 0.767578125\n",
      "Batch: 101, Loss: 0.7928534746170044, Accuracy: 0.7490234375\n",
      "Batch: 102, Loss: 0.6860882639884949, Accuracy: 0.77880859375\n",
      "Batch: 103, Loss: 0.7217092514038086, Accuracy: 0.76513671875\n",
      "Batch: 104, Loss: 0.6941097974777222, Accuracy: 0.77783203125\n",
      "Batch: 105, Loss: 0.7250794172286987, Accuracy: 0.76416015625\n",
      "Batch: 106, Loss: 0.6965499520301819, Accuracy: 0.77490234375\n",
      "Batch: 107, Loss: 0.6990023255348206, Accuracy: 0.775390625\n",
      "Batch: 108, Loss: 0.6769590377807617, Accuracy: 0.78173828125\n",
      "Batch: 109, Loss: 0.6685415506362915, Accuracy: 0.78759765625\n",
      "Batch: 110, Loss: 0.6622419357299805, Accuracy: 0.78173828125\n",
      "Batch: 111, Loss: 0.6306270360946655, Accuracy: 0.78076171875\n",
      "Batch: 112, Loss: 0.6735290288925171, Accuracy: 0.78564453125\n",
      "Batch: 113, Loss: 0.7225472927093506, Accuracy: 0.75927734375\n",
      "Batch: 114, Loss: 0.6950381398200989, Accuracy: 0.78662109375\n",
      "Batch: 115, Loss: 0.7076113224029541, Accuracy: 0.77294921875\n",
      "Batch: 116, Loss: 0.6733880639076233, Accuracy: 0.787109375\n",
      "Batch: 117, Loss: 0.6973958015441895, Accuracy: 0.775390625\n",
      "Batch: 118, Loss: 0.6906241178512573, Accuracy: 0.77783203125\n",
      "Batch: 119, Loss: 0.6805258393287659, Accuracy: 0.7734375\n",
      "Batch: 120, Loss: 0.6664145588874817, Accuracy: 0.794921875\n",
      "Batch: 121, Loss: 0.69828200340271, Accuracy: 0.77880859375\n",
      "Batch: 122, Loss: 0.6582576036453247, Accuracy: 0.78173828125\n",
      "Batch: 123, Loss: 0.6417275667190552, Accuracy: 0.79248046875\n",
      "Batch: 124, Loss: 0.6572221517562866, Accuracy: 0.78076171875\n",
      "Batch: 125, Loss: 0.684526264667511, Accuracy: 0.78564453125\n",
      "Batch: 126, Loss: 0.6683354377746582, Accuracy: 0.78759765625\n",
      "Batch: 127, Loss: 0.6353752613067627, Accuracy: 0.7958984375\n",
      "Batch: 128, Loss: 0.7599788904190063, Accuracy: 0.75537109375\n",
      "Batch: 129, Loss: 0.7867552042007446, Accuracy: 0.7470703125\n",
      "Batch: 130, Loss: 0.815029501914978, Accuracy: 0.73583984375\n",
      "Batch: 131, Loss: 0.7061624526977539, Accuracy: 0.7666015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 132, Loss: 0.6546571254730225, Accuracy: 0.787109375\n",
      "Batch: 133, Loss: 0.6533910632133484, Accuracy: 0.79443359375\n",
      "Batch: 134, Loss: 0.7320513725280762, Accuracy: 0.77197265625\n",
      "Batch: 135, Loss: 0.7086223363876343, Accuracy: 0.7734375\n",
      "Batch: 136, Loss: 0.6534184217453003, Accuracy: 0.78759765625\n",
      "Batch: 137, Loss: 0.7108434438705444, Accuracy: 0.7744140625\n",
      "Batch: 138, Loss: 0.6297218203544617, Accuracy: 0.8076171875\n",
      "Batch: 139, Loss: 0.6861327886581421, Accuracy: 0.78173828125\n",
      "Batch: 140, Loss: 0.6253906488418579, Accuracy: 0.79638671875\n",
      "Batch: 141, Loss: 0.7466258406639099, Accuracy: 0.755859375\n",
      "Batch: 142, Loss: 0.6470720171928406, Accuracy: 0.78759765625\n",
      "Batch: 143, Loss: 0.6845403909683228, Accuracy: 0.779296875\n",
      "Batch: 144, Loss: 0.7451765537261963, Accuracy: 0.76611328125\n",
      "Batch: 145, Loss: 0.6941530704498291, Accuracy: 0.78076171875\n",
      "Batch: 146, Loss: 0.7337273955345154, Accuracy: 0.7548828125\n",
      "Batch: 147, Loss: 0.6941465735435486, Accuracy: 0.77783203125\n",
      "Batch: 148, Loss: 0.7414339184761047, Accuracy: 0.7548828125\n",
      "Batch: 149, Loss: 0.7112184762954712, Accuracy: 0.77294921875\n",
      "Batch: 150, Loss: 0.6075313091278076, Accuracy: 0.80859375\n",
      "Batch: 151, Loss: 0.6185002326965332, Accuracy: 0.796875\n",
      "Batch: 152, Loss: 0.6621137857437134, Accuracy: 0.779296875\n",
      "Batch: 153, Loss: 0.65301114320755, Accuracy: 0.7861328125\n",
      "Batch: 154, Loss: 0.6766853332519531, Accuracy: 0.7783203125\n",
      "Batch: 155, Loss: 0.7428117990493774, Accuracy: 0.7568359375\n",
      "Batch: 156, Loss: 0.6334003210067749, Accuracy: 0.79296875\n",
      "Batch: 157, Loss: 0.6246986389160156, Accuracy: 0.79150390625\n",
      "Batch: 158, Loss: 0.6266427636146545, Accuracy: 0.798828125\n",
      "Batch: 159, Loss: 0.6405842304229736, Accuracy: 0.787109375\n",
      "Batch: 160, Loss: 0.6652624607086182, Accuracy: 0.78759765625\n",
      "Batch: 161, Loss: 0.685471773147583, Accuracy: 0.7802734375\n",
      "Batch: 162, Loss: 0.6536364555358887, Accuracy: 0.78955078125\n",
      "Batch: 163, Loss: 0.6994873285293579, Accuracy: 0.77392578125\n",
      "Batch: 164, Loss: 0.7970821857452393, Accuracy: 0.74169921875\n",
      "Batch: 165, Loss: 0.6863110661506653, Accuracy: 0.78076171875\n",
      "Batch: 166, Loss: 0.6840001344680786, Accuracy: 0.78076171875\n",
      "Batch: 167, Loss: 0.6876620650291443, Accuracy: 0.77197265625\n",
      "Batch: 168, Loss: 0.6120893359184265, Accuracy: 0.79296875\n",
      "Batch: 169, Loss: 0.6903388500213623, Accuracy: 0.77392578125\n",
      "Batch: 170, Loss: 0.720961332321167, Accuracy: 0.76123046875\n",
      "Batch: 171, Loss: 0.6551287770271301, Accuracy: 0.78515625\n",
      "Batch: 172, Loss: 0.6555752754211426, Accuracy: 0.7763671875\n",
      "Batch: 173, Loss: 0.7060563564300537, Accuracy: 0.7802734375\n",
      "Batch: 174, Loss: 0.5980334281921387, Accuracy: 0.80126953125\n",
      "Batch: 175, Loss: 0.7057598829269409, Accuracy: 0.76513671875\n",
      "Batch: 176, Loss: 0.7347475290298462, Accuracy: 0.7607421875\n",
      "Batch: 177, Loss: 0.6732502579689026, Accuracy: 0.79052734375\n",
      "Batch: 178, Loss: 0.657041072845459, Accuracy: 0.78369140625\n",
      "Batch: 179, Loss: 0.6852781176567078, Accuracy: 0.78076171875\n",
      "Batch: 180, Loss: 0.7284129858016968, Accuracy: 0.77294921875\n",
      "Epoch 52/200\n",
      "Batch: 1, Loss: 1.0079078674316406, Accuracy: 0.7158203125\n",
      "Batch: 2, Loss: 0.6897261142730713, Accuracy: 0.77099609375\n",
      "Batch: 3, Loss: 0.6773138046264648, Accuracy: 0.78173828125\n",
      "Batch: 4, Loss: 0.6983132362365723, Accuracy: 0.765625\n",
      "Batch: 5, Loss: 0.68900465965271, Accuracy: 0.77685546875\n",
      "Batch: 6, Loss: 0.7189385890960693, Accuracy: 0.7666015625\n",
      "Batch: 7, Loss: 0.6698113679885864, Accuracy: 0.77978515625\n",
      "Batch: 8, Loss: 0.6786676645278931, Accuracy: 0.77392578125\n",
      "Batch: 9, Loss: 0.735633373260498, Accuracy: 0.76025390625\n",
      "Batch: 10, Loss: 0.6691025495529175, Accuracy: 0.7822265625\n",
      "Batch: 11, Loss: 0.7108049988746643, Accuracy: 0.76708984375\n",
      "Batch: 12, Loss: 0.6359261870384216, Accuracy: 0.7939453125\n",
      "Batch: 13, Loss: 0.695942759513855, Accuracy: 0.77197265625\n",
      "Batch: 14, Loss: 0.6817533373832703, Accuracy: 0.78125\n",
      "Batch: 15, Loss: 0.6886045336723328, Accuracy: 0.77783203125\n",
      "Batch: 16, Loss: 0.745711624622345, Accuracy: 0.76171875\n",
      "Batch: 17, Loss: 0.6786311268806458, Accuracy: 0.78466796875\n",
      "Batch: 18, Loss: 0.7225580215454102, Accuracy: 0.7666015625\n",
      "Batch: 19, Loss: 0.7367657423019409, Accuracy: 0.76708984375\n",
      "Batch: 20, Loss: 0.619242787361145, Accuracy: 0.79736328125\n",
      "Batch: 21, Loss: 0.7401912212371826, Accuracy: 0.7666015625\n",
      "Batch: 22, Loss: 0.670712411403656, Accuracy: 0.7802734375\n",
      "Batch: 23, Loss: 0.6470829248428345, Accuracy: 0.7900390625\n",
      "Batch: 24, Loss: 0.6864202618598938, Accuracy: 0.78759765625\n",
      "Batch: 25, Loss: 0.640177309513092, Accuracy: 0.79443359375\n",
      "Batch: 26, Loss: 0.6780978441238403, Accuracy: 0.78466796875\n",
      "Batch: 27, Loss: 0.7110844254493713, Accuracy: 0.7724609375\n",
      "Batch: 28, Loss: 0.6945866346359253, Accuracy: 0.77880859375\n",
      "Batch: 29, Loss: 0.7535475492477417, Accuracy: 0.76025390625\n",
      "Batch: 30, Loss: 0.738044261932373, Accuracy: 0.763671875\n",
      "Batch: 31, Loss: 0.7902088165283203, Accuracy: 0.74462890625\n",
      "Batch: 32, Loss: 0.7372435331344604, Accuracy: 0.76513671875\n",
      "Batch: 33, Loss: 0.7345414161682129, Accuracy: 0.76123046875\n",
      "Batch: 34, Loss: 0.7436025142669678, Accuracy: 0.76123046875\n",
      "Batch: 35, Loss: 0.7583168745040894, Accuracy: 0.75830078125\n",
      "Batch: 36, Loss: 0.7197862863540649, Accuracy: 0.76953125\n",
      "Batch: 37, Loss: 0.7096569538116455, Accuracy: 0.7666015625\n",
      "Batch: 38, Loss: 0.7659175395965576, Accuracy: 0.7548828125\n",
      "Batch: 39, Loss: 0.7224417924880981, Accuracy: 0.76123046875\n",
      "Batch: 40, Loss: 0.7713848352432251, Accuracy: 0.76220703125\n",
      "Batch: 41, Loss: 0.7399495840072632, Accuracy: 0.75439453125\n",
      "Batch: 42, Loss: 0.7324374914169312, Accuracy: 0.75830078125\n",
      "Batch: 43, Loss: 0.6828954219818115, Accuracy: 0.78857421875\n",
      "Batch: 44, Loss: 0.6277870535850525, Accuracy: 0.79541015625\n",
      "Batch: 45, Loss: 0.694033145904541, Accuracy: 0.7822265625\n",
      "Batch: 46, Loss: 0.6482361555099487, Accuracy: 0.78076171875\n",
      "Batch: 47, Loss: 0.69488525390625, Accuracy: 0.77734375\n",
      "Batch: 48, Loss: 0.6899591088294983, Accuracy: 0.7802734375\n",
      "Batch: 49, Loss: 0.6854022145271301, Accuracy: 0.77783203125\n",
      "Batch: 50, Loss: 0.6939446926116943, Accuracy: 0.77978515625\n",
      "Batch: 51, Loss: 0.6693793535232544, Accuracy: 0.79052734375\n",
      "Batch: 52, Loss: 0.6650746464729309, Accuracy: 0.78271484375\n",
      "Batch: 53, Loss: 0.6933940649032593, Accuracy: 0.77294921875\n",
      "Batch: 54, Loss: 0.7370564937591553, Accuracy: 0.76171875\n",
      "Batch: 55, Loss: 0.6976991891860962, Accuracy: 0.77001953125\n",
      "Batch: 56, Loss: 0.67927086353302, Accuracy: 0.78076171875\n",
      "Batch: 57, Loss: 0.7531272172927856, Accuracy: 0.7666015625\n",
      "Batch: 58, Loss: 0.7246756553649902, Accuracy: 0.7587890625\n",
      "Batch: 59, Loss: 0.7948474287986755, Accuracy: 0.74755859375\n",
      "Batch: 60, Loss: 0.6753817796707153, Accuracy: 0.78173828125\n",
      "Batch: 61, Loss: 0.6449959874153137, Accuracy: 0.7841796875\n",
      "Batch: 62, Loss: 0.6890385746955872, Accuracy: 0.78271484375\n",
      "Batch: 63, Loss: 0.7096158862113953, Accuracy: 0.76220703125\n",
      "Batch: 64, Loss: 0.7338612079620361, Accuracy: 0.7529296875\n",
      "Batch: 65, Loss: 0.7752862572669983, Accuracy: 0.75634765625\n",
      "Batch: 66, Loss: 0.7404170036315918, Accuracy: 0.76513671875\n",
      "Batch: 67, Loss: 0.7450847625732422, Accuracy: 0.76611328125\n",
      "Batch: 68, Loss: 0.6556562185287476, Accuracy: 0.7841796875\n",
      "Batch: 69, Loss: 0.7136622071266174, Accuracy: 0.7568359375\n",
      "Batch: 70, Loss: 0.6685450077056885, Accuracy: 0.77978515625\n",
      "Batch: 71, Loss: 0.6965000033378601, Accuracy: 0.775390625\n",
      "Batch: 72, Loss: 0.7261753082275391, Accuracy: 0.76220703125\n",
      "Batch: 73, Loss: 0.7076416015625, Accuracy: 0.77001953125\n",
      "Batch: 74, Loss: 0.7124581933021545, Accuracy: 0.78173828125\n",
      "Batch: 75, Loss: 0.6583459973335266, Accuracy: 0.78125\n",
      "Batch: 76, Loss: 0.6335985660552979, Accuracy: 0.79541015625\n",
      "Batch: 77, Loss: 0.6624490022659302, Accuracy: 0.791015625\n",
      "Batch: 78, Loss: 0.7038246393203735, Accuracy: 0.7744140625\n",
      "Batch: 79, Loss: 0.6859623193740845, Accuracy: 0.78173828125\n",
      "Batch: 80, Loss: 0.7086220979690552, Accuracy: 0.77197265625\n",
      "Batch: 81, Loss: 0.7179608345031738, Accuracy: 0.77294921875\n",
      "Batch: 82, Loss: 0.6722325682640076, Accuracy: 0.77783203125\n",
      "Batch: 83, Loss: 0.6530218124389648, Accuracy: 0.7890625\n",
      "Batch: 84, Loss: 0.6395785808563232, Accuracy: 0.80029296875\n",
      "Batch: 85, Loss: 0.6843748092651367, Accuracy: 0.77685546875\n",
      "Batch: 86, Loss: 0.7327755093574524, Accuracy: 0.765625\n",
      "Batch: 87, Loss: 0.6507987976074219, Accuracy: 0.794921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 88, Loss: 0.7064822912216187, Accuracy: 0.77587890625\n",
      "Batch: 89, Loss: 0.6834782361984253, Accuracy: 0.77734375\n",
      "Batch: 90, Loss: 0.732445478439331, Accuracy: 0.75927734375\n",
      "Batch: 91, Loss: 0.6735279560089111, Accuracy: 0.787109375\n",
      "Batch: 92, Loss: 0.8074023723602295, Accuracy: 0.72705078125\n",
      "Batch: 93, Loss: 0.7401048541069031, Accuracy: 0.7607421875\n",
      "Batch: 94, Loss: 0.7148016691207886, Accuracy: 0.7763671875\n",
      "Batch: 95, Loss: 0.7521201372146606, Accuracy: 0.76318359375\n",
      "Batch: 96, Loss: 0.6919405460357666, Accuracy: 0.77490234375\n",
      "Batch: 97, Loss: 0.673316240310669, Accuracy: 0.794921875\n",
      "Batch: 98, Loss: 0.7292765378952026, Accuracy: 0.76171875\n",
      "Batch: 99, Loss: 0.7003841400146484, Accuracy: 0.7734375\n",
      "Batch: 100, Loss: 0.7588421106338501, Accuracy: 0.76513671875\n",
      "Batch: 101, Loss: 0.7673149704933167, Accuracy: 0.759765625\n",
      "Batch: 102, Loss: 0.6655763387680054, Accuracy: 0.783203125\n",
      "Batch: 103, Loss: 0.6999102234840393, Accuracy: 0.77490234375\n",
      "Batch: 104, Loss: 0.6894835829734802, Accuracy: 0.78173828125\n",
      "Batch: 105, Loss: 0.7278185486793518, Accuracy: 0.779296875\n",
      "Batch: 106, Loss: 0.675682544708252, Accuracy: 0.78369140625\n",
      "Batch: 107, Loss: 0.7073327898979187, Accuracy: 0.77001953125\n",
      "Batch: 108, Loss: 0.6851480007171631, Accuracy: 0.775390625\n",
      "Batch: 109, Loss: 0.695091962814331, Accuracy: 0.771484375\n",
      "Batch: 110, Loss: 0.6777197122573853, Accuracy: 0.77734375\n",
      "Batch: 111, Loss: 0.6207307577133179, Accuracy: 0.7998046875\n",
      "Batch: 112, Loss: 0.6808322072029114, Accuracy: 0.7841796875\n",
      "Batch: 113, Loss: 0.7285982370376587, Accuracy: 0.76513671875\n",
      "Batch: 114, Loss: 0.6905549764633179, Accuracy: 0.78173828125\n",
      "Batch: 115, Loss: 0.6907453536987305, Accuracy: 0.77734375\n",
      "Batch: 116, Loss: 0.6930299997329712, Accuracy: 0.7705078125\n",
      "Batch: 117, Loss: 0.6786882877349854, Accuracy: 0.775390625\n",
      "Batch: 118, Loss: 0.6875929236412048, Accuracy: 0.7822265625\n",
      "Batch: 119, Loss: 0.6576787829399109, Accuracy: 0.78076171875\n",
      "Batch: 120, Loss: 0.6673190593719482, Accuracy: 0.779296875\n",
      "Batch: 121, Loss: 0.690292239189148, Accuracy: 0.77587890625\n",
      "Batch: 122, Loss: 0.6481120586395264, Accuracy: 0.78564453125\n",
      "Batch: 123, Loss: 0.6472936868667603, Accuracy: 0.80029296875\n",
      "Batch: 124, Loss: 0.647613525390625, Accuracy: 0.79150390625\n",
      "Batch: 125, Loss: 0.6762793064117432, Accuracy: 0.78662109375\n",
      "Batch: 126, Loss: 0.6595293283462524, Accuracy: 0.7841796875\n",
      "Batch: 127, Loss: 0.630996823310852, Accuracy: 0.794921875\n",
      "Batch: 128, Loss: 0.7539753317832947, Accuracy: 0.7548828125\n",
      "Batch: 129, Loss: 0.7856320738792419, Accuracy: 0.74755859375\n",
      "Batch: 130, Loss: 0.785187304019928, Accuracy: 0.7451171875\n",
      "Batch: 131, Loss: 0.7073469758033752, Accuracy: 0.7783203125\n",
      "Batch: 132, Loss: 0.6638420224189758, Accuracy: 0.7880859375\n",
      "Batch: 133, Loss: 0.6605032682418823, Accuracy: 0.79248046875\n",
      "Batch: 134, Loss: 0.7244341969490051, Accuracy: 0.76513671875\n",
      "Batch: 135, Loss: 0.6918693780899048, Accuracy: 0.7666015625\n",
      "Batch: 136, Loss: 0.669730007648468, Accuracy: 0.78125\n",
      "Batch: 137, Loss: 0.6874692440032959, Accuracy: 0.78759765625\n",
      "Batch: 138, Loss: 0.6146094799041748, Accuracy: 0.8046875\n",
      "Batch: 139, Loss: 0.672526478767395, Accuracy: 0.7822265625\n",
      "Batch: 140, Loss: 0.6238764524459839, Accuracy: 0.79931640625\n",
      "Batch: 141, Loss: 0.710943341255188, Accuracy: 0.76806640625\n",
      "Batch: 142, Loss: 0.6523153781890869, Accuracy: 0.77587890625\n",
      "Batch: 143, Loss: 0.6570703983306885, Accuracy: 0.79443359375\n",
      "Batch: 144, Loss: 0.7380573749542236, Accuracy: 0.7607421875\n",
      "Batch: 145, Loss: 0.6813645362854004, Accuracy: 0.7861328125\n",
      "Batch: 146, Loss: 0.7420700788497925, Accuracy: 0.7548828125\n",
      "Batch: 147, Loss: 0.6721733808517456, Accuracy: 0.783203125\n",
      "Batch: 148, Loss: 0.7201282978057861, Accuracy: 0.755859375\n",
      "Batch: 149, Loss: 0.7156074047088623, Accuracy: 0.76953125\n",
      "Batch: 150, Loss: 0.6028033494949341, Accuracy: 0.80615234375\n",
      "Batch: 151, Loss: 0.6176658272743225, Accuracy: 0.80322265625\n",
      "Batch: 152, Loss: 0.648930549621582, Accuracy: 0.794921875\n",
      "Batch: 153, Loss: 0.6497452259063721, Accuracy: 0.7861328125\n",
      "Batch: 154, Loss: 0.659649133682251, Accuracy: 0.78173828125\n",
      "Batch: 155, Loss: 0.724799633026123, Accuracy: 0.763671875\n",
      "Batch: 156, Loss: 0.6259195804595947, Accuracy: 0.791015625\n",
      "Batch: 157, Loss: 0.6110731363296509, Accuracy: 0.7998046875\n",
      "Batch: 158, Loss: 0.6270027756690979, Accuracy: 0.8056640625\n",
      "Batch: 159, Loss: 0.6310504674911499, Accuracy: 0.7978515625\n",
      "Batch: 160, Loss: 0.6660311222076416, Accuracy: 0.78662109375\n",
      "Batch: 161, Loss: 0.6967302560806274, Accuracy: 0.7802734375\n",
      "Batch: 162, Loss: 0.6377508640289307, Accuracy: 0.7998046875\n",
      "Batch: 163, Loss: 0.7101754546165466, Accuracy: 0.76513671875\n",
      "Batch: 164, Loss: 0.7752569913864136, Accuracy: 0.75244140625\n",
      "Batch: 165, Loss: 0.6765264272689819, Accuracy: 0.7900390625\n",
      "Batch: 166, Loss: 0.7112084627151489, Accuracy: 0.77880859375\n",
      "Batch: 167, Loss: 0.6659447550773621, Accuracy: 0.78759765625\n",
      "Batch: 168, Loss: 0.6170175075531006, Accuracy: 0.81103515625\n",
      "Batch: 169, Loss: 0.6782404184341431, Accuracy: 0.779296875\n",
      "Batch: 170, Loss: 0.6961427927017212, Accuracy: 0.77392578125\n",
      "Batch: 171, Loss: 0.6635577082633972, Accuracy: 0.78369140625\n",
      "Batch: 172, Loss: 0.663092851638794, Accuracy: 0.7744140625\n",
      "Batch: 173, Loss: 0.7087521553039551, Accuracy: 0.771484375\n",
      "Batch: 174, Loss: 0.6153017282485962, Accuracy: 0.79150390625\n",
      "Batch: 175, Loss: 0.6996459364891052, Accuracy: 0.76806640625\n",
      "Batch: 176, Loss: 0.7249765396118164, Accuracy: 0.765625\n",
      "Batch: 177, Loss: 0.6540615558624268, Accuracy: 0.79248046875\n",
      "Batch: 178, Loss: 0.6357983946800232, Accuracy: 0.80029296875\n",
      "Batch: 179, Loss: 0.6657763123512268, Accuracy: 0.794921875\n",
      "Batch: 180, Loss: 0.7348040342330933, Accuracy: 0.7685546875\n",
      "Epoch 53/200\n",
      "Batch: 1, Loss: 0.9886001944541931, Accuracy: 0.72412109375\n",
      "Batch: 2, Loss: 0.6948782205581665, Accuracy: 0.765625\n",
      "Batch: 3, Loss: 0.675973653793335, Accuracy: 0.78076171875\n",
      "Batch: 4, Loss: 0.7114257216453552, Accuracy: 0.7744140625\n",
      "Batch: 5, Loss: 0.6952470541000366, Accuracy: 0.77099609375\n",
      "Batch: 6, Loss: 0.6910958290100098, Accuracy: 0.783203125\n",
      "Batch: 7, Loss: 0.6718919277191162, Accuracy: 0.783203125\n",
      "Batch: 8, Loss: 0.69637531042099, Accuracy: 0.76953125\n",
      "Batch: 9, Loss: 0.7350593209266663, Accuracy: 0.7646484375\n",
      "Batch: 10, Loss: 0.66314297914505, Accuracy: 0.7880859375\n",
      "Batch: 11, Loss: 0.7390896677970886, Accuracy: 0.76806640625\n",
      "Batch: 12, Loss: 0.6373850107192993, Accuracy: 0.79638671875\n",
      "Batch: 13, Loss: 0.6934958100318909, Accuracy: 0.779296875\n",
      "Batch: 14, Loss: 0.6829404830932617, Accuracy: 0.80078125\n",
      "Batch: 15, Loss: 0.6830043792724609, Accuracy: 0.77734375\n",
      "Batch: 16, Loss: 0.7267005443572998, Accuracy: 0.76904296875\n",
      "Batch: 17, Loss: 0.6567420959472656, Accuracy: 0.796875\n",
      "Batch: 18, Loss: 0.7253297567367554, Accuracy: 0.77294921875\n",
      "Batch: 19, Loss: 0.7181259393692017, Accuracy: 0.77734375\n",
      "Batch: 20, Loss: 0.6125344038009644, Accuracy: 0.7998046875\n",
      "Batch: 21, Loss: 0.750037431716919, Accuracy: 0.76416015625\n",
      "Batch: 22, Loss: 0.6389526128768921, Accuracy: 0.79443359375\n",
      "Batch: 23, Loss: 0.6584164500236511, Accuracy: 0.7802734375\n",
      "Batch: 24, Loss: 0.6780600547790527, Accuracy: 0.7783203125\n",
      "Batch: 25, Loss: 0.6584979295730591, Accuracy: 0.78955078125\n",
      "Batch: 26, Loss: 0.6762470006942749, Accuracy: 0.7783203125\n",
      "Batch: 27, Loss: 0.7179804444313049, Accuracy: 0.7744140625\n",
      "Batch: 28, Loss: 0.6710690259933472, Accuracy: 0.78125\n",
      "Batch: 29, Loss: 0.7315581440925598, Accuracy: 0.7626953125\n",
      "Batch: 30, Loss: 0.7197913527488708, Accuracy: 0.765625\n",
      "Batch: 31, Loss: 0.7959084510803223, Accuracy: 0.751953125\n",
      "Batch: 32, Loss: 0.7388677597045898, Accuracy: 0.765625\n",
      "Batch: 33, Loss: 0.733112633228302, Accuracy: 0.76318359375\n",
      "Batch: 34, Loss: 0.7505171298980713, Accuracy: 0.748046875\n",
      "Batch: 35, Loss: 0.7527076005935669, Accuracy: 0.74951171875\n",
      "Batch: 36, Loss: 0.7124533653259277, Accuracy: 0.7734375\n",
      "Batch: 37, Loss: 0.7361797094345093, Accuracy: 0.76220703125\n",
      "Batch: 38, Loss: 0.7564709186553955, Accuracy: 0.76123046875\n",
      "Batch: 39, Loss: 0.6931893825531006, Accuracy: 0.77490234375\n",
      "Batch: 40, Loss: 0.7609069347381592, Accuracy: 0.74169921875\n",
      "Batch: 41, Loss: 0.7140647768974304, Accuracy: 0.7705078125\n",
      "Batch: 42, Loss: 0.7071946859359741, Accuracy: 0.76318359375\n",
      "Batch: 43, Loss: 0.6734799742698669, Accuracy: 0.79052734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 44, Loss: 0.6169317960739136, Accuracy: 0.80029296875\n",
      "Batch: 45, Loss: 0.6784911155700684, Accuracy: 0.78271484375\n",
      "Batch: 46, Loss: 0.6641550660133362, Accuracy: 0.77294921875\n",
      "Batch: 47, Loss: 0.6954177021980286, Accuracy: 0.78173828125\n",
      "Batch: 48, Loss: 0.6702431440353394, Accuracy: 0.78759765625\n",
      "Batch: 49, Loss: 0.6670611500740051, Accuracy: 0.77294921875\n",
      "Batch: 50, Loss: 0.693158745765686, Accuracy: 0.78076171875\n",
      "Batch: 51, Loss: 0.6762654781341553, Accuracy: 0.78515625\n",
      "Batch: 52, Loss: 0.6495349407196045, Accuracy: 0.78515625\n",
      "Batch: 53, Loss: 0.6808923482894897, Accuracy: 0.767578125\n",
      "Batch: 54, Loss: 0.7255964875221252, Accuracy: 0.75830078125\n",
      "Batch: 55, Loss: 0.6841024160385132, Accuracy: 0.77783203125\n",
      "Batch: 56, Loss: 0.6866817474365234, Accuracy: 0.7724609375\n",
      "Batch: 57, Loss: 0.7445597052574158, Accuracy: 0.767578125\n",
      "Batch: 58, Loss: 0.7091659307479858, Accuracy: 0.7685546875\n",
      "Batch: 59, Loss: 0.8042954206466675, Accuracy: 0.748046875\n",
      "Batch: 60, Loss: 0.6882814168930054, Accuracy: 0.77783203125\n",
      "Batch: 61, Loss: 0.662157416343689, Accuracy: 0.78271484375\n",
      "Batch: 62, Loss: 0.6611269116401672, Accuracy: 0.7890625\n",
      "Batch: 63, Loss: 0.6878121495246887, Accuracy: 0.77783203125\n",
      "Batch: 64, Loss: 0.693843424320221, Accuracy: 0.7685546875\n",
      "Batch: 65, Loss: 0.7441876530647278, Accuracy: 0.76806640625\n",
      "Batch: 66, Loss: 0.7334438562393188, Accuracy: 0.7685546875\n",
      "Batch: 67, Loss: 0.7617497444152832, Accuracy: 0.75390625\n",
      "Batch: 68, Loss: 0.6453474164009094, Accuracy: 0.783203125\n",
      "Batch: 69, Loss: 0.6798269748687744, Accuracy: 0.7783203125\n",
      "Batch: 70, Loss: 0.6701117157936096, Accuracy: 0.78466796875\n",
      "Batch: 71, Loss: 0.6911353468894958, Accuracy: 0.76806640625\n",
      "Batch: 72, Loss: 0.7010656595230103, Accuracy: 0.76220703125\n",
      "Batch: 73, Loss: 0.6954021453857422, Accuracy: 0.77783203125\n",
      "Batch: 74, Loss: 0.7116130590438843, Accuracy: 0.77001953125\n",
      "Batch: 75, Loss: 0.6485790014266968, Accuracy: 0.78173828125\n",
      "Batch: 76, Loss: 0.6406263113021851, Accuracy: 0.80078125\n",
      "Batch: 77, Loss: 0.6543494462966919, Accuracy: 0.79736328125\n",
      "Batch: 78, Loss: 0.6726632118225098, Accuracy: 0.79052734375\n",
      "Batch: 79, Loss: 0.6977611780166626, Accuracy: 0.7783203125\n",
      "Batch: 80, Loss: 0.7049146890640259, Accuracy: 0.77685546875\n",
      "Batch: 81, Loss: 0.6991914510726929, Accuracy: 0.77880859375\n",
      "Batch: 82, Loss: 0.6651357412338257, Accuracy: 0.77294921875\n",
      "Batch: 83, Loss: 0.6440904140472412, Accuracy: 0.791015625\n",
      "Batch: 84, Loss: 0.6465253829956055, Accuracy: 0.791015625\n",
      "Batch: 85, Loss: 0.6888326406478882, Accuracy: 0.77490234375\n",
      "Batch: 86, Loss: 0.7239816784858704, Accuracy: 0.77099609375\n",
      "Batch: 87, Loss: 0.660893440246582, Accuracy: 0.7861328125\n",
      "Batch: 88, Loss: 0.7221015691757202, Accuracy: 0.77001953125\n",
      "Batch: 89, Loss: 0.6925164461135864, Accuracy: 0.77587890625\n",
      "Batch: 90, Loss: 0.7338173389434814, Accuracy: 0.75927734375\n",
      "Batch: 91, Loss: 0.6651453971862793, Accuracy: 0.78173828125\n",
      "Batch: 92, Loss: 0.7803677916526794, Accuracy: 0.74072265625\n",
      "Batch: 93, Loss: 0.7529724836349487, Accuracy: 0.75\n",
      "Batch: 94, Loss: 0.7136552333831787, Accuracy: 0.759765625\n",
      "Batch: 95, Loss: 0.7540215849876404, Accuracy: 0.75927734375\n",
      "Batch: 96, Loss: 0.6910673379898071, Accuracy: 0.77587890625\n",
      "Batch: 97, Loss: 0.6555017232894897, Accuracy: 0.794921875\n",
      "Batch: 98, Loss: 0.7386013269424438, Accuracy: 0.77099609375\n",
      "Batch: 99, Loss: 0.6726706027984619, Accuracy: 0.779296875\n",
      "Batch: 100, Loss: 0.7610645890235901, Accuracy: 0.75927734375\n",
      "Batch: 101, Loss: 0.7842260003089905, Accuracy: 0.75\n",
      "Batch: 102, Loss: 0.6568652391433716, Accuracy: 0.7861328125\n",
      "Batch: 103, Loss: 0.6992611885070801, Accuracy: 0.779296875\n",
      "Batch: 104, Loss: 0.6719294786453247, Accuracy: 0.7900390625\n",
      "Batch: 105, Loss: 0.7271838188171387, Accuracy: 0.7666015625\n",
      "Batch: 106, Loss: 0.6743979454040527, Accuracy: 0.78955078125\n",
      "Batch: 107, Loss: 0.7040826678276062, Accuracy: 0.775390625\n",
      "Batch: 108, Loss: 0.689856767654419, Accuracy: 0.7734375\n",
      "Batch: 109, Loss: 0.6596983671188354, Accuracy: 0.7841796875\n",
      "Batch: 110, Loss: 0.6654340028762817, Accuracy: 0.7802734375\n",
      "Batch: 111, Loss: 0.6269776821136475, Accuracy: 0.78759765625\n",
      "Batch: 112, Loss: 0.665462851524353, Accuracy: 0.77392578125\n",
      "Batch: 113, Loss: 0.7091695666313171, Accuracy: 0.76806640625\n",
      "Batch: 114, Loss: 0.6926436424255371, Accuracy: 0.779296875\n",
      "Batch: 115, Loss: 0.6924443244934082, Accuracy: 0.78369140625\n",
      "Batch: 116, Loss: 0.6855500936508179, Accuracy: 0.78271484375\n",
      "Batch: 117, Loss: 0.6736729741096497, Accuracy: 0.78173828125\n",
      "Batch: 118, Loss: 0.676016092300415, Accuracy: 0.7802734375\n",
      "Batch: 119, Loss: 0.6720799803733826, Accuracy: 0.7802734375\n",
      "Batch: 120, Loss: 0.6547502279281616, Accuracy: 0.791015625\n",
      "Batch: 121, Loss: 0.6750314235687256, Accuracy: 0.7900390625\n",
      "Batch: 122, Loss: 0.653984546661377, Accuracy: 0.78564453125\n",
      "Batch: 123, Loss: 0.645349383354187, Accuracy: 0.8017578125\n",
      "Batch: 124, Loss: 0.6475374698638916, Accuracy: 0.7890625\n",
      "Batch: 125, Loss: 0.672899603843689, Accuracy: 0.78125\n",
      "Batch: 126, Loss: 0.662971019744873, Accuracy: 0.78125\n",
      "Batch: 127, Loss: 0.6212425231933594, Accuracy: 0.79736328125\n",
      "Batch: 128, Loss: 0.7383042573928833, Accuracy: 0.7578125\n",
      "Batch: 129, Loss: 0.764755368232727, Accuracy: 0.755859375\n",
      "Batch: 130, Loss: 0.7614112496376038, Accuracy: 0.765625\n",
      "Batch: 131, Loss: 0.7100034356117249, Accuracy: 0.7744140625\n",
      "Batch: 132, Loss: 0.6504580974578857, Accuracy: 0.79150390625\n",
      "Batch: 133, Loss: 0.6412200927734375, Accuracy: 0.7958984375\n",
      "Batch: 134, Loss: 0.7076065540313721, Accuracy: 0.76708984375\n",
      "Batch: 135, Loss: 0.7097395658493042, Accuracy: 0.76220703125\n",
      "Batch: 136, Loss: 0.6329749822616577, Accuracy: 0.7978515625\n",
      "Batch: 137, Loss: 0.6582702398300171, Accuracy: 0.79052734375\n",
      "Batch: 138, Loss: 0.6210168600082397, Accuracy: 0.806640625\n",
      "Batch: 139, Loss: 0.6570197343826294, Accuracy: 0.783203125\n",
      "Batch: 140, Loss: 0.6118704676628113, Accuracy: 0.79638671875\n",
      "Batch: 141, Loss: 0.7165656089782715, Accuracy: 0.77197265625\n",
      "Batch: 142, Loss: 0.6590875387191772, Accuracy: 0.78466796875\n",
      "Batch: 143, Loss: 0.6367912292480469, Accuracy: 0.7939453125\n",
      "Batch: 144, Loss: 0.715704083442688, Accuracy: 0.77001953125\n",
      "Batch: 145, Loss: 0.6976888179779053, Accuracy: 0.77880859375\n",
      "Batch: 146, Loss: 0.732467532157898, Accuracy: 0.7646484375\n",
      "Batch: 147, Loss: 0.6930445432662964, Accuracy: 0.7783203125\n",
      "Batch: 148, Loss: 0.7118757367134094, Accuracy: 0.7587890625\n",
      "Batch: 149, Loss: 0.7176297307014465, Accuracy: 0.7685546875\n",
      "Batch: 150, Loss: 0.6151291131973267, Accuracy: 0.8095703125\n",
      "Batch: 151, Loss: 0.6089572906494141, Accuracy: 0.80322265625\n",
      "Batch: 152, Loss: 0.6394045352935791, Accuracy: 0.78857421875\n",
      "Batch: 153, Loss: 0.6465333104133606, Accuracy: 0.798828125\n",
      "Batch: 154, Loss: 0.65745609998703, Accuracy: 0.77978515625\n",
      "Batch: 155, Loss: 0.7135741710662842, Accuracy: 0.77001953125\n",
      "Batch: 156, Loss: 0.6145318746566772, Accuracy: 0.7939453125\n",
      "Batch: 157, Loss: 0.6128787398338318, Accuracy: 0.79736328125\n",
      "Batch: 158, Loss: 0.624663233757019, Accuracy: 0.80126953125\n",
      "Batch: 159, Loss: 0.640893816947937, Accuracy: 0.79150390625\n",
      "Batch: 160, Loss: 0.6704236268997192, Accuracy: 0.78173828125\n",
      "Batch: 161, Loss: 0.681641697883606, Accuracy: 0.787109375\n",
      "Batch: 162, Loss: 0.6235727667808533, Accuracy: 0.80078125\n",
      "Batch: 163, Loss: 0.6992318034172058, Accuracy: 0.77099609375\n",
      "Batch: 164, Loss: 0.7718904614448547, Accuracy: 0.7529296875\n",
      "Batch: 165, Loss: 0.6752519607543945, Accuracy: 0.791015625\n",
      "Batch: 166, Loss: 0.692612886428833, Accuracy: 0.78173828125\n",
      "Batch: 167, Loss: 0.6508479118347168, Accuracy: 0.794921875\n",
      "Batch: 168, Loss: 0.5929688215255737, Accuracy: 0.80517578125\n",
      "Batch: 169, Loss: 0.6575979590415955, Accuracy: 0.7900390625\n",
      "Batch: 170, Loss: 0.6986691355705261, Accuracy: 0.76806640625\n",
      "Batch: 171, Loss: 0.6544488668441772, Accuracy: 0.78857421875\n",
      "Batch: 172, Loss: 0.6205326914787292, Accuracy: 0.802734375\n",
      "Batch: 173, Loss: 0.6944029331207275, Accuracy: 0.77587890625\n",
      "Batch: 174, Loss: 0.5843854546546936, Accuracy: 0.80810546875\n",
      "Batch: 175, Loss: 0.686535120010376, Accuracy: 0.763671875\n",
      "Batch: 176, Loss: 0.7011560797691345, Accuracy: 0.77197265625\n",
      "Batch: 177, Loss: 0.6509388089179993, Accuracy: 0.78955078125\n",
      "Batch: 178, Loss: 0.631579577922821, Accuracy: 0.78955078125\n",
      "Batch: 179, Loss: 0.6582575440406799, Accuracy: 0.78173828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 180, Loss: 0.6945698261260986, Accuracy: 0.78125\n",
      "Epoch 54/200\n",
      "Batch: 1, Loss: 0.9950500130653381, Accuracy: 0.7216796875\n",
      "Batch: 2, Loss: 0.6699166297912598, Accuracy: 0.77978515625\n",
      "Batch: 3, Loss: 0.6751531362533569, Accuracy: 0.77783203125\n",
      "Batch: 4, Loss: 0.7076389789581299, Accuracy: 0.77001953125\n",
      "Batch: 5, Loss: 0.6897004842758179, Accuracy: 0.7783203125\n",
      "Batch: 6, Loss: 0.6943423748016357, Accuracy: 0.7841796875\n",
      "Batch: 7, Loss: 0.6561148762702942, Accuracy: 0.78515625\n",
      "Batch: 8, Loss: 0.684403657913208, Accuracy: 0.76806640625\n",
      "Batch: 9, Loss: 0.7109261155128479, Accuracy: 0.78125\n",
      "Batch: 10, Loss: 0.6601216793060303, Accuracy: 0.79443359375\n",
      "Batch: 11, Loss: 0.717281699180603, Accuracy: 0.76953125\n",
      "Batch: 12, Loss: 0.635208249092102, Accuracy: 0.79248046875\n",
      "Batch: 13, Loss: 0.6964925527572632, Accuracy: 0.767578125\n",
      "Batch: 14, Loss: 0.6959896683692932, Accuracy: 0.78466796875\n",
      "Batch: 15, Loss: 0.679244339466095, Accuracy: 0.78759765625\n",
      "Batch: 16, Loss: 0.7286496162414551, Accuracy: 0.76904296875\n",
      "Batch: 17, Loss: 0.6798000931739807, Accuracy: 0.79052734375\n",
      "Batch: 18, Loss: 0.7034000158309937, Accuracy: 0.77587890625\n",
      "Batch: 19, Loss: 0.7176294922828674, Accuracy: 0.7724609375\n",
      "Batch: 20, Loss: 0.616188645362854, Accuracy: 0.798828125\n",
      "Batch: 21, Loss: 0.7278281450271606, Accuracy: 0.7685546875\n",
      "Batch: 22, Loss: 0.6445162296295166, Accuracy: 0.79296875\n",
      "Batch: 23, Loss: 0.6453821659088135, Accuracy: 0.7939453125\n",
      "Batch: 24, Loss: 0.6713209748268127, Accuracy: 0.78173828125\n",
      "Batch: 25, Loss: 0.6399945616722107, Accuracy: 0.7919921875\n",
      "Batch: 26, Loss: 0.6741232872009277, Accuracy: 0.77783203125\n",
      "Batch: 27, Loss: 0.702391505241394, Accuracy: 0.77099609375\n",
      "Batch: 28, Loss: 0.664641261100769, Accuracy: 0.78515625\n",
      "Batch: 29, Loss: 0.733734667301178, Accuracy: 0.7685546875\n",
      "Batch: 30, Loss: 0.703648567199707, Accuracy: 0.77587890625\n",
      "Batch: 31, Loss: 0.7872791886329651, Accuracy: 0.75244140625\n",
      "Batch: 32, Loss: 0.7275070548057556, Accuracy: 0.77197265625\n",
      "Batch: 33, Loss: 0.7075269818305969, Accuracy: 0.76953125\n",
      "Batch: 34, Loss: 0.7535929679870605, Accuracy: 0.75390625\n",
      "Batch: 35, Loss: 0.7427847385406494, Accuracy: 0.7578125\n",
      "Batch: 36, Loss: 0.7142671346664429, Accuracy: 0.7744140625\n",
      "Batch: 37, Loss: 0.7079406976699829, Accuracy: 0.775390625\n",
      "Batch: 38, Loss: 0.7438400387763977, Accuracy: 0.7607421875\n",
      "Batch: 39, Loss: 0.6860278248786926, Accuracy: 0.7705078125\n",
      "Batch: 40, Loss: 0.7392098307609558, Accuracy: 0.7587890625\n",
      "Batch: 41, Loss: 0.7337905764579773, Accuracy: 0.76220703125\n",
      "Batch: 42, Loss: 0.7045135498046875, Accuracy: 0.76611328125\n",
      "Batch: 43, Loss: 0.6638197898864746, Accuracy: 0.78173828125\n",
      "Batch: 44, Loss: 0.6176146268844604, Accuracy: 0.80322265625\n",
      "Batch: 45, Loss: 0.6688860654830933, Accuracy: 0.78466796875\n",
      "Batch: 46, Loss: 0.6582751274108887, Accuracy: 0.77685546875\n",
      "Batch: 47, Loss: 0.6930441856384277, Accuracy: 0.779296875\n",
      "Batch: 48, Loss: 0.6732264757156372, Accuracy: 0.78076171875\n",
      "Batch: 49, Loss: 0.6510212421417236, Accuracy: 0.7919921875\n",
      "Batch: 50, Loss: 0.6668005585670471, Accuracy: 0.78662109375\n",
      "Batch: 51, Loss: 0.6604793667793274, Accuracy: 0.7900390625\n",
      "Batch: 52, Loss: 0.6560243368148804, Accuracy: 0.78857421875\n",
      "Batch: 53, Loss: 0.6851357817649841, Accuracy: 0.7763671875\n",
      "Batch: 54, Loss: 0.7125725746154785, Accuracy: 0.763671875\n",
      "Batch: 55, Loss: 0.6573829650878906, Accuracy: 0.78271484375\n",
      "Batch: 56, Loss: 0.687462568283081, Accuracy: 0.7822265625\n",
      "Batch: 57, Loss: 0.7228226661682129, Accuracy: 0.77587890625\n",
      "Batch: 58, Loss: 0.6732983589172363, Accuracy: 0.78125\n",
      "Batch: 59, Loss: 0.7932022213935852, Accuracy: 0.74658203125\n",
      "Batch: 60, Loss: 0.6721996068954468, Accuracy: 0.79248046875\n",
      "Batch: 61, Loss: 0.6254826188087463, Accuracy: 0.80078125\n",
      "Batch: 62, Loss: 0.6649875044822693, Accuracy: 0.79345703125\n",
      "Batch: 63, Loss: 0.6713168025016785, Accuracy: 0.771484375\n",
      "Batch: 64, Loss: 0.6884282231330872, Accuracy: 0.7705078125\n",
      "Batch: 65, Loss: 0.7467929124832153, Accuracy: 0.76611328125\n",
      "Batch: 66, Loss: 0.7110268473625183, Accuracy: 0.7724609375\n",
      "Batch: 67, Loss: 0.7346359491348267, Accuracy: 0.76416015625\n",
      "Batch: 68, Loss: 0.660548746585846, Accuracy: 0.79052734375\n",
      "Batch: 69, Loss: 0.6923542022705078, Accuracy: 0.76806640625\n",
      "Batch: 70, Loss: 0.6936075687408447, Accuracy: 0.7666015625\n",
      "Batch: 71, Loss: 0.6635491847991943, Accuracy: 0.78857421875\n",
      "Batch: 72, Loss: 0.7016969323158264, Accuracy: 0.7607421875\n",
      "Batch: 73, Loss: 0.7090430855751038, Accuracy: 0.7626953125\n",
      "Batch: 74, Loss: 0.6934797763824463, Accuracy: 0.77978515625\n",
      "Batch: 75, Loss: 0.6585143208503723, Accuracy: 0.7841796875\n",
      "Batch: 76, Loss: 0.6187801957130432, Accuracy: 0.8056640625\n",
      "Batch: 77, Loss: 0.6463805437088013, Accuracy: 0.78857421875\n",
      "Batch: 78, Loss: 0.6659073829650879, Accuracy: 0.79150390625\n",
      "Batch: 79, Loss: 0.6834756135940552, Accuracy: 0.7841796875\n",
      "Batch: 80, Loss: 0.7147321701049805, Accuracy: 0.76318359375\n",
      "Batch: 81, Loss: 0.6874041557312012, Accuracy: 0.78466796875\n",
      "Batch: 82, Loss: 0.6576517820358276, Accuracy: 0.77978515625\n",
      "Batch: 83, Loss: 0.6379583477973938, Accuracy: 0.79052734375\n",
      "Batch: 84, Loss: 0.6461158990859985, Accuracy: 0.802734375\n",
      "Batch: 85, Loss: 0.6714097261428833, Accuracy: 0.77880859375\n",
      "Batch: 86, Loss: 0.7168092131614685, Accuracy: 0.779296875\n",
      "Batch: 87, Loss: 0.6334279775619507, Accuracy: 0.7919921875\n",
      "Batch: 88, Loss: 0.7129502892494202, Accuracy: 0.7734375\n",
      "Batch: 89, Loss: 0.6737241744995117, Accuracy: 0.7822265625\n",
      "Batch: 90, Loss: 0.7205538749694824, Accuracy: 0.75830078125\n",
      "Batch: 91, Loss: 0.6518511772155762, Accuracy: 0.783203125\n",
      "Batch: 92, Loss: 0.7839411497116089, Accuracy: 0.73828125\n",
      "Batch: 93, Loss: 0.7400744557380676, Accuracy: 0.76171875\n",
      "Batch: 94, Loss: 0.7169325351715088, Accuracy: 0.78076171875\n",
      "Batch: 95, Loss: 0.7387189269065857, Accuracy: 0.7626953125\n",
      "Batch: 96, Loss: 0.6786389350891113, Accuracy: 0.7880859375\n",
      "Batch: 97, Loss: 0.6543232202529907, Accuracy: 0.79833984375\n",
      "Batch: 98, Loss: 0.7327029705047607, Accuracy: 0.771484375\n",
      "Batch: 99, Loss: 0.673386812210083, Accuracy: 0.78125\n",
      "Batch: 100, Loss: 0.7433483600616455, Accuracy: 0.767578125\n",
      "Batch: 101, Loss: 0.7484644055366516, Accuracy: 0.7578125\n",
      "Batch: 102, Loss: 0.6409593820571899, Accuracy: 0.7919921875\n",
      "Batch: 103, Loss: 0.7091407775878906, Accuracy: 0.77099609375\n",
      "Batch: 104, Loss: 0.6790509819984436, Accuracy: 0.783203125\n",
      "Batch: 105, Loss: 0.7029945254325867, Accuracy: 0.77587890625\n",
      "Batch: 106, Loss: 0.6477386951446533, Accuracy: 0.79248046875\n",
      "Batch: 107, Loss: 0.6881645917892456, Accuracy: 0.779296875\n",
      "Batch: 108, Loss: 0.6624690294265747, Accuracy: 0.78515625\n",
      "Batch: 109, Loss: 0.6670783758163452, Accuracy: 0.7861328125\n",
      "Batch: 110, Loss: 0.640420138835907, Accuracy: 0.78369140625\n",
      "Batch: 111, Loss: 0.6219571232795715, Accuracy: 0.80029296875\n",
      "Batch: 112, Loss: 0.6629502773284912, Accuracy: 0.7900390625\n",
      "Batch: 113, Loss: 0.7025575041770935, Accuracy: 0.775390625\n",
      "Batch: 114, Loss: 0.6758852601051331, Accuracy: 0.78857421875\n",
      "Batch: 115, Loss: 0.6740082502365112, Accuracy: 0.78564453125\n",
      "Batch: 116, Loss: 0.6722209453582764, Accuracy: 0.775390625\n",
      "Batch: 117, Loss: 0.676170825958252, Accuracy: 0.77783203125\n",
      "Batch: 118, Loss: 0.6886504888534546, Accuracy: 0.77783203125\n",
      "Batch: 119, Loss: 0.6733859181404114, Accuracy: 0.77490234375\n",
      "Batch: 120, Loss: 0.6694978475570679, Accuracy: 0.78076171875\n",
      "Batch: 121, Loss: 0.664810061454773, Accuracy: 0.78662109375\n",
      "Batch: 122, Loss: 0.6310076713562012, Accuracy: 0.791015625\n",
      "Batch: 123, Loss: 0.6143134832382202, Accuracy: 0.8095703125\n",
      "Batch: 124, Loss: 0.6271368861198425, Accuracy: 0.79248046875\n",
      "Batch: 125, Loss: 0.6643186807632446, Accuracy: 0.78466796875\n",
      "Batch: 126, Loss: 0.6301570534706116, Accuracy: 0.796875\n",
      "Batch: 127, Loss: 0.6199769973754883, Accuracy: 0.79541015625\n",
      "Batch: 128, Loss: 0.7498726844787598, Accuracy: 0.763671875\n",
      "Batch: 129, Loss: 0.7756800055503845, Accuracy: 0.7529296875\n",
      "Batch: 130, Loss: 0.7610410451889038, Accuracy: 0.7548828125\n",
      "Batch: 131, Loss: 0.695125162601471, Accuracy: 0.77490234375\n",
      "Batch: 132, Loss: 0.6503164768218994, Accuracy: 0.796875\n",
      "Batch: 133, Loss: 0.6411893963813782, Accuracy: 0.79345703125\n",
      "Batch: 134, Loss: 0.7004270553588867, Accuracy: 0.77587890625\n",
      "Batch: 135, Loss: 0.7020815014839172, Accuracy: 0.77294921875\n",
      "Batch: 136, Loss: 0.624840259552002, Accuracy: 0.80078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 137, Loss: 0.6716150045394897, Accuracy: 0.78564453125\n",
      "Batch: 138, Loss: 0.6135870218276978, Accuracy: 0.81201171875\n",
      "Batch: 139, Loss: 0.6406723260879517, Accuracy: 0.79150390625\n",
      "Batch: 140, Loss: 0.6145963668823242, Accuracy: 0.79443359375\n",
      "Batch: 141, Loss: 0.7028864026069641, Accuracy: 0.77587890625\n",
      "Batch: 142, Loss: 0.628756582736969, Accuracy: 0.79736328125\n",
      "Batch: 143, Loss: 0.6392207145690918, Accuracy: 0.79345703125\n",
      "Batch: 144, Loss: 0.7171955704689026, Accuracy: 0.76904296875\n",
      "Batch: 145, Loss: 0.6708492040634155, Accuracy: 0.78955078125\n",
      "Batch: 146, Loss: 0.7157098054885864, Accuracy: 0.77001953125\n",
      "Batch: 147, Loss: 0.6739399433135986, Accuracy: 0.7734375\n",
      "Batch: 148, Loss: 0.7163231372833252, Accuracy: 0.7666015625\n",
      "Batch: 149, Loss: 0.7065126895904541, Accuracy: 0.76611328125\n",
      "Batch: 150, Loss: 0.6028685569763184, Accuracy: 0.8037109375\n",
      "Batch: 151, Loss: 0.5954833030700684, Accuracy: 0.80810546875\n",
      "Batch: 152, Loss: 0.6420602798461914, Accuracy: 0.80322265625\n",
      "Batch: 153, Loss: 0.6421152353286743, Accuracy: 0.7958984375\n",
      "Batch: 154, Loss: 0.6306604146957397, Accuracy: 0.7880859375\n",
      "Batch: 155, Loss: 0.7307206392288208, Accuracy: 0.76806640625\n",
      "Batch: 156, Loss: 0.614058256149292, Accuracy: 0.79541015625\n",
      "Batch: 157, Loss: 0.6224337816238403, Accuracy: 0.79296875\n",
      "Batch: 158, Loss: 0.6037987470626831, Accuracy: 0.8125\n",
      "Batch: 159, Loss: 0.6338796615600586, Accuracy: 0.79833984375\n",
      "Batch: 160, Loss: 0.6468886137008667, Accuracy: 0.78955078125\n",
      "Batch: 161, Loss: 0.6941584348678589, Accuracy: 0.77490234375\n",
      "Batch: 162, Loss: 0.6245660781860352, Accuracy: 0.7978515625\n",
      "Batch: 163, Loss: 0.6838864088058472, Accuracy: 0.77978515625\n",
      "Batch: 164, Loss: 0.7394120097160339, Accuracy: 0.7666015625\n",
      "Batch: 165, Loss: 0.656140923500061, Accuracy: 0.794921875\n",
      "Batch: 166, Loss: 0.672307014465332, Accuracy: 0.791015625\n",
      "Batch: 167, Loss: 0.64332115650177, Accuracy: 0.798828125\n",
      "Batch: 168, Loss: 0.5924422740936279, Accuracy: 0.81103515625\n",
      "Batch: 169, Loss: 0.680536687374115, Accuracy: 0.77587890625\n",
      "Batch: 170, Loss: 0.6690788269042969, Accuracy: 0.7890625\n",
      "Batch: 171, Loss: 0.6240904927253723, Accuracy: 0.79248046875\n",
      "Batch: 172, Loss: 0.6333260536193848, Accuracy: 0.7890625\n",
      "Batch: 173, Loss: 0.6921178102493286, Accuracy: 0.77685546875\n",
      "Batch: 174, Loss: 0.5837620496749878, Accuracy: 0.80126953125\n",
      "Batch: 175, Loss: 0.7222177982330322, Accuracy: 0.76171875\n",
      "Batch: 176, Loss: 0.7228621244430542, Accuracy: 0.763671875\n",
      "Batch: 177, Loss: 0.6652677059173584, Accuracy: 0.78955078125\n",
      "Batch: 178, Loss: 0.6227640509605408, Accuracy: 0.7939453125\n",
      "Batch: 179, Loss: 0.641302227973938, Accuracy: 0.79296875\n",
      "Batch: 180, Loss: 0.6949179172515869, Accuracy: 0.77490234375\n",
      "Epoch 55/200\n",
      "Batch: 1, Loss: 0.9977793097496033, Accuracy: 0.71337890625\n",
      "Batch: 2, Loss: 0.6618947982788086, Accuracy: 0.7734375\n",
      "Batch: 3, Loss: 0.6639017462730408, Accuracy: 0.77880859375\n",
      "Batch: 4, Loss: 0.7140598297119141, Accuracy: 0.7626953125\n",
      "Batch: 5, Loss: 0.6764275431632996, Accuracy: 0.7763671875\n",
      "Batch: 6, Loss: 0.7054686546325684, Accuracy: 0.78125\n",
      "Batch: 7, Loss: 0.6474349498748779, Accuracy: 0.783203125\n",
      "Batch: 8, Loss: 0.6579413414001465, Accuracy: 0.78466796875\n",
      "Batch: 9, Loss: 0.6942388415336609, Accuracy: 0.7783203125\n",
      "Batch: 10, Loss: 0.648614764213562, Accuracy: 0.79736328125\n",
      "Batch: 11, Loss: 0.6988315582275391, Accuracy: 0.77685546875\n",
      "Batch: 12, Loss: 0.6279151439666748, Accuracy: 0.79833984375\n",
      "Batch: 13, Loss: 0.6613662242889404, Accuracy: 0.78955078125\n",
      "Batch: 14, Loss: 0.6484327912330627, Accuracy: 0.80029296875\n",
      "Batch: 15, Loss: 0.6876170039176941, Accuracy: 0.783203125\n",
      "Batch: 16, Loss: 0.714573860168457, Accuracy: 0.7666015625\n",
      "Batch: 17, Loss: 0.6396675109863281, Accuracy: 0.802734375\n",
      "Batch: 18, Loss: 0.7146007418632507, Accuracy: 0.77880859375\n",
      "Batch: 19, Loss: 0.7147804498672485, Accuracy: 0.78759765625\n",
      "Batch: 20, Loss: 0.5949074029922485, Accuracy: 0.80859375\n",
      "Batch: 21, Loss: 0.728044867515564, Accuracy: 0.77197265625\n",
      "Batch: 22, Loss: 0.6495587229728699, Accuracy: 0.787109375\n",
      "Batch: 23, Loss: 0.6206266283988953, Accuracy: 0.791015625\n",
      "Batch: 24, Loss: 0.6638609766960144, Accuracy: 0.78759765625\n",
      "Batch: 25, Loss: 0.6504454016685486, Accuracy: 0.796875\n",
      "Batch: 26, Loss: 0.6629945635795593, Accuracy: 0.7744140625\n",
      "Batch: 27, Loss: 0.6948289275169373, Accuracy: 0.7734375\n",
      "Batch: 28, Loss: 0.6456369161605835, Accuracy: 0.78662109375\n",
      "Batch: 29, Loss: 0.7340728044509888, Accuracy: 0.76171875\n",
      "Batch: 30, Loss: 0.6920979619026184, Accuracy: 0.78564453125\n",
      "Batch: 31, Loss: 0.7719712257385254, Accuracy: 0.75048828125\n",
      "Batch: 32, Loss: 0.7146446704864502, Accuracy: 0.7724609375\n",
      "Batch: 33, Loss: 0.7092824578285217, Accuracy: 0.77197265625\n",
      "Batch: 34, Loss: 0.7143397331237793, Accuracy: 0.7734375\n",
      "Batch: 35, Loss: 0.7551250457763672, Accuracy: 0.75830078125\n",
      "Batch: 36, Loss: 0.7164733409881592, Accuracy: 0.76708984375\n",
      "Batch: 37, Loss: 0.7104403972625732, Accuracy: 0.767578125\n",
      "Batch: 38, Loss: 0.733285665512085, Accuracy: 0.76904296875\n",
      "Batch: 39, Loss: 0.7006208896636963, Accuracy: 0.77490234375\n",
      "Batch: 40, Loss: 0.7362515926361084, Accuracy: 0.75927734375\n",
      "Batch: 41, Loss: 0.7484403252601624, Accuracy: 0.76123046875\n",
      "Batch: 42, Loss: 0.7079359889030457, Accuracy: 0.7666015625\n",
      "Batch: 43, Loss: 0.6607416868209839, Accuracy: 0.78466796875\n",
      "Batch: 44, Loss: 0.5973455309867859, Accuracy: 0.8125\n",
      "Batch: 45, Loss: 0.6526873111724854, Accuracy: 0.7958984375\n",
      "Batch: 46, Loss: 0.6420906782150269, Accuracy: 0.78076171875\n",
      "Batch: 47, Loss: 0.6789745092391968, Accuracy: 0.77392578125\n",
      "Batch: 48, Loss: 0.6660360097885132, Accuracy: 0.78125\n",
      "Batch: 49, Loss: 0.6556460857391357, Accuracy: 0.78759765625\n",
      "Batch: 50, Loss: 0.675641655921936, Accuracy: 0.77294921875\n",
      "Batch: 51, Loss: 0.653282642364502, Accuracy: 0.78173828125\n",
      "Batch: 52, Loss: 0.6601829528808594, Accuracy: 0.78369140625\n",
      "Batch: 53, Loss: 0.6565058827400208, Accuracy: 0.78759765625\n",
      "Batch: 54, Loss: 0.7035466432571411, Accuracy: 0.76611328125\n",
      "Batch: 55, Loss: 0.664404034614563, Accuracy: 0.779296875\n",
      "Batch: 56, Loss: 0.6659927368164062, Accuracy: 0.7734375\n",
      "Batch: 57, Loss: 0.7474799156188965, Accuracy: 0.763671875\n",
      "Batch: 58, Loss: 0.6906876564025879, Accuracy: 0.779296875\n",
      "Batch: 59, Loss: 0.7849486470222473, Accuracy: 0.75537109375\n",
      "Batch: 60, Loss: 0.6671537160873413, Accuracy: 0.7900390625\n",
      "Batch: 61, Loss: 0.6364019513130188, Accuracy: 0.7978515625\n",
      "Batch: 62, Loss: 0.6508311033248901, Accuracy: 0.79736328125\n",
      "Batch: 63, Loss: 0.6755075454711914, Accuracy: 0.7763671875\n",
      "Batch: 64, Loss: 0.6952838897705078, Accuracy: 0.76806640625\n",
      "Batch: 65, Loss: 0.732808530330658, Accuracy: 0.767578125\n",
      "Batch: 66, Loss: 0.6986042857170105, Accuracy: 0.77734375\n",
      "Batch: 67, Loss: 0.7286856174468994, Accuracy: 0.76318359375\n",
      "Batch: 68, Loss: 0.6387098431587219, Accuracy: 0.79052734375\n",
      "Batch: 69, Loss: 0.6924625039100647, Accuracy: 0.77197265625\n",
      "Batch: 70, Loss: 0.6784999370574951, Accuracy: 0.77490234375\n",
      "Batch: 71, Loss: 0.6557917594909668, Accuracy: 0.78076171875\n",
      "Batch: 72, Loss: 0.6947603225708008, Accuracy: 0.76806640625\n",
      "Batch: 73, Loss: 0.6889306902885437, Accuracy: 0.76904296875\n",
      "Batch: 74, Loss: 0.7037429809570312, Accuracy: 0.77783203125\n",
      "Batch: 75, Loss: 0.652214527130127, Accuracy: 0.791015625\n",
      "Batch: 76, Loss: 0.6233547329902649, Accuracy: 0.80517578125\n",
      "Batch: 77, Loss: 0.6239500045776367, Accuracy: 0.80810546875\n",
      "Batch: 78, Loss: 0.6735997200012207, Accuracy: 0.78271484375\n",
      "Batch: 79, Loss: 0.663821816444397, Accuracy: 0.79052734375\n",
      "Batch: 80, Loss: 0.7032792568206787, Accuracy: 0.77685546875\n",
      "Batch: 81, Loss: 0.6855776309967041, Accuracy: 0.78466796875\n",
      "Batch: 82, Loss: 0.6502159833908081, Accuracy: 0.7890625\n",
      "Batch: 83, Loss: 0.6250324249267578, Accuracy: 0.79443359375\n",
      "Batch: 84, Loss: 0.6271042823791504, Accuracy: 0.79150390625\n",
      "Batch: 85, Loss: 0.6618503928184509, Accuracy: 0.77685546875\n",
      "Batch: 86, Loss: 0.7084234952926636, Accuracy: 0.78466796875\n",
      "Batch: 87, Loss: 0.6390063762664795, Accuracy: 0.791015625\n",
      "Batch: 88, Loss: 0.6852855682373047, Accuracy: 0.78369140625\n",
      "Batch: 89, Loss: 0.6767653226852417, Accuracy: 0.7734375\n",
      "Batch: 90, Loss: 0.721400260925293, Accuracy: 0.7578125\n",
      "Batch: 91, Loss: 0.6434499025344849, Accuracy: 0.7890625\n",
      "Batch: 92, Loss: 0.7658740282058716, Accuracy: 0.751953125\n",
      "Batch: 93, Loss: 0.7163060903549194, Accuracy: 0.76123046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 94, Loss: 0.7162575721740723, Accuracy: 0.76513671875\n",
      "Batch: 95, Loss: 0.734748899936676, Accuracy: 0.7626953125\n",
      "Batch: 96, Loss: 0.6682878136634827, Accuracy: 0.78515625\n",
      "Batch: 97, Loss: 0.6576474905014038, Accuracy: 0.7978515625\n",
      "Batch: 98, Loss: 0.7137517929077148, Accuracy: 0.76416015625\n",
      "Batch: 99, Loss: 0.6529247760772705, Accuracy: 0.791015625\n",
      "Batch: 100, Loss: 0.7447211742401123, Accuracy: 0.7607421875\n",
      "Batch: 101, Loss: 0.7358397245407104, Accuracy: 0.76708984375\n",
      "Batch: 102, Loss: 0.6622897386550903, Accuracy: 0.77880859375\n",
      "Batch: 103, Loss: 0.6886888742446899, Accuracy: 0.77783203125\n",
      "Batch: 104, Loss: 0.6764185428619385, Accuracy: 0.7734375\n",
      "Batch: 105, Loss: 0.7077440023422241, Accuracy: 0.7744140625\n",
      "Batch: 106, Loss: 0.6584435105323792, Accuracy: 0.787109375\n",
      "Batch: 107, Loss: 0.6911689043045044, Accuracy: 0.77490234375\n",
      "Batch: 108, Loss: 0.6672697067260742, Accuracy: 0.77392578125\n",
      "Batch: 109, Loss: 0.6498573422431946, Accuracy: 0.7978515625\n",
      "Batch: 110, Loss: 0.6392503976821899, Accuracy: 0.79052734375\n",
      "Batch: 111, Loss: 0.6060868501663208, Accuracy: 0.79931640625\n",
      "Batch: 112, Loss: 0.642259955406189, Accuracy: 0.7880859375\n",
      "Batch: 113, Loss: 0.6952014565467834, Accuracy: 0.7724609375\n",
      "Batch: 114, Loss: 0.6588908433914185, Accuracy: 0.791015625\n",
      "Batch: 115, Loss: 0.6909854412078857, Accuracy: 0.7744140625\n",
      "Batch: 116, Loss: 0.6837379932403564, Accuracy: 0.77783203125\n",
      "Batch: 117, Loss: 0.6644415855407715, Accuracy: 0.7841796875\n",
      "Batch: 118, Loss: 0.6751527786254883, Accuracy: 0.78515625\n",
      "Batch: 119, Loss: 0.6686897277832031, Accuracy: 0.775390625\n",
      "Batch: 120, Loss: 0.6543164253234863, Accuracy: 0.791015625\n",
      "Batch: 121, Loss: 0.6439138650894165, Accuracy: 0.787109375\n",
      "Batch: 122, Loss: 0.6243083477020264, Accuracy: 0.79736328125\n",
      "Batch: 123, Loss: 0.6328662037849426, Accuracy: 0.8017578125\n",
      "Batch: 124, Loss: 0.6335086822509766, Accuracy: 0.7900390625\n",
      "Batch: 125, Loss: 0.6800990104675293, Accuracy: 0.7841796875\n",
      "Batch: 126, Loss: 0.6424455642700195, Accuracy: 0.791015625\n",
      "Batch: 127, Loss: 0.6218076944351196, Accuracy: 0.80078125\n",
      "Batch: 128, Loss: 0.7246479988098145, Accuracy: 0.76904296875\n",
      "Batch: 129, Loss: 0.7747672200202942, Accuracy: 0.75732421875\n",
      "Batch: 130, Loss: 0.7905423641204834, Accuracy: 0.75\n",
      "Batch: 131, Loss: 0.6901005506515503, Accuracy: 0.779296875\n",
      "Batch: 132, Loss: 0.6469173431396484, Accuracy: 0.79833984375\n",
      "Batch: 133, Loss: 0.6161890625953674, Accuracy: 0.8037109375\n",
      "Batch: 134, Loss: 0.7115713357925415, Accuracy: 0.7744140625\n",
      "Batch: 135, Loss: 0.6885609030723572, Accuracy: 0.77490234375\n",
      "Batch: 136, Loss: 0.6419012546539307, Accuracy: 0.78466796875\n",
      "Batch: 137, Loss: 0.6739160418510437, Accuracy: 0.77978515625\n",
      "Batch: 138, Loss: 0.6106438636779785, Accuracy: 0.81201171875\n",
      "Batch: 139, Loss: 0.6497799158096313, Accuracy: 0.787109375\n",
      "Batch: 140, Loss: 0.6182438731193542, Accuracy: 0.80224609375\n",
      "Batch: 141, Loss: 0.7158095836639404, Accuracy: 0.775390625\n",
      "Batch: 142, Loss: 0.6296143531799316, Accuracy: 0.79150390625\n",
      "Batch: 143, Loss: 0.6434779167175293, Accuracy: 0.79296875\n",
      "Batch: 144, Loss: 0.7217057943344116, Accuracy: 0.76171875\n",
      "Batch: 145, Loss: 0.6688065528869629, Accuracy: 0.783203125\n",
      "Batch: 146, Loss: 0.706229031085968, Accuracy: 0.7734375\n",
      "Batch: 147, Loss: 0.6733981370925903, Accuracy: 0.7900390625\n",
      "Batch: 148, Loss: 0.724278450012207, Accuracy: 0.7666015625\n",
      "Batch: 149, Loss: 0.6867539286613464, Accuracy: 0.7841796875\n",
      "Batch: 150, Loss: 0.6258998513221741, Accuracy: 0.79541015625\n",
      "Batch: 151, Loss: 0.5844889879226685, Accuracy: 0.814453125\n",
      "Batch: 152, Loss: 0.6341021060943604, Accuracy: 0.78759765625\n",
      "Batch: 153, Loss: 0.6485899686813354, Accuracy: 0.7998046875\n",
      "Batch: 154, Loss: 0.6448181867599487, Accuracy: 0.779296875\n",
      "Batch: 155, Loss: 0.713476300239563, Accuracy: 0.77197265625\n",
      "Batch: 156, Loss: 0.6054019927978516, Accuracy: 0.7958984375\n",
      "Batch: 157, Loss: 0.6119440793991089, Accuracy: 0.79638671875\n",
      "Batch: 158, Loss: 0.6023284196853638, Accuracy: 0.8076171875\n",
      "Batch: 159, Loss: 0.6281214952468872, Accuracy: 0.80224609375\n",
      "Batch: 160, Loss: 0.6415932178497314, Accuracy: 0.79443359375\n",
      "Batch: 161, Loss: 0.6714226007461548, Accuracy: 0.78857421875\n",
      "Batch: 162, Loss: 0.621103048324585, Accuracy: 0.79638671875\n",
      "Batch: 163, Loss: 0.678803026676178, Accuracy: 0.78173828125\n",
      "Batch: 164, Loss: 0.7284670472145081, Accuracy: 0.76806640625\n",
      "Batch: 165, Loss: 0.6567549109458923, Accuracy: 0.78076171875\n",
      "Batch: 166, Loss: 0.6690865755081177, Accuracy: 0.79296875\n",
      "Batch: 167, Loss: 0.654188871383667, Accuracy: 0.7890625\n",
      "Batch: 168, Loss: 0.600941002368927, Accuracy: 0.814453125\n",
      "Batch: 169, Loss: 0.6624914407730103, Accuracy: 0.7802734375\n",
      "Batch: 170, Loss: 0.6743742227554321, Accuracy: 0.7841796875\n",
      "Batch: 171, Loss: 0.6304808855056763, Accuracy: 0.80517578125\n",
      "Batch: 172, Loss: 0.6120806336402893, Accuracy: 0.796875\n",
      "Batch: 173, Loss: 0.6876705884933472, Accuracy: 0.78515625\n",
      "Batch: 174, Loss: 0.5880905389785767, Accuracy: 0.8037109375\n",
      "Batch: 175, Loss: 0.6936264038085938, Accuracy: 0.7724609375\n",
      "Batch: 176, Loss: 0.7194591760635376, Accuracy: 0.7705078125\n",
      "Batch: 177, Loss: 0.6594985127449036, Accuracy: 0.78857421875\n",
      "Batch: 178, Loss: 0.6010511517524719, Accuracy: 0.81298828125\n",
      "Batch: 179, Loss: 0.6569515466690063, Accuracy: 0.79443359375\n",
      "Batch: 180, Loss: 0.6914467811584473, Accuracy: 0.7724609375\n",
      "Epoch 56/200\n",
      "Batch: 1, Loss: 0.9713189601898193, Accuracy: 0.71923828125\n",
      "Batch: 2, Loss: 0.6699872612953186, Accuracy: 0.76513671875\n",
      "Batch: 3, Loss: 0.665390133857727, Accuracy: 0.78369140625\n",
      "Batch: 4, Loss: 0.6845026016235352, Accuracy: 0.77685546875\n",
      "Batch: 5, Loss: 0.653348445892334, Accuracy: 0.79150390625\n",
      "Batch: 6, Loss: 0.6703346371650696, Accuracy: 0.7861328125\n",
      "Batch: 7, Loss: 0.6644027233123779, Accuracy: 0.787109375\n",
      "Batch: 8, Loss: 0.664920449256897, Accuracy: 0.78515625\n",
      "Batch: 9, Loss: 0.7299302816390991, Accuracy: 0.771484375\n",
      "Batch: 10, Loss: 0.6420968770980835, Accuracy: 0.79736328125\n",
      "Batch: 11, Loss: 0.7011587619781494, Accuracy: 0.7724609375\n",
      "Batch: 12, Loss: 0.6202695965766907, Accuracy: 0.798828125\n",
      "Batch: 13, Loss: 0.6753646731376648, Accuracy: 0.7822265625\n",
      "Batch: 14, Loss: 0.6574066877365112, Accuracy: 0.7958984375\n",
      "Batch: 15, Loss: 0.6789259314537048, Accuracy: 0.7880859375\n",
      "Batch: 16, Loss: 0.7236372232437134, Accuracy: 0.76708984375\n",
      "Batch: 17, Loss: 0.6596827507019043, Accuracy: 0.79150390625\n",
      "Batch: 18, Loss: 0.706332802772522, Accuracy: 0.77978515625\n",
      "Batch: 19, Loss: 0.701381266117096, Accuracy: 0.783203125\n",
      "Batch: 20, Loss: 0.5863259434700012, Accuracy: 0.80712890625\n",
      "Batch: 21, Loss: 0.7089130878448486, Accuracy: 0.7724609375\n",
      "Batch: 22, Loss: 0.6303577423095703, Accuracy: 0.8017578125\n",
      "Batch: 23, Loss: 0.609968364238739, Accuracy: 0.80322265625\n",
      "Batch: 24, Loss: 0.6551899313926697, Accuracy: 0.78564453125\n",
      "Batch: 25, Loss: 0.6228689551353455, Accuracy: 0.8017578125\n",
      "Batch: 26, Loss: 0.6326550245285034, Accuracy: 0.7958984375\n",
      "Batch: 27, Loss: 0.6796494722366333, Accuracy: 0.78125\n",
      "Batch: 28, Loss: 0.6579219102859497, Accuracy: 0.7939453125\n",
      "Batch: 29, Loss: 0.7189711332321167, Accuracy: 0.76708984375\n",
      "Batch: 30, Loss: 0.6893691420555115, Accuracy: 0.78125\n",
      "Batch: 31, Loss: 0.7573741674423218, Accuracy: 0.75390625\n",
      "Batch: 32, Loss: 0.7146037817001343, Accuracy: 0.77392578125\n",
      "Batch: 33, Loss: 0.6942023634910583, Accuracy: 0.7734375\n",
      "Batch: 34, Loss: 0.7210938334465027, Accuracy: 0.76220703125\n",
      "Batch: 35, Loss: 0.728679895401001, Accuracy: 0.76025390625\n",
      "Batch: 36, Loss: 0.7054758071899414, Accuracy: 0.77294921875\n",
      "Batch: 37, Loss: 0.7035501599311829, Accuracy: 0.77490234375\n",
      "Batch: 38, Loss: 0.7438396215438843, Accuracy: 0.7607421875\n",
      "Batch: 39, Loss: 0.6793084144592285, Accuracy: 0.7763671875\n",
      "Batch: 40, Loss: 0.7530965209007263, Accuracy: 0.75732421875\n",
      "Batch: 41, Loss: 0.7163926362991333, Accuracy: 0.763671875\n",
      "Batch: 42, Loss: 0.6950676441192627, Accuracy: 0.7646484375\n",
      "Batch: 43, Loss: 0.6511307954788208, Accuracy: 0.79443359375\n",
      "Batch: 44, Loss: 0.5946740508079529, Accuracy: 0.81201171875\n",
      "Batch: 45, Loss: 0.6621202230453491, Accuracy: 0.7880859375\n",
      "Batch: 46, Loss: 0.6406461000442505, Accuracy: 0.78466796875\n",
      "Batch: 47, Loss: 0.6718393564224243, Accuracy: 0.77978515625\n",
      "Batch: 48, Loss: 0.660456657409668, Accuracy: 0.787109375\n",
      "Batch: 49, Loss: 0.6526792049407959, Accuracy: 0.7890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Loss: 0.6722975969314575, Accuracy: 0.78125\n",
      "Batch: 51, Loss: 0.6569602489471436, Accuracy: 0.771484375\n",
      "Batch: 52, Loss: 0.6554387807846069, Accuracy: 0.78662109375\n",
      "Batch: 53, Loss: 0.6561947464942932, Accuracy: 0.78662109375\n",
      "Batch: 54, Loss: 0.7126146554946899, Accuracy: 0.76171875\n",
      "Batch: 55, Loss: 0.6541125774383545, Accuracy: 0.79345703125\n",
      "Batch: 56, Loss: 0.6659776568412781, Accuracy: 0.78466796875\n",
      "Batch: 57, Loss: 0.7069296836853027, Accuracy: 0.77001953125\n",
      "Batch: 58, Loss: 0.6971213221549988, Accuracy: 0.7705078125\n",
      "Batch: 59, Loss: 0.7850685119628906, Accuracy: 0.75\n",
      "Batch: 60, Loss: 0.6729849576950073, Accuracy: 0.78125\n",
      "Batch: 61, Loss: 0.6297634840011597, Accuracy: 0.80029296875\n",
      "Batch: 62, Loss: 0.6307862997055054, Accuracy: 0.80126953125\n",
      "Batch: 63, Loss: 0.6539125442504883, Accuracy: 0.7919921875\n",
      "Batch: 64, Loss: 0.6751295328140259, Accuracy: 0.77099609375\n",
      "Batch: 65, Loss: 0.7241367101669312, Accuracy: 0.76708984375\n",
      "Batch: 66, Loss: 0.6879987716674805, Accuracy: 0.77783203125\n",
      "Batch: 67, Loss: 0.7142140865325928, Accuracy: 0.7685546875\n",
      "Batch: 68, Loss: 0.6314614415168762, Accuracy: 0.7958984375\n",
      "Batch: 69, Loss: 0.6767371892929077, Accuracy: 0.77685546875\n",
      "Batch: 70, Loss: 0.6739013195037842, Accuracy: 0.78662109375\n",
      "Batch: 71, Loss: 0.660138726234436, Accuracy: 0.7841796875\n",
      "Batch: 72, Loss: 0.6870019435882568, Accuracy: 0.76953125\n",
      "Batch: 73, Loss: 0.6751493215560913, Accuracy: 0.77978515625\n",
      "Batch: 74, Loss: 0.6900002956390381, Accuracy: 0.7802734375\n",
      "Batch: 75, Loss: 0.6426820158958435, Accuracy: 0.7861328125\n",
      "Batch: 76, Loss: 0.617641806602478, Accuracy: 0.802734375\n",
      "Batch: 77, Loss: 0.6039443016052246, Accuracy: 0.81396484375\n",
      "Batch: 78, Loss: 0.6682578921318054, Accuracy: 0.78759765625\n",
      "Batch: 79, Loss: 0.6896164417266846, Accuracy: 0.78125\n",
      "Batch: 80, Loss: 0.6875941753387451, Accuracy: 0.7822265625\n",
      "Batch: 81, Loss: 0.6905723214149475, Accuracy: 0.78076171875\n",
      "Batch: 82, Loss: 0.6557007431983948, Accuracy: 0.7841796875\n",
      "Batch: 83, Loss: 0.6282309889793396, Accuracy: 0.80029296875\n",
      "Batch: 84, Loss: 0.653965175151825, Accuracy: 0.78466796875\n",
      "Batch: 85, Loss: 0.6701542735099792, Accuracy: 0.78173828125\n",
      "Batch: 86, Loss: 0.7083916664123535, Accuracy: 0.78564453125\n",
      "Batch: 87, Loss: 0.647173285484314, Accuracy: 0.79931640625\n",
      "Batch: 88, Loss: 0.6748075485229492, Accuracy: 0.78515625\n",
      "Batch: 89, Loss: 0.6469883322715759, Accuracy: 0.7900390625\n",
      "Batch: 90, Loss: 0.7133076786994934, Accuracy: 0.7646484375\n",
      "Batch: 91, Loss: 0.6357665061950684, Accuracy: 0.79541015625\n",
      "Batch: 92, Loss: 0.7697688341140747, Accuracy: 0.74853515625\n",
      "Batch: 93, Loss: 0.7180528044700623, Accuracy: 0.763671875\n",
      "Batch: 94, Loss: 0.707250714302063, Accuracy: 0.775390625\n",
      "Batch: 95, Loss: 0.7191771864891052, Accuracy: 0.771484375\n",
      "Batch: 96, Loss: 0.6690250039100647, Accuracy: 0.7880859375\n",
      "Batch: 97, Loss: 0.6294742822647095, Accuracy: 0.8095703125\n",
      "Batch: 98, Loss: 0.7042224407196045, Accuracy: 0.77880859375\n",
      "Batch: 99, Loss: 0.6603652238845825, Accuracy: 0.783203125\n",
      "Batch: 100, Loss: 0.69948410987854, Accuracy: 0.7763671875\n",
      "Batch: 101, Loss: 0.7294681072235107, Accuracy: 0.7666015625\n",
      "Batch: 102, Loss: 0.6173301339149475, Accuracy: 0.79736328125\n",
      "Batch: 103, Loss: 0.6843871474266052, Accuracy: 0.78173828125\n",
      "Batch: 104, Loss: 0.657067060470581, Accuracy: 0.7822265625\n",
      "Batch: 105, Loss: 0.7147431373596191, Accuracy: 0.77685546875\n",
      "Batch: 106, Loss: 0.6592627167701721, Accuracy: 0.794921875\n",
      "Batch: 107, Loss: 0.6654840707778931, Accuracy: 0.7802734375\n",
      "Batch: 108, Loss: 0.6492820978164673, Accuracy: 0.78466796875\n",
      "Batch: 109, Loss: 0.6541553735733032, Accuracy: 0.791015625\n",
      "Batch: 110, Loss: 0.628851056098938, Accuracy: 0.78759765625\n",
      "Batch: 111, Loss: 0.5965466499328613, Accuracy: 0.80078125\n",
      "Batch: 112, Loss: 0.6468597054481506, Accuracy: 0.79541015625\n",
      "Batch: 113, Loss: 0.7014857530593872, Accuracy: 0.7763671875\n",
      "Batch: 114, Loss: 0.6691789627075195, Accuracy: 0.7822265625\n",
      "Batch: 115, Loss: 0.6573896408081055, Accuracy: 0.783203125\n",
      "Batch: 116, Loss: 0.6503430008888245, Accuracy: 0.794921875\n",
      "Batch: 117, Loss: 0.6532522439956665, Accuracy: 0.7880859375\n",
      "Batch: 118, Loss: 0.6646639108657837, Accuracy: 0.78369140625\n",
      "Batch: 119, Loss: 0.6522533297538757, Accuracy: 0.78662109375\n",
      "Batch: 120, Loss: 0.6634559035301208, Accuracy: 0.78857421875\n",
      "Batch: 121, Loss: 0.6437926292419434, Accuracy: 0.79541015625\n",
      "Batch: 122, Loss: 0.6284117698669434, Accuracy: 0.7900390625\n",
      "Batch: 123, Loss: 0.6178001165390015, Accuracy: 0.798828125\n",
      "Batch: 124, Loss: 0.6205898523330688, Accuracy: 0.7978515625\n",
      "Batch: 125, Loss: 0.6572328805923462, Accuracy: 0.79345703125\n",
      "Batch: 126, Loss: 0.6345118284225464, Accuracy: 0.787109375\n",
      "Batch: 127, Loss: 0.6179807782173157, Accuracy: 0.7939453125\n",
      "Batch: 128, Loss: 0.7268741130828857, Accuracy: 0.76513671875\n",
      "Batch: 129, Loss: 0.7498604655265808, Accuracy: 0.76123046875\n",
      "Batch: 130, Loss: 0.7544599771499634, Accuracy: 0.7626953125\n",
      "Batch: 131, Loss: 0.6718529462814331, Accuracy: 0.78271484375\n",
      "Batch: 132, Loss: 0.6263792514801025, Accuracy: 0.7998046875\n",
      "Batch: 133, Loss: 0.6417762041091919, Accuracy: 0.79052734375\n",
      "Batch: 134, Loss: 0.7123730182647705, Accuracy: 0.765625\n",
      "Batch: 135, Loss: 0.6780768632888794, Accuracy: 0.77587890625\n",
      "Batch: 136, Loss: 0.6496233940124512, Accuracy: 0.7841796875\n",
      "Batch: 137, Loss: 0.671562910079956, Accuracy: 0.7802734375\n",
      "Batch: 138, Loss: 0.60268235206604, Accuracy: 0.81787109375\n",
      "Batch: 139, Loss: 0.6419519186019897, Accuracy: 0.79443359375\n",
      "Batch: 140, Loss: 0.6015933752059937, Accuracy: 0.8037109375\n",
      "Batch: 141, Loss: 0.6949604749679565, Accuracy: 0.7783203125\n",
      "Batch: 142, Loss: 0.6292959451675415, Accuracy: 0.79931640625\n",
      "Batch: 143, Loss: 0.6196116209030151, Accuracy: 0.8017578125\n",
      "Batch: 144, Loss: 0.6935244798660278, Accuracy: 0.78125\n",
      "Batch: 145, Loss: 0.669872522354126, Accuracy: 0.79052734375\n",
      "Batch: 146, Loss: 0.7028311491012573, Accuracy: 0.77197265625\n",
      "Batch: 147, Loss: 0.6803493499755859, Accuracy: 0.78759765625\n",
      "Batch: 148, Loss: 0.6952900886535645, Accuracy: 0.7626953125\n",
      "Batch: 149, Loss: 0.69919353723526, Accuracy: 0.77685546875\n",
      "Batch: 150, Loss: 0.5807094573974609, Accuracy: 0.8154296875\n",
      "Batch: 151, Loss: 0.5947084426879883, Accuracy: 0.810546875\n",
      "Batch: 152, Loss: 0.6181843280792236, Accuracy: 0.80419921875\n",
      "Batch: 153, Loss: 0.6342759132385254, Accuracy: 0.7890625\n",
      "Batch: 154, Loss: 0.6448757648468018, Accuracy: 0.787109375\n",
      "Batch: 155, Loss: 0.7276625037193298, Accuracy: 0.76806640625\n",
      "Batch: 156, Loss: 0.6263618469238281, Accuracy: 0.79541015625\n",
      "Batch: 157, Loss: 0.6055393218994141, Accuracy: 0.79638671875\n",
      "Batch: 158, Loss: 0.6063340902328491, Accuracy: 0.80712890625\n",
      "Batch: 159, Loss: 0.6272182464599609, Accuracy: 0.80419921875\n",
      "Batch: 160, Loss: 0.6432046294212341, Accuracy: 0.7958984375\n",
      "Batch: 161, Loss: 0.6698495149612427, Accuracy: 0.783203125\n",
      "Batch: 162, Loss: 0.6302719712257385, Accuracy: 0.802734375\n",
      "Batch: 163, Loss: 0.6789144277572632, Accuracy: 0.7724609375\n",
      "Batch: 164, Loss: 0.7284563183784485, Accuracy: 0.77099609375\n",
      "Batch: 165, Loss: 0.6494537591934204, Accuracy: 0.7880859375\n",
      "Batch: 166, Loss: 0.6799224615097046, Accuracy: 0.78564453125\n",
      "Batch: 167, Loss: 0.6533929109573364, Accuracy: 0.79638671875\n",
      "Batch: 168, Loss: 0.5916380286216736, Accuracy: 0.81494140625\n",
      "Batch: 169, Loss: 0.6541311740875244, Accuracy: 0.7900390625\n",
      "Batch: 170, Loss: 0.6710541844367981, Accuracy: 0.78076171875\n",
      "Batch: 171, Loss: 0.6221102476119995, Accuracy: 0.791015625\n",
      "Batch: 172, Loss: 0.6309827566146851, Accuracy: 0.79248046875\n",
      "Batch: 173, Loss: 0.6804084777832031, Accuracy: 0.78125\n",
      "Batch: 174, Loss: 0.5788195729255676, Accuracy: 0.8056640625\n",
      "Batch: 175, Loss: 0.6780064105987549, Accuracy: 0.771484375\n",
      "Batch: 176, Loss: 0.6993023157119751, Accuracy: 0.78369140625\n",
      "Batch: 177, Loss: 0.6552513241767883, Accuracy: 0.79248046875\n",
      "Batch: 178, Loss: 0.6157423853874207, Accuracy: 0.79931640625\n",
      "Batch: 179, Loss: 0.6500588655471802, Accuracy: 0.7919921875\n",
      "Batch: 180, Loss: 0.6801596879959106, Accuracy: 0.78564453125\n",
      "Epoch 57/200\n",
      "Batch: 1, Loss: 0.9672324657440186, Accuracy: 0.72802734375\n",
      "Batch: 2, Loss: 0.6520557403564453, Accuracy: 0.78271484375\n",
      "Batch: 3, Loss: 0.6466699242591858, Accuracy: 0.794921875\n",
      "Batch: 4, Loss: 0.6861977577209473, Accuracy: 0.78076171875\n",
      "Batch: 5, Loss: 0.6633442640304565, Accuracy: 0.79345703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 6, Loss: 0.6740842461585999, Accuracy: 0.78271484375\n",
      "Batch: 7, Loss: 0.6560637950897217, Accuracy: 0.79052734375\n",
      "Batch: 8, Loss: 0.653208315372467, Accuracy: 0.78125\n",
      "Batch: 9, Loss: 0.7000536322593689, Accuracy: 0.77783203125\n",
      "Batch: 10, Loss: 0.6398999691009521, Accuracy: 0.796875\n",
      "Batch: 11, Loss: 0.6788032650947571, Accuracy: 0.78515625\n",
      "Batch: 12, Loss: 0.6150494813919067, Accuracy: 0.7978515625\n",
      "Batch: 13, Loss: 0.6437448859214783, Accuracy: 0.79638671875\n",
      "Batch: 14, Loss: 0.6472090482711792, Accuracy: 0.80029296875\n",
      "Batch: 15, Loss: 0.6690109372138977, Accuracy: 0.78466796875\n",
      "Batch: 16, Loss: 0.7058842182159424, Accuracy: 0.7607421875\n",
      "Batch: 17, Loss: 0.6427037715911865, Accuracy: 0.79931640625\n",
      "Batch: 18, Loss: 0.6657261848449707, Accuracy: 0.7802734375\n",
      "Batch: 19, Loss: 0.7069011926651001, Accuracy: 0.7783203125\n",
      "Batch: 20, Loss: 0.5689088106155396, Accuracy: 0.82177734375\n",
      "Batch: 21, Loss: 0.6861039400100708, Accuracy: 0.779296875\n",
      "Batch: 22, Loss: 0.6203678250312805, Accuracy: 0.80078125\n",
      "Batch: 23, Loss: 0.6197208166122437, Accuracy: 0.79736328125\n",
      "Batch: 24, Loss: 0.6611765623092651, Accuracy: 0.78369140625\n",
      "Batch: 25, Loss: 0.6372449994087219, Accuracy: 0.7919921875\n",
      "Batch: 26, Loss: 0.6580044627189636, Accuracy: 0.7880859375\n",
      "Batch: 27, Loss: 0.6877111196517944, Accuracy: 0.77783203125\n",
      "Batch: 28, Loss: 0.6470126509666443, Accuracy: 0.79443359375\n",
      "Batch: 29, Loss: 0.7104674577713013, Accuracy: 0.77734375\n",
      "Batch: 30, Loss: 0.6691564321517944, Accuracy: 0.78857421875\n",
      "Batch: 31, Loss: 0.7505818605422974, Accuracy: 0.763671875\n",
      "Batch: 32, Loss: 0.7048326730728149, Accuracy: 0.7744140625\n",
      "Batch: 33, Loss: 0.7041068077087402, Accuracy: 0.775390625\n",
      "Batch: 34, Loss: 0.724980354309082, Accuracy: 0.77294921875\n",
      "Batch: 35, Loss: 0.7366182804107666, Accuracy: 0.76513671875\n",
      "Batch: 36, Loss: 0.7184306383132935, Accuracy: 0.7734375\n",
      "Batch: 37, Loss: 0.7012441158294678, Accuracy: 0.76416015625\n",
      "Batch: 38, Loss: 0.7198885083198547, Accuracy: 0.771484375\n",
      "Batch: 39, Loss: 0.6828599572181702, Accuracy: 0.78125\n",
      "Batch: 40, Loss: 0.7310037016868591, Accuracy: 0.7587890625\n",
      "Batch: 41, Loss: 0.6945222616195679, Accuracy: 0.77197265625\n",
      "Batch: 42, Loss: 0.6831943392753601, Accuracy: 0.76953125\n",
      "Batch: 43, Loss: 0.6472574472427368, Accuracy: 0.78515625\n",
      "Batch: 44, Loss: 0.5952444076538086, Accuracy: 0.81640625\n",
      "Batch: 45, Loss: 0.6414440274238586, Accuracy: 0.78564453125\n",
      "Batch: 46, Loss: 0.6377953886985779, Accuracy: 0.78515625\n",
      "Batch: 47, Loss: 0.6565840840339661, Accuracy: 0.7861328125\n",
      "Batch: 48, Loss: 0.6692163944244385, Accuracy: 0.78369140625\n",
      "Batch: 49, Loss: 0.6522263288497925, Accuracy: 0.7900390625\n",
      "Batch: 50, Loss: 0.6536531448364258, Accuracy: 0.783203125\n",
      "Batch: 51, Loss: 0.6449867486953735, Accuracy: 0.7939453125\n",
      "Batch: 52, Loss: 0.6485037803649902, Accuracy: 0.78662109375\n",
      "Batch: 53, Loss: 0.652864396572113, Accuracy: 0.7900390625\n",
      "Batch: 54, Loss: 0.6917251348495483, Accuracy: 0.76904296875\n",
      "Batch: 55, Loss: 0.6591475009918213, Accuracy: 0.78515625\n",
      "Batch: 56, Loss: 0.6427971124649048, Accuracy: 0.78564453125\n",
      "Batch: 57, Loss: 0.7219165563583374, Accuracy: 0.77197265625\n",
      "Batch: 58, Loss: 0.6987322568893433, Accuracy: 0.77685546875\n",
      "Batch: 59, Loss: 0.7676961421966553, Accuracy: 0.759765625\n",
      "Batch: 60, Loss: 0.651930570602417, Accuracy: 0.7958984375\n",
      "Batch: 61, Loss: 0.6209245920181274, Accuracy: 0.80029296875\n",
      "Batch: 62, Loss: 0.6246070265769958, Accuracy: 0.8037109375\n",
      "Batch: 63, Loss: 0.64934241771698, Accuracy: 0.78515625\n",
      "Batch: 64, Loss: 0.6735565662384033, Accuracy: 0.77734375\n",
      "Batch: 65, Loss: 0.738002359867096, Accuracy: 0.76806640625\n",
      "Batch: 66, Loss: 0.6987696886062622, Accuracy: 0.77197265625\n",
      "Batch: 67, Loss: 0.7028181552886963, Accuracy: 0.765625\n",
      "Batch: 68, Loss: 0.619544506072998, Accuracy: 0.79541015625\n",
      "Batch: 69, Loss: 0.6866798400878906, Accuracy: 0.7734375\n",
      "Batch: 70, Loss: 0.6481251120567322, Accuracy: 0.78955078125\n",
      "Batch: 71, Loss: 0.6506134867668152, Accuracy: 0.79296875\n",
      "Batch: 72, Loss: 0.6960978507995605, Accuracy: 0.7568359375\n",
      "Batch: 73, Loss: 0.6939892768859863, Accuracy: 0.77099609375\n",
      "Batch: 74, Loss: 0.6775326728820801, Accuracy: 0.78271484375\n",
      "Batch: 75, Loss: 0.6188958883285522, Accuracy: 0.79052734375\n",
      "Batch: 76, Loss: 0.5949559807777405, Accuracy: 0.81103515625\n",
      "Batch: 77, Loss: 0.6282551288604736, Accuracy: 0.80126953125\n",
      "Batch: 78, Loss: 0.6522378921508789, Accuracy: 0.7919921875\n",
      "Batch: 79, Loss: 0.6896244287490845, Accuracy: 0.77685546875\n",
      "Batch: 80, Loss: 0.6921145915985107, Accuracy: 0.7783203125\n",
      "Batch: 81, Loss: 0.6853712797164917, Accuracy: 0.787109375\n",
      "Batch: 82, Loss: 0.6668793559074402, Accuracy: 0.7822265625\n",
      "Batch: 83, Loss: 0.6173233985900879, Accuracy: 0.7978515625\n",
      "Batch: 84, Loss: 0.6179373264312744, Accuracy: 0.8037109375\n",
      "Batch: 85, Loss: 0.6541849970817566, Accuracy: 0.7861328125\n",
      "Batch: 86, Loss: 0.7041533589363098, Accuracy: 0.77685546875\n",
      "Batch: 87, Loss: 0.618140697479248, Accuracy: 0.79833984375\n",
      "Batch: 88, Loss: 0.676240086555481, Accuracy: 0.78955078125\n",
      "Batch: 89, Loss: 0.6498383283615112, Accuracy: 0.78955078125\n",
      "Batch: 90, Loss: 0.6882743835449219, Accuracy: 0.779296875\n",
      "Batch: 91, Loss: 0.6465111374855042, Accuracy: 0.78857421875\n",
      "Batch: 92, Loss: 0.7512490749359131, Accuracy: 0.74609375\n",
      "Batch: 93, Loss: 0.7171846032142639, Accuracy: 0.77099609375\n",
      "Batch: 94, Loss: 0.6889837980270386, Accuracy: 0.77685546875\n",
      "Batch: 95, Loss: 0.7378193140029907, Accuracy: 0.76904296875\n",
      "Batch: 96, Loss: 0.6538100242614746, Accuracy: 0.79296875\n",
      "Batch: 97, Loss: 0.6518018245697021, Accuracy: 0.79931640625\n",
      "Batch: 98, Loss: 0.7171207666397095, Accuracy: 0.77197265625\n",
      "Batch: 99, Loss: 0.653877854347229, Accuracy: 0.79638671875\n",
      "Batch: 100, Loss: 0.7308964729309082, Accuracy: 0.7626953125\n",
      "Batch: 101, Loss: 0.7503954172134399, Accuracy: 0.75830078125\n",
      "Batch: 102, Loss: 0.6216918230056763, Accuracy: 0.79296875\n",
      "Batch: 103, Loss: 0.6746258735656738, Accuracy: 0.7861328125\n",
      "Batch: 104, Loss: 0.6572813987731934, Accuracy: 0.78515625\n",
      "Batch: 105, Loss: 0.6962881684303284, Accuracy: 0.7744140625\n",
      "Batch: 106, Loss: 0.6373424530029297, Accuracy: 0.79150390625\n",
      "Batch: 107, Loss: 0.683007001876831, Accuracy: 0.78759765625\n",
      "Batch: 108, Loss: 0.6429253816604614, Accuracy: 0.787109375\n",
      "Batch: 109, Loss: 0.6490401029586792, Accuracy: 0.79833984375\n",
      "Batch: 110, Loss: 0.6371534466743469, Accuracy: 0.794921875\n",
      "Batch: 111, Loss: 0.6148617267608643, Accuracy: 0.7958984375\n",
      "Batch: 112, Loss: 0.6458485126495361, Accuracy: 0.7939453125\n",
      "Batch: 113, Loss: 0.6876941919326782, Accuracy: 0.77099609375\n",
      "Batch: 114, Loss: 0.6808549165725708, Accuracy: 0.7802734375\n",
      "Batch: 115, Loss: 0.6711589097976685, Accuracy: 0.7880859375\n",
      "Batch: 116, Loss: 0.6461446285247803, Accuracy: 0.7841796875\n",
      "Batch: 117, Loss: 0.6670056581497192, Accuracy: 0.77783203125\n",
      "Batch: 118, Loss: 0.6670454740524292, Accuracy: 0.7880859375\n",
      "Batch: 119, Loss: 0.6487895250320435, Accuracy: 0.77978515625\n",
      "Batch: 120, Loss: 0.6476178765296936, Accuracy: 0.794921875\n",
      "Batch: 121, Loss: 0.6506242752075195, Accuracy: 0.7861328125\n",
      "Batch: 122, Loss: 0.6085346937179565, Accuracy: 0.806640625\n",
      "Batch: 123, Loss: 0.627804160118103, Accuracy: 0.80859375\n",
      "Batch: 124, Loss: 0.6207661628723145, Accuracy: 0.79833984375\n",
      "Batch: 125, Loss: 0.6550866365432739, Accuracy: 0.79296875\n",
      "Batch: 126, Loss: 0.6227340698242188, Accuracy: 0.79541015625\n",
      "Batch: 127, Loss: 0.5911851525306702, Accuracy: 0.79833984375\n",
      "Batch: 128, Loss: 0.7240605354309082, Accuracy: 0.77099609375\n",
      "Batch: 129, Loss: 0.7417524456977844, Accuracy: 0.76123046875\n",
      "Batch: 130, Loss: 0.7504546642303467, Accuracy: 0.7607421875\n",
      "Batch: 131, Loss: 0.6686227321624756, Accuracy: 0.79248046875\n",
      "Batch: 132, Loss: 0.6280233860015869, Accuracy: 0.79931640625\n",
      "Batch: 133, Loss: 0.6261869668960571, Accuracy: 0.798828125\n",
      "Batch: 134, Loss: 0.6697567701339722, Accuracy: 0.77734375\n",
      "Batch: 135, Loss: 0.6736189723014832, Accuracy: 0.7802734375\n",
      "Batch: 136, Loss: 0.6229472756385803, Accuracy: 0.7861328125\n",
      "Batch: 137, Loss: 0.681740403175354, Accuracy: 0.783203125\n",
      "Batch: 138, Loss: 0.5848040580749512, Accuracy: 0.8154296875\n",
      "Batch: 139, Loss: 0.6382261514663696, Accuracy: 0.78759765625\n",
      "Batch: 140, Loss: 0.6000658273696899, Accuracy: 0.80224609375\n",
      "Batch: 141, Loss: 0.6970033049583435, Accuracy: 0.7783203125\n",
      "Batch: 142, Loss: 0.6282557845115662, Accuracy: 0.79248046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 143, Loss: 0.6287039518356323, Accuracy: 0.80615234375\n",
      "Batch: 144, Loss: 0.6905450224876404, Accuracy: 0.7783203125\n",
      "Batch: 145, Loss: 0.638940691947937, Accuracy: 0.7890625\n",
      "Batch: 146, Loss: 0.711015522480011, Accuracy: 0.7666015625\n",
      "Batch: 147, Loss: 0.6421141624450684, Accuracy: 0.791015625\n",
      "Batch: 148, Loss: 0.7131032943725586, Accuracy: 0.76318359375\n",
      "Batch: 149, Loss: 0.6839240789413452, Accuracy: 0.787109375\n",
      "Batch: 150, Loss: 0.5790937542915344, Accuracy: 0.81103515625\n",
      "Batch: 151, Loss: 0.6025270223617554, Accuracy: 0.81201171875\n",
      "Batch: 152, Loss: 0.6296596527099609, Accuracy: 0.79638671875\n",
      "Batch: 153, Loss: 0.6218347549438477, Accuracy: 0.796875\n",
      "Batch: 154, Loss: 0.617662250995636, Accuracy: 0.794921875\n",
      "Batch: 155, Loss: 0.7084135413169861, Accuracy: 0.775390625\n",
      "Batch: 156, Loss: 0.6009721755981445, Accuracy: 0.79931640625\n",
      "Batch: 157, Loss: 0.6027549505233765, Accuracy: 0.79736328125\n",
      "Batch: 158, Loss: 0.596977949142456, Accuracy: 0.8134765625\n",
      "Batch: 159, Loss: 0.6169081926345825, Accuracy: 0.7978515625\n",
      "Batch: 160, Loss: 0.6368605494499207, Accuracy: 0.78955078125\n",
      "Batch: 161, Loss: 0.6450278759002686, Accuracy: 0.79638671875\n",
      "Batch: 162, Loss: 0.6306301355361938, Accuracy: 0.7939453125\n",
      "Batch: 163, Loss: 0.6663236618041992, Accuracy: 0.7783203125\n",
      "Batch: 164, Loss: 0.724568247795105, Accuracy: 0.7734375\n",
      "Batch: 165, Loss: 0.6393463611602783, Accuracy: 0.79736328125\n",
      "Batch: 166, Loss: 0.6686596870422363, Accuracy: 0.7890625\n",
      "Batch: 167, Loss: 0.6343611478805542, Accuracy: 0.7998046875\n",
      "Batch: 168, Loss: 0.5898807048797607, Accuracy: 0.81640625\n",
      "Batch: 169, Loss: 0.6466138958930969, Accuracy: 0.79150390625\n",
      "Batch: 170, Loss: 0.6771360635757446, Accuracy: 0.79248046875\n",
      "Batch: 171, Loss: 0.632127046585083, Accuracy: 0.79443359375\n",
      "Batch: 172, Loss: 0.6189807653427124, Accuracy: 0.79541015625\n",
      "Batch: 173, Loss: 0.6743607521057129, Accuracy: 0.78125\n",
      "Batch: 174, Loss: 0.5740690231323242, Accuracy: 0.80859375\n",
      "Batch: 175, Loss: 0.6628328561782837, Accuracy: 0.78271484375\n",
      "Batch: 176, Loss: 0.6904196739196777, Accuracy: 0.78662109375\n",
      "Batch: 177, Loss: 0.6494030356407166, Accuracy: 0.78125\n",
      "Batch: 178, Loss: 0.6148035526275635, Accuracy: 0.7958984375\n",
      "Batch: 179, Loss: 0.6536062955856323, Accuracy: 0.7958984375\n",
      "Batch: 180, Loss: 0.6680127382278442, Accuracy: 0.78466796875\n",
      "Epoch 58/200\n",
      "Batch: 1, Loss: 0.9338123798370361, Accuracy: 0.73388671875\n",
      "Batch: 2, Loss: 0.6609736680984497, Accuracy: 0.7783203125\n",
      "Batch: 3, Loss: 0.644947350025177, Accuracy: 0.779296875\n",
      "Batch: 4, Loss: 0.6900424957275391, Accuracy: 0.7783203125\n",
      "Batch: 5, Loss: 0.6708071827888489, Accuracy: 0.775390625\n",
      "Batch: 6, Loss: 0.6806278228759766, Accuracy: 0.78076171875\n",
      "Batch: 7, Loss: 0.6385161876678467, Accuracy: 0.79248046875\n",
      "Batch: 8, Loss: 0.6455422639846802, Accuracy: 0.77734375\n",
      "Batch: 9, Loss: 0.6913583278656006, Accuracy: 0.78125\n",
      "Batch: 10, Loss: 0.6434506177902222, Accuracy: 0.802734375\n",
      "Batch: 11, Loss: 0.6877776384353638, Accuracy: 0.7724609375\n",
      "Batch: 12, Loss: 0.6086732149124146, Accuracy: 0.80419921875\n",
      "Batch: 13, Loss: 0.6606308817863464, Accuracy: 0.7890625\n",
      "Batch: 14, Loss: 0.6556304693222046, Accuracy: 0.79296875\n",
      "Batch: 15, Loss: 0.6435917615890503, Accuracy: 0.794921875\n",
      "Batch: 16, Loss: 0.6940710544586182, Accuracy: 0.77001953125\n",
      "Batch: 17, Loss: 0.6374503374099731, Accuracy: 0.7919921875\n",
      "Batch: 18, Loss: 0.6776810884475708, Accuracy: 0.7890625\n",
      "Batch: 19, Loss: 0.7008318901062012, Accuracy: 0.77978515625\n",
      "Batch: 20, Loss: 0.5695555806159973, Accuracy: 0.81396484375\n",
      "Batch: 21, Loss: 0.7029699087142944, Accuracy: 0.767578125\n",
      "Batch: 22, Loss: 0.617998480796814, Accuracy: 0.80419921875\n",
      "Batch: 23, Loss: 0.6088557243347168, Accuracy: 0.80029296875\n",
      "Batch: 24, Loss: 0.6564358472824097, Accuracy: 0.7880859375\n",
      "Batch: 25, Loss: 0.6060678958892822, Accuracy: 0.810546875\n",
      "Batch: 26, Loss: 0.6241582632064819, Accuracy: 0.79931640625\n",
      "Batch: 27, Loss: 0.6585357189178467, Accuracy: 0.7939453125\n",
      "Batch: 28, Loss: 0.6456525325775146, Accuracy: 0.7841796875\n",
      "Batch: 29, Loss: 0.717117428779602, Accuracy: 0.76513671875\n",
      "Batch: 30, Loss: 0.6964937448501587, Accuracy: 0.775390625\n",
      "Batch: 31, Loss: 0.761325478553772, Accuracy: 0.755859375\n",
      "Batch: 32, Loss: 0.7067734599113464, Accuracy: 0.7763671875\n",
      "Batch: 33, Loss: 0.6945376992225647, Accuracy: 0.78076171875\n",
      "Batch: 34, Loss: 0.6978774070739746, Accuracy: 0.7705078125\n",
      "Batch: 35, Loss: 0.7220790386199951, Accuracy: 0.7646484375\n",
      "Batch: 36, Loss: 0.6859500408172607, Accuracy: 0.77978515625\n",
      "Batch: 37, Loss: 0.6886371374130249, Accuracy: 0.775390625\n",
      "Batch: 38, Loss: 0.7218325138092041, Accuracy: 0.771484375\n",
      "Batch: 39, Loss: 0.6819620132446289, Accuracy: 0.7744140625\n",
      "Batch: 40, Loss: 0.7238169312477112, Accuracy: 0.77001953125\n",
      "Batch: 41, Loss: 0.7043153047561646, Accuracy: 0.76708984375\n",
      "Batch: 42, Loss: 0.6846483945846558, Accuracy: 0.7734375\n",
      "Batch: 43, Loss: 0.6353588104248047, Accuracy: 0.79248046875\n",
      "Batch: 44, Loss: 0.5920363664627075, Accuracy: 0.8134765625\n",
      "Batch: 45, Loss: 0.6298666000366211, Accuracy: 0.80859375\n",
      "Batch: 46, Loss: 0.620979368686676, Accuracy: 0.78857421875\n",
      "Batch: 47, Loss: 0.6478440761566162, Accuracy: 0.79443359375\n",
      "Batch: 48, Loss: 0.6574400663375854, Accuracy: 0.78955078125\n",
      "Batch: 49, Loss: 0.6420794129371643, Accuracy: 0.7890625\n",
      "Batch: 50, Loss: 0.6431712508201599, Accuracy: 0.78173828125\n",
      "Batch: 51, Loss: 0.6330026388168335, Accuracy: 0.796875\n",
      "Batch: 52, Loss: 0.6165791749954224, Accuracy: 0.79345703125\n",
      "Batch: 53, Loss: 0.6413309574127197, Accuracy: 0.78955078125\n",
      "Batch: 54, Loss: 0.6959173679351807, Accuracy: 0.76904296875\n",
      "Batch: 55, Loss: 0.6397851705551147, Accuracy: 0.7939453125\n",
      "Batch: 56, Loss: 0.6541180610656738, Accuracy: 0.77880859375\n",
      "Batch: 57, Loss: 0.6920675039291382, Accuracy: 0.78564453125\n",
      "Batch: 58, Loss: 0.6626109480857849, Accuracy: 0.78369140625\n",
      "Batch: 59, Loss: 0.7668318748474121, Accuracy: 0.765625\n",
      "Batch: 60, Loss: 0.6640918850898743, Accuracy: 0.79150390625\n",
      "Batch: 61, Loss: 0.611219048500061, Accuracy: 0.79833984375\n",
      "Batch: 62, Loss: 0.6220595836639404, Accuracy: 0.79296875\n",
      "Batch: 63, Loss: 0.6362289190292358, Accuracy: 0.791015625\n",
      "Batch: 64, Loss: 0.6630285978317261, Accuracy: 0.787109375\n",
      "Batch: 65, Loss: 0.7176694273948669, Accuracy: 0.7734375\n",
      "Batch: 66, Loss: 0.6721377372741699, Accuracy: 0.7841796875\n",
      "Batch: 67, Loss: 0.694411039352417, Accuracy: 0.77783203125\n",
      "Batch: 68, Loss: 0.6037188768386841, Accuracy: 0.79541015625\n",
      "Batch: 69, Loss: 0.667190432548523, Accuracy: 0.78076171875\n",
      "Batch: 70, Loss: 0.6537119150161743, Accuracy: 0.7802734375\n",
      "Batch: 71, Loss: 0.6436628103256226, Accuracy: 0.7880859375\n",
      "Batch: 72, Loss: 0.7039002180099487, Accuracy: 0.76953125\n",
      "Batch: 73, Loss: 0.6643122434616089, Accuracy: 0.77392578125\n",
      "Batch: 74, Loss: 0.6723524332046509, Accuracy: 0.78369140625\n",
      "Batch: 75, Loss: 0.6229985952377319, Accuracy: 0.79345703125\n",
      "Batch: 76, Loss: 0.6060380339622498, Accuracy: 0.81640625\n",
      "Batch: 77, Loss: 0.6038861274719238, Accuracy: 0.81396484375\n",
      "Batch: 78, Loss: 0.6569181680679321, Accuracy: 0.794921875\n",
      "Batch: 79, Loss: 0.6602455973625183, Accuracy: 0.7841796875\n",
      "Batch: 80, Loss: 0.6691946387290955, Accuracy: 0.7900390625\n",
      "Batch: 81, Loss: 0.6736146211624146, Accuracy: 0.7919921875\n",
      "Batch: 82, Loss: 0.6406969428062439, Accuracy: 0.7890625\n",
      "Batch: 83, Loss: 0.6090174913406372, Accuracy: 0.79931640625\n",
      "Batch: 84, Loss: 0.6375607848167419, Accuracy: 0.80029296875\n",
      "Batch: 85, Loss: 0.6757120490074158, Accuracy: 0.7802734375\n",
      "Batch: 86, Loss: 0.7018685340881348, Accuracy: 0.7841796875\n",
      "Batch: 87, Loss: 0.6235058307647705, Accuracy: 0.796875\n",
      "Batch: 88, Loss: 0.6818546056747437, Accuracy: 0.783203125\n",
      "Batch: 89, Loss: 0.6549115180969238, Accuracy: 0.7861328125\n",
      "Batch: 90, Loss: 0.687817394733429, Accuracy: 0.77783203125\n",
      "Batch: 91, Loss: 0.6392720341682434, Accuracy: 0.79443359375\n",
      "Batch: 92, Loss: 0.7357649207115173, Accuracy: 0.74951171875\n",
      "Batch: 93, Loss: 0.6913949251174927, Accuracy: 0.77197265625\n",
      "Batch: 94, Loss: 0.6857478618621826, Accuracy: 0.78173828125\n",
      "Batch: 95, Loss: 0.7088543176651001, Accuracy: 0.77587890625\n",
      "Batch: 96, Loss: 0.6506699323654175, Accuracy: 0.796875\n",
      "Batch: 97, Loss: 0.6389287710189819, Accuracy: 0.8017578125\n",
      "Batch: 98, Loss: 0.6878789663314819, Accuracy: 0.77880859375\n",
      "Batch: 99, Loss: 0.6488540768623352, Accuracy: 0.7958984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Loss: 0.7190686464309692, Accuracy: 0.76708984375\n",
      "Batch: 101, Loss: 0.7165610790252686, Accuracy: 0.7705078125\n",
      "Batch: 102, Loss: 0.6332826614379883, Accuracy: 0.79296875\n",
      "Batch: 103, Loss: 0.6654183864593506, Accuracy: 0.78515625\n",
      "Batch: 104, Loss: 0.6503891944885254, Accuracy: 0.78857421875\n",
      "Batch: 105, Loss: 0.6812101602554321, Accuracy: 0.77880859375\n",
      "Batch: 106, Loss: 0.6281356811523438, Accuracy: 0.80126953125\n",
      "Batch: 107, Loss: 0.6729284524917603, Accuracy: 0.78466796875\n",
      "Batch: 108, Loss: 0.6121933460235596, Accuracy: 0.7978515625\n",
      "Batch: 109, Loss: 0.6361865997314453, Accuracy: 0.8017578125\n",
      "Batch: 110, Loss: 0.6354082822799683, Accuracy: 0.79541015625\n",
      "Batch: 111, Loss: 0.5979064702987671, Accuracy: 0.79296875\n",
      "Batch: 112, Loss: 0.6502230763435364, Accuracy: 0.7890625\n",
      "Batch: 113, Loss: 0.6536642909049988, Accuracy: 0.78466796875\n",
      "Batch: 114, Loss: 0.6621525287628174, Accuracy: 0.79052734375\n",
      "Batch: 115, Loss: 0.6424243450164795, Accuracy: 0.79541015625\n",
      "Batch: 116, Loss: 0.6460483074188232, Accuracy: 0.7900390625\n",
      "Batch: 117, Loss: 0.6352075338363647, Accuracy: 0.7939453125\n",
      "Batch: 118, Loss: 0.6457255482673645, Accuracy: 0.7890625\n",
      "Batch: 119, Loss: 0.647871196269989, Accuracy: 0.7900390625\n",
      "Batch: 120, Loss: 0.6047759056091309, Accuracy: 0.81103515625\n",
      "Batch: 121, Loss: 0.6626108884811401, Accuracy: 0.78125\n",
      "Batch: 122, Loss: 0.5984104871749878, Accuracy: 0.80224609375\n",
      "Batch: 123, Loss: 0.5898213982582092, Accuracy: 0.81201171875\n",
      "Batch: 124, Loss: 0.6094077825546265, Accuracy: 0.798828125\n",
      "Batch: 125, Loss: 0.6413495540618896, Accuracy: 0.79736328125\n",
      "Batch: 126, Loss: 0.6211975812911987, Accuracy: 0.80224609375\n",
      "Batch: 127, Loss: 0.6015197038650513, Accuracy: 0.80078125\n",
      "Batch: 128, Loss: 0.7359088063240051, Accuracy: 0.76318359375\n",
      "Batch: 129, Loss: 0.7353892922401428, Accuracy: 0.7607421875\n",
      "Batch: 130, Loss: 0.7289050221443176, Accuracy: 0.76025390625\n",
      "Batch: 131, Loss: 0.6699482798576355, Accuracy: 0.7783203125\n",
      "Batch: 132, Loss: 0.6172149181365967, Accuracy: 0.79931640625\n",
      "Batch: 133, Loss: 0.6248021125793457, Accuracy: 0.79833984375\n",
      "Batch: 134, Loss: 0.680046796798706, Accuracy: 0.78173828125\n",
      "Batch: 135, Loss: 0.6729515194892883, Accuracy: 0.7783203125\n",
      "Batch: 136, Loss: 0.6231972575187683, Accuracy: 0.79931640625\n",
      "Batch: 137, Loss: 0.6472969055175781, Accuracy: 0.796875\n",
      "Batch: 138, Loss: 0.60332190990448, Accuracy: 0.8125\n",
      "Batch: 139, Loss: 0.6122264862060547, Accuracy: 0.80029296875\n",
      "Batch: 140, Loss: 0.5827759504318237, Accuracy: 0.8125\n",
      "Batch: 141, Loss: 0.6829692721366882, Accuracy: 0.77734375\n",
      "Batch: 142, Loss: 0.621232807636261, Accuracy: 0.7900390625\n",
      "Batch: 143, Loss: 0.6182204484939575, Accuracy: 0.80126953125\n",
      "Batch: 144, Loss: 0.6904895901679993, Accuracy: 0.775390625\n",
      "Batch: 145, Loss: 0.6624394655227661, Accuracy: 0.79345703125\n",
      "Batch: 146, Loss: 0.6832895278930664, Accuracy: 0.7802734375\n",
      "Batch: 147, Loss: 0.6426815986633301, Accuracy: 0.79150390625\n",
      "Batch: 148, Loss: 0.7071825265884399, Accuracy: 0.76806640625\n",
      "Batch: 149, Loss: 0.6831048727035522, Accuracy: 0.7783203125\n",
      "Batch: 150, Loss: 0.5763625502586365, Accuracy: 0.81103515625\n",
      "Batch: 151, Loss: 0.5683022737503052, Accuracy: 0.81494140625\n",
      "Batch: 152, Loss: 0.6320363283157349, Accuracy: 0.79443359375\n",
      "Batch: 153, Loss: 0.624340295791626, Accuracy: 0.7998046875\n",
      "Batch: 154, Loss: 0.6187395453453064, Accuracy: 0.798828125\n",
      "Batch: 155, Loss: 0.6816284656524658, Accuracy: 0.78369140625\n",
      "Batch: 156, Loss: 0.6044450998306274, Accuracy: 0.8037109375\n",
      "Batch: 157, Loss: 0.5892425775527954, Accuracy: 0.8046875\n",
      "Batch: 158, Loss: 0.5903215408325195, Accuracy: 0.8134765625\n",
      "Batch: 159, Loss: 0.6126964688301086, Accuracy: 0.8056640625\n",
      "Batch: 160, Loss: 0.6273676156997681, Accuracy: 0.79931640625\n",
      "Batch: 161, Loss: 0.6478537917137146, Accuracy: 0.7890625\n",
      "Batch: 162, Loss: 0.5960664749145508, Accuracy: 0.80615234375\n",
      "Batch: 163, Loss: 0.675463855266571, Accuracy: 0.78662109375\n",
      "Batch: 164, Loss: 0.7076011896133423, Accuracy: 0.7744140625\n",
      "Batch: 165, Loss: 0.6561009287834167, Accuracy: 0.79931640625\n",
      "Batch: 166, Loss: 0.6658803224563599, Accuracy: 0.80078125\n",
      "Batch: 167, Loss: 0.6287410259246826, Accuracy: 0.79150390625\n",
      "Batch: 168, Loss: 0.5731478929519653, Accuracy: 0.81396484375\n",
      "Batch: 169, Loss: 0.6451402902603149, Accuracy: 0.787109375\n",
      "Batch: 170, Loss: 0.6563257575035095, Accuracy: 0.79443359375\n",
      "Batch: 171, Loss: 0.615540087223053, Accuracy: 0.79931640625\n",
      "Batch: 172, Loss: 0.6441236734390259, Accuracy: 0.78955078125\n",
      "Batch: 173, Loss: 0.6715433597564697, Accuracy: 0.77978515625\n",
      "Batch: 174, Loss: 0.5623518824577332, Accuracy: 0.81201171875\n",
      "Batch: 175, Loss: 0.6608957052230835, Accuracy: 0.77880859375\n",
      "Batch: 176, Loss: 0.6840170621871948, Accuracy: 0.78271484375\n",
      "Batch: 177, Loss: 0.6251811981201172, Accuracy: 0.80419921875\n",
      "Batch: 178, Loss: 0.5952056646347046, Accuracy: 0.81005859375\n",
      "Batch: 179, Loss: 0.6373759508132935, Accuracy: 0.79736328125\n",
      "Batch: 180, Loss: 0.6903778314590454, Accuracy: 0.77978515625\n",
      "Epoch 59/200\n",
      "Batch: 1, Loss: 0.9596155285835266, Accuracy: 0.7294921875\n",
      "Batch: 2, Loss: 0.6531915068626404, Accuracy: 0.77734375\n",
      "Batch: 3, Loss: 0.6420927047729492, Accuracy: 0.79638671875\n",
      "Batch: 4, Loss: 0.669468104839325, Accuracy: 0.77587890625\n",
      "Batch: 5, Loss: 0.6389533877372742, Accuracy: 0.787109375\n",
      "Batch: 6, Loss: 0.6502295732498169, Accuracy: 0.78125\n",
      "Batch: 7, Loss: 0.6344398856163025, Accuracy: 0.79736328125\n",
      "Batch: 8, Loss: 0.6472066044807434, Accuracy: 0.791015625\n",
      "Batch: 9, Loss: 0.6673222780227661, Accuracy: 0.7900390625\n",
      "Batch: 10, Loss: 0.6247168779373169, Accuracy: 0.79931640625\n",
      "Batch: 11, Loss: 0.6871288418769836, Accuracy: 0.78173828125\n",
      "Batch: 12, Loss: 0.5931071043014526, Accuracy: 0.8115234375\n",
      "Batch: 13, Loss: 0.6393333673477173, Accuracy: 0.78857421875\n",
      "Batch: 14, Loss: 0.6405549645423889, Accuracy: 0.798828125\n",
      "Batch: 15, Loss: 0.6573868989944458, Accuracy: 0.78955078125\n",
      "Batch: 16, Loss: 0.6959055662155151, Accuracy: 0.77001953125\n",
      "Batch: 17, Loss: 0.6327066421508789, Accuracy: 0.8017578125\n",
      "Batch: 18, Loss: 0.6883513331413269, Accuracy: 0.787109375\n",
      "Batch: 19, Loss: 0.6657284498214722, Accuracy: 0.7900390625\n",
      "Batch: 20, Loss: 0.5618201494216919, Accuracy: 0.82470703125\n",
      "Batch: 21, Loss: 0.6806880235671997, Accuracy: 0.78466796875\n",
      "Batch: 22, Loss: 0.6154395937919617, Accuracy: 0.8046875\n",
      "Batch: 23, Loss: 0.6016790866851807, Accuracy: 0.80419921875\n",
      "Batch: 24, Loss: 0.6299254298210144, Accuracy: 0.794921875\n",
      "Batch: 25, Loss: 0.618208646774292, Accuracy: 0.7998046875\n",
      "Batch: 26, Loss: 0.6355854868888855, Accuracy: 0.78515625\n",
      "Batch: 27, Loss: 0.679913341999054, Accuracy: 0.779296875\n",
      "Batch: 28, Loss: 0.632577657699585, Accuracy: 0.79638671875\n",
      "Batch: 29, Loss: 0.7084252834320068, Accuracy: 0.7763671875\n",
      "Batch: 30, Loss: 0.6665003895759583, Accuracy: 0.77880859375\n",
      "Batch: 31, Loss: 0.7440937757492065, Accuracy: 0.763671875\n",
      "Batch: 32, Loss: 0.6792091131210327, Accuracy: 0.77978515625\n",
      "Batch: 33, Loss: 0.6950381994247437, Accuracy: 0.77099609375\n",
      "Batch: 34, Loss: 0.7037065029144287, Accuracy: 0.76806640625\n",
      "Batch: 35, Loss: 0.6982550621032715, Accuracy: 0.765625\n",
      "Batch: 36, Loss: 0.6671428680419922, Accuracy: 0.7802734375\n",
      "Batch: 37, Loss: 0.6939103603363037, Accuracy: 0.771484375\n",
      "Batch: 38, Loss: 0.7166857123374939, Accuracy: 0.76416015625\n",
      "Batch: 39, Loss: 0.6623165607452393, Accuracy: 0.78173828125\n",
      "Batch: 40, Loss: 0.7259922623634338, Accuracy: 0.76416015625\n",
      "Batch: 41, Loss: 0.6798098087310791, Accuracy: 0.77734375\n",
      "Batch: 42, Loss: 0.6712049841880798, Accuracy: 0.7724609375\n",
      "Batch: 43, Loss: 0.6171320676803589, Accuracy: 0.80419921875\n",
      "Batch: 44, Loss: 0.5729842185974121, Accuracy: 0.814453125\n",
      "Batch: 45, Loss: 0.6473681330680847, Accuracy: 0.78369140625\n",
      "Batch: 46, Loss: 0.6136512160301208, Accuracy: 0.78759765625\n",
      "Batch: 47, Loss: 0.647168755531311, Accuracy: 0.79052734375\n",
      "Batch: 48, Loss: 0.6467044949531555, Accuracy: 0.794921875\n",
      "Batch: 49, Loss: 0.6276686191558838, Accuracy: 0.794921875\n",
      "Batch: 50, Loss: 0.664959728717804, Accuracy: 0.78076171875\n",
      "Batch: 51, Loss: 0.6317688822746277, Accuracy: 0.796875\n",
      "Batch: 52, Loss: 0.6409972310066223, Accuracy: 0.787109375\n",
      "Batch: 53, Loss: 0.6501663327217102, Accuracy: 0.78564453125\n",
      "Batch: 54, Loss: 0.7053711414337158, Accuracy: 0.76611328125\n",
      "Batch: 55, Loss: 0.672839879989624, Accuracy: 0.78369140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 56, Loss: 0.6539521217346191, Accuracy: 0.78759765625\n",
      "Batch: 57, Loss: 0.7078008055686951, Accuracy: 0.77734375\n",
      "Batch: 58, Loss: 0.66490638256073, Accuracy: 0.78515625\n",
      "Batch: 59, Loss: 0.7754608392715454, Accuracy: 0.74951171875\n",
      "Batch: 60, Loss: 0.6409524083137512, Accuracy: 0.79541015625\n",
      "Batch: 61, Loss: 0.6123844981193542, Accuracy: 0.8046875\n",
      "Batch: 62, Loss: 0.6130977272987366, Accuracy: 0.81591796875\n",
      "Batch: 63, Loss: 0.6332094073295593, Accuracy: 0.79052734375\n",
      "Batch: 64, Loss: 0.6516213417053223, Accuracy: 0.78173828125\n",
      "Batch: 65, Loss: 0.722598135471344, Accuracy: 0.76806640625\n",
      "Batch: 66, Loss: 0.6676827669143677, Accuracy: 0.78466796875\n",
      "Batch: 67, Loss: 0.6780775189399719, Accuracy: 0.78857421875\n",
      "Batch: 68, Loss: 0.6214781999588013, Accuracy: 0.79296875\n",
      "Batch: 69, Loss: 0.6582812070846558, Accuracy: 0.7841796875\n",
      "Batch: 70, Loss: 0.6375080347061157, Accuracy: 0.77880859375\n",
      "Batch: 71, Loss: 0.6332961320877075, Accuracy: 0.7880859375\n",
      "Batch: 72, Loss: 0.6760613918304443, Accuracy: 0.76416015625\n",
      "Batch: 73, Loss: 0.6466526985168457, Accuracy: 0.78955078125\n",
      "Batch: 74, Loss: 0.6558830738067627, Accuracy: 0.7919921875\n",
      "Batch: 75, Loss: 0.607033908367157, Accuracy: 0.79541015625\n",
      "Batch: 76, Loss: 0.5972706079483032, Accuracy: 0.8134765625\n",
      "Batch: 77, Loss: 0.6287447214126587, Accuracy: 0.80126953125\n",
      "Batch: 78, Loss: 0.6273607611656189, Accuracy: 0.798828125\n",
      "Batch: 79, Loss: 0.6396149396896362, Accuracy: 0.80615234375\n",
      "Batch: 80, Loss: 0.6934287548065186, Accuracy: 0.78173828125\n",
      "Batch: 81, Loss: 0.6460511088371277, Accuracy: 0.79931640625\n",
      "Batch: 82, Loss: 0.644014298915863, Accuracy: 0.779296875\n",
      "Batch: 83, Loss: 0.5986264944076538, Accuracy: 0.8095703125\n",
      "Batch: 84, Loss: 0.6313983201980591, Accuracy: 0.80078125\n",
      "Batch: 85, Loss: 0.6598572731018066, Accuracy: 0.7880859375\n",
      "Batch: 86, Loss: 0.7021195888519287, Accuracy: 0.78662109375\n",
      "Batch: 87, Loss: 0.6209882497787476, Accuracy: 0.79931640625\n",
      "Batch: 88, Loss: 0.6661475300788879, Accuracy: 0.7900390625\n",
      "Batch: 89, Loss: 0.6467921137809753, Accuracy: 0.78955078125\n",
      "Batch: 90, Loss: 0.6856759190559387, Accuracy: 0.77392578125\n",
      "Batch: 91, Loss: 0.6396174430847168, Accuracy: 0.796875\n",
      "Batch: 92, Loss: 0.7399192452430725, Accuracy: 0.76611328125\n",
      "Batch: 93, Loss: 0.7140077352523804, Accuracy: 0.76806640625\n",
      "Batch: 94, Loss: 0.665727972984314, Accuracy: 0.78515625\n",
      "Batch: 95, Loss: 0.7013744115829468, Accuracy: 0.77392578125\n",
      "Batch: 96, Loss: 0.6417485475540161, Accuracy: 0.7978515625\n",
      "Batch: 97, Loss: 0.6303279399871826, Accuracy: 0.8056640625\n",
      "Batch: 98, Loss: 0.7000553607940674, Accuracy: 0.78271484375\n",
      "Batch: 99, Loss: 0.6375985741615295, Accuracy: 0.79296875\n",
      "Batch: 100, Loss: 0.7129991054534912, Accuracy: 0.77197265625\n",
      "Batch: 101, Loss: 0.7169696688652039, Accuracy: 0.78271484375\n",
      "Batch: 102, Loss: 0.6083788871765137, Accuracy: 0.80029296875\n",
      "Batch: 103, Loss: 0.6580085754394531, Accuracy: 0.78955078125\n",
      "Batch: 104, Loss: 0.6435427665710449, Accuracy: 0.79345703125\n",
      "Batch: 105, Loss: 0.6719347238540649, Accuracy: 0.79345703125\n",
      "Batch: 106, Loss: 0.6518087387084961, Accuracy: 0.79052734375\n",
      "Batch: 107, Loss: 0.6694163084030151, Accuracy: 0.78369140625\n",
      "Batch: 108, Loss: 0.6226836442947388, Accuracy: 0.79296875\n",
      "Batch: 109, Loss: 0.6417079567909241, Accuracy: 0.7890625\n",
      "Batch: 110, Loss: 0.6053153276443481, Accuracy: 0.79833984375\n",
      "Batch: 111, Loss: 0.5887147188186646, Accuracy: 0.80810546875\n",
      "Batch: 112, Loss: 0.6373282670974731, Accuracy: 0.796875\n",
      "Batch: 113, Loss: 0.6720278859138489, Accuracy: 0.78271484375\n",
      "Batch: 114, Loss: 0.6445081233978271, Accuracy: 0.791015625\n",
      "Batch: 115, Loss: 0.6464207172393799, Accuracy: 0.78955078125\n",
      "Batch: 116, Loss: 0.6479409337043762, Accuracy: 0.787109375\n",
      "Batch: 117, Loss: 0.63413405418396, Accuracy: 0.79638671875\n",
      "Batch: 118, Loss: 0.6620464324951172, Accuracy: 0.7763671875\n",
      "Batch: 119, Loss: 0.6224445104598999, Accuracy: 0.80859375\n",
      "Batch: 120, Loss: 0.6201013922691345, Accuracy: 0.80517578125\n",
      "Batch: 121, Loss: 0.6422610282897949, Accuracy: 0.78955078125\n",
      "Batch: 122, Loss: 0.6241248250007629, Accuracy: 0.78857421875\n",
      "Batch: 123, Loss: 0.5985210537910461, Accuracy: 0.80859375\n",
      "Batch: 124, Loss: 0.6016198992729187, Accuracy: 0.80517578125\n",
      "Batch: 125, Loss: 0.6428743004798889, Accuracy: 0.7978515625\n",
      "Batch: 126, Loss: 0.6175185441970825, Accuracy: 0.79638671875\n",
      "Batch: 127, Loss: 0.5930481553077698, Accuracy: 0.80517578125\n",
      "Batch: 128, Loss: 0.706400990486145, Accuracy: 0.7783203125\n",
      "Batch: 129, Loss: 0.7306852340698242, Accuracy: 0.75830078125\n",
      "Batch: 130, Loss: 0.7543389201164246, Accuracy: 0.759765625\n",
      "Batch: 131, Loss: 0.6682584285736084, Accuracy: 0.78173828125\n",
      "Batch: 132, Loss: 0.638135552406311, Accuracy: 0.79443359375\n",
      "Batch: 133, Loss: 0.580136775970459, Accuracy: 0.81298828125\n",
      "Batch: 134, Loss: 0.6741496324539185, Accuracy: 0.77783203125\n",
      "Batch: 135, Loss: 0.644731879234314, Accuracy: 0.7890625\n",
      "Batch: 136, Loss: 0.6123625040054321, Accuracy: 0.798828125\n",
      "Batch: 137, Loss: 0.6640735864639282, Accuracy: 0.7880859375\n",
      "Batch: 138, Loss: 0.6066523790359497, Accuracy: 0.81396484375\n",
      "Batch: 139, Loss: 0.607183575630188, Accuracy: 0.798828125\n",
      "Batch: 140, Loss: 0.5856332778930664, Accuracy: 0.8134765625\n",
      "Batch: 141, Loss: 0.6723397970199585, Accuracy: 0.78125\n",
      "Batch: 142, Loss: 0.6196637153625488, Accuracy: 0.8017578125\n",
      "Batch: 143, Loss: 0.5966142416000366, Accuracy: 0.80908203125\n",
      "Batch: 144, Loss: 0.6958020925521851, Accuracy: 0.78125\n",
      "Batch: 145, Loss: 0.6483161449432373, Accuracy: 0.78857421875\n",
      "Batch: 146, Loss: 0.6902056932449341, Accuracy: 0.7802734375\n",
      "Batch: 147, Loss: 0.6361826062202454, Accuracy: 0.79736328125\n",
      "Batch: 148, Loss: 0.7045520544052124, Accuracy: 0.7607421875\n",
      "Batch: 149, Loss: 0.6830187439918518, Accuracy: 0.779296875\n",
      "Batch: 150, Loss: 0.5899546146392822, Accuracy: 0.8193359375\n",
      "Batch: 151, Loss: 0.5664030313491821, Accuracy: 0.8232421875\n",
      "Batch: 152, Loss: 0.6053563356399536, Accuracy: 0.8095703125\n",
      "Batch: 153, Loss: 0.6200483441352844, Accuracy: 0.79296875\n",
      "Batch: 154, Loss: 0.6237083077430725, Accuracy: 0.79150390625\n",
      "Batch: 155, Loss: 0.6914712190628052, Accuracy: 0.77294921875\n",
      "Batch: 156, Loss: 0.5895326733589172, Accuracy: 0.81005859375\n",
      "Batch: 157, Loss: 0.5778685212135315, Accuracy: 0.80859375\n",
      "Batch: 158, Loss: 0.6068887710571289, Accuracy: 0.8115234375\n",
      "Batch: 159, Loss: 0.6231478452682495, Accuracy: 0.810546875\n",
      "Batch: 160, Loss: 0.6229516863822937, Accuracy: 0.7958984375\n",
      "Batch: 161, Loss: 0.6528820991516113, Accuracy: 0.78857421875\n",
      "Batch: 162, Loss: 0.6249632835388184, Accuracy: 0.79931640625\n",
      "Batch: 163, Loss: 0.6572889089584351, Accuracy: 0.78173828125\n",
      "Batch: 164, Loss: 0.7120864391326904, Accuracy: 0.77392578125\n",
      "Batch: 165, Loss: 0.6446366310119629, Accuracy: 0.8037109375\n",
      "Batch: 166, Loss: 0.6574392318725586, Accuracy: 0.7822265625\n",
      "Batch: 167, Loss: 0.6276358962059021, Accuracy: 0.8046875\n",
      "Batch: 168, Loss: 0.5777497887611389, Accuracy: 0.81298828125\n",
      "Batch: 169, Loss: 0.6334439516067505, Accuracy: 0.79052734375\n",
      "Batch: 170, Loss: 0.6528663635253906, Accuracy: 0.7919921875\n",
      "Batch: 171, Loss: 0.5994312763214111, Accuracy: 0.8046875\n",
      "Batch: 172, Loss: 0.6213403940200806, Accuracy: 0.7978515625\n",
      "Batch: 173, Loss: 0.6664008498191833, Accuracy: 0.7841796875\n",
      "Batch: 174, Loss: 0.573081374168396, Accuracy: 0.80322265625\n",
      "Batch: 175, Loss: 0.6894203424453735, Accuracy: 0.76513671875\n",
      "Batch: 176, Loss: 0.684299111366272, Accuracy: 0.783203125\n",
      "Batch: 177, Loss: 0.640648603439331, Accuracy: 0.7919921875\n",
      "Batch: 178, Loss: 0.5902765989303589, Accuracy: 0.80908203125\n",
      "Batch: 179, Loss: 0.5979968905448914, Accuracy: 0.8076171875\n",
      "Batch: 180, Loss: 0.6718838214874268, Accuracy: 0.7783203125\n",
      "Epoch 60/200\n",
      "Batch: 1, Loss: 0.9254257678985596, Accuracy: 0.734375\n",
      "Batch: 2, Loss: 0.6357988119125366, Accuracy: 0.79541015625\n",
      "Batch: 3, Loss: 0.6399918794631958, Accuracy: 0.7919921875\n",
      "Batch: 4, Loss: 0.6720262765884399, Accuracy: 0.7822265625\n",
      "Batch: 5, Loss: 0.6292548179626465, Accuracy: 0.79052734375\n",
      "Batch: 6, Loss: 0.6652007102966309, Accuracy: 0.78173828125\n",
      "Batch: 7, Loss: 0.6316656470298767, Accuracy: 0.794921875\n",
      "Batch: 8, Loss: 0.6437981128692627, Accuracy: 0.78515625\n",
      "Batch: 9, Loss: 0.6619764566421509, Accuracy: 0.78955078125\n",
      "Batch: 10, Loss: 0.6185200214385986, Accuracy: 0.80517578125\n",
      "Batch: 11, Loss: 0.6744480133056641, Accuracy: 0.7841796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 12, Loss: 0.5929999351501465, Accuracy: 0.81494140625\n",
      "Batch: 13, Loss: 0.6584261059761047, Accuracy: 0.78076171875\n",
      "Batch: 14, Loss: 0.6286073923110962, Accuracy: 0.80712890625\n",
      "Batch: 15, Loss: 0.6727125644683838, Accuracy: 0.7880859375\n",
      "Batch: 16, Loss: 0.6913274526596069, Accuracy: 0.76953125\n",
      "Batch: 17, Loss: 0.6277273893356323, Accuracy: 0.7978515625\n",
      "Batch: 18, Loss: 0.6566181182861328, Accuracy: 0.7958984375\n",
      "Batch: 19, Loss: 0.6724303960800171, Accuracy: 0.78515625\n",
      "Batch: 20, Loss: 0.5648195743560791, Accuracy: 0.8232421875\n",
      "Batch: 21, Loss: 0.6961682438850403, Accuracy: 0.7744140625\n",
      "Batch: 22, Loss: 0.5966343879699707, Accuracy: 0.81005859375\n",
      "Batch: 23, Loss: 0.5828121304512024, Accuracy: 0.8076171875\n",
      "Batch: 24, Loss: 0.6274794340133667, Accuracy: 0.79443359375\n",
      "Batch: 25, Loss: 0.6247445344924927, Accuracy: 0.8037109375\n",
      "Batch: 26, Loss: 0.6334812045097351, Accuracy: 0.78857421875\n",
      "Batch: 27, Loss: 0.6545634865760803, Accuracy: 0.79248046875\n",
      "Batch: 28, Loss: 0.6320730447769165, Accuracy: 0.79296875\n",
      "Batch: 29, Loss: 0.7035703063011169, Accuracy: 0.7783203125\n",
      "Batch: 30, Loss: 0.6667413115501404, Accuracy: 0.7841796875\n",
      "Batch: 31, Loss: 0.723553478717804, Accuracy: 0.77685546875\n",
      "Batch: 32, Loss: 0.690085768699646, Accuracy: 0.787109375\n",
      "Batch: 33, Loss: 0.6714016199111938, Accuracy: 0.77880859375\n",
      "Batch: 34, Loss: 0.7016590237617493, Accuracy: 0.787109375\n",
      "Batch: 35, Loss: 0.7306199669837952, Accuracy: 0.76220703125\n",
      "Batch: 36, Loss: 0.690428614616394, Accuracy: 0.77685546875\n",
      "Batch: 37, Loss: 0.6704809665679932, Accuracy: 0.7802734375\n",
      "Batch: 38, Loss: 0.6939626932144165, Accuracy: 0.7783203125\n",
      "Batch: 39, Loss: 0.6366956233978271, Accuracy: 0.79052734375\n",
      "Batch: 40, Loss: 0.7089799046516418, Accuracy: 0.7724609375\n",
      "Batch: 41, Loss: 0.6714075207710266, Accuracy: 0.77685546875\n",
      "Batch: 42, Loss: 0.6557109951972961, Accuracy: 0.78369140625\n",
      "Batch: 43, Loss: 0.6351437568664551, Accuracy: 0.79296875\n",
      "Batch: 44, Loss: 0.5622609257698059, Accuracy: 0.822265625\n",
      "Batch: 45, Loss: 0.6455663442611694, Accuracy: 0.791015625\n",
      "Batch: 46, Loss: 0.6193944215774536, Accuracy: 0.7900390625\n",
      "Batch: 47, Loss: 0.6485679149627686, Accuracy: 0.7900390625\n",
      "Batch: 48, Loss: 0.655182421207428, Accuracy: 0.78857421875\n",
      "Batch: 49, Loss: 0.6342926621437073, Accuracy: 0.79296875\n",
      "Batch: 50, Loss: 0.6554268002510071, Accuracy: 0.78076171875\n",
      "Batch: 51, Loss: 0.634858250617981, Accuracy: 0.79150390625\n",
      "Batch: 52, Loss: 0.6250700950622559, Accuracy: 0.7919921875\n",
      "Batch: 53, Loss: 0.6469800472259521, Accuracy: 0.78759765625\n",
      "Batch: 54, Loss: 0.6734370589256287, Accuracy: 0.767578125\n",
      "Batch: 55, Loss: 0.6444007754325867, Accuracy: 0.79150390625\n",
      "Batch: 56, Loss: 0.6281163692474365, Accuracy: 0.79052734375\n",
      "Batch: 57, Loss: 0.7019338011741638, Accuracy: 0.77978515625\n",
      "Batch: 58, Loss: 0.6480147838592529, Accuracy: 0.78662109375\n",
      "Batch: 59, Loss: 0.7524752616882324, Accuracy: 0.76416015625\n",
      "Batch: 60, Loss: 0.6478073000907898, Accuracy: 0.79443359375\n",
      "Batch: 61, Loss: 0.6173470616340637, Accuracy: 0.80810546875\n",
      "Batch: 62, Loss: 0.6246708631515503, Accuracy: 0.80029296875\n",
      "Batch: 63, Loss: 0.6288628578186035, Accuracy: 0.791015625\n",
      "Batch: 64, Loss: 0.6567431092262268, Accuracy: 0.7783203125\n",
      "Batch: 65, Loss: 0.6926380395889282, Accuracy: 0.77197265625\n",
      "Batch: 66, Loss: 0.6600620746612549, Accuracy: 0.78857421875\n",
      "Batch: 67, Loss: 0.6875744462013245, Accuracy: 0.77685546875\n",
      "Batch: 68, Loss: 0.6132557392120361, Accuracy: 0.79736328125\n",
      "Batch: 69, Loss: 0.6446213126182556, Accuracy: 0.7880859375\n",
      "Batch: 70, Loss: 0.6415129899978638, Accuracy: 0.78759765625\n",
      "Batch: 71, Loss: 0.6254374980926514, Accuracy: 0.8017578125\n",
      "Batch: 72, Loss: 0.6865832805633545, Accuracy: 0.7705078125\n",
      "Batch: 73, Loss: 0.6780226230621338, Accuracy: 0.78369140625\n",
      "Batch: 74, Loss: 0.660273551940918, Accuracy: 0.7783203125\n",
      "Batch: 75, Loss: 0.6185085773468018, Accuracy: 0.796875\n",
      "Batch: 76, Loss: 0.5953289270401001, Accuracy: 0.8193359375\n",
      "Batch: 77, Loss: 0.5964754819869995, Accuracy: 0.8125\n",
      "Batch: 78, Loss: 0.6215111017227173, Accuracy: 0.80224609375\n",
      "Batch: 79, Loss: 0.655012309551239, Accuracy: 0.78173828125\n",
      "Batch: 80, Loss: 0.6725186109542847, Accuracy: 0.78759765625\n",
      "Batch: 81, Loss: 0.6493490934371948, Accuracy: 0.79541015625\n",
      "Batch: 82, Loss: 0.6247151494026184, Accuracy: 0.7890625\n",
      "Batch: 83, Loss: 0.5929404497146606, Accuracy: 0.81005859375\n",
      "Batch: 84, Loss: 0.6160612106323242, Accuracy: 0.80224609375\n",
      "Batch: 85, Loss: 0.6506011486053467, Accuracy: 0.78662109375\n",
      "Batch: 86, Loss: 0.6904350519180298, Accuracy: 0.78759765625\n",
      "Batch: 87, Loss: 0.5914036631584167, Accuracy: 0.81103515625\n",
      "Batch: 88, Loss: 0.6596525311470032, Accuracy: 0.779296875\n",
      "Batch: 89, Loss: 0.648904025554657, Accuracy: 0.79248046875\n",
      "Batch: 90, Loss: 0.6803257465362549, Accuracy: 0.767578125\n",
      "Batch: 91, Loss: 0.6256349086761475, Accuracy: 0.80517578125\n",
      "Batch: 92, Loss: 0.7043043971061707, Accuracy: 0.76611328125\n",
      "Batch: 93, Loss: 0.6913825869560242, Accuracy: 0.77001953125\n",
      "Batch: 94, Loss: 0.6654203534126282, Accuracy: 0.7919921875\n",
      "Batch: 95, Loss: 0.7134422063827515, Accuracy: 0.77001953125\n",
      "Batch: 96, Loss: 0.6471006870269775, Accuracy: 0.794921875\n",
      "Batch: 97, Loss: 0.651788592338562, Accuracy: 0.7998046875\n",
      "Batch: 98, Loss: 0.6749135851860046, Accuracy: 0.78662109375\n",
      "Batch: 99, Loss: 0.639022707939148, Accuracy: 0.7822265625\n",
      "Batch: 100, Loss: 0.713034987449646, Accuracy: 0.77001953125\n",
      "Batch: 101, Loss: 0.7186918258666992, Accuracy: 0.7763671875\n",
      "Batch: 102, Loss: 0.6169835329055786, Accuracy: 0.80126953125\n",
      "Batch: 103, Loss: 0.6560798287391663, Accuracy: 0.779296875\n",
      "Batch: 104, Loss: 0.6479755640029907, Accuracy: 0.79248046875\n",
      "Batch: 105, Loss: 0.6930792331695557, Accuracy: 0.791015625\n",
      "Batch: 106, Loss: 0.6297460794448853, Accuracy: 0.78759765625\n",
      "Batch: 107, Loss: 0.6629297137260437, Accuracy: 0.79052734375\n",
      "Batch: 108, Loss: 0.6123145818710327, Accuracy: 0.79931640625\n",
      "Batch: 109, Loss: 0.624826192855835, Accuracy: 0.79833984375\n",
      "Batch: 110, Loss: 0.6314430236816406, Accuracy: 0.802734375\n",
      "Batch: 111, Loss: 0.584320604801178, Accuracy: 0.80322265625\n",
      "Batch: 112, Loss: 0.6335296630859375, Accuracy: 0.78271484375\n",
      "Batch: 113, Loss: 0.6500072479248047, Accuracy: 0.78955078125\n",
      "Batch: 114, Loss: 0.6429218649864197, Accuracy: 0.78759765625\n",
      "Batch: 115, Loss: 0.6489549875259399, Accuracy: 0.79638671875\n",
      "Batch: 116, Loss: 0.6321454644203186, Accuracy: 0.79345703125\n",
      "Batch: 117, Loss: 0.6357001066207886, Accuracy: 0.79248046875\n",
      "Batch: 118, Loss: 0.6566963195800781, Accuracy: 0.78662109375\n",
      "Batch: 119, Loss: 0.6242358684539795, Accuracy: 0.78857421875\n",
      "Batch: 120, Loss: 0.6140688061714172, Accuracy: 0.79736328125\n",
      "Batch: 121, Loss: 0.6266114115715027, Accuracy: 0.80029296875\n",
      "Batch: 122, Loss: 0.6048988699913025, Accuracy: 0.8046875\n",
      "Batch: 123, Loss: 0.5970418453216553, Accuracy: 0.81396484375\n",
      "Batch: 124, Loss: 0.5730704069137573, Accuracy: 0.81787109375\n",
      "Batch: 125, Loss: 0.6389736533164978, Accuracy: 0.798828125\n",
      "Batch: 126, Loss: 0.601099967956543, Accuracy: 0.8037109375\n",
      "Batch: 127, Loss: 0.5717355608940125, Accuracy: 0.8193359375\n",
      "Batch: 128, Loss: 0.6886754035949707, Accuracy: 0.77978515625\n",
      "Batch: 129, Loss: 0.7231152057647705, Accuracy: 0.7734375\n",
      "Batch: 130, Loss: 0.7185390591621399, Accuracy: 0.7763671875\n",
      "Batch: 131, Loss: 0.6599634289741516, Accuracy: 0.78662109375\n",
      "Batch: 132, Loss: 0.5978994369506836, Accuracy: 0.8115234375\n",
      "Batch: 133, Loss: 0.6074733734130859, Accuracy: 0.81201171875\n",
      "Batch: 134, Loss: 0.6482502818107605, Accuracy: 0.79345703125\n",
      "Batch: 135, Loss: 0.6437773704528809, Accuracy: 0.7958984375\n",
      "Batch: 136, Loss: 0.6149919033050537, Accuracy: 0.7978515625\n",
      "Batch: 137, Loss: 0.641740083694458, Accuracy: 0.79296875\n",
      "Batch: 138, Loss: 0.6003475189208984, Accuracy: 0.81103515625\n",
      "Batch: 139, Loss: 0.6095584034919739, Accuracy: 0.8017578125\n",
      "Batch: 140, Loss: 0.5652246475219727, Accuracy: 0.82275390625\n",
      "Batch: 141, Loss: 0.660851776599884, Accuracy: 0.78271484375\n",
      "Batch: 142, Loss: 0.5894607305526733, Accuracy: 0.80810546875\n",
      "Batch: 143, Loss: 0.6158928871154785, Accuracy: 0.79736328125\n",
      "Batch: 144, Loss: 0.6962723731994629, Accuracy: 0.77587890625\n",
      "Batch: 145, Loss: 0.6484167575836182, Accuracy: 0.794921875\n",
      "Batch: 146, Loss: 0.6612215638160706, Accuracy: 0.787109375\n",
      "Batch: 147, Loss: 0.6097126007080078, Accuracy: 0.80029296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 148, Loss: 0.6912177801132202, Accuracy: 0.76806640625\n",
      "Batch: 149, Loss: 0.6689185500144958, Accuracy: 0.779296875\n",
      "Batch: 150, Loss: 0.5786449909210205, Accuracy: 0.8115234375\n",
      "Batch: 151, Loss: 0.5884512066841125, Accuracy: 0.8115234375\n",
      "Batch: 152, Loss: 0.614574670791626, Accuracy: 0.7998046875\n",
      "Batch: 153, Loss: 0.6282663345336914, Accuracy: 0.791015625\n",
      "Batch: 154, Loss: 0.6228504776954651, Accuracy: 0.80419921875\n",
      "Batch: 155, Loss: 0.6778287291526794, Accuracy: 0.779296875\n",
      "Batch: 156, Loss: 0.5842267870903015, Accuracy: 0.80126953125\n",
      "Batch: 157, Loss: 0.6078718900680542, Accuracy: 0.7998046875\n",
      "Batch: 158, Loss: 0.592971682548523, Accuracy: 0.810546875\n",
      "Batch: 159, Loss: 0.6115578413009644, Accuracy: 0.8017578125\n",
      "Batch: 160, Loss: 0.6171985864639282, Accuracy: 0.79833984375\n",
      "Batch: 161, Loss: 0.6243335008621216, Accuracy: 0.794921875\n",
      "Batch: 162, Loss: 0.6197751760482788, Accuracy: 0.80126953125\n",
      "Batch: 163, Loss: 0.6773597598075867, Accuracy: 0.787109375\n",
      "Batch: 164, Loss: 0.7262849807739258, Accuracy: 0.77001953125\n",
      "Batch: 165, Loss: 0.626218318939209, Accuracy: 0.80126953125\n",
      "Batch: 166, Loss: 0.6465350389480591, Accuracy: 0.7919921875\n",
      "Batch: 167, Loss: 0.608197808265686, Accuracy: 0.8125\n",
      "Batch: 168, Loss: 0.5610127449035645, Accuracy: 0.81494140625\n",
      "Batch: 169, Loss: 0.6205105185508728, Accuracy: 0.79541015625\n",
      "Batch: 170, Loss: 0.6544670462608337, Accuracy: 0.78564453125\n",
      "Batch: 171, Loss: 0.5846389532089233, Accuracy: 0.80517578125\n",
      "Batch: 172, Loss: 0.6058642268180847, Accuracy: 0.80029296875\n",
      "Batch: 173, Loss: 0.6656028032302856, Accuracy: 0.7880859375\n",
      "Batch: 174, Loss: 0.5581434965133667, Accuracy: 0.81298828125\n",
      "Batch: 175, Loss: 0.6442127227783203, Accuracy: 0.791015625\n",
      "Batch: 176, Loss: 0.6816640496253967, Accuracy: 0.779296875\n",
      "Batch: 177, Loss: 0.6226794719696045, Accuracy: 0.80078125\n",
      "Batch: 178, Loss: 0.5948711633682251, Accuracy: 0.8134765625\n",
      "Batch: 179, Loss: 0.6267715096473694, Accuracy: 0.802734375\n",
      "Batch: 180, Loss: 0.638267993927002, Accuracy: 0.78955078125\n",
      "Saved Weights at epoch 60 to file Weights_60.h5\n",
      "Epoch 61/200\n",
      "Batch: 1, Loss: 0.9410284757614136, Accuracy: 0.732421875\n",
      "Batch: 2, Loss: 0.6224156022071838, Accuracy: 0.77978515625\n",
      "Batch: 3, Loss: 0.6188793182373047, Accuracy: 0.80029296875\n",
      "Batch: 4, Loss: 0.6559513807296753, Accuracy: 0.78466796875\n",
      "Batch: 5, Loss: 0.6385776996612549, Accuracy: 0.78857421875\n",
      "Batch: 6, Loss: 0.6383235454559326, Accuracy: 0.7919921875\n",
      "Batch: 7, Loss: 0.6142513751983643, Accuracy: 0.7998046875\n",
      "Batch: 8, Loss: 0.6131150722503662, Accuracy: 0.80517578125\n",
      "Batch: 9, Loss: 0.6608035564422607, Accuracy: 0.79541015625\n",
      "Batch: 10, Loss: 0.62716144323349, Accuracy: 0.80419921875\n",
      "Batch: 11, Loss: 0.6644392013549805, Accuracy: 0.78271484375\n",
      "Batch: 12, Loss: 0.5942469835281372, Accuracy: 0.8125\n",
      "Batch: 13, Loss: 0.6331105828285217, Accuracy: 0.7939453125\n",
      "Batch: 14, Loss: 0.6419314742088318, Accuracy: 0.7998046875\n",
      "Batch: 15, Loss: 0.6423522233963013, Accuracy: 0.79296875\n",
      "Batch: 16, Loss: 0.6872943639755249, Accuracy: 0.78076171875\n",
      "Batch: 17, Loss: 0.6279700994491577, Accuracy: 0.7998046875\n",
      "Batch: 18, Loss: 0.6381008625030518, Accuracy: 0.79931640625\n",
      "Batch: 19, Loss: 0.6561654806137085, Accuracy: 0.79345703125\n",
      "Batch: 20, Loss: 0.561616837978363, Accuracy: 0.81640625\n",
      "Batch: 21, Loss: 0.6819137334823608, Accuracy: 0.7763671875\n",
      "Batch: 22, Loss: 0.590266764163971, Accuracy: 0.81396484375\n",
      "Batch: 23, Loss: 0.5859391093254089, Accuracy: 0.8193359375\n",
      "Batch: 24, Loss: 0.6333633661270142, Accuracy: 0.7978515625\n",
      "Batch: 25, Loss: 0.6047716736793518, Accuracy: 0.814453125\n",
      "Batch: 26, Loss: 0.6157851815223694, Accuracy: 0.80322265625\n",
      "Batch: 27, Loss: 0.6801739931106567, Accuracy: 0.775390625\n",
      "Batch: 28, Loss: 0.625658392906189, Accuracy: 0.79638671875\n",
      "Batch: 29, Loss: 0.6904075145721436, Accuracy: 0.78271484375\n",
      "Batch: 30, Loss: 0.6683939099311829, Accuracy: 0.79296875\n",
      "Batch: 31, Loss: 0.7337894439697266, Accuracy: 0.7685546875\n",
      "Batch: 32, Loss: 0.6756737232208252, Accuracy: 0.79345703125\n",
      "Batch: 33, Loss: 0.6605103611946106, Accuracy: 0.78271484375\n",
      "Batch: 34, Loss: 0.7026511430740356, Accuracy: 0.7783203125\n",
      "Batch: 35, Loss: 0.6982958316802979, Accuracy: 0.77392578125\n",
      "Batch: 36, Loss: 0.650204062461853, Accuracy: 0.7939453125\n",
      "Batch: 37, Loss: 0.6733981370925903, Accuracy: 0.7744140625\n",
      "Batch: 38, Loss: 0.7034175395965576, Accuracy: 0.77294921875\n",
      "Batch: 39, Loss: 0.6234225034713745, Accuracy: 0.79638671875\n",
      "Batch: 40, Loss: 0.7160120010375977, Accuracy: 0.7626953125\n",
      "Batch: 41, Loss: 0.6518346667289734, Accuracy: 0.783203125\n",
      "Batch: 42, Loss: 0.6659711003303528, Accuracy: 0.7763671875\n",
      "Batch: 43, Loss: 0.6044086217880249, Accuracy: 0.81494140625\n",
      "Batch: 44, Loss: 0.5647282600402832, Accuracy: 0.822265625\n",
      "Batch: 45, Loss: 0.6198845505714417, Accuracy: 0.79248046875\n",
      "Batch: 46, Loss: 0.6039897203445435, Accuracy: 0.78955078125\n",
      "Batch: 47, Loss: 0.6384165287017822, Accuracy: 0.79052734375\n",
      "Batch: 48, Loss: 0.6489416360855103, Accuracy: 0.7880859375\n",
      "Batch: 49, Loss: 0.6385430097579956, Accuracy: 0.79736328125\n",
      "Batch: 50, Loss: 0.6442611217498779, Accuracy: 0.79150390625\n",
      "Batch: 51, Loss: 0.6067398190498352, Accuracy: 0.79833984375\n",
      "Batch: 52, Loss: 0.6265084743499756, Accuracy: 0.7919921875\n",
      "Batch: 53, Loss: 0.637429416179657, Accuracy: 0.7822265625\n",
      "Batch: 54, Loss: 0.666695773601532, Accuracy: 0.7763671875\n",
      "Batch: 55, Loss: 0.6407099962234497, Accuracy: 0.7890625\n",
      "Batch: 56, Loss: 0.6206409335136414, Accuracy: 0.7919921875\n",
      "Batch: 57, Loss: 0.6961493492126465, Accuracy: 0.78125\n",
      "Batch: 58, Loss: 0.6555065512657166, Accuracy: 0.79443359375\n",
      "Batch: 59, Loss: 0.7338487505912781, Accuracy: 0.7685546875\n",
      "Batch: 60, Loss: 0.6297928690910339, Accuracy: 0.7978515625\n",
      "Batch: 61, Loss: 0.600009560585022, Accuracy: 0.80712890625\n",
      "Batch: 62, Loss: 0.6393259167671204, Accuracy: 0.8076171875\n",
      "Batch: 63, Loss: 0.6240215301513672, Accuracy: 0.79052734375\n",
      "Batch: 64, Loss: 0.6295461654663086, Accuracy: 0.78857421875\n",
      "Batch: 65, Loss: 0.6957974433898926, Accuracy: 0.7724609375\n",
      "Batch: 66, Loss: 0.6447010040283203, Accuracy: 0.7880859375\n",
      "Batch: 67, Loss: 0.6646947860717773, Accuracy: 0.79443359375\n",
      "Batch: 68, Loss: 0.5970933437347412, Accuracy: 0.80517578125\n",
      "Batch: 69, Loss: 0.634975790977478, Accuracy: 0.80419921875\n",
      "Batch: 70, Loss: 0.6259607672691345, Accuracy: 0.7939453125\n",
      "Batch: 71, Loss: 0.6352330446243286, Accuracy: 0.79541015625\n",
      "Batch: 72, Loss: 0.6793656945228577, Accuracy: 0.77880859375\n",
      "Batch: 73, Loss: 0.6400596499443054, Accuracy: 0.79296875\n",
      "Batch: 74, Loss: 0.6563602089881897, Accuracy: 0.78564453125\n",
      "Batch: 75, Loss: 0.6180012226104736, Accuracy: 0.79150390625\n",
      "Batch: 76, Loss: 0.6000798344612122, Accuracy: 0.81591796875\n",
      "Batch: 77, Loss: 0.5894525051116943, Accuracy: 0.8212890625\n",
      "Batch: 78, Loss: 0.6169900298118591, Accuracy: 0.80078125\n",
      "Batch: 79, Loss: 0.6535001993179321, Accuracy: 0.79541015625\n",
      "Batch: 80, Loss: 0.656112551689148, Accuracy: 0.7890625\n",
      "Batch: 81, Loss: 0.637582540512085, Accuracy: 0.79931640625\n",
      "Batch: 82, Loss: 0.6391767263412476, Accuracy: 0.78369140625\n",
      "Batch: 83, Loss: 0.5895150899887085, Accuracy: 0.80810546875\n",
      "Batch: 84, Loss: 0.6122527122497559, Accuracy: 0.80615234375\n",
      "Batch: 85, Loss: 0.6452693939208984, Accuracy: 0.796875\n",
      "Batch: 86, Loss: 0.6904354095458984, Accuracy: 0.7880859375\n",
      "Batch: 87, Loss: 0.6094411611557007, Accuracy: 0.8056640625\n",
      "Batch: 88, Loss: 0.6751519441604614, Accuracy: 0.79443359375\n",
      "Batch: 89, Loss: 0.6196339130401611, Accuracy: 0.794921875\n",
      "Batch: 90, Loss: 0.6714695692062378, Accuracy: 0.78076171875\n",
      "Batch: 91, Loss: 0.6363698244094849, Accuracy: 0.79443359375\n",
      "Batch: 92, Loss: 0.7311439514160156, Accuracy: 0.7587890625\n",
      "Batch: 93, Loss: 0.6908235549926758, Accuracy: 0.77587890625\n",
      "Batch: 94, Loss: 0.6539552211761475, Accuracy: 0.7900390625\n",
      "Batch: 95, Loss: 0.687811553478241, Accuracy: 0.77734375\n",
      "Batch: 96, Loss: 0.6435434818267822, Accuracy: 0.787109375\n",
      "Batch: 97, Loss: 0.6290864944458008, Accuracy: 0.80322265625\n",
      "Batch: 98, Loss: 0.6625308394432068, Accuracy: 0.78515625\n",
      "Batch: 99, Loss: 0.6272319555282593, Accuracy: 0.79248046875\n",
      "Batch: 100, Loss: 0.7089700102806091, Accuracy: 0.7744140625\n",
      "Batch: 101, Loss: 0.7072258591651917, Accuracy: 0.7744140625\n",
      "Batch: 102, Loss: 0.627843976020813, Accuracy: 0.7939453125\n",
      "Batch: 103, Loss: 0.6532911062240601, Accuracy: 0.796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 104, Loss: 0.6388427019119263, Accuracy: 0.79541015625\n",
      "Batch: 105, Loss: 0.657678484916687, Accuracy: 0.78466796875\n",
      "Batch: 106, Loss: 0.6148898601531982, Accuracy: 0.8076171875\n",
      "Batch: 107, Loss: 0.6469213366508484, Accuracy: 0.791015625\n",
      "Batch: 108, Loss: 0.6302051544189453, Accuracy: 0.79736328125\n",
      "Batch: 109, Loss: 0.6400524973869324, Accuracy: 0.78955078125\n",
      "Batch: 110, Loss: 0.6184148788452148, Accuracy: 0.79931640625\n",
      "Batch: 111, Loss: 0.5738525986671448, Accuracy: 0.81005859375\n",
      "Batch: 112, Loss: 0.6378649473190308, Accuracy: 0.79443359375\n",
      "Batch: 113, Loss: 0.6497490406036377, Accuracy: 0.7919921875\n",
      "Batch: 114, Loss: 0.6460500359535217, Accuracy: 0.7890625\n",
      "Batch: 115, Loss: 0.6526657342910767, Accuracy: 0.794921875\n",
      "Batch: 116, Loss: 0.6440902948379517, Accuracy: 0.79296875\n",
      "Batch: 117, Loss: 0.6194950342178345, Accuracy: 0.79248046875\n",
      "Batch: 118, Loss: 0.6405636072158813, Accuracy: 0.79541015625\n",
      "Batch: 119, Loss: 0.6507829427719116, Accuracy: 0.7802734375\n",
      "Batch: 120, Loss: 0.6153913736343384, Accuracy: 0.8056640625\n",
      "Batch: 121, Loss: 0.6157170534133911, Accuracy: 0.8056640625\n",
      "Batch: 122, Loss: 0.5944654941558838, Accuracy: 0.80615234375\n",
      "Batch: 123, Loss: 0.5800745487213135, Accuracy: 0.81494140625\n",
      "Batch: 124, Loss: 0.5855425596237183, Accuracy: 0.82080078125\n",
      "Batch: 125, Loss: 0.6386260390281677, Accuracy: 0.79638671875\n",
      "Batch: 126, Loss: 0.6167894601821899, Accuracy: 0.79736328125\n",
      "Batch: 127, Loss: 0.5816569924354553, Accuracy: 0.8056640625\n",
      "Batch: 128, Loss: 0.6969438791275024, Accuracy: 0.78564453125\n",
      "Batch: 129, Loss: 0.7263669967651367, Accuracy: 0.771484375\n",
      "Batch: 130, Loss: 0.724636435508728, Accuracy: 0.7646484375\n",
      "Batch: 131, Loss: 0.6542539000511169, Accuracy: 0.78125\n",
      "Batch: 132, Loss: 0.6002512574195862, Accuracy: 0.80078125\n",
      "Batch: 133, Loss: 0.5964244604110718, Accuracy: 0.80712890625\n",
      "Batch: 134, Loss: 0.6669477224349976, Accuracy: 0.7822265625\n",
      "Batch: 135, Loss: 0.6396660804748535, Accuracy: 0.7841796875\n",
      "Batch: 136, Loss: 0.6172599792480469, Accuracy: 0.79443359375\n",
      "Batch: 137, Loss: 0.6551179885864258, Accuracy: 0.7900390625\n",
      "Batch: 138, Loss: 0.5845516920089722, Accuracy: 0.810546875\n",
      "Batch: 139, Loss: 0.6080150604248047, Accuracy: 0.802734375\n",
      "Batch: 140, Loss: 0.5696594715118408, Accuracy: 0.81982421875\n",
      "Batch: 141, Loss: 0.6706498861312866, Accuracy: 0.7802734375\n",
      "Batch: 142, Loss: 0.608532190322876, Accuracy: 0.8017578125\n",
      "Batch: 143, Loss: 0.6149944067001343, Accuracy: 0.80908203125\n",
      "Batch: 144, Loss: 0.672404944896698, Accuracy: 0.783203125\n",
      "Batch: 145, Loss: 0.6336909532546997, Accuracy: 0.802734375\n",
      "Batch: 146, Loss: 0.6792254447937012, Accuracy: 0.7880859375\n",
      "Batch: 147, Loss: 0.6355797052383423, Accuracy: 0.7939453125\n",
      "Batch: 148, Loss: 0.6752043962478638, Accuracy: 0.77783203125\n",
      "Batch: 149, Loss: 0.6441512703895569, Accuracy: 0.79541015625\n",
      "Batch: 150, Loss: 0.5752387642860413, Accuracy: 0.8154296875\n",
      "Batch: 151, Loss: 0.5873878598213196, Accuracy: 0.806640625\n",
      "Batch: 152, Loss: 0.6072649955749512, Accuracy: 0.79931640625\n",
      "Batch: 153, Loss: 0.6192449331283569, Accuracy: 0.7919921875\n",
      "Batch: 154, Loss: 0.6121238470077515, Accuracy: 0.7958984375\n",
      "Batch: 155, Loss: 0.6804863214492798, Accuracy: 0.77685546875\n",
      "Batch: 156, Loss: 0.5809985399246216, Accuracy: 0.8125\n",
      "Batch: 157, Loss: 0.5618064403533936, Accuracy: 0.81591796875\n",
      "Batch: 158, Loss: 0.5836273431777954, Accuracy: 0.8125\n",
      "Batch: 159, Loss: 0.5975923538208008, Accuracy: 0.80517578125\n",
      "Batch: 160, Loss: 0.6189959049224854, Accuracy: 0.7978515625\n",
      "Batch: 161, Loss: 0.6473061442375183, Accuracy: 0.78955078125\n",
      "Batch: 162, Loss: 0.5822429656982422, Accuracy: 0.802734375\n",
      "Batch: 163, Loss: 0.6424680948257446, Accuracy: 0.79296875\n",
      "Batch: 164, Loss: 0.7111752033233643, Accuracy: 0.77099609375\n",
      "Batch: 165, Loss: 0.6170514822006226, Accuracy: 0.80126953125\n",
      "Batch: 166, Loss: 0.6375802755355835, Accuracy: 0.78662109375\n",
      "Batch: 167, Loss: 0.6263519525527954, Accuracy: 0.79638671875\n",
      "Batch: 168, Loss: 0.5706784725189209, Accuracy: 0.81640625\n",
      "Batch: 169, Loss: 0.623990535736084, Accuracy: 0.791015625\n",
      "Batch: 170, Loss: 0.6559621095657349, Accuracy: 0.7998046875\n",
      "Batch: 171, Loss: 0.6064330339431763, Accuracy: 0.80029296875\n",
      "Batch: 172, Loss: 0.6017724871635437, Accuracy: 0.79638671875\n",
      "Batch: 173, Loss: 0.6429287791252136, Accuracy: 0.7919921875\n",
      "Batch: 174, Loss: 0.5725434422492981, Accuracy: 0.8115234375\n",
      "Batch: 175, Loss: 0.6377599239349365, Accuracy: 0.79150390625\n",
      "Batch: 176, Loss: 0.6801066994667053, Accuracy: 0.78515625\n",
      "Batch: 177, Loss: 0.6104508638381958, Accuracy: 0.806640625\n",
      "Batch: 178, Loss: 0.6012349128723145, Accuracy: 0.80859375\n",
      "Batch: 179, Loss: 0.6279395222663879, Accuracy: 0.798828125\n",
      "Batch: 180, Loss: 0.6315739154815674, Accuracy: 0.80029296875\n",
      "Epoch 62/200\n",
      "Batch: 1, Loss: 0.9475620985031128, Accuracy: 0.72705078125\n",
      "Batch: 2, Loss: 0.6216176748275757, Accuracy: 0.79150390625\n",
      "Batch: 3, Loss: 0.6417434811592102, Accuracy: 0.78955078125\n",
      "Batch: 4, Loss: 0.6548229455947876, Accuracy: 0.79541015625\n",
      "Batch: 5, Loss: 0.6216871738433838, Accuracy: 0.79833984375\n",
      "Batch: 6, Loss: 0.6549811363220215, Accuracy: 0.78564453125\n",
      "Batch: 7, Loss: 0.6182364225387573, Accuracy: 0.8017578125\n",
      "Batch: 8, Loss: 0.6336672306060791, Accuracy: 0.7890625\n",
      "Batch: 9, Loss: 0.6681171655654907, Accuracy: 0.7861328125\n",
      "Batch: 10, Loss: 0.6007552146911621, Accuracy: 0.810546875\n",
      "Batch: 11, Loss: 0.6652863025665283, Accuracy: 0.78076171875\n",
      "Batch: 12, Loss: 0.5895246267318726, Accuracy: 0.814453125\n",
      "Batch: 13, Loss: 0.6318105459213257, Accuracy: 0.7958984375\n",
      "Batch: 14, Loss: 0.6372653841972351, Accuracy: 0.798828125\n",
      "Batch: 15, Loss: 0.6526287794113159, Accuracy: 0.7919921875\n",
      "Batch: 16, Loss: 0.672630250453949, Accuracy: 0.77294921875\n",
      "Batch: 17, Loss: 0.616195023059845, Accuracy: 0.8056640625\n",
      "Batch: 18, Loss: 0.6566058397293091, Accuracy: 0.7919921875\n",
      "Batch: 19, Loss: 0.6547524333000183, Accuracy: 0.79296875\n",
      "Batch: 20, Loss: 0.5712413787841797, Accuracy: 0.8203125\n",
      "Batch: 21, Loss: 0.664696216583252, Accuracy: 0.783203125\n",
      "Batch: 22, Loss: 0.5709723234176636, Accuracy: 0.81201171875\n",
      "Batch: 23, Loss: 0.5648406744003296, Accuracy: 0.80712890625\n",
      "Batch: 24, Loss: 0.6196790933609009, Accuracy: 0.80224609375\n",
      "Batch: 25, Loss: 0.600326418876648, Accuracy: 0.81396484375\n",
      "Batch: 26, Loss: 0.6267744302749634, Accuracy: 0.79443359375\n",
      "Batch: 27, Loss: 0.6354062557220459, Accuracy: 0.8017578125\n",
      "Batch: 28, Loss: 0.6113903522491455, Accuracy: 0.79150390625\n",
      "Batch: 29, Loss: 0.6652483940124512, Accuracy: 0.78759765625\n",
      "Batch: 30, Loss: 0.6419587135314941, Accuracy: 0.79833984375\n",
      "Batch: 31, Loss: 0.714231014251709, Accuracy: 0.7744140625\n",
      "Batch: 32, Loss: 0.6905999779701233, Accuracy: 0.77294921875\n",
      "Batch: 33, Loss: 0.666405439376831, Accuracy: 0.77734375\n",
      "Batch: 34, Loss: 0.6809868812561035, Accuracy: 0.7841796875\n",
      "Batch: 35, Loss: 0.7204201221466064, Accuracy: 0.7646484375\n",
      "Batch: 36, Loss: 0.6656812429428101, Accuracy: 0.78955078125\n",
      "Batch: 37, Loss: 0.6647563576698303, Accuracy: 0.78466796875\n",
      "Batch: 38, Loss: 0.6828418970108032, Accuracy: 0.77978515625\n",
      "Batch: 39, Loss: 0.6262691617012024, Accuracy: 0.79541015625\n",
      "Batch: 40, Loss: 0.7079697251319885, Accuracy: 0.76708984375\n",
      "Batch: 41, Loss: 0.6444993019104004, Accuracy: 0.7822265625\n",
      "Batch: 42, Loss: 0.6536616086959839, Accuracy: 0.7802734375\n",
      "Batch: 43, Loss: 0.6247503161430359, Accuracy: 0.79541015625\n",
      "Batch: 44, Loss: 0.5557180643081665, Accuracy: 0.82958984375\n",
      "Batch: 45, Loss: 0.6227646470069885, Accuracy: 0.80029296875\n",
      "Batch: 46, Loss: 0.5923851728439331, Accuracy: 0.7998046875\n",
      "Batch: 47, Loss: 0.6302145719528198, Accuracy: 0.79931640625\n",
      "Batch: 48, Loss: 0.6340102553367615, Accuracy: 0.80029296875\n",
      "Batch: 49, Loss: 0.6057189702987671, Accuracy: 0.80224609375\n",
      "Batch: 50, Loss: 0.6324721574783325, Accuracy: 0.7978515625\n",
      "Batch: 51, Loss: 0.6092041730880737, Accuracy: 0.796875\n",
      "Batch: 52, Loss: 0.611041247844696, Accuracy: 0.79248046875\n",
      "Batch: 53, Loss: 0.6317599415779114, Accuracy: 0.79345703125\n",
      "Batch: 54, Loss: 0.6655669212341309, Accuracy: 0.7822265625\n",
      "Batch: 55, Loss: 0.6262848377227783, Accuracy: 0.7939453125\n",
      "Batch: 56, Loss: 0.6081850528717041, Accuracy: 0.80126953125\n",
      "Batch: 57, Loss: 0.6897004842758179, Accuracy: 0.78173828125\n",
      "Batch: 58, Loss: 0.6350550651550293, Accuracy: 0.79541015625\n",
      "Batch: 59, Loss: 0.7345677614212036, Accuracy: 0.77294921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 60, Loss: 0.6400854587554932, Accuracy: 0.796875\n",
      "Batch: 61, Loss: 0.5977892279624939, Accuracy: 0.80712890625\n",
      "Batch: 62, Loss: 0.6305912733078003, Accuracy: 0.80615234375\n",
      "Batch: 63, Loss: 0.6181716918945312, Accuracy: 0.802734375\n",
      "Batch: 64, Loss: 0.6435784697532654, Accuracy: 0.796875\n",
      "Batch: 65, Loss: 0.6874768137931824, Accuracy: 0.78173828125\n",
      "Batch: 66, Loss: 0.6608994007110596, Accuracy: 0.7841796875\n",
      "Batch: 67, Loss: 0.6834242939949036, Accuracy: 0.7802734375\n",
      "Batch: 68, Loss: 0.5787359476089478, Accuracy: 0.80615234375\n",
      "Batch: 69, Loss: 0.6423972845077515, Accuracy: 0.791015625\n",
      "Batch: 70, Loss: 0.6293603181838989, Accuracy: 0.7802734375\n",
      "Batch: 71, Loss: 0.6178085803985596, Accuracy: 0.80078125\n",
      "Batch: 72, Loss: 0.6584591865539551, Accuracy: 0.77880859375\n",
      "Batch: 73, Loss: 0.6236813068389893, Accuracy: 0.79638671875\n",
      "Batch: 74, Loss: 0.6563280820846558, Accuracy: 0.7900390625\n",
      "Batch: 75, Loss: 0.5961312055587769, Accuracy: 0.80078125\n",
      "Batch: 76, Loss: 0.5700435638427734, Accuracy: 0.82421875\n",
      "Batch: 77, Loss: 0.5983712673187256, Accuracy: 0.810546875\n",
      "Batch: 78, Loss: 0.6014541983604431, Accuracy: 0.80517578125\n",
      "Batch: 79, Loss: 0.6267582178115845, Accuracy: 0.7978515625\n",
      "Batch: 80, Loss: 0.6361700296401978, Accuracy: 0.7900390625\n",
      "Batch: 81, Loss: 0.6269908547401428, Accuracy: 0.80859375\n",
      "Batch: 82, Loss: 0.6129758954048157, Accuracy: 0.796875\n",
      "Batch: 83, Loss: 0.5758898258209229, Accuracy: 0.81689453125\n",
      "Batch: 84, Loss: 0.5924683213233948, Accuracy: 0.82373046875\n",
      "Batch: 85, Loss: 0.656857967376709, Accuracy: 0.78955078125\n",
      "Batch: 86, Loss: 0.6806485652923584, Accuracy: 0.78564453125\n",
      "Batch: 87, Loss: 0.609028160572052, Accuracy: 0.7998046875\n",
      "Batch: 88, Loss: 0.6607181429862976, Accuracy: 0.794921875\n",
      "Batch: 89, Loss: 0.618115246295929, Accuracy: 0.79345703125\n",
      "Batch: 90, Loss: 0.6583875417709351, Accuracy: 0.77197265625\n",
      "Batch: 91, Loss: 0.6220099925994873, Accuracy: 0.80322265625\n",
      "Batch: 92, Loss: 0.7019280195236206, Accuracy: 0.7705078125\n",
      "Batch: 93, Loss: 0.6843841671943665, Accuracy: 0.78125\n",
      "Batch: 94, Loss: 0.6380637884140015, Accuracy: 0.80224609375\n",
      "Batch: 95, Loss: 0.7002948522567749, Accuracy: 0.77880859375\n",
      "Batch: 96, Loss: 0.6381243467330933, Accuracy: 0.7939453125\n",
      "Batch: 97, Loss: 0.6225762963294983, Accuracy: 0.81982421875\n",
      "Batch: 98, Loss: 0.6495770812034607, Accuracy: 0.80078125\n",
      "Batch: 99, Loss: 0.6411842107772827, Accuracy: 0.80224609375\n",
      "Batch: 100, Loss: 0.6749446392059326, Accuracy: 0.77685546875\n",
      "Batch: 101, Loss: 0.7029824256896973, Accuracy: 0.771484375\n",
      "Batch: 102, Loss: 0.606238842010498, Accuracy: 0.798828125\n",
      "Batch: 103, Loss: 0.6383780837059021, Accuracy: 0.79296875\n",
      "Batch: 104, Loss: 0.6378148198127747, Accuracy: 0.798828125\n",
      "Batch: 105, Loss: 0.65848308801651, Accuracy: 0.78857421875\n",
      "Batch: 106, Loss: 0.6244966387748718, Accuracy: 0.79736328125\n",
      "Batch: 107, Loss: 0.6536470651626587, Accuracy: 0.7900390625\n",
      "Batch: 108, Loss: 0.5970270037651062, Accuracy: 0.8076171875\n",
      "Batch: 109, Loss: 0.609613299369812, Accuracy: 0.8037109375\n",
      "Batch: 110, Loss: 0.6012818813323975, Accuracy: 0.8037109375\n",
      "Batch: 111, Loss: 0.586093544960022, Accuracy: 0.79833984375\n",
      "Batch: 112, Loss: 0.5964821577072144, Accuracy: 0.80810546875\n",
      "Batch: 113, Loss: 0.648611843585968, Accuracy: 0.7802734375\n",
      "Batch: 114, Loss: 0.6341900825500488, Accuracy: 0.78369140625\n",
      "Batch: 115, Loss: 0.6441488862037659, Accuracy: 0.78564453125\n",
      "Batch: 116, Loss: 0.6435550451278687, Accuracy: 0.79150390625\n",
      "Batch: 117, Loss: 0.6017667651176453, Accuracy: 0.8046875\n",
      "Batch: 118, Loss: 0.6277053356170654, Accuracy: 0.7890625\n",
      "Batch: 119, Loss: 0.6297678351402283, Accuracy: 0.80322265625\n",
      "Batch: 120, Loss: 0.5928699970245361, Accuracy: 0.81005859375\n",
      "Batch: 121, Loss: 0.6225415468215942, Accuracy: 0.79833984375\n",
      "Batch: 122, Loss: 0.5736308097839355, Accuracy: 0.80908203125\n",
      "Batch: 123, Loss: 0.6081197261810303, Accuracy: 0.79541015625\n",
      "Batch: 124, Loss: 0.5909894704818726, Accuracy: 0.81103515625\n",
      "Batch: 125, Loss: 0.6333928108215332, Accuracy: 0.80078125\n",
      "Batch: 126, Loss: 0.6096253991127014, Accuracy: 0.80224609375\n",
      "Batch: 127, Loss: 0.5773515701293945, Accuracy: 0.806640625\n",
      "Batch: 128, Loss: 0.6805142164230347, Accuracy: 0.7822265625\n",
      "Batch: 129, Loss: 0.7130866646766663, Accuracy: 0.7646484375\n",
      "Batch: 130, Loss: 0.7304413914680481, Accuracy: 0.76318359375\n",
      "Batch: 131, Loss: 0.6411592364311218, Accuracy: 0.78857421875\n",
      "Batch: 132, Loss: 0.5862427949905396, Accuracy: 0.82373046875\n",
      "Batch: 133, Loss: 0.5860171914100647, Accuracy: 0.8232421875\n",
      "Batch: 134, Loss: 0.6572422385215759, Accuracy: 0.77783203125\n",
      "Batch: 135, Loss: 0.6300491690635681, Accuracy: 0.79443359375\n",
      "Batch: 136, Loss: 0.6014268398284912, Accuracy: 0.814453125\n",
      "Batch: 137, Loss: 0.6121676564216614, Accuracy: 0.7978515625\n",
      "Batch: 138, Loss: 0.5563639402389526, Accuracy: 0.82958984375\n",
      "Batch: 139, Loss: 0.618055522441864, Accuracy: 0.8017578125\n",
      "Batch: 140, Loss: 0.5475760102272034, Accuracy: 0.8212890625\n",
      "Batch: 141, Loss: 0.6810394525527954, Accuracy: 0.78076171875\n",
      "Batch: 142, Loss: 0.5950707197189331, Accuracy: 0.80029296875\n",
      "Batch: 143, Loss: 0.5816413164138794, Accuracy: 0.81396484375\n",
      "Batch: 144, Loss: 0.6688954830169678, Accuracy: 0.79150390625\n",
      "Batch: 145, Loss: 0.6261014342308044, Accuracy: 0.798828125\n",
      "Batch: 146, Loss: 0.6540722846984863, Accuracy: 0.78564453125\n",
      "Batch: 147, Loss: 0.6115550994873047, Accuracy: 0.79443359375\n",
      "Batch: 148, Loss: 0.6758708953857422, Accuracy: 0.77197265625\n",
      "Batch: 149, Loss: 0.649296760559082, Accuracy: 0.78662109375\n",
      "Batch: 150, Loss: 0.5382323265075684, Accuracy: 0.83740234375\n",
      "Batch: 151, Loss: 0.568433403968811, Accuracy: 0.81494140625\n",
      "Batch: 152, Loss: 0.6001471877098083, Accuracy: 0.80224609375\n",
      "Batch: 153, Loss: 0.6263623833656311, Accuracy: 0.7919921875\n",
      "Batch: 154, Loss: 0.5987131595611572, Accuracy: 0.8056640625\n",
      "Batch: 155, Loss: 0.6617159843444824, Accuracy: 0.78466796875\n",
      "Batch: 156, Loss: 0.5657482147216797, Accuracy: 0.81396484375\n",
      "Batch: 157, Loss: 0.5535296201705933, Accuracy: 0.8173828125\n",
      "Batch: 158, Loss: 0.5804920196533203, Accuracy: 0.82080078125\n",
      "Batch: 159, Loss: 0.6056078672409058, Accuracy: 0.8125\n",
      "Batch: 160, Loss: 0.6151701211929321, Accuracy: 0.80126953125\n",
      "Batch: 161, Loss: 0.6273768544197083, Accuracy: 0.78955078125\n",
      "Batch: 162, Loss: 0.575118362903595, Accuracy: 0.810546875\n",
      "Batch: 163, Loss: 0.6379135251045227, Accuracy: 0.79052734375\n",
      "Batch: 164, Loss: 0.7061535120010376, Accuracy: 0.78515625\n",
      "Batch: 165, Loss: 0.621584415435791, Accuracy: 0.80322265625\n",
      "Batch: 166, Loss: 0.6506911516189575, Accuracy: 0.79638671875\n",
      "Batch: 167, Loss: 0.6142941117286682, Accuracy: 0.80419921875\n",
      "Batch: 168, Loss: 0.5611840486526489, Accuracy: 0.81884765625\n",
      "Batch: 169, Loss: 0.6403833627700806, Accuracy: 0.7890625\n",
      "Batch: 170, Loss: 0.6271976232528687, Accuracy: 0.8056640625\n",
      "Batch: 171, Loss: 0.5985227823257446, Accuracy: 0.8056640625\n",
      "Batch: 172, Loss: 0.587981641292572, Accuracy: 0.80322265625\n",
      "Batch: 173, Loss: 0.6621864438056946, Accuracy: 0.78466796875\n",
      "Batch: 174, Loss: 0.5483666658401489, Accuracy: 0.81689453125\n",
      "Batch: 175, Loss: 0.6237403154373169, Accuracy: 0.79150390625\n",
      "Batch: 176, Loss: 0.6619393825531006, Accuracy: 0.78173828125\n",
      "Batch: 177, Loss: 0.6119506359100342, Accuracy: 0.798828125\n",
      "Batch: 178, Loss: 0.5866090059280396, Accuracy: 0.8056640625\n",
      "Batch: 179, Loss: 0.6123841404914856, Accuracy: 0.8134765625\n",
      "Batch: 180, Loss: 0.6373076438903809, Accuracy: 0.79248046875\n",
      "Epoch 63/200\n",
      "Batch: 1, Loss: 0.8911193609237671, Accuracy: 0.75048828125\n",
      "Batch: 2, Loss: 0.6323693990707397, Accuracy: 0.7822265625\n",
      "Batch: 3, Loss: 0.6355005502700806, Accuracy: 0.791015625\n",
      "Batch: 4, Loss: 0.6297104954719543, Accuracy: 0.79736328125\n",
      "Batch: 5, Loss: 0.6260512471199036, Accuracy: 0.80029296875\n",
      "Batch: 6, Loss: 0.6286829710006714, Accuracy: 0.802734375\n",
      "Batch: 7, Loss: 0.6209418177604675, Accuracy: 0.80078125\n",
      "Batch: 8, Loss: 0.6122698783874512, Accuracy: 0.794921875\n",
      "Batch: 9, Loss: 0.6387737989425659, Accuracy: 0.7978515625\n",
      "Batch: 10, Loss: 0.6044331789016724, Accuracy: 0.80859375\n",
      "Batch: 11, Loss: 0.6475410461425781, Accuracy: 0.7880859375\n",
      "Batch: 12, Loss: 0.5778176784515381, Accuracy: 0.81005859375\n",
      "Batch: 13, Loss: 0.6228569746017456, Accuracy: 0.79833984375\n",
      "Batch: 14, Loss: 0.6272488832473755, Accuracy: 0.80224609375\n",
      "Batch: 15, Loss: 0.6335471868515015, Accuracy: 0.79052734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 16, Loss: 0.662402868270874, Accuracy: 0.78271484375\n",
      "Batch: 17, Loss: 0.6159679889678955, Accuracy: 0.80078125\n",
      "Batch: 18, Loss: 0.6435728073120117, Accuracy: 0.7939453125\n",
      "Batch: 19, Loss: 0.6548796892166138, Accuracy: 0.79296875\n",
      "Batch: 20, Loss: 0.5462594032287598, Accuracy: 0.8251953125\n",
      "Batch: 21, Loss: 0.6298075914382935, Accuracy: 0.79736328125\n",
      "Batch: 22, Loss: 0.5931064486503601, Accuracy: 0.80908203125\n",
      "Batch: 23, Loss: 0.5738382339477539, Accuracy: 0.81298828125\n",
      "Batch: 24, Loss: 0.6115703582763672, Accuracy: 0.798828125\n",
      "Batch: 25, Loss: 0.5940316915512085, Accuracy: 0.80712890625\n",
      "Batch: 26, Loss: 0.6245944499969482, Accuracy: 0.7919921875\n",
      "Batch: 27, Loss: 0.6563803553581238, Accuracy: 0.78515625\n",
      "Batch: 28, Loss: 0.5882389545440674, Accuracy: 0.81396484375\n",
      "Batch: 29, Loss: 0.6826697587966919, Accuracy: 0.787109375\n",
      "Batch: 30, Loss: 0.6234169006347656, Accuracy: 0.81201171875\n",
      "Batch: 31, Loss: 0.7169861197471619, Accuracy: 0.77734375\n",
      "Batch: 32, Loss: 0.6807186007499695, Accuracy: 0.779296875\n",
      "Batch: 33, Loss: 0.6364278793334961, Accuracy: 0.80078125\n",
      "Batch: 34, Loss: 0.6866228580474854, Accuracy: 0.77734375\n",
      "Batch: 35, Loss: 0.6964848041534424, Accuracy: 0.775390625\n",
      "Batch: 36, Loss: 0.6494830846786499, Accuracy: 0.7958984375\n",
      "Batch: 37, Loss: 0.6508150100708008, Accuracy: 0.7939453125\n",
      "Batch: 38, Loss: 0.6810010671615601, Accuracy: 0.77392578125\n",
      "Batch: 39, Loss: 0.6351995468139648, Accuracy: 0.7958984375\n",
      "Batch: 40, Loss: 0.6769405603408813, Accuracy: 0.79052734375\n",
      "Batch: 41, Loss: 0.6721984148025513, Accuracy: 0.77734375\n",
      "Batch: 42, Loss: 0.6393172740936279, Accuracy: 0.79052734375\n",
      "Batch: 43, Loss: 0.6081687211990356, Accuracy: 0.80419921875\n",
      "Batch: 44, Loss: 0.5596485733985901, Accuracy: 0.8232421875\n",
      "Batch: 45, Loss: 0.6192224025726318, Accuracy: 0.80078125\n",
      "Batch: 46, Loss: 0.5891983509063721, Accuracy: 0.80029296875\n",
      "Batch: 47, Loss: 0.6210242509841919, Accuracy: 0.79833984375\n",
      "Batch: 48, Loss: 0.6189272403717041, Accuracy: 0.806640625\n",
      "Batch: 49, Loss: 0.6091801524162292, Accuracy: 0.80029296875\n",
      "Batch: 50, Loss: 0.6119483709335327, Accuracy: 0.7890625\n",
      "Batch: 51, Loss: 0.6091668605804443, Accuracy: 0.7998046875\n",
      "Batch: 52, Loss: 0.6069226264953613, Accuracy: 0.806640625\n",
      "Batch: 53, Loss: 0.6260842680931091, Accuracy: 0.78369140625\n",
      "Batch: 54, Loss: 0.6713551878929138, Accuracy: 0.7763671875\n",
      "Batch: 55, Loss: 0.6300019025802612, Accuracy: 0.7939453125\n",
      "Batch: 56, Loss: 0.619600772857666, Accuracy: 0.7900390625\n",
      "Batch: 57, Loss: 0.687486469745636, Accuracy: 0.7783203125\n",
      "Batch: 58, Loss: 0.6418647766113281, Accuracy: 0.7958984375\n",
      "Batch: 59, Loss: 0.7322434186935425, Accuracy: 0.76220703125\n",
      "Batch: 60, Loss: 0.6290740966796875, Accuracy: 0.80810546875\n",
      "Batch: 61, Loss: 0.591205358505249, Accuracy: 0.8037109375\n",
      "Batch: 62, Loss: 0.6034862995147705, Accuracy: 0.8125\n",
      "Batch: 63, Loss: 0.6152915954589844, Accuracy: 0.79150390625\n",
      "Batch: 64, Loss: 0.6304174661636353, Accuracy: 0.7919921875\n",
      "Batch: 65, Loss: 0.672490119934082, Accuracy: 0.77880859375\n",
      "Batch: 66, Loss: 0.6338298320770264, Accuracy: 0.79638671875\n",
      "Batch: 67, Loss: 0.6700042486190796, Accuracy: 0.7841796875\n",
      "Batch: 68, Loss: 0.5801266431808472, Accuracy: 0.806640625\n",
      "Batch: 69, Loss: 0.6479910016059875, Accuracy: 0.78515625\n",
      "Batch: 70, Loss: 0.6069544553756714, Accuracy: 0.798828125\n",
      "Batch: 71, Loss: 0.6383686065673828, Accuracy: 0.79638671875\n",
      "Batch: 72, Loss: 0.6600952744483948, Accuracy: 0.7783203125\n",
      "Batch: 73, Loss: 0.6571110486984253, Accuracy: 0.77734375\n",
      "Batch: 74, Loss: 0.6406382322311401, Accuracy: 0.794921875\n",
      "Batch: 75, Loss: 0.5645785927772522, Accuracy: 0.8134765625\n",
      "Batch: 76, Loss: 0.5743566751480103, Accuracy: 0.82421875\n",
      "Batch: 77, Loss: 0.5769689083099365, Accuracy: 0.8203125\n",
      "Batch: 78, Loss: 0.6229498386383057, Accuracy: 0.8017578125\n",
      "Batch: 79, Loss: 0.6184890270233154, Accuracy: 0.80029296875\n",
      "Batch: 80, Loss: 0.6369016170501709, Accuracy: 0.79833984375\n",
      "Batch: 81, Loss: 0.6393924951553345, Accuracy: 0.79150390625\n",
      "Batch: 82, Loss: 0.6178067922592163, Accuracy: 0.79638671875\n",
      "Batch: 83, Loss: 0.5848071575164795, Accuracy: 0.810546875\n",
      "Batch: 84, Loss: 0.5980954766273499, Accuracy: 0.80859375\n",
      "Batch: 85, Loss: 0.6313767433166504, Accuracy: 0.80322265625\n",
      "Batch: 86, Loss: 0.6770918369293213, Accuracy: 0.8046875\n",
      "Batch: 87, Loss: 0.6027671098709106, Accuracy: 0.806640625\n",
      "Batch: 88, Loss: 0.6533936858177185, Accuracy: 0.79248046875\n",
      "Batch: 89, Loss: 0.6400584578514099, Accuracy: 0.79248046875\n",
      "Batch: 90, Loss: 0.6559866666793823, Accuracy: 0.77978515625\n",
      "Batch: 91, Loss: 0.592029869556427, Accuracy: 0.81396484375\n",
      "Batch: 92, Loss: 0.7018964886665344, Accuracy: 0.763671875\n",
      "Batch: 93, Loss: 0.6850417852401733, Accuracy: 0.7734375\n",
      "Batch: 94, Loss: 0.6369633674621582, Accuracy: 0.794921875\n",
      "Batch: 95, Loss: 0.6838873624801636, Accuracy: 0.7802734375\n",
      "Batch: 96, Loss: 0.6187077164649963, Accuracy: 0.80078125\n",
      "Batch: 97, Loss: 0.6291374564170837, Accuracy: 0.80029296875\n",
      "Batch: 98, Loss: 0.6434890031814575, Accuracy: 0.7919921875\n",
      "Batch: 99, Loss: 0.6208035945892334, Accuracy: 0.80029296875\n",
      "Batch: 100, Loss: 0.6770975589752197, Accuracy: 0.79638671875\n",
      "Batch: 101, Loss: 0.6908743381500244, Accuracy: 0.77490234375\n",
      "Batch: 102, Loss: 0.5846253633499146, Accuracy: 0.81201171875\n",
      "Batch: 103, Loss: 0.6464252471923828, Accuracy: 0.79541015625\n",
      "Batch: 104, Loss: 0.6241337060928345, Accuracy: 0.7978515625\n",
      "Batch: 105, Loss: 0.6748301982879639, Accuracy: 0.7802734375\n",
      "Batch: 106, Loss: 0.6077788472175598, Accuracy: 0.80322265625\n",
      "Batch: 107, Loss: 0.6362723708152771, Accuracy: 0.7978515625\n",
      "Batch: 108, Loss: 0.6032575368881226, Accuracy: 0.7998046875\n",
      "Batch: 109, Loss: 0.604640007019043, Accuracy: 0.80712890625\n",
      "Batch: 110, Loss: 0.5807301998138428, Accuracy: 0.80859375\n",
      "Batch: 111, Loss: 0.5554363131523132, Accuracy: 0.81494140625\n",
      "Batch: 112, Loss: 0.5862433910369873, Accuracy: 0.79931640625\n",
      "Batch: 113, Loss: 0.6347129344940186, Accuracy: 0.7890625\n",
      "Batch: 114, Loss: 0.6385040283203125, Accuracy: 0.79736328125\n",
      "Batch: 115, Loss: 0.6214253902435303, Accuracy: 0.802734375\n",
      "Batch: 116, Loss: 0.5902427434921265, Accuracy: 0.80517578125\n",
      "Batch: 117, Loss: 0.5814533233642578, Accuracy: 0.8056640625\n",
      "Batch: 118, Loss: 0.6235194206237793, Accuracy: 0.80322265625\n",
      "Batch: 119, Loss: 0.5862395167350769, Accuracy: 0.80810546875\n",
      "Batch: 120, Loss: 0.591468095779419, Accuracy: 0.814453125\n",
      "Batch: 121, Loss: 0.6218856573104858, Accuracy: 0.8076171875\n",
      "Batch: 122, Loss: 0.5663888454437256, Accuracy: 0.8076171875\n",
      "Batch: 123, Loss: 0.5623154640197754, Accuracy: 0.8251953125\n",
      "Batch: 124, Loss: 0.593173623085022, Accuracy: 0.80029296875\n",
      "Batch: 125, Loss: 0.6052834987640381, Accuracy: 0.80859375\n",
      "Batch: 126, Loss: 0.5924593210220337, Accuracy: 0.81640625\n",
      "Batch: 127, Loss: 0.57845139503479, Accuracy: 0.81982421875\n",
      "Batch: 128, Loss: 0.6860252022743225, Accuracy: 0.77880859375\n",
      "Batch: 129, Loss: 0.7030004262924194, Accuracy: 0.77197265625\n",
      "Batch: 130, Loss: 0.7138813138008118, Accuracy: 0.77587890625\n",
      "Batch: 131, Loss: 0.6453452706336975, Accuracy: 0.79052734375\n",
      "Batch: 132, Loss: 0.5847489237785339, Accuracy: 0.81298828125\n",
      "Batch: 133, Loss: 0.5782051682472229, Accuracy: 0.818359375\n",
      "Batch: 134, Loss: 0.6283824443817139, Accuracy: 0.79541015625\n",
      "Batch: 135, Loss: 0.6487939953804016, Accuracy: 0.7880859375\n",
      "Batch: 136, Loss: 0.6025071144104004, Accuracy: 0.81298828125\n",
      "Batch: 137, Loss: 0.6434988975524902, Accuracy: 0.7978515625\n",
      "Batch: 138, Loss: 0.5600425601005554, Accuracy: 0.82080078125\n",
      "Batch: 139, Loss: 0.5974526405334473, Accuracy: 0.7998046875\n",
      "Batch: 140, Loss: 0.549752950668335, Accuracy: 0.81689453125\n",
      "Batch: 141, Loss: 0.6582489013671875, Accuracy: 0.7841796875\n",
      "Batch: 142, Loss: 0.5911505818367004, Accuracy: 0.80419921875\n",
      "Batch: 143, Loss: 0.6062583923339844, Accuracy: 0.8076171875\n",
      "Batch: 144, Loss: 0.6543847918510437, Accuracy: 0.78759765625\n",
      "Batch: 145, Loss: 0.641128659248352, Accuracy: 0.80224609375\n",
      "Batch: 146, Loss: 0.6494747996330261, Accuracy: 0.80126953125\n",
      "Batch: 147, Loss: 0.638827919960022, Accuracy: 0.791015625\n",
      "Batch: 148, Loss: 0.6565074324607849, Accuracy: 0.78125\n",
      "Batch: 149, Loss: 0.6351960897445679, Accuracy: 0.79296875\n",
      "Batch: 150, Loss: 0.5392018556594849, Accuracy: 0.82373046875\n",
      "Batch: 151, Loss: 0.564071774482727, Accuracy: 0.8173828125\n",
      "Batch: 152, Loss: 0.6001647710800171, Accuracy: 0.81005859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 153, Loss: 0.6073166728019714, Accuracy: 0.8037109375\n",
      "Batch: 154, Loss: 0.6151371002197266, Accuracy: 0.7919921875\n",
      "Batch: 155, Loss: 0.659229040145874, Accuracy: 0.787109375\n",
      "Batch: 156, Loss: 0.5678271055221558, Accuracy: 0.814453125\n",
      "Batch: 157, Loss: 0.565157413482666, Accuracy: 0.81005859375\n",
      "Batch: 158, Loss: 0.5641300082206726, Accuracy: 0.828125\n",
      "Batch: 159, Loss: 0.5790968537330627, Accuracy: 0.8193359375\n",
      "Batch: 160, Loss: 0.6089079976081848, Accuracy: 0.80078125\n",
      "Batch: 161, Loss: 0.6131832003593445, Accuracy: 0.80810546875\n",
      "Batch: 162, Loss: 0.5751024484634399, Accuracy: 0.814453125\n",
      "Batch: 163, Loss: 0.6379269361495972, Accuracy: 0.78466796875\n",
      "Batch: 164, Loss: 0.6840335130691528, Accuracy: 0.77880859375\n",
      "Batch: 165, Loss: 0.6173517107963562, Accuracy: 0.7978515625\n",
      "Batch: 166, Loss: 0.6500868797302246, Accuracy: 0.787109375\n",
      "Batch: 167, Loss: 0.6127510666847229, Accuracy: 0.8017578125\n",
      "Batch: 168, Loss: 0.5763181447982788, Accuracy: 0.814453125\n",
      "Batch: 169, Loss: 0.5985345840454102, Accuracy: 0.80322265625\n",
      "Batch: 170, Loss: 0.6584469676017761, Accuracy: 0.791015625\n",
      "Batch: 171, Loss: 0.5899651050567627, Accuracy: 0.80419921875\n",
      "Batch: 172, Loss: 0.6033351421356201, Accuracy: 0.79931640625\n",
      "Batch: 173, Loss: 0.650328516960144, Accuracy: 0.791015625\n",
      "Batch: 174, Loss: 0.5379507541656494, Accuracy: 0.8203125\n",
      "Batch: 175, Loss: 0.632890522480011, Accuracy: 0.787109375\n",
      "Batch: 176, Loss: 0.6688896417617798, Accuracy: 0.779296875\n",
      "Batch: 177, Loss: 0.6104995608329773, Accuracy: 0.80517578125\n",
      "Batch: 178, Loss: 0.5879719257354736, Accuracy: 0.8076171875\n",
      "Batch: 179, Loss: 0.603234052658081, Accuracy: 0.80712890625\n",
      "Batch: 180, Loss: 0.6506452560424805, Accuracy: 0.7919921875\n",
      "Epoch 64/200\n",
      "Batch: 1, Loss: 0.9219518899917603, Accuracy: 0.74853515625\n",
      "Batch: 2, Loss: 0.6195327043533325, Accuracy: 0.794921875\n",
      "Batch: 3, Loss: 0.6138839721679688, Accuracy: 0.8017578125\n",
      "Batch: 4, Loss: 0.6357479095458984, Accuracy: 0.79541015625\n",
      "Batch: 5, Loss: 0.6168341040611267, Accuracy: 0.80712890625\n",
      "Batch: 6, Loss: 0.6313395500183105, Accuracy: 0.79248046875\n",
      "Batch: 7, Loss: 0.6067463159561157, Accuracy: 0.79833984375\n",
      "Batch: 8, Loss: 0.6239068508148193, Accuracy: 0.79296875\n",
      "Batch: 9, Loss: 0.6408326625823975, Accuracy: 0.7958984375\n",
      "Batch: 10, Loss: 0.5958024263381958, Accuracy: 0.80810546875\n",
      "Batch: 11, Loss: 0.6502039432525635, Accuracy: 0.78466796875\n",
      "Batch: 12, Loss: 0.5713751316070557, Accuracy: 0.81689453125\n",
      "Batch: 13, Loss: 0.6258004307746887, Accuracy: 0.802734375\n",
      "Batch: 14, Loss: 0.6194213628768921, Accuracy: 0.80224609375\n",
      "Batch: 15, Loss: 0.6404569149017334, Accuracy: 0.79296875\n",
      "Batch: 16, Loss: 0.6696489453315735, Accuracy: 0.787109375\n",
      "Batch: 17, Loss: 0.6056593060493469, Accuracy: 0.8095703125\n",
      "Batch: 18, Loss: 0.6448862552642822, Accuracy: 0.80029296875\n",
      "Batch: 19, Loss: 0.6394302845001221, Accuracy: 0.80029296875\n",
      "Batch: 20, Loss: 0.549950361251831, Accuracy: 0.82373046875\n",
      "Batch: 21, Loss: 0.6445162892341614, Accuracy: 0.79736328125\n",
      "Batch: 22, Loss: 0.5882384181022644, Accuracy: 0.806640625\n",
      "Batch: 23, Loss: 0.5589718222618103, Accuracy: 0.8193359375\n",
      "Batch: 24, Loss: 0.6071827411651611, Accuracy: 0.8037109375\n",
      "Batch: 25, Loss: 0.6038712859153748, Accuracy: 0.80322265625\n",
      "Batch: 26, Loss: 0.6276149749755859, Accuracy: 0.79541015625\n",
      "Batch: 27, Loss: 0.6340919733047485, Accuracy: 0.79931640625\n",
      "Batch: 28, Loss: 0.599287211894989, Accuracy: 0.806640625\n",
      "Batch: 29, Loss: 0.6851382851600647, Accuracy: 0.7802734375\n",
      "Batch: 30, Loss: 0.6232548356056213, Accuracy: 0.80908203125\n",
      "Batch: 31, Loss: 0.6962640881538391, Accuracy: 0.78173828125\n",
      "Batch: 32, Loss: 0.6657711863517761, Accuracy: 0.78369140625\n",
      "Batch: 33, Loss: 0.6396001577377319, Accuracy: 0.7939453125\n",
      "Batch: 34, Loss: 0.6540993452072144, Accuracy: 0.7958984375\n",
      "Batch: 35, Loss: 0.6862014532089233, Accuracy: 0.77392578125\n",
      "Batch: 36, Loss: 0.6511483788490295, Accuracy: 0.7958984375\n",
      "Batch: 37, Loss: 0.6633467674255371, Accuracy: 0.78466796875\n",
      "Batch: 38, Loss: 0.6731789112091064, Accuracy: 0.78173828125\n",
      "Batch: 39, Loss: 0.6168412566184998, Accuracy: 0.79296875\n",
      "Batch: 40, Loss: 0.6918296813964844, Accuracy: 0.7763671875\n",
      "Batch: 41, Loss: 0.634125292301178, Accuracy: 0.7919921875\n",
      "Batch: 42, Loss: 0.6319922208786011, Accuracy: 0.791015625\n",
      "Batch: 43, Loss: 0.5982341766357422, Accuracy: 0.80517578125\n",
      "Batch: 44, Loss: 0.5692331790924072, Accuracy: 0.81103515625\n",
      "Batch: 45, Loss: 0.6138068437576294, Accuracy: 0.79638671875\n",
      "Batch: 46, Loss: 0.6002423763275146, Accuracy: 0.79541015625\n",
      "Batch: 47, Loss: 0.6300384998321533, Accuracy: 0.7978515625\n",
      "Batch: 48, Loss: 0.6243807673454285, Accuracy: 0.802734375\n",
      "Batch: 49, Loss: 0.6259253621101379, Accuracy: 0.79345703125\n",
      "Batch: 50, Loss: 0.6103661060333252, Accuracy: 0.7939453125\n",
      "Batch: 51, Loss: 0.6140519380569458, Accuracy: 0.79638671875\n",
      "Batch: 52, Loss: 0.6115140318870544, Accuracy: 0.80078125\n",
      "Batch: 53, Loss: 0.6167458295822144, Accuracy: 0.796875\n",
      "Batch: 54, Loss: 0.6638346910476685, Accuracy: 0.76416015625\n",
      "Batch: 55, Loss: 0.6074398159980774, Accuracy: 0.7978515625\n",
      "Batch: 56, Loss: 0.6187450289726257, Accuracy: 0.79541015625\n",
      "Batch: 57, Loss: 0.6848518252372742, Accuracy: 0.7841796875\n",
      "Batch: 58, Loss: 0.6237426996231079, Accuracy: 0.7978515625\n",
      "Batch: 59, Loss: 0.7155190110206604, Accuracy: 0.7705078125\n",
      "Batch: 60, Loss: 0.6411008834838867, Accuracy: 0.79541015625\n",
      "Batch: 61, Loss: 0.5867963433265686, Accuracy: 0.80859375\n",
      "Batch: 62, Loss: 0.5955163240432739, Accuracy: 0.8154296875\n",
      "Batch: 63, Loss: 0.6299418807029724, Accuracy: 0.79052734375\n",
      "Batch: 64, Loss: 0.6571086645126343, Accuracy: 0.77685546875\n",
      "Batch: 65, Loss: 0.6682254076004028, Accuracy: 0.7880859375\n",
      "Batch: 66, Loss: 0.6304612159729004, Accuracy: 0.79248046875\n",
      "Batch: 67, Loss: 0.6616619229316711, Accuracy: 0.79150390625\n",
      "Batch: 68, Loss: 0.5942933559417725, Accuracy: 0.802734375\n",
      "Batch: 69, Loss: 0.6333574056625366, Accuracy: 0.78759765625\n",
      "Batch: 70, Loss: 0.6149563789367676, Accuracy: 0.79150390625\n",
      "Batch: 71, Loss: 0.6143307089805603, Accuracy: 0.798828125\n",
      "Batch: 72, Loss: 0.6504371762275696, Accuracy: 0.78955078125\n",
      "Batch: 73, Loss: 0.641152024269104, Accuracy: 0.7880859375\n",
      "Batch: 74, Loss: 0.6532328724861145, Accuracy: 0.794921875\n",
      "Batch: 75, Loss: 0.5999274253845215, Accuracy: 0.802734375\n",
      "Batch: 76, Loss: 0.5786172151565552, Accuracy: 0.81982421875\n",
      "Batch: 77, Loss: 0.5674092769622803, Accuracy: 0.82568359375\n",
      "Batch: 78, Loss: 0.6107815504074097, Accuracy: 0.8046875\n",
      "Batch: 79, Loss: 0.6254274845123291, Accuracy: 0.802734375\n",
      "Batch: 80, Loss: 0.6354327201843262, Accuracy: 0.79638671875\n",
      "Batch: 81, Loss: 0.6275113821029663, Accuracy: 0.8056640625\n",
      "Batch: 82, Loss: 0.6033318638801575, Accuracy: 0.8076171875\n",
      "Batch: 83, Loss: 0.5879359841346741, Accuracy: 0.81005859375\n",
      "Batch: 84, Loss: 0.5959779620170593, Accuracy: 0.80859375\n",
      "Batch: 85, Loss: 0.6294580698013306, Accuracy: 0.79931640625\n",
      "Batch: 86, Loss: 0.6582909822463989, Accuracy: 0.80126953125\n",
      "Batch: 87, Loss: 0.5931496620178223, Accuracy: 0.81298828125\n",
      "Batch: 88, Loss: 0.6346870064735413, Accuracy: 0.7998046875\n",
      "Batch: 89, Loss: 0.6222350597381592, Accuracy: 0.79541015625\n",
      "Batch: 90, Loss: 0.6514208316802979, Accuracy: 0.78466796875\n",
      "Batch: 91, Loss: 0.6108306050300598, Accuracy: 0.80322265625\n",
      "Batch: 92, Loss: 0.7039368748664856, Accuracy: 0.7734375\n",
      "Batch: 93, Loss: 0.6786672472953796, Accuracy: 0.7783203125\n",
      "Batch: 94, Loss: 0.6560468673706055, Accuracy: 0.7822265625\n",
      "Batch: 95, Loss: 0.6799916625022888, Accuracy: 0.78271484375\n",
      "Batch: 96, Loss: 0.6209149956703186, Accuracy: 0.80419921875\n",
      "Batch: 97, Loss: 0.6252825260162354, Accuracy: 0.8046875\n",
      "Batch: 98, Loss: 0.6541250348091125, Accuracy: 0.78955078125\n",
      "Batch: 99, Loss: 0.6043180823326111, Accuracy: 0.80322265625\n",
      "Batch: 100, Loss: 0.6973482370376587, Accuracy: 0.77978515625\n",
      "Batch: 101, Loss: 0.7073345184326172, Accuracy: 0.7666015625\n",
      "Batch: 102, Loss: 0.6153026819229126, Accuracy: 0.79736328125\n",
      "Batch: 103, Loss: 0.6386936902999878, Accuracy: 0.791015625\n",
      "Batch: 104, Loss: 0.6091403961181641, Accuracy: 0.8095703125\n",
      "Batch: 105, Loss: 0.6414588093757629, Accuracy: 0.79833984375\n",
      "Batch: 106, Loss: 0.5941439270973206, Accuracy: 0.80224609375\n",
      "Batch: 107, Loss: 0.6312198638916016, Accuracy: 0.80029296875\n",
      "Batch: 108, Loss: 0.6013169288635254, Accuracy: 0.8037109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 109, Loss: 0.6121594905853271, Accuracy: 0.8056640625\n",
      "Batch: 110, Loss: 0.5751693844795227, Accuracy: 0.81591796875\n",
      "Batch: 111, Loss: 0.5819387435913086, Accuracy: 0.80517578125\n",
      "Batch: 112, Loss: 0.6063351035118103, Accuracy: 0.80615234375\n",
      "Batch: 113, Loss: 0.6377294063568115, Accuracy: 0.7880859375\n",
      "Batch: 114, Loss: 0.6303105354309082, Accuracy: 0.79736328125\n",
      "Batch: 115, Loss: 0.6369045972824097, Accuracy: 0.79296875\n",
      "Batch: 116, Loss: 0.6205303072929382, Accuracy: 0.80322265625\n",
      "Batch: 117, Loss: 0.5973805785179138, Accuracy: 0.80517578125\n",
      "Batch: 118, Loss: 0.6184109449386597, Accuracy: 0.798828125\n",
      "Batch: 119, Loss: 0.6008557081222534, Accuracy: 0.79833984375\n",
      "Batch: 120, Loss: 0.6068721413612366, Accuracy: 0.7998046875\n",
      "Batch: 121, Loss: 0.5994091033935547, Accuracy: 0.8125\n",
      "Batch: 122, Loss: 0.5599501729011536, Accuracy: 0.81591796875\n",
      "Batch: 123, Loss: 0.5858789682388306, Accuracy: 0.8193359375\n",
      "Batch: 124, Loss: 0.5788941383361816, Accuracy: 0.81103515625\n",
      "Batch: 125, Loss: 0.5971866846084595, Accuracy: 0.8056640625\n",
      "Batch: 126, Loss: 0.6121696829795837, Accuracy: 0.802734375\n",
      "Batch: 127, Loss: 0.5677738785743713, Accuracy: 0.81396484375\n",
      "Batch: 128, Loss: 0.6657600402832031, Accuracy: 0.791015625\n",
      "Batch: 129, Loss: 0.688431978225708, Accuracy: 0.77099609375\n",
      "Batch: 130, Loss: 0.7009846568107605, Accuracy: 0.77734375\n",
      "Batch: 131, Loss: 0.6150140762329102, Accuracy: 0.7958984375\n",
      "Batch: 132, Loss: 0.5818910598754883, Accuracy: 0.8203125\n",
      "Batch: 133, Loss: 0.5602434873580933, Accuracy: 0.8212890625\n",
      "Batch: 134, Loss: 0.6456538438796997, Accuracy: 0.7900390625\n",
      "Batch: 135, Loss: 0.6349962949752808, Accuracy: 0.79248046875\n",
      "Batch: 136, Loss: 0.5846767425537109, Accuracy: 0.8037109375\n",
      "Batch: 137, Loss: 0.6004877090454102, Accuracy: 0.8046875\n",
      "Batch: 138, Loss: 0.5480338931083679, Accuracy: 0.83447265625\n",
      "Batch: 139, Loss: 0.5834594964981079, Accuracy: 0.80810546875\n",
      "Batch: 140, Loss: 0.5431103706359863, Accuracy: 0.81884765625\n",
      "Batch: 141, Loss: 0.6463654041290283, Accuracy: 0.78564453125\n",
      "Batch: 142, Loss: 0.5763292908668518, Accuracy: 0.8115234375\n",
      "Batch: 143, Loss: 0.583961009979248, Accuracy: 0.81005859375\n",
      "Batch: 144, Loss: 0.6632540225982666, Accuracy: 0.78515625\n",
      "Batch: 145, Loss: 0.628139317035675, Accuracy: 0.80029296875\n",
      "Batch: 146, Loss: 0.6376219391822815, Accuracy: 0.7939453125\n",
      "Batch: 147, Loss: 0.6197172403335571, Accuracy: 0.80126953125\n",
      "Batch: 148, Loss: 0.6494674682617188, Accuracy: 0.78466796875\n",
      "Batch: 149, Loss: 0.630943775177002, Accuracy: 0.798828125\n",
      "Batch: 150, Loss: 0.5710082054138184, Accuracy: 0.81982421875\n",
      "Batch: 151, Loss: 0.5703110694885254, Accuracy: 0.810546875\n",
      "Batch: 152, Loss: 0.5963091850280762, Accuracy: 0.806640625\n",
      "Batch: 153, Loss: 0.6083576083183289, Accuracy: 0.80908203125\n",
      "Batch: 154, Loss: 0.6132663488388062, Accuracy: 0.79248046875\n",
      "Batch: 155, Loss: 0.6491274833679199, Accuracy: 0.79345703125\n",
      "Batch: 156, Loss: 0.5672502517700195, Accuracy: 0.8095703125\n",
      "Batch: 157, Loss: 0.5522894859313965, Accuracy: 0.822265625\n",
      "Batch: 158, Loss: 0.5901532173156738, Accuracy: 0.81103515625\n",
      "Batch: 159, Loss: 0.5946706533432007, Accuracy: 0.81396484375\n",
      "Batch: 160, Loss: 0.6072201728820801, Accuracy: 0.8125\n",
      "Batch: 161, Loss: 0.6256629228591919, Accuracy: 0.80078125\n",
      "Batch: 162, Loss: 0.5999507308006287, Accuracy: 0.80078125\n",
      "Batch: 163, Loss: 0.6350001096725464, Accuracy: 0.79541015625\n",
      "Batch: 164, Loss: 0.6859499216079712, Accuracy: 0.78076171875\n",
      "Batch: 165, Loss: 0.6102161407470703, Accuracy: 0.80419921875\n",
      "Batch: 166, Loss: 0.6153944730758667, Accuracy: 0.80419921875\n",
      "Batch: 167, Loss: 0.6143866777420044, Accuracy: 0.798828125\n",
      "Batch: 168, Loss: 0.5461246371269226, Accuracy: 0.8271484375\n",
      "Batch: 169, Loss: 0.6219824552536011, Accuracy: 0.7958984375\n",
      "Batch: 170, Loss: 0.6268880367279053, Accuracy: 0.8017578125\n",
      "Batch: 171, Loss: 0.5936526656150818, Accuracy: 0.802734375\n",
      "Batch: 172, Loss: 0.6211897730827332, Accuracy: 0.79443359375\n",
      "Batch: 173, Loss: 0.65386962890625, Accuracy: 0.7841796875\n",
      "Batch: 174, Loss: 0.5222805738449097, Accuracy: 0.8203125\n",
      "Batch: 175, Loss: 0.6454116106033325, Accuracy: 0.79736328125\n",
      "Batch: 176, Loss: 0.6400556564331055, Accuracy: 0.794921875\n",
      "Batch: 177, Loss: 0.5847305059432983, Accuracy: 0.81494140625\n",
      "Batch: 178, Loss: 0.5617748498916626, Accuracy: 0.82275390625\n",
      "Batch: 179, Loss: 0.6131427884101868, Accuracy: 0.81103515625\n",
      "Batch: 180, Loss: 0.6400354504585266, Accuracy: 0.79443359375\n",
      "Epoch 65/200\n",
      "Batch: 1, Loss: 0.8984649777412415, Accuracy: 0.7353515625\n",
      "Batch: 2, Loss: 0.6076009273529053, Accuracy: 0.80029296875\n",
      "Batch: 3, Loss: 0.600473165512085, Accuracy: 0.81201171875\n",
      "Batch: 4, Loss: 0.637688398361206, Accuracy: 0.7890625\n",
      "Batch: 5, Loss: 0.6091995239257812, Accuracy: 0.80419921875\n",
      "Batch: 6, Loss: 0.6176009178161621, Accuracy: 0.79345703125\n",
      "Batch: 7, Loss: 0.6061811447143555, Accuracy: 0.8046875\n",
      "Batch: 8, Loss: 0.6186326742172241, Accuracy: 0.7978515625\n",
      "Batch: 9, Loss: 0.6560012102127075, Accuracy: 0.79248046875\n",
      "Batch: 10, Loss: 0.5954786539077759, Accuracy: 0.80810546875\n",
      "Batch: 11, Loss: 0.6258217096328735, Accuracy: 0.7978515625\n",
      "Batch: 12, Loss: 0.5690333843231201, Accuracy: 0.81982421875\n",
      "Batch: 13, Loss: 0.6087533831596375, Accuracy: 0.80224609375\n",
      "Batch: 14, Loss: 0.6062870025634766, Accuracy: 0.80810546875\n",
      "Batch: 15, Loss: 0.6172952651977539, Accuracy: 0.8046875\n",
      "Batch: 16, Loss: 0.6498121023178101, Accuracy: 0.78515625\n",
      "Batch: 17, Loss: 0.604861855506897, Accuracy: 0.80517578125\n",
      "Batch: 18, Loss: 0.6338557004928589, Accuracy: 0.8046875\n",
      "Batch: 19, Loss: 0.6473826169967651, Accuracy: 0.798828125\n",
      "Batch: 20, Loss: 0.5478599071502686, Accuracy: 0.82763671875\n",
      "Batch: 21, Loss: 0.6426031589508057, Accuracy: 0.7919921875\n",
      "Batch: 22, Loss: 0.5731375217437744, Accuracy: 0.81103515625\n",
      "Batch: 23, Loss: 0.5588258504867554, Accuracy: 0.81298828125\n",
      "Batch: 24, Loss: 0.6119383573532104, Accuracy: 0.80322265625\n",
      "Batch: 25, Loss: 0.59428870677948, Accuracy: 0.8125\n",
      "Batch: 26, Loss: 0.5996368527412415, Accuracy: 0.80517578125\n",
      "Batch: 27, Loss: 0.6296223402023315, Accuracy: 0.791015625\n",
      "Batch: 28, Loss: 0.6022001504898071, Accuracy: 0.80126953125\n",
      "Batch: 29, Loss: 0.6636598110198975, Accuracy: 0.79052734375\n",
      "Batch: 30, Loss: 0.6356518268585205, Accuracy: 0.791015625\n",
      "Batch: 31, Loss: 0.7087820768356323, Accuracy: 0.775390625\n",
      "Batch: 32, Loss: 0.6751773357391357, Accuracy: 0.78857421875\n",
      "Batch: 33, Loss: 0.6396915912628174, Accuracy: 0.794921875\n",
      "Batch: 34, Loss: 0.6600149869918823, Accuracy: 0.79541015625\n",
      "Batch: 35, Loss: 0.6782693862915039, Accuracy: 0.77734375\n",
      "Batch: 36, Loss: 0.6523929238319397, Accuracy: 0.7734375\n",
      "Batch: 37, Loss: 0.6437010765075684, Accuracy: 0.7919921875\n",
      "Batch: 38, Loss: 0.6881990432739258, Accuracy: 0.7724609375\n",
      "Batch: 39, Loss: 0.6500729322433472, Accuracy: 0.7861328125\n",
      "Batch: 40, Loss: 0.6656757593154907, Accuracy: 0.77978515625\n",
      "Batch: 41, Loss: 0.6350400447845459, Accuracy: 0.80029296875\n",
      "Batch: 42, Loss: 0.6396008729934692, Accuracy: 0.79150390625\n",
      "Batch: 43, Loss: 0.599041759967804, Accuracy: 0.810546875\n",
      "Batch: 44, Loss: 0.55464106798172, Accuracy: 0.82470703125\n",
      "Batch: 45, Loss: 0.633165180683136, Accuracy: 0.78759765625\n",
      "Batch: 46, Loss: 0.5932173728942871, Accuracy: 0.79736328125\n",
      "Batch: 47, Loss: 0.6146969795227051, Accuracy: 0.8076171875\n",
      "Batch: 48, Loss: 0.6169018745422363, Accuracy: 0.81103515625\n",
      "Batch: 49, Loss: 0.5898729562759399, Accuracy: 0.80810546875\n",
      "Batch: 50, Loss: 0.6054940223693848, Accuracy: 0.802734375\n",
      "Batch: 51, Loss: 0.6016891002655029, Accuracy: 0.8017578125\n",
      "Batch: 52, Loss: 0.6080272197723389, Accuracy: 0.79931640625\n",
      "Batch: 53, Loss: 0.6399612426757812, Accuracy: 0.7890625\n",
      "Batch: 54, Loss: 0.6596090197563171, Accuracy: 0.7841796875\n",
      "Batch: 55, Loss: 0.6196430325508118, Accuracy: 0.79345703125\n",
      "Batch: 56, Loss: 0.6112451553344727, Accuracy: 0.798828125\n",
      "Batch: 57, Loss: 0.6811216473579407, Accuracy: 0.78369140625\n",
      "Batch: 58, Loss: 0.619494616985321, Accuracy: 0.78759765625\n",
      "Batch: 59, Loss: 0.734161376953125, Accuracy: 0.771484375\n",
      "Batch: 60, Loss: 0.6469491124153137, Accuracy: 0.79248046875\n",
      "Batch: 61, Loss: 0.5789635181427002, Accuracy: 0.81396484375\n",
      "Batch: 62, Loss: 0.6001319885253906, Accuracy: 0.80517578125\n",
      "Batch: 63, Loss: 0.6151245832443237, Accuracy: 0.80126953125\n",
      "Batch: 64, Loss: 0.624082088470459, Accuracy: 0.79638671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 65, Loss: 0.6615615487098694, Accuracy: 0.787109375\n",
      "Batch: 66, Loss: 0.6299026012420654, Accuracy: 0.79248046875\n",
      "Batch: 67, Loss: 0.6528580188751221, Accuracy: 0.78955078125\n",
      "Batch: 68, Loss: 0.5724287033081055, Accuracy: 0.80712890625\n",
      "Batch: 69, Loss: 0.6272996664047241, Accuracy: 0.80224609375\n",
      "Batch: 70, Loss: 0.6117838621139526, Accuracy: 0.79833984375\n",
      "Batch: 71, Loss: 0.6263505816459656, Accuracy: 0.79638671875\n",
      "Batch: 72, Loss: 0.640310525894165, Accuracy: 0.7822265625\n",
      "Batch: 73, Loss: 0.6458568572998047, Accuracy: 0.787109375\n",
      "Batch: 74, Loss: 0.649174153804779, Accuracy: 0.7880859375\n",
      "Batch: 75, Loss: 0.5666950345039368, Accuracy: 0.82373046875\n",
      "Batch: 76, Loss: 0.5836807489395142, Accuracy: 0.81640625\n",
      "Batch: 77, Loss: 0.5839496850967407, Accuracy: 0.8203125\n",
      "Batch: 78, Loss: 0.6178591251373291, Accuracy: 0.798828125\n",
      "Batch: 79, Loss: 0.6265969276428223, Accuracy: 0.80517578125\n",
      "Batch: 80, Loss: 0.6263657808303833, Accuracy: 0.79443359375\n",
      "Batch: 81, Loss: 0.638198733329773, Accuracy: 0.8037109375\n",
      "Batch: 82, Loss: 0.5923311710357666, Accuracy: 0.80126953125\n",
      "Batch: 83, Loss: 0.5703443288803101, Accuracy: 0.810546875\n",
      "Batch: 84, Loss: 0.5794636011123657, Accuracy: 0.806640625\n",
      "Batch: 85, Loss: 0.6287097930908203, Accuracy: 0.79150390625\n",
      "Batch: 86, Loss: 0.6406830549240112, Accuracy: 0.79931640625\n",
      "Batch: 87, Loss: 0.5931402444839478, Accuracy: 0.80322265625\n",
      "Batch: 88, Loss: 0.629193902015686, Accuracy: 0.7978515625\n",
      "Batch: 89, Loss: 0.6054705381393433, Accuracy: 0.80078125\n",
      "Batch: 90, Loss: 0.6562565565109253, Accuracy: 0.78369140625\n",
      "Batch: 91, Loss: 0.611803412437439, Accuracy: 0.806640625\n",
      "Batch: 92, Loss: 0.6896296739578247, Accuracy: 0.78125\n",
      "Batch: 93, Loss: 0.6639047861099243, Accuracy: 0.77978515625\n",
      "Batch: 94, Loss: 0.6356186866760254, Accuracy: 0.79638671875\n",
      "Batch: 95, Loss: 0.6796988248825073, Accuracy: 0.7890625\n",
      "Batch: 96, Loss: 0.6152614951133728, Accuracy: 0.80224609375\n",
      "Batch: 97, Loss: 0.6231776475906372, Accuracy: 0.8037109375\n",
      "Batch: 98, Loss: 0.6472766399383545, Accuracy: 0.7978515625\n",
      "Batch: 99, Loss: 0.5963054895401001, Accuracy: 0.81201171875\n",
      "Batch: 100, Loss: 0.6725286245346069, Accuracy: 0.7841796875\n",
      "Batch: 101, Loss: 0.6708903312683105, Accuracy: 0.78955078125\n",
      "Batch: 102, Loss: 0.5758446455001831, Accuracy: 0.814453125\n",
      "Batch: 103, Loss: 0.6230776906013489, Accuracy: 0.80126953125\n",
      "Batch: 104, Loss: 0.6008697748184204, Accuracy: 0.7998046875\n",
      "Batch: 105, Loss: 0.6332414150238037, Accuracy: 0.8056640625\n",
      "Batch: 106, Loss: 0.5932661890983582, Accuracy: 0.80126953125\n",
      "Batch: 107, Loss: 0.6254585385322571, Accuracy: 0.796875\n",
      "Batch: 108, Loss: 0.5828022360801697, Accuracy: 0.8056640625\n",
      "Batch: 109, Loss: 0.6013044118881226, Accuracy: 0.8056640625\n",
      "Batch: 110, Loss: 0.6024993062019348, Accuracy: 0.79833984375\n",
      "Batch: 111, Loss: 0.5653725862503052, Accuracy: 0.81298828125\n",
      "Batch: 112, Loss: 0.6067383289337158, Accuracy: 0.80029296875\n",
      "Batch: 113, Loss: 0.6406642198562622, Accuracy: 0.78564453125\n",
      "Batch: 114, Loss: 0.6231689453125, Accuracy: 0.7958984375\n",
      "Batch: 115, Loss: 0.611981987953186, Accuracy: 0.80322265625\n",
      "Batch: 116, Loss: 0.6233084201812744, Accuracy: 0.79150390625\n",
      "Batch: 117, Loss: 0.5897031426429749, Accuracy: 0.81103515625\n",
      "Batch: 118, Loss: 0.6276103258132935, Accuracy: 0.79443359375\n",
      "Batch: 119, Loss: 0.5945711731910706, Accuracy: 0.80615234375\n",
      "Batch: 120, Loss: 0.5760857462882996, Accuracy: 0.82177734375\n",
      "Batch: 121, Loss: 0.5862864255905151, Accuracy: 0.80615234375\n",
      "Batch: 122, Loss: 0.5657162666320801, Accuracy: 0.81884765625\n",
      "Batch: 123, Loss: 0.5663444995880127, Accuracy: 0.82666015625\n",
      "Batch: 124, Loss: 0.5646213889122009, Accuracy: 0.81591796875\n",
      "Batch: 125, Loss: 0.6073653697967529, Accuracy: 0.806640625\n",
      "Batch: 126, Loss: 0.5754721164703369, Accuracy: 0.8115234375\n",
      "Batch: 127, Loss: 0.5615223050117493, Accuracy: 0.822265625\n",
      "Batch: 128, Loss: 0.6571188569068909, Accuracy: 0.79052734375\n",
      "Batch: 129, Loss: 0.692658543586731, Accuracy: 0.77685546875\n",
      "Batch: 130, Loss: 0.6817871332168579, Accuracy: 0.78564453125\n",
      "Batch: 131, Loss: 0.6348897218704224, Accuracy: 0.798828125\n",
      "Batch: 132, Loss: 0.5977981090545654, Accuracy: 0.81396484375\n",
      "Batch: 133, Loss: 0.5672775506973267, Accuracy: 0.822265625\n",
      "Batch: 134, Loss: 0.6319830417633057, Accuracy: 0.80517578125\n",
      "Batch: 135, Loss: 0.6206697225570679, Accuracy: 0.79541015625\n",
      "Batch: 136, Loss: 0.587273120880127, Accuracy: 0.802734375\n",
      "Batch: 137, Loss: 0.6128093600273132, Accuracy: 0.80517578125\n",
      "Batch: 138, Loss: 0.5695834159851074, Accuracy: 0.822265625\n",
      "Batch: 139, Loss: 0.5758978128433228, Accuracy: 0.81689453125\n",
      "Batch: 140, Loss: 0.5579286813735962, Accuracy: 0.8193359375\n",
      "Batch: 141, Loss: 0.6357470750808716, Accuracy: 0.7861328125\n",
      "Batch: 142, Loss: 0.5487256646156311, Accuracy: 0.82421875\n",
      "Batch: 143, Loss: 0.572633683681488, Accuracy: 0.8193359375\n",
      "Batch: 144, Loss: 0.662003219127655, Accuracy: 0.78955078125\n",
      "Batch: 145, Loss: 0.6145597100257874, Accuracy: 0.79638671875\n",
      "Batch: 146, Loss: 0.6437292098999023, Accuracy: 0.78662109375\n",
      "Batch: 147, Loss: 0.6046619415283203, Accuracy: 0.806640625\n",
      "Batch: 148, Loss: 0.6732469797134399, Accuracy: 0.77294921875\n",
      "Batch: 149, Loss: 0.6329326033592224, Accuracy: 0.7939453125\n",
      "Batch: 150, Loss: 0.546103835105896, Accuracy: 0.8251953125\n",
      "Batch: 151, Loss: 0.5679313540458679, Accuracy: 0.818359375\n",
      "Batch: 152, Loss: 0.5785922408103943, Accuracy: 0.81640625\n",
      "Batch: 153, Loss: 0.6104893684387207, Accuracy: 0.7998046875\n",
      "Batch: 154, Loss: 0.5913794040679932, Accuracy: 0.802734375\n",
      "Batch: 155, Loss: 0.6570762395858765, Accuracy: 0.79443359375\n",
      "Batch: 156, Loss: 0.5728727579116821, Accuracy: 0.81396484375\n",
      "Batch: 157, Loss: 0.556527316570282, Accuracy: 0.8134765625\n",
      "Batch: 158, Loss: 0.5697288513183594, Accuracy: 0.8154296875\n",
      "Batch: 159, Loss: 0.5919895172119141, Accuracy: 0.81787109375\n",
      "Batch: 160, Loss: 0.5873728394508362, Accuracy: 0.810546875\n",
      "Batch: 161, Loss: 0.6355143189430237, Accuracy: 0.8037109375\n",
      "Batch: 162, Loss: 0.5851836800575256, Accuracy: 0.80908203125\n",
      "Batch: 163, Loss: 0.6055372953414917, Accuracy: 0.8046875\n",
      "Batch: 164, Loss: 0.6990938782691956, Accuracy: 0.77294921875\n",
      "Batch: 165, Loss: 0.6215404868125916, Accuracy: 0.79150390625\n",
      "Batch: 166, Loss: 0.6228423118591309, Accuracy: 0.79833984375\n",
      "Batch: 167, Loss: 0.6096361875534058, Accuracy: 0.80078125\n",
      "Batch: 168, Loss: 0.5377017259597778, Accuracy: 0.8251953125\n",
      "Batch: 169, Loss: 0.599018394947052, Accuracy: 0.79736328125\n",
      "Batch: 170, Loss: 0.6455454230308533, Accuracy: 0.79638671875\n",
      "Batch: 171, Loss: 0.5921750664710999, Accuracy: 0.81005859375\n",
      "Batch: 172, Loss: 0.5887899398803711, Accuracy: 0.7939453125\n",
      "Batch: 173, Loss: 0.6264560222625732, Accuracy: 0.79541015625\n",
      "Batch: 174, Loss: 0.5410923957824707, Accuracy: 0.82470703125\n",
      "Batch: 175, Loss: 0.6182595491409302, Accuracy: 0.80224609375\n",
      "Batch: 176, Loss: 0.6716005802154541, Accuracy: 0.783203125\n",
      "Batch: 177, Loss: 0.5793965458869934, Accuracy: 0.8154296875\n",
      "Batch: 178, Loss: 0.5566670894622803, Accuracy: 0.822265625\n",
      "Batch: 179, Loss: 0.614709734916687, Accuracy: 0.80224609375\n",
      "Batch: 180, Loss: 0.6149221658706665, Accuracy: 0.8076171875\n",
      "Epoch 66/200\n",
      "Batch: 1, Loss: 0.8836595416069031, Accuracy: 0.7529296875\n",
      "Batch: 2, Loss: 0.6180768013000488, Accuracy: 0.7900390625\n",
      "Batch: 3, Loss: 0.6028881072998047, Accuracy: 0.80029296875\n",
      "Batch: 4, Loss: 0.636741042137146, Accuracy: 0.79248046875\n",
      "Batch: 5, Loss: 0.6165106892585754, Accuracy: 0.80078125\n",
      "Batch: 6, Loss: 0.6322144269943237, Accuracy: 0.8037109375\n",
      "Batch: 7, Loss: 0.5979596376419067, Accuracy: 0.8037109375\n",
      "Batch: 8, Loss: 0.5948340892791748, Accuracy: 0.79931640625\n",
      "Batch: 9, Loss: 0.6330152750015259, Accuracy: 0.79248046875\n",
      "Batch: 10, Loss: 0.5953609943389893, Accuracy: 0.81005859375\n",
      "Batch: 11, Loss: 0.6409720182418823, Accuracy: 0.787109375\n",
      "Batch: 12, Loss: 0.5820016860961914, Accuracy: 0.810546875\n",
      "Batch: 13, Loss: 0.621148943901062, Accuracy: 0.7900390625\n",
      "Batch: 14, Loss: 0.6115081310272217, Accuracy: 0.79345703125\n",
      "Batch: 15, Loss: 0.6122019290924072, Accuracy: 0.81103515625\n",
      "Batch: 16, Loss: 0.6436210870742798, Accuracy: 0.79345703125\n",
      "Batch: 17, Loss: 0.6142944693565369, Accuracy: 0.7978515625\n",
      "Batch: 18, Loss: 0.624722957611084, Accuracy: 0.80029296875\n",
      "Batch: 19, Loss: 0.6537773609161377, Accuracy: 0.798828125\n",
      "Batch: 20, Loss: 0.5373729467391968, Accuracy: 0.8251953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 21, Loss: 0.6293898820877075, Accuracy: 0.796875\n",
      "Batch: 22, Loss: 0.5615819692611694, Accuracy: 0.8154296875\n",
      "Batch: 23, Loss: 0.5413442850112915, Accuracy: 0.818359375\n",
      "Batch: 24, Loss: 0.6059889197349548, Accuracy: 0.80224609375\n",
      "Batch: 25, Loss: 0.5801635980606079, Accuracy: 0.8173828125\n",
      "Batch: 26, Loss: 0.6023448705673218, Accuracy: 0.79638671875\n",
      "Batch: 27, Loss: 0.643413782119751, Accuracy: 0.78271484375\n",
      "Batch: 28, Loss: 0.5904114246368408, Accuracy: 0.8115234375\n",
      "Batch: 29, Loss: 0.6471465229988098, Accuracy: 0.7998046875\n",
      "Batch: 30, Loss: 0.5956155061721802, Accuracy: 0.8115234375\n",
      "Batch: 31, Loss: 0.6888265609741211, Accuracy: 0.78955078125\n",
      "Batch: 32, Loss: 0.6486878395080566, Accuracy: 0.78662109375\n",
      "Batch: 33, Loss: 0.6344410181045532, Accuracy: 0.794921875\n",
      "Batch: 34, Loss: 0.6464455127716064, Accuracy: 0.79248046875\n",
      "Batch: 35, Loss: 0.677453875541687, Accuracy: 0.7841796875\n",
      "Batch: 36, Loss: 0.6352415084838867, Accuracy: 0.7939453125\n",
      "Batch: 37, Loss: 0.6389951705932617, Accuracy: 0.7890625\n",
      "Batch: 38, Loss: 0.6540014147758484, Accuracy: 0.77978515625\n",
      "Batch: 39, Loss: 0.6197924613952637, Accuracy: 0.79638671875\n",
      "Batch: 40, Loss: 0.6899746656417847, Accuracy: 0.771484375\n",
      "Batch: 41, Loss: 0.6505084037780762, Accuracy: 0.7958984375\n",
      "Batch: 42, Loss: 0.6462457180023193, Accuracy: 0.787109375\n",
      "Batch: 43, Loss: 0.5935443639755249, Accuracy: 0.81640625\n",
      "Batch: 44, Loss: 0.5401564240455627, Accuracy: 0.830078125\n",
      "Batch: 45, Loss: 0.6050407886505127, Accuracy: 0.80908203125\n",
      "Batch: 46, Loss: 0.593021035194397, Accuracy: 0.798828125\n",
      "Batch: 47, Loss: 0.6023404002189636, Accuracy: 0.80419921875\n",
      "Batch: 48, Loss: 0.610897421836853, Accuracy: 0.80810546875\n",
      "Batch: 49, Loss: 0.6004658937454224, Accuracy: 0.8046875\n",
      "Batch: 50, Loss: 0.6164408326148987, Accuracy: 0.7978515625\n",
      "Batch: 51, Loss: 0.6059079170227051, Accuracy: 0.7978515625\n",
      "Batch: 52, Loss: 0.5964748859405518, Accuracy: 0.80517578125\n",
      "Batch: 53, Loss: 0.6133891344070435, Accuracy: 0.7880859375\n",
      "Batch: 54, Loss: 0.6423740983009338, Accuracy: 0.78564453125\n",
      "Batch: 55, Loss: 0.6101984977722168, Accuracy: 0.79931640625\n",
      "Batch: 56, Loss: 0.6032071113586426, Accuracy: 0.79931640625\n",
      "Batch: 57, Loss: 0.6735888123512268, Accuracy: 0.78564453125\n",
      "Batch: 58, Loss: 0.6286786794662476, Accuracy: 0.798828125\n",
      "Batch: 59, Loss: 0.7201234102249146, Accuracy: 0.783203125\n",
      "Batch: 60, Loss: 0.5865245461463928, Accuracy: 0.81689453125\n",
      "Batch: 61, Loss: 0.5783188939094543, Accuracy: 0.8154296875\n",
      "Batch: 62, Loss: 0.5880725383758545, Accuracy: 0.810546875\n",
      "Batch: 63, Loss: 0.5960867404937744, Accuracy: 0.79296875\n",
      "Batch: 64, Loss: 0.640836238861084, Accuracy: 0.775390625\n",
      "Batch: 65, Loss: 0.6531847715377808, Accuracy: 0.791015625\n",
      "Batch: 66, Loss: 0.6189581751823425, Accuracy: 0.798828125\n",
      "Batch: 67, Loss: 0.6489031910896301, Accuracy: 0.79443359375\n",
      "Batch: 68, Loss: 0.5727769136428833, Accuracy: 0.8095703125\n",
      "Batch: 69, Loss: 0.6079268455505371, Accuracy: 0.80224609375\n",
      "Batch: 70, Loss: 0.6142399907112122, Accuracy: 0.7978515625\n",
      "Batch: 71, Loss: 0.5827207565307617, Accuracy: 0.814453125\n",
      "Batch: 72, Loss: 0.6577632427215576, Accuracy: 0.78076171875\n",
      "Batch: 73, Loss: 0.6338348388671875, Accuracy: 0.798828125\n",
      "Batch: 74, Loss: 0.6274183988571167, Accuracy: 0.796875\n",
      "Batch: 75, Loss: 0.576700747013092, Accuracy: 0.80712890625\n",
      "Batch: 76, Loss: 0.5537787675857544, Accuracy: 0.82275390625\n",
      "Batch: 77, Loss: 0.5771453380584717, Accuracy: 0.82177734375\n",
      "Batch: 78, Loss: 0.6104788780212402, Accuracy: 0.80810546875\n",
      "Batch: 79, Loss: 0.6117880940437317, Accuracy: 0.8017578125\n",
      "Batch: 80, Loss: 0.6082504987716675, Accuracy: 0.80615234375\n",
      "Batch: 81, Loss: 0.6255536079406738, Accuracy: 0.8134765625\n",
      "Batch: 82, Loss: 0.5996694564819336, Accuracy: 0.802734375\n",
      "Batch: 83, Loss: 0.5650871992111206, Accuracy: 0.81591796875\n",
      "Batch: 84, Loss: 0.5941694974899292, Accuracy: 0.81591796875\n",
      "Batch: 85, Loss: 0.6245311498641968, Accuracy: 0.79296875\n",
      "Batch: 86, Loss: 0.6416170597076416, Accuracy: 0.7958984375\n",
      "Batch: 87, Loss: 0.5737420320510864, Accuracy: 0.8115234375\n",
      "Batch: 88, Loss: 0.620593786239624, Accuracy: 0.80078125\n",
      "Batch: 89, Loss: 0.6116344332695007, Accuracy: 0.79931640625\n",
      "Batch: 90, Loss: 0.6410625576972961, Accuracy: 0.79638671875\n",
      "Batch: 91, Loss: 0.6087372899055481, Accuracy: 0.806640625\n",
      "Batch: 92, Loss: 0.6886911988258362, Accuracy: 0.77099609375\n",
      "Batch: 93, Loss: 0.665621280670166, Accuracy: 0.7783203125\n",
      "Batch: 94, Loss: 0.6622419357299805, Accuracy: 0.796875\n",
      "Batch: 95, Loss: 0.6699948310852051, Accuracy: 0.78466796875\n",
      "Batch: 96, Loss: 0.6172021627426147, Accuracy: 0.80810546875\n",
      "Batch: 97, Loss: 0.608271598815918, Accuracy: 0.814453125\n",
      "Batch: 98, Loss: 0.6257894039154053, Accuracy: 0.7958984375\n",
      "Batch: 99, Loss: 0.6004367470741272, Accuracy: 0.81396484375\n",
      "Batch: 100, Loss: 0.6635422110557556, Accuracy: 0.7939453125\n",
      "Batch: 101, Loss: 0.6610590815544128, Accuracy: 0.7890625\n",
      "Batch: 102, Loss: 0.5747026205062866, Accuracy: 0.8193359375\n",
      "Batch: 103, Loss: 0.6161128282546997, Accuracy: 0.806640625\n",
      "Batch: 104, Loss: 0.6023324728012085, Accuracy: 0.80615234375\n",
      "Batch: 105, Loss: 0.643328070640564, Accuracy: 0.7919921875\n",
      "Batch: 106, Loss: 0.5791678428649902, Accuracy: 0.81298828125\n",
      "Batch: 107, Loss: 0.6118279695510864, Accuracy: 0.79833984375\n",
      "Batch: 108, Loss: 0.5899802446365356, Accuracy: 0.81103515625\n",
      "Batch: 109, Loss: 0.5767771005630493, Accuracy: 0.8134765625\n",
      "Batch: 110, Loss: 0.5922393202781677, Accuracy: 0.79833984375\n",
      "Batch: 111, Loss: 0.5652986764907837, Accuracy: 0.81591796875\n",
      "Batch: 112, Loss: 0.6175187826156616, Accuracy: 0.79833984375\n",
      "Batch: 113, Loss: 0.6304930448532104, Accuracy: 0.791015625\n",
      "Batch: 114, Loss: 0.6235450506210327, Accuracy: 0.80224609375\n",
      "Batch: 115, Loss: 0.6073768734931946, Accuracy: 0.810546875\n",
      "Batch: 116, Loss: 0.6163079738616943, Accuracy: 0.80322265625\n",
      "Batch: 117, Loss: 0.5905860662460327, Accuracy: 0.806640625\n",
      "Batch: 118, Loss: 0.6063976287841797, Accuracy: 0.796875\n",
      "Batch: 119, Loss: 0.6030049324035645, Accuracy: 0.7998046875\n",
      "Batch: 120, Loss: 0.5710819959640503, Accuracy: 0.81884765625\n",
      "Batch: 121, Loss: 0.5953443050384521, Accuracy: 0.81103515625\n",
      "Batch: 122, Loss: 0.55140221118927, Accuracy: 0.8212890625\n",
      "Batch: 123, Loss: 0.5752677321434021, Accuracy: 0.81640625\n",
      "Batch: 124, Loss: 0.5699186325073242, Accuracy: 0.822265625\n",
      "Batch: 125, Loss: 0.5926677584648132, Accuracy: 0.8173828125\n",
      "Batch: 126, Loss: 0.5812826156616211, Accuracy: 0.80615234375\n",
      "Batch: 127, Loss: 0.5537259578704834, Accuracy: 0.81591796875\n",
      "Batch: 128, Loss: 0.6534382104873657, Accuracy: 0.78466796875\n",
      "Batch: 129, Loss: 0.6859235763549805, Accuracy: 0.7744140625\n",
      "Batch: 130, Loss: 0.6600357294082642, Accuracy: 0.7880859375\n",
      "Batch: 131, Loss: 0.6177722215652466, Accuracy: 0.80224609375\n",
      "Batch: 132, Loss: 0.5650473833084106, Accuracy: 0.82177734375\n",
      "Batch: 133, Loss: 0.5607445240020752, Accuracy: 0.82763671875\n",
      "Batch: 134, Loss: 0.6294295191764832, Accuracy: 0.79541015625\n",
      "Batch: 135, Loss: 0.6190237998962402, Accuracy: 0.80322265625\n",
      "Batch: 136, Loss: 0.5421727895736694, Accuracy: 0.81640625\n",
      "Batch: 137, Loss: 0.6354447603225708, Accuracy: 0.79736328125\n",
      "Batch: 138, Loss: 0.5589331388473511, Accuracy: 0.8251953125\n",
      "Batch: 139, Loss: 0.5892912745475769, Accuracy: 0.80029296875\n",
      "Batch: 140, Loss: 0.5275102853775024, Accuracy: 0.828125\n",
      "Batch: 141, Loss: 0.6314963698387146, Accuracy: 0.79638671875\n",
      "Batch: 142, Loss: 0.573581874370575, Accuracy: 0.8212890625\n",
      "Batch: 143, Loss: 0.5902231931686401, Accuracy: 0.8125\n",
      "Batch: 144, Loss: 0.6658325791358948, Accuracy: 0.7861328125\n",
      "Batch: 145, Loss: 0.6176999807357788, Accuracy: 0.80517578125\n",
      "Batch: 146, Loss: 0.6520892381668091, Accuracy: 0.787109375\n",
      "Batch: 147, Loss: 0.6066078543663025, Accuracy: 0.8037109375\n",
      "Batch: 148, Loss: 0.6399085521697998, Accuracy: 0.7958984375\n",
      "Batch: 149, Loss: 0.6349485516548157, Accuracy: 0.7998046875\n",
      "Batch: 150, Loss: 0.520414412021637, Accuracy: 0.84375\n",
      "Batch: 151, Loss: 0.5453385710716248, Accuracy: 0.8212890625\n",
      "Batch: 152, Loss: 0.5765649080276489, Accuracy: 0.81640625\n",
      "Batch: 153, Loss: 0.5979149341583252, Accuracy: 0.8046875\n",
      "Batch: 154, Loss: 0.5639812350273132, Accuracy: 0.8134765625\n",
      "Batch: 155, Loss: 0.6570917367935181, Accuracy: 0.783203125\n",
      "Batch: 156, Loss: 0.5523384213447571, Accuracy: 0.81103515625\n",
      "Batch: 157, Loss: 0.5367046594619751, Accuracy: 0.82177734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 158, Loss: 0.5723577737808228, Accuracy: 0.8203125\n",
      "Batch: 159, Loss: 0.586790144443512, Accuracy: 0.8076171875\n",
      "Batch: 160, Loss: 0.6044871807098389, Accuracy: 0.806640625\n",
      "Batch: 161, Loss: 0.6197864413261414, Accuracy: 0.7998046875\n",
      "Batch: 162, Loss: 0.5693360567092896, Accuracy: 0.8115234375\n",
      "Batch: 163, Loss: 0.6385033130645752, Accuracy: 0.78564453125\n",
      "Batch: 164, Loss: 0.6799333691596985, Accuracy: 0.783203125\n",
      "Batch: 165, Loss: 0.6197914481163025, Accuracy: 0.80859375\n",
      "Batch: 166, Loss: 0.6261640191078186, Accuracy: 0.80029296875\n",
      "Batch: 167, Loss: 0.5972564220428467, Accuracy: 0.818359375\n",
      "Batch: 168, Loss: 0.5347657799720764, Accuracy: 0.82958984375\n",
      "Batch: 169, Loss: 0.5916402339935303, Accuracy: 0.810546875\n",
      "Batch: 170, Loss: 0.6419559717178345, Accuracy: 0.79052734375\n",
      "Batch: 171, Loss: 0.5828315019607544, Accuracy: 0.81103515625\n",
      "Batch: 172, Loss: 0.5728821754455566, Accuracy: 0.80078125\n",
      "Batch: 173, Loss: 0.6295939683914185, Accuracy: 0.79248046875\n",
      "Batch: 174, Loss: 0.5292794704437256, Accuracy: 0.8212890625\n",
      "Batch: 175, Loss: 0.6147054433822632, Accuracy: 0.79150390625\n",
      "Batch: 176, Loss: 0.6477564573287964, Accuracy: 0.791015625\n",
      "Batch: 177, Loss: 0.5908105969429016, Accuracy: 0.81689453125\n",
      "Batch: 178, Loss: 0.5528557300567627, Accuracy: 0.82275390625\n",
      "Batch: 179, Loss: 0.6027956604957581, Accuracy: 0.814453125\n",
      "Batch: 180, Loss: 0.6090552806854248, Accuracy: 0.80419921875\n",
      "Epoch 67/200\n",
      "Batch: 1, Loss: 0.8853485584259033, Accuracy: 0.7529296875\n",
      "Batch: 2, Loss: 0.597309947013855, Accuracy: 0.79345703125\n",
      "Batch: 3, Loss: 0.6116629838943481, Accuracy: 0.798828125\n",
      "Batch: 4, Loss: 0.6242552995681763, Accuracy: 0.80224609375\n",
      "Batch: 5, Loss: 0.6094309687614441, Accuracy: 0.796875\n",
      "Batch: 6, Loss: 0.6285800933837891, Accuracy: 0.78466796875\n",
      "Batch: 7, Loss: 0.6110063791275024, Accuracy: 0.80322265625\n",
      "Batch: 8, Loss: 0.5965365171432495, Accuracy: 0.80224609375\n",
      "Batch: 9, Loss: 0.5997646450996399, Accuracy: 0.8046875\n",
      "Batch: 10, Loss: 0.5892272591590881, Accuracy: 0.80712890625\n",
      "Batch: 11, Loss: 0.6211727857589722, Accuracy: 0.8037109375\n",
      "Batch: 12, Loss: 0.5609922409057617, Accuracy: 0.8134765625\n",
      "Batch: 13, Loss: 0.6274456977844238, Accuracy: 0.79541015625\n",
      "Batch: 14, Loss: 0.605930507183075, Accuracy: 0.8095703125\n",
      "Batch: 15, Loss: 0.6023814678192139, Accuracy: 0.80908203125\n",
      "Batch: 16, Loss: 0.6547420620918274, Accuracy: 0.77294921875\n",
      "Batch: 17, Loss: 0.5930280089378357, Accuracy: 0.818359375\n",
      "Batch: 18, Loss: 0.6147392988204956, Accuracy: 0.81689453125\n",
      "Batch: 19, Loss: 0.6282391548156738, Accuracy: 0.806640625\n",
      "Batch: 20, Loss: 0.5336833000183105, Accuracy: 0.83154296875\n",
      "Batch: 21, Loss: 0.6283212900161743, Accuracy: 0.79638671875\n",
      "Batch: 22, Loss: 0.559752881526947, Accuracy: 0.8173828125\n",
      "Batch: 23, Loss: 0.5569096803665161, Accuracy: 0.814453125\n",
      "Batch: 24, Loss: 0.6032928228378296, Accuracy: 0.798828125\n",
      "Batch: 25, Loss: 0.6037296652793884, Accuracy: 0.8095703125\n",
      "Batch: 26, Loss: 0.5822360515594482, Accuracy: 0.81103515625\n",
      "Batch: 27, Loss: 0.6337372660636902, Accuracy: 0.8037109375\n",
      "Batch: 28, Loss: 0.5962477922439575, Accuracy: 0.80712890625\n",
      "Batch: 29, Loss: 0.6628831624984741, Accuracy: 0.787109375\n",
      "Batch: 30, Loss: 0.6297152638435364, Accuracy: 0.8017578125\n",
      "Batch: 31, Loss: 0.6758939027786255, Accuracy: 0.783203125\n",
      "Batch: 32, Loss: 0.6465574502944946, Accuracy: 0.78857421875\n",
      "Batch: 33, Loss: 0.6327019929885864, Accuracy: 0.78955078125\n",
      "Batch: 34, Loss: 0.6586564779281616, Accuracy: 0.79248046875\n",
      "Batch: 35, Loss: 0.6728715896606445, Accuracy: 0.78515625\n",
      "Batch: 36, Loss: 0.6128768920898438, Accuracy: 0.80615234375\n",
      "Batch: 37, Loss: 0.6473701000213623, Accuracy: 0.79296875\n",
      "Batch: 38, Loss: 0.6585445404052734, Accuracy: 0.78369140625\n",
      "Batch: 39, Loss: 0.6076304912567139, Accuracy: 0.8037109375\n",
      "Batch: 40, Loss: 0.650431752204895, Accuracy: 0.79052734375\n",
      "Batch: 41, Loss: 0.6277782917022705, Accuracy: 0.796875\n",
      "Batch: 42, Loss: 0.6377688646316528, Accuracy: 0.78955078125\n",
      "Batch: 43, Loss: 0.5835333466529846, Accuracy: 0.81103515625\n",
      "Batch: 44, Loss: 0.5564295649528503, Accuracy: 0.8232421875\n",
      "Batch: 45, Loss: 0.5990140438079834, Accuracy: 0.8056640625\n",
      "Batch: 46, Loss: 0.5792468190193176, Accuracy: 0.80615234375\n",
      "Batch: 47, Loss: 0.5987759828567505, Accuracy: 0.80810546875\n",
      "Batch: 48, Loss: 0.6136341094970703, Accuracy: 0.79736328125\n",
      "Batch: 49, Loss: 0.5787415504455566, Accuracy: 0.8095703125\n",
      "Batch: 50, Loss: 0.6170121431350708, Accuracy: 0.80078125\n",
      "Batch: 51, Loss: 0.5796585083007812, Accuracy: 0.80078125\n",
      "Batch: 52, Loss: 0.5951144695281982, Accuracy: 0.80029296875\n",
      "Batch: 53, Loss: 0.6070522665977478, Accuracy: 0.8037109375\n",
      "Batch: 54, Loss: 0.6542940139770508, Accuracy: 0.7880859375\n",
      "Batch: 55, Loss: 0.5963627099990845, Accuracy: 0.8017578125\n",
      "Batch: 56, Loss: 0.599528431892395, Accuracy: 0.798828125\n",
      "Batch: 57, Loss: 0.6701607704162598, Accuracy: 0.791015625\n",
      "Batch: 58, Loss: 0.6083594560623169, Accuracy: 0.80078125\n",
      "Batch: 59, Loss: 0.7007244825363159, Accuracy: 0.77685546875\n",
      "Batch: 60, Loss: 0.6004399061203003, Accuracy: 0.80810546875\n",
      "Batch: 61, Loss: 0.5623706579208374, Accuracy: 0.8154296875\n",
      "Batch: 62, Loss: 0.5789546966552734, Accuracy: 0.81640625\n",
      "Batch: 63, Loss: 0.6025640964508057, Accuracy: 0.80419921875\n",
      "Batch: 64, Loss: 0.6229965686798096, Accuracy: 0.79443359375\n",
      "Batch: 65, Loss: 0.6557168960571289, Accuracy: 0.79248046875\n",
      "Batch: 66, Loss: 0.6199749112129211, Accuracy: 0.8037109375\n",
      "Batch: 67, Loss: 0.6635841727256775, Accuracy: 0.787109375\n",
      "Batch: 68, Loss: 0.56117182970047, Accuracy: 0.81494140625\n",
      "Batch: 69, Loss: 0.6085226535797119, Accuracy: 0.806640625\n",
      "Batch: 70, Loss: 0.5949398875236511, Accuracy: 0.81005859375\n",
      "Batch: 71, Loss: 0.6134027242660522, Accuracy: 0.810546875\n",
      "Batch: 72, Loss: 0.6491620540618896, Accuracy: 0.779296875\n",
      "Batch: 73, Loss: 0.6135969161987305, Accuracy: 0.80029296875\n",
      "Batch: 74, Loss: 0.6099212765693665, Accuracy: 0.80078125\n",
      "Batch: 75, Loss: 0.5715891122817993, Accuracy: 0.81005859375\n",
      "Batch: 76, Loss: 0.559328019618988, Accuracy: 0.828125\n",
      "Batch: 77, Loss: 0.5600125789642334, Accuracy: 0.8212890625\n",
      "Batch: 78, Loss: 0.5893652439117432, Accuracy: 0.8017578125\n",
      "Batch: 79, Loss: 0.5841110944747925, Accuracy: 0.80908203125\n",
      "Batch: 80, Loss: 0.6226961016654968, Accuracy: 0.796875\n",
      "Batch: 81, Loss: 0.624189019203186, Accuracy: 0.81591796875\n",
      "Batch: 82, Loss: 0.6032171845436096, Accuracy: 0.79443359375\n",
      "Batch: 83, Loss: 0.5499364137649536, Accuracy: 0.81005859375\n",
      "Batch: 84, Loss: 0.5703209638595581, Accuracy: 0.8251953125\n",
      "Batch: 85, Loss: 0.6042819023132324, Accuracy: 0.802734375\n",
      "Batch: 86, Loss: 0.6638205647468567, Accuracy: 0.79541015625\n",
      "Batch: 87, Loss: 0.5804617404937744, Accuracy: 0.81103515625\n",
      "Batch: 88, Loss: 0.6497409343719482, Accuracy: 0.80078125\n",
      "Batch: 89, Loss: 0.5933873653411865, Accuracy: 0.80224609375\n",
      "Batch: 90, Loss: 0.6274442672729492, Accuracy: 0.7919921875\n",
      "Batch: 91, Loss: 0.5934746265411377, Accuracy: 0.80712890625\n",
      "Batch: 92, Loss: 0.6820998191833496, Accuracy: 0.76513671875\n",
      "Batch: 93, Loss: 0.6531820297241211, Accuracy: 0.78271484375\n",
      "Batch: 94, Loss: 0.6342908143997192, Accuracy: 0.7939453125\n",
      "Batch: 95, Loss: 0.6692873239517212, Accuracy: 0.7822265625\n",
      "Batch: 96, Loss: 0.6173022389411926, Accuracy: 0.798828125\n",
      "Batch: 97, Loss: 0.6170552968978882, Accuracy: 0.80615234375\n",
      "Batch: 98, Loss: 0.6215882301330566, Accuracy: 0.8046875\n",
      "Batch: 99, Loss: 0.5815200805664062, Accuracy: 0.81640625\n",
      "Batch: 100, Loss: 0.6509596705436707, Accuracy: 0.7939453125\n",
      "Batch: 101, Loss: 0.6716361045837402, Accuracy: 0.78369140625\n",
      "Batch: 102, Loss: 0.5836858749389648, Accuracy: 0.81298828125\n",
      "Batch: 103, Loss: 0.608628511428833, Accuracy: 0.8046875\n",
      "Batch: 104, Loss: 0.5979459285736084, Accuracy: 0.80029296875\n",
      "Batch: 105, Loss: 0.6076502799987793, Accuracy: 0.794921875\n",
      "Batch: 106, Loss: 0.5965099334716797, Accuracy: 0.80615234375\n",
      "Batch: 107, Loss: 0.6076517701148987, Accuracy: 0.8037109375\n",
      "Batch: 108, Loss: 0.5885885953903198, Accuracy: 0.82421875\n",
      "Batch: 109, Loss: 0.5764675736427307, Accuracy: 0.81689453125\n",
      "Batch: 110, Loss: 0.5855246782302856, Accuracy: 0.80859375\n",
      "Batch: 111, Loss: 0.5587725639343262, Accuracy: 0.81396484375\n",
      "Batch: 112, Loss: 0.5957667827606201, Accuracy: 0.7998046875\n",
      "Batch: 113, Loss: 0.631902813911438, Accuracy: 0.79443359375\n",
      "Batch: 114, Loss: 0.611935019493103, Accuracy: 0.80517578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 115, Loss: 0.6128924489021301, Accuracy: 0.7978515625\n",
      "Batch: 116, Loss: 0.5994398593902588, Accuracy: 0.80615234375\n",
      "Batch: 117, Loss: 0.5874166488647461, Accuracy: 0.8095703125\n",
      "Batch: 118, Loss: 0.6004550457000732, Accuracy: 0.80712890625\n",
      "Batch: 119, Loss: 0.6160765886306763, Accuracy: 0.80908203125\n",
      "Batch: 120, Loss: 0.556136965751648, Accuracy: 0.8251953125\n",
      "Batch: 121, Loss: 0.5816594958305359, Accuracy: 0.8134765625\n",
      "Batch: 122, Loss: 0.5610062479972839, Accuracy: 0.80908203125\n",
      "Batch: 123, Loss: 0.5578009486198425, Accuracy: 0.82373046875\n",
      "Batch: 124, Loss: 0.5515968799591064, Accuracy: 0.81689453125\n",
      "Batch: 125, Loss: 0.5954834818840027, Accuracy: 0.81494140625\n",
      "Batch: 126, Loss: 0.5773077011108398, Accuracy: 0.8046875\n",
      "Batch: 127, Loss: 0.5288875102996826, Accuracy: 0.8203125\n",
      "Batch: 128, Loss: 0.6859886646270752, Accuracy: 0.77685546875\n",
      "Batch: 129, Loss: 0.6786543130874634, Accuracy: 0.783203125\n",
      "Batch: 130, Loss: 0.6878268718719482, Accuracy: 0.7802734375\n",
      "Batch: 131, Loss: 0.6095739603042603, Accuracy: 0.80078125\n",
      "Batch: 132, Loss: 0.5768440961837769, Accuracy: 0.82177734375\n",
      "Batch: 133, Loss: 0.5767256021499634, Accuracy: 0.8134765625\n",
      "Batch: 134, Loss: 0.6148865222930908, Accuracy: 0.80224609375\n",
      "Batch: 135, Loss: 0.6076676845550537, Accuracy: 0.80517578125\n",
      "Batch: 136, Loss: 0.5591729879379272, Accuracy: 0.8134765625\n",
      "Batch: 137, Loss: 0.5953630208969116, Accuracy: 0.8076171875\n",
      "Batch: 138, Loss: 0.540269136428833, Accuracy: 0.83251953125\n",
      "Batch: 139, Loss: 0.5687977075576782, Accuracy: 0.81005859375\n",
      "Batch: 140, Loss: 0.5482228398323059, Accuracy: 0.81640625\n",
      "Batch: 141, Loss: 0.6349838972091675, Accuracy: 0.80126953125\n",
      "Batch: 142, Loss: 0.5550897121429443, Accuracy: 0.81689453125\n",
      "Batch: 143, Loss: 0.5866650938987732, Accuracy: 0.82080078125\n",
      "Batch: 144, Loss: 0.652515172958374, Accuracy: 0.78271484375\n",
      "Batch: 145, Loss: 0.6045113801956177, Accuracy: 0.81005859375\n",
      "Batch: 146, Loss: 0.6100766658782959, Accuracy: 0.798828125\n",
      "Batch: 147, Loss: 0.570064902305603, Accuracy: 0.81689453125\n",
      "Batch: 148, Loss: 0.6443166732788086, Accuracy: 0.7919921875\n",
      "Batch: 149, Loss: 0.6164981722831726, Accuracy: 0.7978515625\n",
      "Batch: 150, Loss: 0.5403334498405457, Accuracy: 0.82421875\n",
      "Batch: 151, Loss: 0.525748610496521, Accuracy: 0.83544921875\n",
      "Batch: 152, Loss: 0.563073992729187, Accuracy: 0.8095703125\n",
      "Batch: 153, Loss: 0.5923925638198853, Accuracy: 0.814453125\n",
      "Batch: 154, Loss: 0.5812246799468994, Accuracy: 0.80615234375\n",
      "Batch: 155, Loss: 0.657636284828186, Accuracy: 0.79443359375\n",
      "Batch: 156, Loss: 0.5604729652404785, Accuracy: 0.810546875\n",
      "Batch: 157, Loss: 0.5370938181877136, Accuracy: 0.82177734375\n",
      "Batch: 158, Loss: 0.5474802255630493, Accuracy: 0.82958984375\n",
      "Batch: 159, Loss: 0.579840362071991, Accuracy: 0.8154296875\n",
      "Batch: 160, Loss: 0.5952021479606628, Accuracy: 0.8095703125\n",
      "Batch: 161, Loss: 0.6081262826919556, Accuracy: 0.8076171875\n",
      "Batch: 162, Loss: 0.5546343326568604, Accuracy: 0.82275390625\n",
      "Batch: 163, Loss: 0.6202112436294556, Accuracy: 0.7978515625\n",
      "Batch: 164, Loss: 0.6839014291763306, Accuracy: 0.78271484375\n",
      "Batch: 165, Loss: 0.6132615804672241, Accuracy: 0.8115234375\n",
      "Batch: 166, Loss: 0.6296957731246948, Accuracy: 0.798828125\n",
      "Batch: 167, Loss: 0.5928309559822083, Accuracy: 0.80517578125\n",
      "Batch: 168, Loss: 0.5345932245254517, Accuracy: 0.8291015625\n",
      "Batch: 169, Loss: 0.5798153877258301, Accuracy: 0.814453125\n",
      "Batch: 170, Loss: 0.6072404384613037, Accuracy: 0.81298828125\n",
      "Batch: 171, Loss: 0.5727419853210449, Accuracy: 0.810546875\n",
      "Batch: 172, Loss: 0.5689975023269653, Accuracy: 0.81494140625\n",
      "Batch: 173, Loss: 0.6205742955207825, Accuracy: 0.79638671875\n",
      "Batch: 174, Loss: 0.5294085741043091, Accuracy: 0.82568359375\n",
      "Batch: 175, Loss: 0.6183988451957703, Accuracy: 0.78955078125\n",
      "Batch: 176, Loss: 0.649174153804779, Accuracy: 0.7880859375\n",
      "Batch: 177, Loss: 0.5749127268791199, Accuracy: 0.81103515625\n",
      "Batch: 178, Loss: 0.5505993962287903, Accuracy: 0.814453125\n",
      "Batch: 179, Loss: 0.5855530500411987, Accuracy: 0.8203125\n",
      "Batch: 180, Loss: 0.6095024347305298, Accuracy: 0.810546875\n",
      "Epoch 68/200\n",
      "Batch: 1, Loss: 0.8426400423049927, Accuracy: 0.75390625\n",
      "Batch: 2, Loss: 0.6224350929260254, Accuracy: 0.7919921875\n",
      "Batch: 3, Loss: 0.6075518727302551, Accuracy: 0.80322265625\n",
      "Batch: 4, Loss: 0.6229827404022217, Accuracy: 0.80078125\n",
      "Batch: 5, Loss: 0.608174204826355, Accuracy: 0.79931640625\n",
      "Batch: 6, Loss: 0.6354259848594666, Accuracy: 0.796875\n",
      "Batch: 7, Loss: 0.5856033563613892, Accuracy: 0.8154296875\n",
      "Batch: 8, Loss: 0.5950727462768555, Accuracy: 0.8046875\n",
      "Batch: 9, Loss: 0.6380758285522461, Accuracy: 0.80126953125\n",
      "Batch: 10, Loss: 0.5818499326705933, Accuracy: 0.81103515625\n",
      "Batch: 11, Loss: 0.6275405287742615, Accuracy: 0.79443359375\n",
      "Batch: 12, Loss: 0.5547198057174683, Accuracy: 0.8251953125\n",
      "Batch: 13, Loss: 0.6060634851455688, Accuracy: 0.79736328125\n",
      "Batch: 14, Loss: 0.580844521522522, Accuracy: 0.8232421875\n",
      "Batch: 15, Loss: 0.6103090047836304, Accuracy: 0.81298828125\n",
      "Batch: 16, Loss: 0.64454585313797, Accuracy: 0.79248046875\n",
      "Batch: 17, Loss: 0.5955220460891724, Accuracy: 0.81005859375\n",
      "Batch: 18, Loss: 0.6165342330932617, Accuracy: 0.80517578125\n",
      "Batch: 19, Loss: 0.631447970867157, Accuracy: 0.8017578125\n",
      "Batch: 20, Loss: 0.5057474374771118, Accuracy: 0.83154296875\n",
      "Batch: 21, Loss: 0.616981029510498, Accuracy: 0.802734375\n",
      "Batch: 22, Loss: 0.57491135597229, Accuracy: 0.8056640625\n",
      "Batch: 23, Loss: 0.5518133640289307, Accuracy: 0.81591796875\n",
      "Batch: 24, Loss: 0.5665336847305298, Accuracy: 0.82177734375\n",
      "Batch: 25, Loss: 0.5714849233627319, Accuracy: 0.8193359375\n",
      "Batch: 26, Loss: 0.583572268486023, Accuracy: 0.81494140625\n",
      "Batch: 27, Loss: 0.6082650423049927, Accuracy: 0.79541015625\n",
      "Batch: 28, Loss: 0.5819556713104248, Accuracy: 0.81787109375\n",
      "Batch: 29, Loss: 0.6552122235298157, Accuracy: 0.79833984375\n",
      "Batch: 30, Loss: 0.619744598865509, Accuracy: 0.810546875\n",
      "Batch: 31, Loss: 0.6755965352058411, Accuracy: 0.791015625\n",
      "Batch: 32, Loss: 0.6561724543571472, Accuracy: 0.78955078125\n",
      "Batch: 33, Loss: 0.6302660703659058, Accuracy: 0.794921875\n",
      "Batch: 34, Loss: 0.6430041790008545, Accuracy: 0.79150390625\n",
      "Batch: 35, Loss: 0.6606045961380005, Accuracy: 0.78759765625\n",
      "Batch: 36, Loss: 0.6138395071029663, Accuracy: 0.806640625\n",
      "Batch: 37, Loss: 0.6358130574226379, Accuracy: 0.80126953125\n",
      "Batch: 38, Loss: 0.6600157618522644, Accuracy: 0.78564453125\n",
      "Batch: 39, Loss: 0.6024279594421387, Accuracy: 0.80224609375\n",
      "Batch: 40, Loss: 0.6647530198097229, Accuracy: 0.78662109375\n",
      "Batch: 41, Loss: 0.6388019323348999, Accuracy: 0.796875\n",
      "Batch: 42, Loss: 0.6290526390075684, Accuracy: 0.79150390625\n",
      "Batch: 43, Loss: 0.5823541879653931, Accuracy: 0.80859375\n",
      "Batch: 44, Loss: 0.5447430610656738, Accuracy: 0.82470703125\n",
      "Batch: 45, Loss: 0.6042234897613525, Accuracy: 0.80517578125\n",
      "Batch: 46, Loss: 0.5880122184753418, Accuracy: 0.80078125\n",
      "Batch: 47, Loss: 0.6054320335388184, Accuracy: 0.81298828125\n",
      "Batch: 48, Loss: 0.5896474719047546, Accuracy: 0.8037109375\n",
      "Batch: 49, Loss: 0.595248818397522, Accuracy: 0.80078125\n",
      "Batch: 50, Loss: 0.592710018157959, Accuracy: 0.80419921875\n",
      "Batch: 51, Loss: 0.5846441984176636, Accuracy: 0.80224609375\n",
      "Batch: 52, Loss: 0.5759296417236328, Accuracy: 0.80029296875\n",
      "Batch: 53, Loss: 0.6185616254806519, Accuracy: 0.80224609375\n",
      "Batch: 54, Loss: 0.6462924480438232, Accuracy: 0.79248046875\n",
      "Batch: 55, Loss: 0.6189911365509033, Accuracy: 0.7978515625\n",
      "Batch: 56, Loss: 0.5902858972549438, Accuracy: 0.80029296875\n",
      "Batch: 57, Loss: 0.6736849546432495, Accuracy: 0.79248046875\n",
      "Batch: 58, Loss: 0.6104986667633057, Accuracy: 0.80517578125\n",
      "Batch: 59, Loss: 0.7050763368606567, Accuracy: 0.775390625\n",
      "Batch: 60, Loss: 0.6012610197067261, Accuracy: 0.80517578125\n",
      "Batch: 61, Loss: 0.5783264636993408, Accuracy: 0.8076171875\n",
      "Batch: 62, Loss: 0.5893228054046631, Accuracy: 0.81396484375\n",
      "Batch: 63, Loss: 0.596024215221405, Accuracy: 0.8017578125\n",
      "Batch: 64, Loss: 0.6224428415298462, Accuracy: 0.7978515625\n",
      "Batch: 65, Loss: 0.6597334146499634, Accuracy: 0.783203125\n",
      "Batch: 66, Loss: 0.6050924062728882, Accuracy: 0.802734375\n",
      "Batch: 67, Loss: 0.6309964656829834, Accuracy: 0.7919921875\n",
      "Batch: 68, Loss: 0.5503485202789307, Accuracy: 0.82275390625\n",
      "Batch: 69, Loss: 0.6061067581176758, Accuracy: 0.8017578125\n",
      "Batch: 70, Loss: 0.5967588424682617, Accuracy: 0.8017578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 71, Loss: 0.5848239660263062, Accuracy: 0.8115234375\n",
      "Batch: 72, Loss: 0.6429728269577026, Accuracy: 0.77978515625\n",
      "Batch: 73, Loss: 0.5842867493629456, Accuracy: 0.81005859375\n",
      "Batch: 74, Loss: 0.6102251410484314, Accuracy: 0.81103515625\n",
      "Batch: 75, Loss: 0.5646604299545288, Accuracy: 0.81884765625\n",
      "Batch: 76, Loss: 0.5484610199928284, Accuracy: 0.8359375\n",
      "Batch: 77, Loss: 0.5611631274223328, Accuracy: 0.830078125\n",
      "Batch: 78, Loss: 0.6069796681404114, Accuracy: 0.80419921875\n",
      "Batch: 79, Loss: 0.5946291089057922, Accuracy: 0.8134765625\n",
      "Batch: 80, Loss: 0.618897557258606, Accuracy: 0.7998046875\n",
      "Batch: 81, Loss: 0.6237906813621521, Accuracy: 0.80078125\n",
      "Batch: 82, Loss: 0.5991610884666443, Accuracy: 0.7978515625\n",
      "Batch: 83, Loss: 0.5671756267547607, Accuracy: 0.814453125\n",
      "Batch: 84, Loss: 0.5920350551605225, Accuracy: 0.8056640625\n",
      "Batch: 85, Loss: 0.6024156808853149, Accuracy: 0.80078125\n",
      "Batch: 86, Loss: 0.6336781978607178, Accuracy: 0.80859375\n",
      "Batch: 87, Loss: 0.5679537057876587, Accuracy: 0.8154296875\n",
      "Batch: 88, Loss: 0.6343766450881958, Accuracy: 0.791015625\n",
      "Batch: 89, Loss: 0.605892539024353, Accuracy: 0.80859375\n",
      "Batch: 90, Loss: 0.6305917501449585, Accuracy: 0.791015625\n",
      "Batch: 91, Loss: 0.598251223564148, Accuracy: 0.8046875\n",
      "Batch: 92, Loss: 0.6751270294189453, Accuracy: 0.7724609375\n",
      "Batch: 93, Loss: 0.6357067823410034, Accuracy: 0.78662109375\n",
      "Batch: 94, Loss: 0.6080217361450195, Accuracy: 0.80908203125\n",
      "Batch: 95, Loss: 0.6756357550621033, Accuracy: 0.78125\n",
      "Batch: 96, Loss: 0.5957239270210266, Accuracy: 0.8095703125\n",
      "Batch: 97, Loss: 0.6025220155715942, Accuracy: 0.8154296875\n",
      "Batch: 98, Loss: 0.6113231182098389, Accuracy: 0.7939453125\n",
      "Batch: 99, Loss: 0.5902301669120789, Accuracy: 0.8037109375\n",
      "Batch: 100, Loss: 0.666519045829773, Accuracy: 0.78759765625\n",
      "Batch: 101, Loss: 0.6609512567520142, Accuracy: 0.79150390625\n",
      "Batch: 102, Loss: 0.5765384435653687, Accuracy: 0.8076171875\n",
      "Batch: 103, Loss: 0.6003168821334839, Accuracy: 0.80419921875\n",
      "Batch: 104, Loss: 0.5921535491943359, Accuracy: 0.80517578125\n",
      "Batch: 105, Loss: 0.6189745664596558, Accuracy: 0.80517578125\n",
      "Batch: 106, Loss: 0.5740031003952026, Accuracy: 0.8095703125\n",
      "Batch: 107, Loss: 0.6145431995391846, Accuracy: 0.8056640625\n",
      "Batch: 108, Loss: 0.5883424282073975, Accuracy: 0.80859375\n",
      "Batch: 109, Loss: 0.6029980182647705, Accuracy: 0.79638671875\n",
      "Batch: 110, Loss: 0.5716190934181213, Accuracy: 0.8134765625\n",
      "Batch: 111, Loss: 0.5396764874458313, Accuracy: 0.81982421875\n",
      "Batch: 112, Loss: 0.5738587975502014, Accuracy: 0.8154296875\n",
      "Batch: 113, Loss: 0.6195676326751709, Accuracy: 0.78564453125\n",
      "Batch: 114, Loss: 0.6181607842445374, Accuracy: 0.79443359375\n",
      "Batch: 115, Loss: 0.5971258282661438, Accuracy: 0.8046875\n",
      "Batch: 116, Loss: 0.6051813364028931, Accuracy: 0.802734375\n",
      "Batch: 117, Loss: 0.5796750783920288, Accuracy: 0.81201171875\n",
      "Batch: 118, Loss: 0.6152118444442749, Accuracy: 0.810546875\n",
      "Batch: 119, Loss: 0.5893524289131165, Accuracy: 0.80859375\n",
      "Batch: 120, Loss: 0.5815585851669312, Accuracy: 0.814453125\n",
      "Batch: 121, Loss: 0.5718356370925903, Accuracy: 0.8193359375\n",
      "Batch: 122, Loss: 0.5515098571777344, Accuracy: 0.82275390625\n",
      "Batch: 123, Loss: 0.5770922899246216, Accuracy: 0.8154296875\n",
      "Batch: 124, Loss: 0.5395811200141907, Accuracy: 0.830078125\n",
      "Batch: 125, Loss: 0.5929093956947327, Accuracy: 0.81103515625\n",
      "Batch: 126, Loss: 0.5701956748962402, Accuracy: 0.80615234375\n",
      "Batch: 127, Loss: 0.5530929565429688, Accuracy: 0.82958984375\n",
      "Batch: 128, Loss: 0.6589925289154053, Accuracy: 0.78759765625\n",
      "Batch: 129, Loss: 0.670123815536499, Accuracy: 0.779296875\n",
      "Batch: 130, Loss: 0.6831045150756836, Accuracy: 0.77197265625\n",
      "Batch: 131, Loss: 0.610826313495636, Accuracy: 0.80126953125\n",
      "Batch: 132, Loss: 0.5832851529121399, Accuracy: 0.810546875\n",
      "Batch: 133, Loss: 0.565398097038269, Accuracy: 0.81494140625\n",
      "Batch: 134, Loss: 0.6209797859191895, Accuracy: 0.794921875\n",
      "Batch: 135, Loss: 0.6191918849945068, Accuracy: 0.79248046875\n",
      "Batch: 136, Loss: 0.5572742223739624, Accuracy: 0.81689453125\n",
      "Batch: 137, Loss: 0.6056720018386841, Accuracy: 0.81298828125\n",
      "Batch: 138, Loss: 0.5368345975875854, Accuracy: 0.830078125\n",
      "Batch: 139, Loss: 0.563572883605957, Accuracy: 0.8212890625\n",
      "Batch: 140, Loss: 0.5414507389068604, Accuracy: 0.82275390625\n",
      "Batch: 141, Loss: 0.6107856631278992, Accuracy: 0.80126953125\n",
      "Batch: 142, Loss: 0.5578773617744446, Accuracy: 0.81201171875\n",
      "Batch: 143, Loss: 0.5962952971458435, Accuracy: 0.806640625\n",
      "Batch: 144, Loss: 0.6318719387054443, Accuracy: 0.7880859375\n",
      "Batch: 145, Loss: 0.598024845123291, Accuracy: 0.814453125\n",
      "Batch: 146, Loss: 0.634400486946106, Accuracy: 0.7998046875\n",
      "Batch: 147, Loss: 0.5949218273162842, Accuracy: 0.80810546875\n",
      "Batch: 148, Loss: 0.6503292322158813, Accuracy: 0.78662109375\n",
      "Batch: 149, Loss: 0.6144040822982788, Accuracy: 0.80029296875\n",
      "Batch: 150, Loss: 0.524076521396637, Accuracy: 0.837890625\n",
      "Batch: 151, Loss: 0.5397547483444214, Accuracy: 0.82470703125\n",
      "Batch: 152, Loss: 0.5671378374099731, Accuracy: 0.81396484375\n",
      "Batch: 153, Loss: 0.5876340270042419, Accuracy: 0.81494140625\n",
      "Batch: 154, Loss: 0.5608583092689514, Accuracy: 0.81787109375\n",
      "Batch: 155, Loss: 0.651121973991394, Accuracy: 0.78515625\n",
      "Batch: 156, Loss: 0.5549720525741577, Accuracy: 0.8134765625\n",
      "Batch: 157, Loss: 0.5314468145370483, Accuracy: 0.83203125\n",
      "Batch: 158, Loss: 0.5444607734680176, Accuracy: 0.8291015625\n",
      "Batch: 159, Loss: 0.5636477470397949, Accuracy: 0.822265625\n",
      "Batch: 160, Loss: 0.5882514715194702, Accuracy: 0.80859375\n",
      "Batch: 161, Loss: 0.6050031185150146, Accuracy: 0.81201171875\n",
      "Batch: 162, Loss: 0.5587706565856934, Accuracy: 0.81396484375\n",
      "Batch: 163, Loss: 0.6018683314323425, Accuracy: 0.8037109375\n",
      "Batch: 164, Loss: 0.677842378616333, Accuracy: 0.78173828125\n",
      "Batch: 165, Loss: 0.5968818664550781, Accuracy: 0.81396484375\n",
      "Batch: 166, Loss: 0.6124813556671143, Accuracy: 0.79833984375\n",
      "Batch: 167, Loss: 0.6011707782745361, Accuracy: 0.80810546875\n",
      "Batch: 168, Loss: 0.5401061773300171, Accuracy: 0.82666015625\n",
      "Batch: 169, Loss: 0.5896151065826416, Accuracy: 0.8125\n",
      "Batch: 170, Loss: 0.6059376001358032, Accuracy: 0.8115234375\n",
      "Batch: 171, Loss: 0.5756352543830872, Accuracy: 0.80712890625\n",
      "Batch: 172, Loss: 0.5568654537200928, Accuracy: 0.8134765625\n",
      "Batch: 173, Loss: 0.6422082185745239, Accuracy: 0.78955078125\n",
      "Batch: 174, Loss: 0.527046799659729, Accuracy: 0.822265625\n",
      "Batch: 175, Loss: 0.6110501289367676, Accuracy: 0.79736328125\n",
      "Batch: 176, Loss: 0.6237082481384277, Accuracy: 0.79833984375\n",
      "Batch: 177, Loss: 0.5864461660385132, Accuracy: 0.81103515625\n",
      "Batch: 178, Loss: 0.538486659526825, Accuracy: 0.8310546875\n",
      "Batch: 179, Loss: 0.5881249904632568, Accuracy: 0.810546875\n",
      "Batch: 180, Loss: 0.6229541301727295, Accuracy: 0.79345703125\n",
      "Epoch 69/200\n",
      "Batch: 1, Loss: 0.8619272708892822, Accuracy: 0.7548828125\n",
      "Batch: 2, Loss: 0.5957314372062683, Accuracy: 0.79736328125\n",
      "Batch: 3, Loss: 0.5835052132606506, Accuracy: 0.81591796875\n",
      "Batch: 4, Loss: 0.600296139717102, Accuracy: 0.80859375\n",
      "Batch: 5, Loss: 0.6043028235435486, Accuracy: 0.80712890625\n",
      "Batch: 6, Loss: 0.5971187949180603, Accuracy: 0.80322265625\n",
      "Batch: 7, Loss: 0.581695556640625, Accuracy: 0.80615234375\n",
      "Batch: 8, Loss: 0.5834662914276123, Accuracy: 0.81103515625\n",
      "Batch: 9, Loss: 0.6223493814468384, Accuracy: 0.80810546875\n",
      "Batch: 10, Loss: 0.5874025821685791, Accuracy: 0.80908203125\n",
      "Batch: 11, Loss: 0.6335671544075012, Accuracy: 0.80029296875\n",
      "Batch: 12, Loss: 0.541900098323822, Accuracy: 0.828125\n",
      "Batch: 13, Loss: 0.6053832769393921, Accuracy: 0.80322265625\n",
      "Batch: 14, Loss: 0.5984309911727905, Accuracy: 0.81005859375\n",
      "Batch: 15, Loss: 0.6232823133468628, Accuracy: 0.80517578125\n",
      "Batch: 16, Loss: 0.6422716379165649, Accuracy: 0.7890625\n",
      "Batch: 17, Loss: 0.5793944597244263, Accuracy: 0.8212890625\n",
      "Batch: 18, Loss: 0.6185742616653442, Accuracy: 0.8017578125\n",
      "Batch: 19, Loss: 0.6198974251747131, Accuracy: 0.80908203125\n",
      "Batch: 20, Loss: 0.5129404067993164, Accuracy: 0.83203125\n",
      "Batch: 21, Loss: 0.6128710508346558, Accuracy: 0.8017578125\n",
      "Batch: 22, Loss: 0.5574847459793091, Accuracy: 0.81591796875\n",
      "Batch: 23, Loss: 0.5627820491790771, Accuracy: 0.806640625\n",
      "Batch: 24, Loss: 0.582503080368042, Accuracy: 0.8056640625\n",
      "Batch: 25, Loss: 0.5761111974716187, Accuracy: 0.81591796875\n",
      "Batch: 26, Loss: 0.5958927869796753, Accuracy: 0.80419921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 27, Loss: 0.6467348337173462, Accuracy: 0.7919921875\n",
      "Batch: 28, Loss: 0.5922637581825256, Accuracy: 0.81298828125\n",
      "Batch: 29, Loss: 0.631801962852478, Accuracy: 0.80908203125\n",
      "Batch: 30, Loss: 0.6095342636108398, Accuracy: 0.80517578125\n",
      "Batch: 31, Loss: 0.6935723423957825, Accuracy: 0.78662109375\n",
      "Batch: 32, Loss: 0.6460230350494385, Accuracy: 0.798828125\n",
      "Batch: 33, Loss: 0.6287791728973389, Accuracy: 0.7919921875\n",
      "Batch: 34, Loss: 0.6353878974914551, Accuracy: 0.79443359375\n",
      "Batch: 35, Loss: 0.6510916948318481, Accuracy: 0.79052734375\n",
      "Batch: 36, Loss: 0.6247391700744629, Accuracy: 0.80126953125\n",
      "Batch: 37, Loss: 0.64206862449646, Accuracy: 0.796875\n",
      "Batch: 38, Loss: 0.6492419242858887, Accuracy: 0.791015625\n",
      "Batch: 39, Loss: 0.6098122596740723, Accuracy: 0.8056640625\n",
      "Batch: 40, Loss: 0.6651178598403931, Accuracy: 0.79638671875\n",
      "Batch: 41, Loss: 0.6493504643440247, Accuracy: 0.7939453125\n",
      "Batch: 42, Loss: 0.6256661415100098, Accuracy: 0.79150390625\n",
      "Batch: 43, Loss: 0.5660738348960876, Accuracy: 0.80908203125\n",
      "Batch: 44, Loss: 0.5391242504119873, Accuracy: 0.830078125\n",
      "Batch: 45, Loss: 0.595405101776123, Accuracy: 0.7978515625\n",
      "Batch: 46, Loss: 0.5772870779037476, Accuracy: 0.7998046875\n",
      "Batch: 47, Loss: 0.6078869104385376, Accuracy: 0.80712890625\n",
      "Batch: 48, Loss: 0.5873786211013794, Accuracy: 0.8115234375\n",
      "Batch: 49, Loss: 0.5829035043716431, Accuracy: 0.80859375\n",
      "Batch: 50, Loss: 0.605460524559021, Accuracy: 0.7958984375\n",
      "Batch: 51, Loss: 0.5923578143119812, Accuracy: 0.802734375\n",
      "Batch: 52, Loss: 0.5764830708503723, Accuracy: 0.810546875\n",
      "Batch: 53, Loss: 0.5853220224380493, Accuracy: 0.81396484375\n",
      "Batch: 54, Loss: 0.6307505369186401, Accuracy: 0.79052734375\n",
      "Batch: 55, Loss: 0.6059389114379883, Accuracy: 0.806640625\n",
      "Batch: 56, Loss: 0.6003892421722412, Accuracy: 0.798828125\n",
      "Batch: 57, Loss: 0.651888370513916, Accuracy: 0.79931640625\n",
      "Batch: 58, Loss: 0.6254781484603882, Accuracy: 0.79638671875\n",
      "Batch: 59, Loss: 0.6871140003204346, Accuracy: 0.78125\n",
      "Batch: 60, Loss: 0.5839201211929321, Accuracy: 0.81689453125\n",
      "Batch: 61, Loss: 0.5803917050361633, Accuracy: 0.80859375\n",
      "Batch: 62, Loss: 0.5693814754486084, Accuracy: 0.82275390625\n",
      "Batch: 63, Loss: 0.5937278270721436, Accuracy: 0.8076171875\n",
      "Batch: 64, Loss: 0.6216309070587158, Accuracy: 0.78759765625\n",
      "Batch: 65, Loss: 0.6463518142700195, Accuracy: 0.79736328125\n",
      "Batch: 66, Loss: 0.6224018931388855, Accuracy: 0.80322265625\n",
      "Batch: 67, Loss: 0.6376819610595703, Accuracy: 0.7978515625\n",
      "Batch: 68, Loss: 0.5677657127380371, Accuracy: 0.81787109375\n",
      "Batch: 69, Loss: 0.5964494347572327, Accuracy: 0.8017578125\n",
      "Batch: 70, Loss: 0.5689252614974976, Accuracy: 0.81884765625\n",
      "Batch: 71, Loss: 0.5980625748634338, Accuracy: 0.8037109375\n",
      "Batch: 72, Loss: 0.6326508522033691, Accuracy: 0.7880859375\n",
      "Batch: 73, Loss: 0.6006425619125366, Accuracy: 0.79833984375\n",
      "Batch: 74, Loss: 0.6137921810150146, Accuracy: 0.79931640625\n",
      "Batch: 75, Loss: 0.5609215497970581, Accuracy: 0.8193359375\n",
      "Batch: 76, Loss: 0.5542654395103455, Accuracy: 0.82373046875\n",
      "Batch: 77, Loss: 0.5662736892700195, Accuracy: 0.82666015625\n",
      "Batch: 78, Loss: 0.5890552401542664, Accuracy: 0.81201171875\n",
      "Batch: 79, Loss: 0.5850001573562622, Accuracy: 0.80615234375\n",
      "Batch: 80, Loss: 0.5995275974273682, Accuracy: 0.798828125\n",
      "Batch: 81, Loss: 0.5951428413391113, Accuracy: 0.81005859375\n",
      "Batch: 82, Loss: 0.5760023593902588, Accuracy: 0.8076171875\n",
      "Batch: 83, Loss: 0.5524379014968872, Accuracy: 0.82470703125\n",
      "Batch: 84, Loss: 0.566646933555603, Accuracy: 0.82080078125\n",
      "Batch: 85, Loss: 0.6156095266342163, Accuracy: 0.80126953125\n",
      "Batch: 86, Loss: 0.6461642980575562, Accuracy: 0.80419921875\n",
      "Batch: 87, Loss: 0.5651230812072754, Accuracy: 0.818359375\n",
      "Batch: 88, Loss: 0.6233733892440796, Accuracy: 0.79638671875\n",
      "Batch: 89, Loss: 0.5919506549835205, Accuracy: 0.80615234375\n",
      "Batch: 90, Loss: 0.629684567451477, Accuracy: 0.78759765625\n",
      "Batch: 91, Loss: 0.5839810967445374, Accuracy: 0.8134765625\n",
      "Batch: 92, Loss: 0.6599217653274536, Accuracy: 0.77587890625\n",
      "Batch: 93, Loss: 0.6434206366539001, Accuracy: 0.7880859375\n",
      "Batch: 94, Loss: 0.6216084361076355, Accuracy: 0.794921875\n",
      "Batch: 95, Loss: 0.660780668258667, Accuracy: 0.7861328125\n",
      "Batch: 96, Loss: 0.6049615740776062, Accuracy: 0.80078125\n",
      "Batch: 97, Loss: 0.6005427837371826, Accuracy: 0.810546875\n",
      "Batch: 98, Loss: 0.6232483386993408, Accuracy: 0.80224609375\n",
      "Batch: 99, Loss: 0.5686458349227905, Accuracy: 0.822265625\n",
      "Batch: 100, Loss: 0.6519780158996582, Accuracy: 0.7919921875\n",
      "Batch: 101, Loss: 0.6621739268302917, Accuracy: 0.779296875\n",
      "Batch: 102, Loss: 0.5507235527038574, Accuracy: 0.82177734375\n",
      "Batch: 103, Loss: 0.5971164703369141, Accuracy: 0.81494140625\n",
      "Batch: 104, Loss: 0.5869055986404419, Accuracy: 0.8037109375\n",
      "Batch: 105, Loss: 0.6287828087806702, Accuracy: 0.798828125\n",
      "Batch: 106, Loss: 0.5684400796890259, Accuracy: 0.8193359375\n",
      "Batch: 107, Loss: 0.602321982383728, Accuracy: 0.81201171875\n",
      "Batch: 108, Loss: 0.5578826665878296, Accuracy: 0.80908203125\n",
      "Batch: 109, Loss: 0.5844747424125671, Accuracy: 0.81591796875\n",
      "Batch: 110, Loss: 0.5744807720184326, Accuracy: 0.80419921875\n",
      "Batch: 111, Loss: 0.5364253520965576, Accuracy: 0.81689453125\n",
      "Batch: 112, Loss: 0.5875048637390137, Accuracy: 0.810546875\n",
      "Batch: 113, Loss: 0.5991014242172241, Accuracy: 0.80126953125\n",
      "Batch: 114, Loss: 0.6087441444396973, Accuracy: 0.8095703125\n",
      "Batch: 115, Loss: 0.5958775281906128, Accuracy: 0.81103515625\n",
      "Batch: 116, Loss: 0.5886802673339844, Accuracy: 0.80078125\n",
      "Batch: 117, Loss: 0.5722423791885376, Accuracy: 0.80322265625\n",
      "Batch: 118, Loss: 0.5889898538589478, Accuracy: 0.8056640625\n",
      "Batch: 119, Loss: 0.5717188119888306, Accuracy: 0.8125\n",
      "Batch: 120, Loss: 0.5788472890853882, Accuracy: 0.8125\n",
      "Batch: 121, Loss: 0.5805716514587402, Accuracy: 0.80517578125\n",
      "Batch: 122, Loss: 0.5548673868179321, Accuracy: 0.8115234375\n",
      "Batch: 123, Loss: 0.5520234107971191, Accuracy: 0.8310546875\n",
      "Batch: 124, Loss: 0.5494883060455322, Accuracy: 0.822265625\n",
      "Batch: 125, Loss: 0.587279200553894, Accuracy: 0.8193359375\n",
      "Batch: 126, Loss: 0.5647529363632202, Accuracy: 0.814453125\n",
      "Batch: 127, Loss: 0.5432783961296082, Accuracy: 0.82568359375\n",
      "Batch: 128, Loss: 0.6521865129470825, Accuracy: 0.78857421875\n",
      "Batch: 129, Loss: 0.6785716414451599, Accuracy: 0.78466796875\n",
      "Batch: 130, Loss: 0.680405855178833, Accuracy: 0.76806640625\n",
      "Batch: 131, Loss: 0.6126718521118164, Accuracy: 0.79931640625\n",
      "Batch: 132, Loss: 0.5477079749107361, Accuracy: 0.81982421875\n",
      "Batch: 133, Loss: 0.5403009653091431, Accuracy: 0.8310546875\n",
      "Batch: 134, Loss: 0.5940290093421936, Accuracy: 0.8046875\n",
      "Batch: 135, Loss: 0.6104918718338013, Accuracy: 0.79931640625\n",
      "Batch: 136, Loss: 0.5376458168029785, Accuracy: 0.8203125\n",
      "Batch: 137, Loss: 0.600882351398468, Accuracy: 0.80078125\n",
      "Batch: 138, Loss: 0.5394200086593628, Accuracy: 0.82470703125\n",
      "Batch: 139, Loss: 0.5452694296836853, Accuracy: 0.82275390625\n",
      "Batch: 140, Loss: 0.5394362211227417, Accuracy: 0.8212890625\n",
      "Batch: 141, Loss: 0.6129200458526611, Accuracy: 0.80419921875\n",
      "Batch: 142, Loss: 0.5540685057640076, Accuracy: 0.82763671875\n",
      "Batch: 143, Loss: 0.5560575723648071, Accuracy: 0.82275390625\n",
      "Batch: 144, Loss: 0.636071503162384, Accuracy: 0.7939453125\n",
      "Batch: 145, Loss: 0.6084463596343994, Accuracy: 0.8115234375\n",
      "Batch: 146, Loss: 0.6298731565475464, Accuracy: 0.7958984375\n",
      "Batch: 147, Loss: 0.6047807335853577, Accuracy: 0.80517578125\n",
      "Batch: 148, Loss: 0.6329275369644165, Accuracy: 0.7919921875\n",
      "Batch: 149, Loss: 0.6210082769393921, Accuracy: 0.79443359375\n",
      "Batch: 150, Loss: 0.5402988195419312, Accuracy: 0.8310546875\n",
      "Batch: 151, Loss: 0.5549666285514832, Accuracy: 0.82568359375\n",
      "Batch: 152, Loss: 0.5593598484992981, Accuracy: 0.822265625\n",
      "Batch: 153, Loss: 0.5758806467056274, Accuracy: 0.8173828125\n",
      "Batch: 154, Loss: 0.5700081586837769, Accuracy: 0.810546875\n",
      "Batch: 155, Loss: 0.6316770315170288, Accuracy: 0.7939453125\n",
      "Batch: 156, Loss: 0.5432683229446411, Accuracy: 0.82421875\n",
      "Batch: 157, Loss: 0.5266230702400208, Accuracy: 0.82763671875\n",
      "Batch: 158, Loss: 0.5604520440101624, Accuracy: 0.82275390625\n",
      "Batch: 159, Loss: 0.5774626135826111, Accuracy: 0.81640625\n",
      "Batch: 160, Loss: 0.603670597076416, Accuracy: 0.81201171875\n",
      "Batch: 161, Loss: 0.6105811595916748, Accuracy: 0.7998046875\n",
      "Batch: 162, Loss: 0.5595511198043823, Accuracy: 0.8154296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 163, Loss: 0.6171388626098633, Accuracy: 0.7900390625\n",
      "Batch: 164, Loss: 0.6479374766349792, Accuracy: 0.796875\n",
      "Batch: 165, Loss: 0.5854295492172241, Accuracy: 0.822265625\n",
      "Batch: 166, Loss: 0.5888168811798096, Accuracy: 0.7978515625\n",
      "Batch: 167, Loss: 0.5932187438011169, Accuracy: 0.80419921875\n",
      "Batch: 168, Loss: 0.5138587951660156, Accuracy: 0.84130859375\n",
      "Batch: 169, Loss: 0.5829912424087524, Accuracy: 0.80615234375\n",
      "Batch: 170, Loss: 0.6162921190261841, Accuracy: 0.7998046875\n",
      "Batch: 171, Loss: 0.5702353715896606, Accuracy: 0.81298828125\n",
      "Batch: 172, Loss: 0.5576972961425781, Accuracy: 0.81396484375\n",
      "Batch: 173, Loss: 0.6241719722747803, Accuracy: 0.79541015625\n",
      "Batch: 174, Loss: 0.5258193016052246, Accuracy: 0.82421875\n",
      "Batch: 175, Loss: 0.6194438934326172, Accuracy: 0.78955078125\n",
      "Batch: 176, Loss: 0.6328297853469849, Accuracy: 0.79736328125\n",
      "Batch: 177, Loss: 0.5845116972923279, Accuracy: 0.81787109375\n",
      "Batch: 178, Loss: 0.5462133884429932, Accuracy: 0.81689453125\n",
      "Batch: 179, Loss: 0.5703545808792114, Accuracy: 0.81884765625\n",
      "Batch: 180, Loss: 0.593530535697937, Accuracy: 0.8232421875\n",
      "Epoch 70/200\n",
      "Batch: 1, Loss: 0.8754878044128418, Accuracy: 0.759765625\n",
      "Batch: 2, Loss: 0.5762081146240234, Accuracy: 0.806640625\n",
      "Batch: 3, Loss: 0.5792222619056702, Accuracy: 0.806640625\n",
      "Batch: 4, Loss: 0.6044864654541016, Accuracy: 0.806640625\n",
      "Batch: 5, Loss: 0.600783109664917, Accuracy: 0.8115234375\n",
      "Batch: 6, Loss: 0.5979458093643188, Accuracy: 0.80615234375\n",
      "Batch: 7, Loss: 0.572619616985321, Accuracy: 0.81298828125\n",
      "Batch: 8, Loss: 0.5898297429084778, Accuracy: 0.8056640625\n",
      "Batch: 9, Loss: 0.6222877502441406, Accuracy: 0.7998046875\n",
      "Batch: 10, Loss: 0.5764596462249756, Accuracy: 0.8232421875\n",
      "Batch: 11, Loss: 0.6082075238227844, Accuracy: 0.7998046875\n",
      "Batch: 12, Loss: 0.5594161748886108, Accuracy: 0.82275390625\n",
      "Batch: 13, Loss: 0.5905235409736633, Accuracy: 0.81103515625\n",
      "Batch: 14, Loss: 0.5960210561752319, Accuracy: 0.8125\n",
      "Batch: 15, Loss: 0.5844138860702515, Accuracy: 0.81591796875\n",
      "Batch: 16, Loss: 0.6218104362487793, Accuracy: 0.7958984375\n",
      "Batch: 17, Loss: 0.5746034383773804, Accuracy: 0.8154296875\n",
      "Batch: 18, Loss: 0.6002106666564941, Accuracy: 0.8125\n",
      "Batch: 19, Loss: 0.6100231409072876, Accuracy: 0.8076171875\n",
      "Batch: 20, Loss: 0.5177865028381348, Accuracy: 0.8349609375\n",
      "Batch: 21, Loss: 0.6015725135803223, Accuracy: 0.80810546875\n",
      "Batch: 22, Loss: 0.5740553140640259, Accuracy: 0.81591796875\n",
      "Batch: 23, Loss: 0.542433500289917, Accuracy: 0.82568359375\n",
      "Batch: 24, Loss: 0.575745701789856, Accuracy: 0.8173828125\n",
      "Batch: 25, Loss: 0.5707314014434814, Accuracy: 0.81884765625\n",
      "Batch: 26, Loss: 0.598860502243042, Accuracy: 0.80615234375\n",
      "Batch: 27, Loss: 0.6221035718917847, Accuracy: 0.80419921875\n",
      "Batch: 28, Loss: 0.5903189182281494, Accuracy: 0.802734375\n",
      "Batch: 29, Loss: 0.6294769048690796, Accuracy: 0.796875\n",
      "Batch: 30, Loss: 0.5982004404067993, Accuracy: 0.80810546875\n",
      "Batch: 31, Loss: 0.6754258871078491, Accuracy: 0.79296875\n",
      "Batch: 32, Loss: 0.6304581165313721, Accuracy: 0.8017578125\n",
      "Batch: 33, Loss: 0.6111939549446106, Accuracy: 0.798828125\n",
      "Batch: 34, Loss: 0.6362636089324951, Accuracy: 0.79638671875\n",
      "Batch: 35, Loss: 0.6306915283203125, Accuracy: 0.7939453125\n",
      "Batch: 36, Loss: 0.5982950329780579, Accuracy: 0.8115234375\n",
      "Batch: 37, Loss: 0.6219156980514526, Accuracy: 0.78564453125\n",
      "Batch: 38, Loss: 0.6148819923400879, Accuracy: 0.79833984375\n",
      "Batch: 39, Loss: 0.5950635075569153, Accuracy: 0.81201171875\n",
      "Batch: 40, Loss: 0.6337918043136597, Accuracy: 0.80029296875\n",
      "Batch: 41, Loss: 0.6331219673156738, Accuracy: 0.79541015625\n",
      "Batch: 42, Loss: 0.6011727452278137, Accuracy: 0.796875\n",
      "Batch: 43, Loss: 0.5646028518676758, Accuracy: 0.82177734375\n",
      "Batch: 44, Loss: 0.5124625563621521, Accuracy: 0.8427734375\n",
      "Batch: 45, Loss: 0.5954077839851379, Accuracy: 0.80322265625\n",
      "Batch: 46, Loss: 0.5795239210128784, Accuracy: 0.802734375\n",
      "Batch: 47, Loss: 0.5886826515197754, Accuracy: 0.8095703125\n",
      "Batch: 48, Loss: 0.6010835766792297, Accuracy: 0.81005859375\n",
      "Batch: 49, Loss: 0.5818008184432983, Accuracy: 0.8125\n",
      "Batch: 50, Loss: 0.5918223857879639, Accuracy: 0.80419921875\n",
      "Batch: 51, Loss: 0.5619117021560669, Accuracy: 0.81396484375\n",
      "Batch: 52, Loss: 0.5742119550704956, Accuracy: 0.806640625\n",
      "Batch: 53, Loss: 0.5767802596092224, Accuracy: 0.8056640625\n",
      "Batch: 54, Loss: 0.6105363368988037, Accuracy: 0.80078125\n",
      "Batch: 55, Loss: 0.5892601013183594, Accuracy: 0.81640625\n",
      "Batch: 56, Loss: 0.5723496079444885, Accuracy: 0.8046875\n",
      "Batch: 57, Loss: 0.6304543018341064, Accuracy: 0.8037109375\n",
      "Batch: 58, Loss: 0.6006464958190918, Accuracy: 0.802734375\n",
      "Batch: 59, Loss: 0.6936125755310059, Accuracy: 0.7783203125\n",
      "Batch: 60, Loss: 0.5929932594299316, Accuracy: 0.8115234375\n",
      "Batch: 61, Loss: 0.5627599954605103, Accuracy: 0.8134765625\n",
      "Batch: 62, Loss: 0.5814297795295715, Accuracy: 0.81689453125\n",
      "Batch: 63, Loss: 0.5785315632820129, Accuracy: 0.80712890625\n",
      "Batch: 64, Loss: 0.6096466779708862, Accuracy: 0.80517578125\n",
      "Batch: 65, Loss: 0.6430273056030273, Accuracy: 0.7890625\n",
      "Batch: 66, Loss: 0.6048281788825989, Accuracy: 0.80712890625\n",
      "Batch: 67, Loss: 0.6302688121795654, Accuracy: 0.802734375\n",
      "Batch: 68, Loss: 0.5737291574478149, Accuracy: 0.8056640625\n",
      "Batch: 69, Loss: 0.5821929574012756, Accuracy: 0.80029296875\n",
      "Batch: 70, Loss: 0.5846759676933289, Accuracy: 0.81494140625\n",
      "Batch: 71, Loss: 0.5779666900634766, Accuracy: 0.8095703125\n",
      "Batch: 72, Loss: 0.6399142742156982, Accuracy: 0.78662109375\n",
      "Batch: 73, Loss: 0.6000665426254272, Accuracy: 0.79833984375\n",
      "Batch: 74, Loss: 0.6166068911552429, Accuracy: 0.794921875\n",
      "Batch: 75, Loss: 0.5525398254394531, Accuracy: 0.81640625\n",
      "Batch: 76, Loss: 0.5505856275558472, Accuracy: 0.82666015625\n",
      "Batch: 77, Loss: 0.5646049976348877, Accuracy: 0.82470703125\n",
      "Batch: 78, Loss: 0.5924913883209229, Accuracy: 0.806640625\n",
      "Batch: 79, Loss: 0.5744563341140747, Accuracy: 0.80908203125\n",
      "Batch: 80, Loss: 0.6129883527755737, Accuracy: 0.8154296875\n",
      "Batch: 81, Loss: 0.6056008338928223, Accuracy: 0.8056640625\n",
      "Batch: 82, Loss: 0.5765816569328308, Accuracy: 0.798828125\n",
      "Batch: 83, Loss: 0.5617321729660034, Accuracy: 0.82373046875\n",
      "Batch: 84, Loss: 0.5642132759094238, Accuracy: 0.8212890625\n",
      "Batch: 85, Loss: 0.6054322719573975, Accuracy: 0.79638671875\n",
      "Batch: 86, Loss: 0.6408872604370117, Accuracy: 0.794921875\n",
      "Batch: 87, Loss: 0.5668104887008667, Accuracy: 0.8154296875\n",
      "Batch: 88, Loss: 0.6241096258163452, Accuracy: 0.79736328125\n",
      "Batch: 89, Loss: 0.584991455078125, Accuracy: 0.80078125\n",
      "Batch: 90, Loss: 0.6190100312232971, Accuracy: 0.8046875\n",
      "Batch: 91, Loss: 0.5883371829986572, Accuracy: 0.806640625\n",
      "Batch: 92, Loss: 0.6572136282920837, Accuracy: 0.7841796875\n",
      "Batch: 93, Loss: 0.636299192905426, Accuracy: 0.79638671875\n",
      "Batch: 94, Loss: 0.5879502892494202, Accuracy: 0.8115234375\n",
      "Batch: 95, Loss: 0.6437376141548157, Accuracy: 0.7900390625\n",
      "Batch: 96, Loss: 0.5739293098449707, Accuracy: 0.81884765625\n",
      "Batch: 97, Loss: 0.5714812278747559, Accuracy: 0.82470703125\n",
      "Batch: 98, Loss: 0.6109894514083862, Accuracy: 0.80419921875\n",
      "Batch: 99, Loss: 0.5685945749282837, Accuracy: 0.8173828125\n",
      "Batch: 100, Loss: 0.6437322497367859, Accuracy: 0.796875\n",
      "Batch: 101, Loss: 0.6409359574317932, Accuracy: 0.7880859375\n",
      "Batch: 102, Loss: 0.568800151348114, Accuracy: 0.81787109375\n",
      "Batch: 103, Loss: 0.6223132610321045, Accuracy: 0.80224609375\n",
      "Batch: 104, Loss: 0.5891337394714355, Accuracy: 0.81005859375\n",
      "Batch: 105, Loss: 0.6242575645446777, Accuracy: 0.798828125\n",
      "Batch: 106, Loss: 0.5622475147247314, Accuracy: 0.8095703125\n",
      "Batch: 107, Loss: 0.6330790519714355, Accuracy: 0.80029296875\n",
      "Batch: 108, Loss: 0.5630260705947876, Accuracy: 0.8125\n",
      "Batch: 109, Loss: 0.5711047649383545, Accuracy: 0.8173828125\n",
      "Batch: 110, Loss: 0.5666476488113403, Accuracy: 0.8125\n",
      "Batch: 111, Loss: 0.5379385948181152, Accuracy: 0.82275390625\n",
      "Batch: 112, Loss: 0.5586886405944824, Accuracy: 0.81103515625\n",
      "Batch: 113, Loss: 0.6036839485168457, Accuracy: 0.7939453125\n",
      "Batch: 114, Loss: 0.6052041053771973, Accuracy: 0.798828125\n",
      "Batch: 115, Loss: 0.582166314125061, Accuracy: 0.81201171875\n",
      "Batch: 116, Loss: 0.5788713693618774, Accuracy: 0.8125\n",
      "Batch: 117, Loss: 0.5669397115707397, Accuracy: 0.810546875\n",
      "Batch: 118, Loss: 0.6018953323364258, Accuracy: 0.81201171875\n",
      "Batch: 119, Loss: 0.5879032611846924, Accuracy: 0.8017578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 120, Loss: 0.568589985370636, Accuracy: 0.81201171875\n",
      "Batch: 121, Loss: 0.5789772272109985, Accuracy: 0.80859375\n",
      "Batch: 122, Loss: 0.5669716596603394, Accuracy: 0.8037109375\n",
      "Batch: 123, Loss: 0.5514811873435974, Accuracy: 0.82421875\n",
      "Batch: 124, Loss: 0.5537213087081909, Accuracy: 0.82373046875\n",
      "Batch: 125, Loss: 0.5836962461471558, Accuracy: 0.81689453125\n",
      "Batch: 126, Loss: 0.55968177318573, Accuracy: 0.8232421875\n",
      "Batch: 127, Loss: 0.5350295901298523, Accuracy: 0.82275390625\n",
      "Batch: 128, Loss: 0.6642336845397949, Accuracy: 0.7841796875\n",
      "Batch: 129, Loss: 0.6555469036102295, Accuracy: 0.77978515625\n",
      "Batch: 130, Loss: 0.6601028442382812, Accuracy: 0.7841796875\n",
      "Batch: 131, Loss: 0.6093670129776001, Accuracy: 0.7998046875\n",
      "Batch: 132, Loss: 0.5565992593765259, Accuracy: 0.8271484375\n",
      "Batch: 133, Loss: 0.5380643606185913, Accuracy: 0.83203125\n",
      "Batch: 134, Loss: 0.6051380038261414, Accuracy: 0.79736328125\n",
      "Batch: 135, Loss: 0.5980743169784546, Accuracy: 0.80322265625\n",
      "Batch: 136, Loss: 0.540791392326355, Accuracy: 0.8251953125\n",
      "Batch: 137, Loss: 0.5905498266220093, Accuracy: 0.80712890625\n",
      "Batch: 138, Loss: 0.5386815071105957, Accuracy: 0.822265625\n",
      "Batch: 139, Loss: 0.5704887509346008, Accuracy: 0.810546875\n",
      "Batch: 140, Loss: 0.5364281535148621, Accuracy: 0.82421875\n",
      "Batch: 141, Loss: 0.6095577478408813, Accuracy: 0.79638671875\n",
      "Batch: 142, Loss: 0.5557141900062561, Accuracy: 0.81591796875\n",
      "Batch: 143, Loss: 0.5509504079818726, Accuracy: 0.8193359375\n",
      "Batch: 144, Loss: 0.6205415725708008, Accuracy: 0.79833984375\n",
      "Batch: 145, Loss: 0.5927634239196777, Accuracy: 0.8046875\n",
      "Batch: 146, Loss: 0.6136692762374878, Accuracy: 0.79443359375\n",
      "Batch: 147, Loss: 0.5677231550216675, Accuracy: 0.822265625\n",
      "Batch: 148, Loss: 0.6287860870361328, Accuracy: 0.80419921875\n",
      "Batch: 149, Loss: 0.6314799785614014, Accuracy: 0.79345703125\n",
      "Batch: 150, Loss: 0.52228182554245, Accuracy: 0.8359375\n",
      "Batch: 151, Loss: 0.5230874419212341, Accuracy: 0.8310546875\n",
      "Batch: 152, Loss: 0.551817774772644, Accuracy: 0.8212890625\n",
      "Batch: 153, Loss: 0.5653896331787109, Accuracy: 0.818359375\n",
      "Batch: 154, Loss: 0.560429036617279, Accuracy: 0.8134765625\n",
      "Batch: 155, Loss: 0.6114778518676758, Accuracy: 0.80029296875\n",
      "Batch: 156, Loss: 0.5475436449050903, Accuracy: 0.8154296875\n",
      "Batch: 157, Loss: 0.5105825662612915, Accuracy: 0.826171875\n",
      "Batch: 158, Loss: 0.533894956111908, Accuracy: 0.83154296875\n",
      "Batch: 159, Loss: 0.5587973594665527, Accuracy: 0.8173828125\n",
      "Batch: 160, Loss: 0.5726474523544312, Accuracy: 0.8115234375\n",
      "Batch: 161, Loss: 0.6000769734382629, Accuracy: 0.80126953125\n",
      "Batch: 162, Loss: 0.5451250076293945, Accuracy: 0.828125\n",
      "Batch: 163, Loss: 0.6019153594970703, Accuracy: 0.79736328125\n",
      "Batch: 164, Loss: 0.6725293397903442, Accuracy: 0.78271484375\n",
      "Batch: 165, Loss: 0.584358811378479, Accuracy: 0.81787109375\n",
      "Batch: 166, Loss: 0.6111667156219482, Accuracy: 0.79736328125\n",
      "Batch: 167, Loss: 0.5750284790992737, Accuracy: 0.82470703125\n",
      "Batch: 168, Loss: 0.5204339027404785, Accuracy: 0.83203125\n",
      "Batch: 169, Loss: 0.5845456719398499, Accuracy: 0.80126953125\n",
      "Batch: 170, Loss: 0.5979819893836975, Accuracy: 0.810546875\n",
      "Batch: 171, Loss: 0.562283992767334, Accuracy: 0.8212890625\n",
      "Batch: 172, Loss: 0.5697478652000427, Accuracy: 0.81396484375\n",
      "Batch: 173, Loss: 0.6186079978942871, Accuracy: 0.80078125\n",
      "Batch: 174, Loss: 0.5171943306922913, Accuracy: 0.826171875\n",
      "Batch: 175, Loss: 0.5893253684043884, Accuracy: 0.80908203125\n",
      "Batch: 176, Loss: 0.6325706839561462, Accuracy: 0.79541015625\n",
      "Batch: 177, Loss: 0.5756721496582031, Accuracy: 0.81494140625\n",
      "Batch: 178, Loss: 0.534011960029602, Accuracy: 0.8232421875\n",
      "Batch: 179, Loss: 0.5739655494689941, Accuracy: 0.81201171875\n",
      "Batch: 180, Loss: 0.5957130193710327, Accuracy: 0.80712890625\n",
      "Saved Weights at epoch 70 to file Weights_70.h5\n",
      "Epoch 71/200\n",
      "Batch: 1, Loss: 0.8828110694885254, Accuracy: 0.74072265625\n",
      "Batch: 2, Loss: 0.5998615622520447, Accuracy: 0.79248046875\n",
      "Batch: 3, Loss: 0.5881086587905884, Accuracy: 0.80615234375\n",
      "Batch: 4, Loss: 0.618954598903656, Accuracy: 0.80029296875\n",
      "Batch: 5, Loss: 0.5908819437026978, Accuracy: 0.8115234375\n",
      "Batch: 6, Loss: 0.6002455949783325, Accuracy: 0.80078125\n",
      "Batch: 7, Loss: 0.577254056930542, Accuracy: 0.80810546875\n",
      "Batch: 8, Loss: 0.5633907318115234, Accuracy: 0.81103515625\n",
      "Batch: 9, Loss: 0.6049486398696899, Accuracy: 0.81298828125\n",
      "Batch: 10, Loss: 0.5701534748077393, Accuracy: 0.810546875\n",
      "Batch: 11, Loss: 0.6130958795547485, Accuracy: 0.80419921875\n",
      "Batch: 12, Loss: 0.54416424036026, Accuracy: 0.830078125\n",
      "Batch: 13, Loss: 0.5863164067268372, Accuracy: 0.8095703125\n",
      "Batch: 14, Loss: 0.5788297057151794, Accuracy: 0.810546875\n",
      "Batch: 15, Loss: 0.5823190212249756, Accuracy: 0.814453125\n",
      "Batch: 16, Loss: 0.6143851280212402, Accuracy: 0.7939453125\n",
      "Batch: 17, Loss: 0.563298225402832, Accuracy: 0.81298828125\n",
      "Batch: 18, Loss: 0.5972029566764832, Accuracy: 0.81201171875\n",
      "Batch: 19, Loss: 0.6024494171142578, Accuracy: 0.81201171875\n",
      "Batch: 20, Loss: 0.5286371111869812, Accuracy: 0.8388671875\n",
      "Batch: 21, Loss: 0.5991323590278625, Accuracy: 0.814453125\n",
      "Batch: 22, Loss: 0.5487443208694458, Accuracy: 0.82275390625\n",
      "Batch: 23, Loss: 0.5546966195106506, Accuracy: 0.81689453125\n",
      "Batch: 24, Loss: 0.5697097778320312, Accuracy: 0.8173828125\n",
      "Batch: 25, Loss: 0.5608091354370117, Accuracy: 0.828125\n",
      "Batch: 26, Loss: 0.5550984144210815, Accuracy: 0.81298828125\n",
      "Batch: 27, Loss: 0.5981414914131165, Accuracy: 0.8017578125\n",
      "Batch: 28, Loss: 0.5724257826805115, Accuracy: 0.81103515625\n",
      "Batch: 29, Loss: 0.6329367160797119, Accuracy: 0.7978515625\n",
      "Batch: 30, Loss: 0.5912723541259766, Accuracy: 0.810546875\n",
      "Batch: 31, Loss: 0.6624059677124023, Accuracy: 0.79248046875\n",
      "Batch: 32, Loss: 0.6255584955215454, Accuracy: 0.79541015625\n",
      "Batch: 33, Loss: 0.5823919773101807, Accuracy: 0.8056640625\n",
      "Batch: 34, Loss: 0.6136034727096558, Accuracy: 0.8037109375\n",
      "Batch: 35, Loss: 0.6364681720733643, Accuracy: 0.80615234375\n",
      "Batch: 36, Loss: 0.597797155380249, Accuracy: 0.80908203125\n",
      "Batch: 37, Loss: 0.6268665790557861, Accuracy: 0.796875\n",
      "Batch: 38, Loss: 0.6530081033706665, Accuracy: 0.7861328125\n",
      "Batch: 39, Loss: 0.5718305110931396, Accuracy: 0.814453125\n",
      "Batch: 40, Loss: 0.6459841132164001, Accuracy: 0.794921875\n",
      "Batch: 41, Loss: 0.6105194091796875, Accuracy: 0.80859375\n",
      "Batch: 42, Loss: 0.6120575666427612, Accuracy: 0.79541015625\n",
      "Batch: 43, Loss: 0.5669304132461548, Accuracy: 0.82373046875\n",
      "Batch: 44, Loss: 0.5357688069343567, Accuracy: 0.826171875\n",
      "Batch: 45, Loss: 0.5938253402709961, Accuracy: 0.8056640625\n",
      "Batch: 46, Loss: 0.5484635829925537, Accuracy: 0.8154296875\n",
      "Batch: 47, Loss: 0.5977106094360352, Accuracy: 0.8056640625\n",
      "Batch: 48, Loss: 0.6046887636184692, Accuracy: 0.80224609375\n",
      "Batch: 49, Loss: 0.5898468494415283, Accuracy: 0.81201171875\n",
      "Batch: 50, Loss: 0.5946925282478333, Accuracy: 0.79931640625\n",
      "Batch: 51, Loss: 0.5678716897964478, Accuracy: 0.8173828125\n",
      "Batch: 52, Loss: 0.5684962272644043, Accuracy: 0.8095703125\n",
      "Batch: 53, Loss: 0.5853121280670166, Accuracy: 0.79638671875\n",
      "Batch: 54, Loss: 0.6133466362953186, Accuracy: 0.79443359375\n",
      "Batch: 55, Loss: 0.5899973511695862, Accuracy: 0.8046875\n",
      "Batch: 56, Loss: 0.5876950025558472, Accuracy: 0.80859375\n",
      "Batch: 57, Loss: 0.6438806653022766, Accuracy: 0.79150390625\n",
      "Batch: 58, Loss: 0.6011564135551453, Accuracy: 0.8076171875\n",
      "Batch: 59, Loss: 0.6782209873199463, Accuracy: 0.7841796875\n",
      "Batch: 60, Loss: 0.5830416679382324, Accuracy: 0.81591796875\n",
      "Batch: 61, Loss: 0.5466290712356567, Accuracy: 0.82275390625\n",
      "Batch: 62, Loss: 0.5603106021881104, Accuracy: 0.82861328125\n",
      "Batch: 63, Loss: 0.5705677270889282, Accuracy: 0.81298828125\n",
      "Batch: 64, Loss: 0.600354015827179, Accuracy: 0.791015625\n",
      "Batch: 65, Loss: 0.6280100345611572, Accuracy: 0.80029296875\n",
      "Batch: 66, Loss: 0.6114041805267334, Accuracy: 0.796875\n",
      "Batch: 67, Loss: 0.6286330223083496, Accuracy: 0.802734375\n",
      "Batch: 68, Loss: 0.5380123853683472, Accuracy: 0.81640625\n",
      "Batch: 69, Loss: 0.59433913230896, Accuracy: 0.81005859375\n",
      "Batch: 70, Loss: 0.5831769704818726, Accuracy: 0.81103515625\n",
      "Batch: 71, Loss: 0.5797187089920044, Accuracy: 0.80322265625\n",
      "Batch: 72, Loss: 0.617861270904541, Accuracy: 0.78515625\n",
      "Batch: 73, Loss: 0.6015491485595703, Accuracy: 0.79833984375\n",
      "Batch: 74, Loss: 0.5993379354476929, Accuracy: 0.806640625\n",
      "Batch: 75, Loss: 0.5560214519500732, Accuracy: 0.8203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 76, Loss: 0.5361384153366089, Accuracy: 0.84033203125\n",
      "Batch: 77, Loss: 0.5388226509094238, Accuracy: 0.83984375\n",
      "Batch: 78, Loss: 0.585793137550354, Accuracy: 0.81298828125\n",
      "Batch: 79, Loss: 0.6096245050430298, Accuracy: 0.80517578125\n",
      "Batch: 80, Loss: 0.5825887322425842, Accuracy: 0.8203125\n",
      "Batch: 81, Loss: 0.6082135438919067, Accuracy: 0.81201171875\n",
      "Batch: 82, Loss: 0.5678101778030396, Accuracy: 0.80517578125\n",
      "Batch: 83, Loss: 0.5630868673324585, Accuracy: 0.81884765625\n",
      "Batch: 84, Loss: 0.5500882863998413, Accuracy: 0.8203125\n",
      "Batch: 85, Loss: 0.5840310454368591, Accuracy: 0.80224609375\n",
      "Batch: 86, Loss: 0.6244774460792542, Accuracy: 0.810546875\n",
      "Batch: 87, Loss: 0.562922477722168, Accuracy: 0.818359375\n",
      "Batch: 88, Loss: 0.6249574422836304, Accuracy: 0.79931640625\n",
      "Batch: 89, Loss: 0.5978069305419922, Accuracy: 0.79931640625\n",
      "Batch: 90, Loss: 0.6119251251220703, Accuracy: 0.79638671875\n",
      "Batch: 91, Loss: 0.5894704461097717, Accuracy: 0.8017578125\n",
      "Batch: 92, Loss: 0.6590241193771362, Accuracy: 0.77099609375\n",
      "Batch: 93, Loss: 0.6558186411857605, Accuracy: 0.77783203125\n",
      "Batch: 94, Loss: 0.6078705191612244, Accuracy: 0.80615234375\n",
      "Batch: 95, Loss: 0.671385645866394, Accuracy: 0.783203125\n",
      "Batch: 96, Loss: 0.5851688981056213, Accuracy: 0.8203125\n",
      "Batch: 97, Loss: 0.5802322030067444, Accuracy: 0.822265625\n",
      "Batch: 98, Loss: 0.6040593981742859, Accuracy: 0.80224609375\n",
      "Batch: 99, Loss: 0.5721942186355591, Accuracy: 0.8125\n",
      "Batch: 100, Loss: 0.6431996822357178, Accuracy: 0.7978515625\n",
      "Batch: 101, Loss: 0.6341854333877563, Accuracy: 0.791015625\n",
      "Batch: 102, Loss: 0.5371420383453369, Accuracy: 0.82861328125\n",
      "Batch: 103, Loss: 0.594214916229248, Accuracy: 0.81396484375\n",
      "Batch: 104, Loss: 0.5770891308784485, Accuracy: 0.81787109375\n",
      "Batch: 105, Loss: 0.6030066013336182, Accuracy: 0.80419921875\n",
      "Batch: 106, Loss: 0.552673876285553, Accuracy: 0.8251953125\n",
      "Batch: 107, Loss: 0.6046066880226135, Accuracy: 0.81103515625\n",
      "Batch: 108, Loss: 0.552426278591156, Accuracy: 0.814453125\n",
      "Batch: 109, Loss: 0.5548632740974426, Accuracy: 0.8173828125\n",
      "Batch: 110, Loss: 0.5452278256416321, Accuracy: 0.81884765625\n",
      "Batch: 111, Loss: 0.5204227566719055, Accuracy: 0.8232421875\n",
      "Batch: 112, Loss: 0.5550674796104431, Accuracy: 0.82373046875\n",
      "Batch: 113, Loss: 0.6083236932754517, Accuracy: 0.80615234375\n",
      "Batch: 114, Loss: 0.5983180999755859, Accuracy: 0.8095703125\n",
      "Batch: 115, Loss: 0.5653659105300903, Accuracy: 0.8154296875\n",
      "Batch: 116, Loss: 0.5728560090065002, Accuracy: 0.80859375\n",
      "Batch: 117, Loss: 0.5652216076850891, Accuracy: 0.8095703125\n",
      "Batch: 118, Loss: 0.6030250787734985, Accuracy: 0.802734375\n",
      "Batch: 119, Loss: 0.574124813079834, Accuracy: 0.8095703125\n",
      "Batch: 120, Loss: 0.5524749755859375, Accuracy: 0.81591796875\n",
      "Batch: 121, Loss: 0.5646419525146484, Accuracy: 0.8212890625\n",
      "Batch: 122, Loss: 0.5491399765014648, Accuracy: 0.81640625\n",
      "Batch: 123, Loss: 0.554297924041748, Accuracy: 0.82470703125\n",
      "Batch: 124, Loss: 0.537771463394165, Accuracy: 0.82275390625\n",
      "Batch: 125, Loss: 0.5748574733734131, Accuracy: 0.822265625\n",
      "Batch: 126, Loss: 0.5588235855102539, Accuracy: 0.8173828125\n",
      "Batch: 127, Loss: 0.5125196576118469, Accuracy: 0.83740234375\n",
      "Batch: 128, Loss: 0.624047040939331, Accuracy: 0.8037109375\n",
      "Batch: 129, Loss: 0.6646974086761475, Accuracy: 0.78076171875\n",
      "Batch: 130, Loss: 0.6776114106178284, Accuracy: 0.77783203125\n",
      "Batch: 131, Loss: 0.5862224102020264, Accuracy: 0.810546875\n",
      "Batch: 132, Loss: 0.5271477699279785, Accuracy: 0.8369140625\n",
      "Batch: 133, Loss: 0.5376406908035278, Accuracy: 0.83251953125\n",
      "Batch: 134, Loss: 0.5855879187583923, Accuracy: 0.80712890625\n",
      "Batch: 135, Loss: 0.5806636810302734, Accuracy: 0.80029296875\n",
      "Batch: 136, Loss: 0.5461061596870422, Accuracy: 0.814453125\n",
      "Batch: 137, Loss: 0.6021403074264526, Accuracy: 0.80322265625\n",
      "Batch: 138, Loss: 0.5292506217956543, Accuracy: 0.8310546875\n",
      "Batch: 139, Loss: 0.5581384897232056, Accuracy: 0.81396484375\n",
      "Batch: 140, Loss: 0.5304142236709595, Accuracy: 0.82080078125\n",
      "Batch: 141, Loss: 0.6052737236022949, Accuracy: 0.7958984375\n",
      "Batch: 142, Loss: 0.5524559020996094, Accuracy: 0.81396484375\n",
      "Batch: 143, Loss: 0.5556856989860535, Accuracy: 0.82177734375\n",
      "Batch: 144, Loss: 0.6220807433128357, Accuracy: 0.79736328125\n",
      "Batch: 145, Loss: 0.5951024293899536, Accuracy: 0.80712890625\n",
      "Batch: 146, Loss: 0.5954896211624146, Accuracy: 0.8125\n",
      "Batch: 147, Loss: 0.5767807960510254, Accuracy: 0.8193359375\n",
      "Batch: 148, Loss: 0.6006882190704346, Accuracy: 0.7978515625\n",
      "Batch: 149, Loss: 0.6149433851242065, Accuracy: 0.79638671875\n",
      "Batch: 150, Loss: 0.5399233102798462, Accuracy: 0.82763671875\n",
      "Batch: 151, Loss: 0.5346817374229431, Accuracy: 0.83154296875\n",
      "Batch: 152, Loss: 0.5559800863265991, Accuracy: 0.8154296875\n",
      "Batch: 153, Loss: 0.5605069398880005, Accuracy: 0.81982421875\n",
      "Batch: 154, Loss: 0.563020646572113, Accuracy: 0.81005859375\n",
      "Batch: 155, Loss: 0.6395999789237976, Accuracy: 0.796875\n",
      "Batch: 156, Loss: 0.5479250550270081, Accuracy: 0.8232421875\n",
      "Batch: 157, Loss: 0.5312172770500183, Accuracy: 0.8251953125\n",
      "Batch: 158, Loss: 0.547873854637146, Accuracy: 0.8310546875\n",
      "Batch: 159, Loss: 0.546955943107605, Accuracy: 0.82177734375\n",
      "Batch: 160, Loss: 0.5656552910804749, Accuracy: 0.814453125\n",
      "Batch: 161, Loss: 0.6145803928375244, Accuracy: 0.8037109375\n",
      "Batch: 162, Loss: 0.5560651421546936, Accuracy: 0.82861328125\n",
      "Batch: 163, Loss: 0.6145389676094055, Accuracy: 0.79541015625\n",
      "Batch: 164, Loss: 0.6636031866073608, Accuracy: 0.78515625\n",
      "Batch: 165, Loss: 0.5847287178039551, Accuracy: 0.81591796875\n",
      "Batch: 166, Loss: 0.5839745998382568, Accuracy: 0.8076171875\n",
      "Batch: 167, Loss: 0.576392412185669, Accuracy: 0.8125\n",
      "Batch: 168, Loss: 0.52803635597229, Accuracy: 0.8330078125\n",
      "Batch: 169, Loss: 0.5903775691986084, Accuracy: 0.798828125\n",
      "Batch: 170, Loss: 0.584478497505188, Accuracy: 0.80810546875\n",
      "Batch: 171, Loss: 0.570306658744812, Accuracy: 0.8115234375\n",
      "Batch: 172, Loss: 0.5443159937858582, Accuracy: 0.8193359375\n",
      "Batch: 173, Loss: 0.6411430835723877, Accuracy: 0.79150390625\n",
      "Batch: 174, Loss: 0.5181565880775452, Accuracy: 0.82470703125\n",
      "Batch: 175, Loss: 0.5831902623176575, Accuracy: 0.810546875\n",
      "Batch: 176, Loss: 0.6332700848579407, Accuracy: 0.79443359375\n",
      "Batch: 177, Loss: 0.5843855142593384, Accuracy: 0.8125\n",
      "Batch: 178, Loss: 0.5461242198944092, Accuracy: 0.82080078125\n",
      "Batch: 179, Loss: 0.5988065004348755, Accuracy: 0.8134765625\n",
      "Batch: 180, Loss: 0.593090832233429, Accuracy: 0.8056640625\n",
      "Epoch 72/200\n",
      "Batch: 1, Loss: 0.8671035766601562, Accuracy: 0.75\n",
      "Batch: 2, Loss: 0.5834391713142395, Accuracy: 0.8056640625\n",
      "Batch: 3, Loss: 0.5708140134811401, Accuracy: 0.82373046875\n",
      "Batch: 4, Loss: 0.6097357273101807, Accuracy: 0.80126953125\n",
      "Batch: 5, Loss: 0.5851786732673645, Accuracy: 0.81005859375\n",
      "Batch: 6, Loss: 0.6016464233398438, Accuracy: 0.80126953125\n",
      "Batch: 7, Loss: 0.5799957513809204, Accuracy: 0.80419921875\n",
      "Batch: 8, Loss: 0.573989748954773, Accuracy: 0.80859375\n",
      "Batch: 9, Loss: 0.5974987745285034, Accuracy: 0.79638671875\n",
      "Batch: 10, Loss: 0.5591423511505127, Accuracy: 0.81396484375\n",
      "Batch: 11, Loss: 0.604007363319397, Accuracy: 0.79736328125\n",
      "Batch: 12, Loss: 0.533035397529602, Accuracy: 0.82861328125\n",
      "Batch: 13, Loss: 0.5904715061187744, Accuracy: 0.81201171875\n",
      "Batch: 14, Loss: 0.5710248947143555, Accuracy: 0.80908203125\n",
      "Batch: 15, Loss: 0.5828778147697449, Accuracy: 0.80224609375\n",
      "Batch: 16, Loss: 0.5948140025138855, Accuracy: 0.7958984375\n",
      "Batch: 17, Loss: 0.5725265145301819, Accuracy: 0.8134765625\n",
      "Batch: 18, Loss: 0.6057814359664917, Accuracy: 0.798828125\n",
      "Batch: 19, Loss: 0.6043636798858643, Accuracy: 0.806640625\n",
      "Batch: 20, Loss: 0.5021613836288452, Accuracy: 0.8369140625\n",
      "Batch: 21, Loss: 0.5901678800582886, Accuracy: 0.81396484375\n",
      "Batch: 22, Loss: 0.5418492555618286, Accuracy: 0.818359375\n",
      "Batch: 23, Loss: 0.5361781120300293, Accuracy: 0.8173828125\n",
      "Batch: 24, Loss: 0.5741405487060547, Accuracy: 0.8125\n",
      "Batch: 25, Loss: 0.5700821876525879, Accuracy: 0.82373046875\n",
      "Batch: 26, Loss: 0.5651129484176636, Accuracy: 0.82177734375\n",
      "Batch: 27, Loss: 0.5931769609451294, Accuracy: 0.80859375\n",
      "Batch: 28, Loss: 0.5657166242599487, Accuracy: 0.82275390625\n",
      "Batch: 29, Loss: 0.6109576225280762, Accuracy: 0.80224609375\n",
      "Batch: 30, Loss: 0.6123366951942444, Accuracy: 0.802734375\n",
      "Batch: 31, Loss: 0.6510286927223206, Accuracy: 0.78857421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 32, Loss: 0.617485761642456, Accuracy: 0.80029296875\n",
      "Batch: 33, Loss: 0.5842134952545166, Accuracy: 0.8046875\n",
      "Batch: 34, Loss: 0.6133774518966675, Accuracy: 0.7958984375\n",
      "Batch: 35, Loss: 0.6391472220420837, Accuracy: 0.79443359375\n",
      "Batch: 36, Loss: 0.6074841618537903, Accuracy: 0.8056640625\n",
      "Batch: 37, Loss: 0.6182488203048706, Accuracy: 0.80224609375\n",
      "Batch: 38, Loss: 0.6448241472244263, Accuracy: 0.791015625\n",
      "Batch: 39, Loss: 0.5988057851791382, Accuracy: 0.80810546875\n",
      "Batch: 40, Loss: 0.6498480439186096, Accuracy: 0.79541015625\n",
      "Batch: 41, Loss: 0.6234636902809143, Accuracy: 0.80078125\n",
      "Batch: 42, Loss: 0.60355544090271, Accuracy: 0.80224609375\n",
      "Batch: 43, Loss: 0.5598912239074707, Accuracy: 0.82470703125\n",
      "Batch: 44, Loss: 0.5394389629364014, Accuracy: 0.82421875\n",
      "Batch: 45, Loss: 0.5916149616241455, Accuracy: 0.80712890625\n",
      "Batch: 46, Loss: 0.5694384574890137, Accuracy: 0.810546875\n",
      "Batch: 47, Loss: 0.5968480706214905, Accuracy: 0.80126953125\n",
      "Batch: 48, Loss: 0.583183228969574, Accuracy: 0.814453125\n",
      "Batch: 49, Loss: 0.5936098098754883, Accuracy: 0.80712890625\n",
      "Batch: 50, Loss: 0.5837172269821167, Accuracy: 0.81103515625\n",
      "Batch: 51, Loss: 0.5768470168113708, Accuracy: 0.81689453125\n",
      "Batch: 52, Loss: 0.5528467893600464, Accuracy: 0.8095703125\n",
      "Batch: 53, Loss: 0.5911948680877686, Accuracy: 0.806640625\n",
      "Batch: 54, Loss: 0.6223563551902771, Accuracy: 0.794921875\n",
      "Batch: 55, Loss: 0.5994454026222229, Accuracy: 0.7998046875\n",
      "Batch: 56, Loss: 0.5649312138557434, Accuracy: 0.80517578125\n",
      "Batch: 57, Loss: 0.6322855949401855, Accuracy: 0.8017578125\n",
      "Batch: 58, Loss: 0.5968083143234253, Accuracy: 0.79638671875\n",
      "Batch: 59, Loss: 0.6758381128311157, Accuracy: 0.78271484375\n",
      "Batch: 60, Loss: 0.5946487784385681, Accuracy: 0.81396484375\n",
      "Batch: 61, Loss: 0.5608257055282593, Accuracy: 0.82373046875\n",
      "Batch: 62, Loss: 0.545046865940094, Accuracy: 0.828125\n",
      "Batch: 63, Loss: 0.5593913793563843, Accuracy: 0.80712890625\n",
      "Batch: 64, Loss: 0.6180258989334106, Accuracy: 0.79345703125\n",
      "Batch: 65, Loss: 0.6383383870124817, Accuracy: 0.7939453125\n",
      "Batch: 66, Loss: 0.6035152077674866, Accuracy: 0.80517578125\n",
      "Batch: 67, Loss: 0.603000819683075, Accuracy: 0.80517578125\n",
      "Batch: 68, Loss: 0.5619815587997437, Accuracy: 0.81298828125\n",
      "Batch: 69, Loss: 0.6109421253204346, Accuracy: 0.8017578125\n",
      "Batch: 70, Loss: 0.5728754997253418, Accuracy: 0.80712890625\n",
      "Batch: 71, Loss: 0.5580270290374756, Accuracy: 0.8173828125\n",
      "Batch: 72, Loss: 0.603646993637085, Accuracy: 0.7998046875\n",
      "Batch: 73, Loss: 0.6077774167060852, Accuracy: 0.80712890625\n",
      "Batch: 74, Loss: 0.5842913389205933, Accuracy: 0.81494140625\n",
      "Batch: 75, Loss: 0.5570486783981323, Accuracy: 0.810546875\n",
      "Batch: 76, Loss: 0.5365678071975708, Accuracy: 0.833984375\n",
      "Batch: 77, Loss: 0.5414111614227295, Accuracy: 0.833984375\n",
      "Batch: 78, Loss: 0.5660203695297241, Accuracy: 0.82080078125\n",
      "Batch: 79, Loss: 0.5897153615951538, Accuracy: 0.80908203125\n",
      "Batch: 80, Loss: 0.6091254949569702, Accuracy: 0.802734375\n",
      "Batch: 81, Loss: 0.5815140008926392, Accuracy: 0.8134765625\n",
      "Batch: 82, Loss: 0.5787183046340942, Accuracy: 0.8056640625\n",
      "Batch: 83, Loss: 0.5307618379592896, Accuracy: 0.83349609375\n",
      "Batch: 84, Loss: 0.5534235239028931, Accuracy: 0.8203125\n",
      "Batch: 85, Loss: 0.5915501713752747, Accuracy: 0.81005859375\n",
      "Batch: 86, Loss: 0.6491918563842773, Accuracy: 0.79736328125\n",
      "Batch: 87, Loss: 0.5435001850128174, Accuracy: 0.8271484375\n",
      "Batch: 88, Loss: 0.5956214666366577, Accuracy: 0.81201171875\n",
      "Batch: 89, Loss: 0.5841909646987915, Accuracy: 0.81494140625\n",
      "Batch: 90, Loss: 0.6232749223709106, Accuracy: 0.7978515625\n",
      "Batch: 91, Loss: 0.5735551118850708, Accuracy: 0.80810546875\n",
      "Batch: 92, Loss: 0.6429731249809265, Accuracy: 0.7822265625\n",
      "Batch: 93, Loss: 0.6461960077285767, Accuracy: 0.79052734375\n",
      "Batch: 94, Loss: 0.6137570142745972, Accuracy: 0.80712890625\n",
      "Batch: 95, Loss: 0.6262415051460266, Accuracy: 0.798828125\n",
      "Batch: 96, Loss: 0.5760151147842407, Accuracy: 0.8232421875\n",
      "Batch: 97, Loss: 0.572599470615387, Accuracy: 0.82470703125\n",
      "Batch: 98, Loss: 0.5988612174987793, Accuracy: 0.80224609375\n",
      "Batch: 99, Loss: 0.5699998140335083, Accuracy: 0.822265625\n",
      "Batch: 100, Loss: 0.6196871995925903, Accuracy: 0.794921875\n",
      "Batch: 101, Loss: 0.6561771631240845, Accuracy: 0.78515625\n",
      "Batch: 102, Loss: 0.5501726269721985, Accuracy: 0.81982421875\n",
      "Batch: 103, Loss: 0.5828698873519897, Accuracy: 0.8115234375\n",
      "Batch: 104, Loss: 0.581139087677002, Accuracy: 0.81298828125\n",
      "Batch: 105, Loss: 0.5928798317909241, Accuracy: 0.81103515625\n",
      "Batch: 106, Loss: 0.5631024241447449, Accuracy: 0.81591796875\n",
      "Batch: 107, Loss: 0.5893931984901428, Accuracy: 0.814453125\n",
      "Batch: 108, Loss: 0.5438125133514404, Accuracy: 0.81982421875\n",
      "Batch: 109, Loss: 0.5617355108261108, Accuracy: 0.8173828125\n",
      "Batch: 110, Loss: 0.5369036793708801, Accuracy: 0.81396484375\n",
      "Batch: 111, Loss: 0.5279908180236816, Accuracy: 0.82275390625\n",
      "Batch: 112, Loss: 0.5510700941085815, Accuracy: 0.82568359375\n",
      "Batch: 113, Loss: 0.602798581123352, Accuracy: 0.79736328125\n",
      "Batch: 114, Loss: 0.58233642578125, Accuracy: 0.80859375\n",
      "Batch: 115, Loss: 0.608444094657898, Accuracy: 0.80224609375\n",
      "Batch: 116, Loss: 0.578472375869751, Accuracy: 0.8115234375\n",
      "Batch: 117, Loss: 0.5619616508483887, Accuracy: 0.8134765625\n",
      "Batch: 118, Loss: 0.5899531841278076, Accuracy: 0.8076171875\n",
      "Batch: 119, Loss: 0.5590643882751465, Accuracy: 0.81884765625\n",
      "Batch: 120, Loss: 0.5631505250930786, Accuracy: 0.81494140625\n",
      "Batch: 121, Loss: 0.5602155923843384, Accuracy: 0.828125\n",
      "Batch: 122, Loss: 0.5492783188819885, Accuracy: 0.82080078125\n",
      "Batch: 123, Loss: 0.5387670993804932, Accuracy: 0.83349609375\n",
      "Batch: 124, Loss: 0.5278237462043762, Accuracy: 0.8291015625\n",
      "Batch: 125, Loss: 0.5674164295196533, Accuracy: 0.8203125\n",
      "Batch: 126, Loss: 0.559284508228302, Accuracy: 0.82177734375\n",
      "Batch: 127, Loss: 0.5312359929084778, Accuracy: 0.8232421875\n",
      "Batch: 128, Loss: 0.635674238204956, Accuracy: 0.7958984375\n",
      "Batch: 129, Loss: 0.6488242745399475, Accuracy: 0.78662109375\n",
      "Batch: 130, Loss: 0.6596555709838867, Accuracy: 0.787109375\n",
      "Batch: 131, Loss: 0.5743752717971802, Accuracy: 0.81494140625\n",
      "Batch: 132, Loss: 0.5211935043334961, Accuracy: 0.8310546875\n",
      "Batch: 133, Loss: 0.5304282307624817, Accuracy: 0.8349609375\n",
      "Batch: 134, Loss: 0.574460506439209, Accuracy: 0.814453125\n",
      "Batch: 135, Loss: 0.5936712026596069, Accuracy: 0.8056640625\n",
      "Batch: 136, Loss: 0.5322824120521545, Accuracy: 0.82666015625\n",
      "Batch: 137, Loss: 0.584209144115448, Accuracy: 0.8125\n",
      "Batch: 138, Loss: 0.5332605242729187, Accuracy: 0.8310546875\n",
      "Batch: 139, Loss: 0.5369859933853149, Accuracy: 0.830078125\n",
      "Batch: 140, Loss: 0.5151879787445068, Accuracy: 0.82861328125\n",
      "Batch: 141, Loss: 0.5947484970092773, Accuracy: 0.81494140625\n",
      "Batch: 142, Loss: 0.5478087663650513, Accuracy: 0.82275390625\n",
      "Batch: 143, Loss: 0.5520862340927124, Accuracy: 0.8271484375\n",
      "Batch: 144, Loss: 0.61949622631073, Accuracy: 0.79833984375\n",
      "Batch: 145, Loss: 0.5821092128753662, Accuracy: 0.8173828125\n",
      "Batch: 146, Loss: 0.6145983934402466, Accuracy: 0.80078125\n",
      "Batch: 147, Loss: 0.5617679357528687, Accuracy: 0.82275390625\n",
      "Batch: 148, Loss: 0.6333971619606018, Accuracy: 0.7919921875\n",
      "Batch: 149, Loss: 0.5859737992286682, Accuracy: 0.81103515625\n",
      "Batch: 150, Loss: 0.5177991986274719, Accuracy: 0.83837890625\n",
      "Batch: 151, Loss: 0.5243159532546997, Accuracy: 0.830078125\n",
      "Batch: 152, Loss: 0.5551033020019531, Accuracy: 0.8154296875\n",
      "Batch: 153, Loss: 0.5723917484283447, Accuracy: 0.81640625\n",
      "Batch: 154, Loss: 0.559325098991394, Accuracy: 0.8232421875\n",
      "Batch: 155, Loss: 0.6095566749572754, Accuracy: 0.806640625\n",
      "Batch: 156, Loss: 0.5300182700157166, Accuracy: 0.82373046875\n",
      "Batch: 157, Loss: 0.51619952917099, Accuracy: 0.82421875\n",
      "Batch: 158, Loss: 0.5360013842582703, Accuracy: 0.83056640625\n",
      "Batch: 159, Loss: 0.5433771014213562, Accuracy: 0.8310546875\n",
      "Batch: 160, Loss: 0.5700550079345703, Accuracy: 0.81982421875\n",
      "Batch: 161, Loss: 0.5956381559371948, Accuracy: 0.81640625\n",
      "Batch: 162, Loss: 0.5400114059448242, Accuracy: 0.8193359375\n",
      "Batch: 163, Loss: 0.5892598032951355, Accuracy: 0.798828125\n",
      "Batch: 164, Loss: 0.6377527713775635, Accuracy: 0.79052734375\n",
      "Batch: 165, Loss: 0.5783292055130005, Accuracy: 0.81494140625\n",
      "Batch: 166, Loss: 0.6139470934867859, Accuracy: 0.8037109375\n",
      "Batch: 167, Loss: 0.5617430210113525, Accuracy: 0.8232421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 168, Loss: 0.5097834467887878, Accuracy: 0.8408203125\n",
      "Batch: 169, Loss: 0.5664469003677368, Accuracy: 0.8154296875\n",
      "Batch: 170, Loss: 0.5886551141738892, Accuracy: 0.81103515625\n",
      "Batch: 171, Loss: 0.556858241558075, Accuracy: 0.81689453125\n",
      "Batch: 172, Loss: 0.5796507000923157, Accuracy: 0.8095703125\n",
      "Batch: 173, Loss: 0.5922211408615112, Accuracy: 0.81201171875\n",
      "Batch: 174, Loss: 0.5073278546333313, Accuracy: 0.83349609375\n",
      "Batch: 175, Loss: 0.5737425684928894, Accuracy: 0.8017578125\n",
      "Batch: 176, Loss: 0.618608832359314, Accuracy: 0.80029296875\n",
      "Batch: 177, Loss: 0.5806092023849487, Accuracy: 0.80908203125\n",
      "Batch: 178, Loss: 0.5422219038009644, Accuracy: 0.82568359375\n",
      "Batch: 179, Loss: 0.5637153387069702, Accuracy: 0.8134765625\n",
      "Batch: 180, Loss: 0.5706663131713867, Accuracy: 0.818359375\n",
      "Epoch 73/200\n",
      "Batch: 1, Loss: 0.8776845932006836, Accuracy: 0.74755859375\n",
      "Batch: 2, Loss: 0.5805232524871826, Accuracy: 0.8046875\n",
      "Batch: 3, Loss: 0.5839399695396423, Accuracy: 0.81005859375\n",
      "Batch: 4, Loss: 0.6053625345230103, Accuracy: 0.8046875\n",
      "Batch: 5, Loss: 0.5583587884902954, Accuracy: 0.82470703125\n",
      "Batch: 6, Loss: 0.5814623832702637, Accuracy: 0.806640625\n",
      "Batch: 7, Loss: 0.5643376708030701, Accuracy: 0.82275390625\n",
      "Batch: 8, Loss: 0.5470860004425049, Accuracy: 0.82666015625\n",
      "Batch: 9, Loss: 0.5815061330795288, Accuracy: 0.80859375\n",
      "Batch: 10, Loss: 0.550902783870697, Accuracy: 0.82275390625\n",
      "Batch: 11, Loss: 0.605527400970459, Accuracy: 0.802734375\n",
      "Batch: 12, Loss: 0.5387638807296753, Accuracy: 0.82666015625\n",
      "Batch: 13, Loss: 0.5791060924530029, Accuracy: 0.81396484375\n",
      "Batch: 14, Loss: 0.5916910767555237, Accuracy: 0.81201171875\n",
      "Batch: 15, Loss: 0.5985250473022461, Accuracy: 0.81103515625\n",
      "Batch: 16, Loss: 0.6078687906265259, Accuracy: 0.79638671875\n",
      "Batch: 17, Loss: 0.5437415838241577, Accuracy: 0.8330078125\n",
      "Batch: 18, Loss: 0.5899127721786499, Accuracy: 0.81689453125\n",
      "Batch: 19, Loss: 0.6027045249938965, Accuracy: 0.80419921875\n",
      "Batch: 20, Loss: 0.5275121927261353, Accuracy: 0.82177734375\n",
      "Batch: 21, Loss: 0.6055716872215271, Accuracy: 0.81298828125\n",
      "Batch: 22, Loss: 0.5391581654548645, Accuracy: 0.8212890625\n",
      "Batch: 23, Loss: 0.5271974205970764, Accuracy: 0.82275390625\n",
      "Batch: 24, Loss: 0.5575428605079651, Accuracy: 0.81689453125\n",
      "Batch: 25, Loss: 0.5589187145233154, Accuracy: 0.8232421875\n",
      "Batch: 26, Loss: 0.5666503310203552, Accuracy: 0.8095703125\n",
      "Batch: 27, Loss: 0.5968217253684998, Accuracy: 0.80419921875\n",
      "Batch: 28, Loss: 0.5619708299636841, Accuracy: 0.81396484375\n",
      "Batch: 29, Loss: 0.6333972215652466, Accuracy: 0.7998046875\n",
      "Batch: 30, Loss: 0.5919177532196045, Accuracy: 0.81640625\n",
      "Batch: 31, Loss: 0.6390010118484497, Accuracy: 0.798828125\n",
      "Batch: 32, Loss: 0.6183326244354248, Accuracy: 0.80908203125\n",
      "Batch: 33, Loss: 0.579384446144104, Accuracy: 0.80908203125\n",
      "Batch: 34, Loss: 0.6146867275238037, Accuracy: 0.79931640625\n",
      "Batch: 35, Loss: 0.614994466304779, Accuracy: 0.7958984375\n",
      "Batch: 36, Loss: 0.6022678017616272, Accuracy: 0.810546875\n",
      "Batch: 37, Loss: 0.6306309700012207, Accuracy: 0.7958984375\n",
      "Batch: 38, Loss: 0.6139163970947266, Accuracy: 0.7998046875\n",
      "Batch: 39, Loss: 0.5817638039588928, Accuracy: 0.81103515625\n",
      "Batch: 40, Loss: 0.6278399229049683, Accuracy: 0.798828125\n",
      "Batch: 41, Loss: 0.593768298625946, Accuracy: 0.80322265625\n",
      "Batch: 42, Loss: 0.5786623954772949, Accuracy: 0.80078125\n",
      "Batch: 43, Loss: 0.555752158164978, Accuracy: 0.822265625\n",
      "Batch: 44, Loss: 0.5140527486801147, Accuracy: 0.837890625\n",
      "Batch: 45, Loss: 0.5580640435218811, Accuracy: 0.8173828125\n",
      "Batch: 46, Loss: 0.5635519027709961, Accuracy: 0.810546875\n",
      "Batch: 47, Loss: 0.5546509027481079, Accuracy: 0.82080078125\n",
      "Batch: 48, Loss: 0.5929687023162842, Accuracy: 0.8076171875\n",
      "Batch: 49, Loss: 0.583561897277832, Accuracy: 0.81396484375\n",
      "Batch: 50, Loss: 0.5741844773292542, Accuracy: 0.81640625\n",
      "Batch: 51, Loss: 0.5650432705879211, Accuracy: 0.81640625\n",
      "Batch: 52, Loss: 0.5679157376289368, Accuracy: 0.8125\n",
      "Batch: 53, Loss: 0.564683198928833, Accuracy: 0.8125\n",
      "Batch: 54, Loss: 0.6258701682090759, Accuracy: 0.79296875\n",
      "Batch: 55, Loss: 0.5896686315536499, Accuracy: 0.80712890625\n",
      "Batch: 56, Loss: 0.572966456413269, Accuracy: 0.80810546875\n",
      "Batch: 57, Loss: 0.617743730545044, Accuracy: 0.7978515625\n",
      "Batch: 58, Loss: 0.59637451171875, Accuracy: 0.8134765625\n",
      "Batch: 59, Loss: 0.6653867959976196, Accuracy: 0.78515625\n",
      "Batch: 60, Loss: 0.5631639361381531, Accuracy: 0.81982421875\n",
      "Batch: 61, Loss: 0.5594626665115356, Accuracy: 0.8134765625\n",
      "Batch: 62, Loss: 0.5525401830673218, Accuracy: 0.8271484375\n",
      "Batch: 63, Loss: 0.5562277436256409, Accuracy: 0.8134765625\n",
      "Batch: 64, Loss: 0.58689284324646, Accuracy: 0.802734375\n",
      "Batch: 65, Loss: 0.6266651153564453, Accuracy: 0.79296875\n",
      "Batch: 66, Loss: 0.5763509273529053, Accuracy: 0.814453125\n",
      "Batch: 67, Loss: 0.6160430908203125, Accuracy: 0.79345703125\n",
      "Batch: 68, Loss: 0.5312756299972534, Accuracy: 0.82763671875\n",
      "Batch: 69, Loss: 0.5825657844543457, Accuracy: 0.79931640625\n",
      "Batch: 70, Loss: 0.5714045763015747, Accuracy: 0.81396484375\n",
      "Batch: 71, Loss: 0.5628862380981445, Accuracy: 0.80615234375\n",
      "Batch: 72, Loss: 0.6342354416847229, Accuracy: 0.7802734375\n",
      "Batch: 73, Loss: 0.5969063639640808, Accuracy: 0.80126953125\n",
      "Batch: 74, Loss: 0.5996928215026855, Accuracy: 0.8056640625\n",
      "Batch: 75, Loss: 0.5408437252044678, Accuracy: 0.81640625\n",
      "Batch: 76, Loss: 0.5147098302841187, Accuracy: 0.8359375\n",
      "Batch: 77, Loss: 0.5361382961273193, Accuracy: 0.83349609375\n",
      "Batch: 78, Loss: 0.5628119707107544, Accuracy: 0.81689453125\n",
      "Batch: 79, Loss: 0.5852632522583008, Accuracy: 0.810546875\n",
      "Batch: 80, Loss: 0.599197268486023, Accuracy: 0.8115234375\n",
      "Batch: 81, Loss: 0.5888509750366211, Accuracy: 0.81396484375\n",
      "Batch: 82, Loss: 0.5591772794723511, Accuracy: 0.8125\n",
      "Batch: 83, Loss: 0.5411472320556641, Accuracy: 0.82080078125\n",
      "Batch: 84, Loss: 0.5612549781799316, Accuracy: 0.81982421875\n",
      "Batch: 85, Loss: 0.5855944156646729, Accuracy: 0.8017578125\n",
      "Batch: 86, Loss: 0.6208968162536621, Accuracy: 0.8125\n",
      "Batch: 87, Loss: 0.5508803129196167, Accuracy: 0.81982421875\n",
      "Batch: 88, Loss: 0.5982979536056519, Accuracy: 0.80908203125\n",
      "Batch: 89, Loss: 0.5891923904418945, Accuracy: 0.810546875\n",
      "Batch: 90, Loss: 0.610724687576294, Accuracy: 0.7978515625\n",
      "Batch: 91, Loss: 0.5884995460510254, Accuracy: 0.80908203125\n",
      "Batch: 92, Loss: 0.6393981575965881, Accuracy: 0.7841796875\n",
      "Batch: 93, Loss: 0.6165993213653564, Accuracy: 0.7998046875\n",
      "Batch: 94, Loss: 0.6010191440582275, Accuracy: 0.806640625\n",
      "Batch: 95, Loss: 0.6521197557449341, Accuracy: 0.7900390625\n",
      "Batch: 96, Loss: 0.5570600032806396, Accuracy: 0.8251953125\n",
      "Batch: 97, Loss: 0.5681544542312622, Accuracy: 0.82666015625\n",
      "Batch: 98, Loss: 0.600081205368042, Accuracy: 0.7998046875\n",
      "Batch: 99, Loss: 0.5696517825126648, Accuracy: 0.81787109375\n",
      "Batch: 100, Loss: 0.6184167861938477, Accuracy: 0.802734375\n",
      "Batch: 101, Loss: 0.6238923072814941, Accuracy: 0.8056640625\n",
      "Batch: 102, Loss: 0.5442589521408081, Accuracy: 0.8271484375\n",
      "Batch: 103, Loss: 0.5964522361755371, Accuracy: 0.80859375\n",
      "Batch: 104, Loss: 0.5710276365280151, Accuracy: 0.8154296875\n",
      "Batch: 105, Loss: 0.5841109752655029, Accuracy: 0.80615234375\n",
      "Batch: 106, Loss: 0.5496121644973755, Accuracy: 0.82275390625\n",
      "Batch: 107, Loss: 0.5720057487487793, Accuracy: 0.82080078125\n",
      "Batch: 108, Loss: 0.544908344745636, Accuracy: 0.82763671875\n",
      "Batch: 109, Loss: 0.553588330745697, Accuracy: 0.81201171875\n",
      "Batch: 110, Loss: 0.5390846133232117, Accuracy: 0.82177734375\n",
      "Batch: 111, Loss: 0.5175700187683105, Accuracy: 0.830078125\n",
      "Batch: 112, Loss: 0.5583223700523376, Accuracy: 0.8271484375\n",
      "Batch: 113, Loss: 0.6026430130004883, Accuracy: 0.8037109375\n",
      "Batch: 114, Loss: 0.5855346918106079, Accuracy: 0.822265625\n",
      "Batch: 115, Loss: 0.572938084602356, Accuracy: 0.81982421875\n",
      "Batch: 116, Loss: 0.5533936023712158, Accuracy: 0.81884765625\n",
      "Batch: 117, Loss: 0.5768204927444458, Accuracy: 0.80712890625\n",
      "Batch: 118, Loss: 0.5796598196029663, Accuracy: 0.80517578125\n",
      "Batch: 119, Loss: 0.5781676173210144, Accuracy: 0.80908203125\n",
      "Batch: 120, Loss: 0.5482907295227051, Accuracy: 0.82373046875\n",
      "Batch: 121, Loss: 0.5746141672134399, Accuracy: 0.81298828125\n",
      "Batch: 122, Loss: 0.5398613810539246, Accuracy: 0.82275390625\n",
      "Batch: 123, Loss: 0.5425999760627747, Accuracy: 0.83203125\n",
      "Batch: 124, Loss: 0.541469156742096, Accuracy: 0.82958984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 125, Loss: 0.5824512243270874, Accuracy: 0.8212890625\n",
      "Batch: 126, Loss: 0.5618851184844971, Accuracy: 0.82373046875\n",
      "Batch: 127, Loss: 0.5263513326644897, Accuracy: 0.8369140625\n",
      "Batch: 128, Loss: 0.6279308795928955, Accuracy: 0.7978515625\n",
      "Batch: 129, Loss: 0.6193233728408813, Accuracy: 0.806640625\n",
      "Batch: 130, Loss: 0.6460484266281128, Accuracy: 0.79541015625\n",
      "Batch: 131, Loss: 0.5862056016921997, Accuracy: 0.8115234375\n",
      "Batch: 132, Loss: 0.5419277548789978, Accuracy: 0.8251953125\n",
      "Batch: 133, Loss: 0.5307830572128296, Accuracy: 0.83154296875\n",
      "Batch: 134, Loss: 0.5710359811782837, Accuracy: 0.818359375\n",
      "Batch: 135, Loss: 0.5780767202377319, Accuracy: 0.8115234375\n",
      "Batch: 136, Loss: 0.5368839502334595, Accuracy: 0.8330078125\n",
      "Batch: 137, Loss: 0.5946024656295776, Accuracy: 0.80615234375\n",
      "Batch: 138, Loss: 0.5374084711074829, Accuracy: 0.82568359375\n",
      "Batch: 139, Loss: 0.5573227405548096, Accuracy: 0.82080078125\n",
      "Batch: 140, Loss: 0.5139687061309814, Accuracy: 0.83056640625\n",
      "Batch: 141, Loss: 0.6173409819602966, Accuracy: 0.7890625\n",
      "Batch: 142, Loss: 0.5465671420097351, Accuracy: 0.8193359375\n",
      "Batch: 143, Loss: 0.5482854247093201, Accuracy: 0.82177734375\n",
      "Batch: 144, Loss: 0.6350350975990295, Accuracy: 0.79736328125\n",
      "Batch: 145, Loss: 0.5780115127563477, Accuracy: 0.8125\n",
      "Batch: 146, Loss: 0.5916306972503662, Accuracy: 0.802734375\n",
      "Batch: 147, Loss: 0.5652885437011719, Accuracy: 0.81787109375\n",
      "Batch: 148, Loss: 0.5923089981079102, Accuracy: 0.8125\n",
      "Batch: 149, Loss: 0.5686166286468506, Accuracy: 0.81201171875\n",
      "Batch: 150, Loss: 0.5174201726913452, Accuracy: 0.833984375\n",
      "Batch: 151, Loss: 0.5403648614883423, Accuracy: 0.82177734375\n",
      "Batch: 152, Loss: 0.5431944727897644, Accuracy: 0.826171875\n",
      "Batch: 153, Loss: 0.5493036508560181, Accuracy: 0.818359375\n",
      "Batch: 154, Loss: 0.5534777641296387, Accuracy: 0.81787109375\n",
      "Batch: 155, Loss: 0.6248973608016968, Accuracy: 0.80029296875\n",
      "Batch: 156, Loss: 0.5305940508842468, Accuracy: 0.82666015625\n",
      "Batch: 157, Loss: 0.521032452583313, Accuracy: 0.8291015625\n",
      "Batch: 158, Loss: 0.5080404877662659, Accuracy: 0.837890625\n",
      "Batch: 159, Loss: 0.5606957077980042, Accuracy: 0.81494140625\n",
      "Batch: 160, Loss: 0.5661958456039429, Accuracy: 0.82568359375\n",
      "Batch: 161, Loss: 0.58188796043396, Accuracy: 0.81005859375\n",
      "Batch: 162, Loss: 0.5423665642738342, Accuracy: 0.82470703125\n",
      "Batch: 163, Loss: 0.5893076658248901, Accuracy: 0.80810546875\n",
      "Batch: 164, Loss: 0.6274876594543457, Accuracy: 0.80419921875\n",
      "Batch: 165, Loss: 0.5877654552459717, Accuracy: 0.80810546875\n",
      "Batch: 166, Loss: 0.6030332446098328, Accuracy: 0.80029296875\n",
      "Batch: 167, Loss: 0.5741685032844543, Accuracy: 0.81689453125\n",
      "Batch: 168, Loss: 0.5094647407531738, Accuracy: 0.84228515625\n",
      "Batch: 169, Loss: 0.5793793201446533, Accuracy: 0.81591796875\n",
      "Batch: 170, Loss: 0.5807977914810181, Accuracy: 0.81884765625\n",
      "Batch: 171, Loss: 0.5409983396530151, Accuracy: 0.81982421875\n",
      "Batch: 172, Loss: 0.5322874188423157, Accuracy: 0.8134765625\n",
      "Batch: 173, Loss: 0.6206786632537842, Accuracy: 0.79931640625\n",
      "Batch: 174, Loss: 0.506538450717926, Accuracy: 0.826171875\n",
      "Batch: 175, Loss: 0.5848277807235718, Accuracy: 0.7978515625\n",
      "Batch: 176, Loss: 0.6102966070175171, Accuracy: 0.80078125\n",
      "Batch: 177, Loss: 0.5688924789428711, Accuracy: 0.81640625\n",
      "Batch: 178, Loss: 0.5222413539886475, Accuracy: 0.826171875\n",
      "Batch: 179, Loss: 0.5654671788215637, Accuracy: 0.8212890625\n",
      "Batch: 180, Loss: 0.5860860347747803, Accuracy: 0.81689453125\n",
      "Epoch 74/200\n",
      "Batch: 1, Loss: 0.833663821220398, Accuracy: 0.7578125\n",
      "Batch: 2, Loss: 0.5645106434822083, Accuracy: 0.81201171875\n",
      "Batch: 3, Loss: 0.5825163125991821, Accuracy: 0.81103515625\n",
      "Batch: 4, Loss: 0.5851314067840576, Accuracy: 0.8115234375\n",
      "Batch: 5, Loss: 0.5682513117790222, Accuracy: 0.81591796875\n",
      "Batch: 6, Loss: 0.5842489004135132, Accuracy: 0.80810546875\n",
      "Batch: 7, Loss: 0.562727689743042, Accuracy: 0.8203125\n",
      "Batch: 8, Loss: 0.5565634965896606, Accuracy: 0.81591796875\n",
      "Batch: 9, Loss: 0.6145060658454895, Accuracy: 0.80029296875\n",
      "Batch: 10, Loss: 0.5460394620895386, Accuracy: 0.8251953125\n",
      "Batch: 11, Loss: 0.5852674841880798, Accuracy: 0.81005859375\n",
      "Batch: 12, Loss: 0.5223841667175293, Accuracy: 0.83349609375\n",
      "Batch: 13, Loss: 0.5921062231063843, Accuracy: 0.810546875\n",
      "Batch: 14, Loss: 0.5797815322875977, Accuracy: 0.81494140625\n",
      "Batch: 15, Loss: 0.5774279236793518, Accuracy: 0.82177734375\n",
      "Batch: 16, Loss: 0.6106977462768555, Accuracy: 0.80224609375\n",
      "Batch: 17, Loss: 0.5608426332473755, Accuracy: 0.8154296875\n",
      "Batch: 18, Loss: 0.5836415886878967, Accuracy: 0.81298828125\n",
      "Batch: 19, Loss: 0.5904078483581543, Accuracy: 0.81396484375\n",
      "Batch: 20, Loss: 0.48542773723602295, Accuracy: 0.8408203125\n",
      "Batch: 21, Loss: 0.5937457084655762, Accuracy: 0.8134765625\n",
      "Batch: 22, Loss: 0.5439852476119995, Accuracy: 0.8251953125\n",
      "Batch: 23, Loss: 0.513455331325531, Accuracy: 0.83154296875\n",
      "Batch: 24, Loss: 0.5493861436843872, Accuracy: 0.82080078125\n",
      "Batch: 25, Loss: 0.537151038646698, Accuracy: 0.8271484375\n",
      "Batch: 26, Loss: 0.5466815233230591, Accuracy: 0.828125\n",
      "Batch: 27, Loss: 0.6057707071304321, Accuracy: 0.806640625\n",
      "Batch: 28, Loss: 0.5477757453918457, Accuracy: 0.8212890625\n",
      "Batch: 29, Loss: 0.5904964208602905, Accuracy: 0.80078125\n",
      "Batch: 30, Loss: 0.5902516841888428, Accuracy: 0.81005859375\n",
      "Batch: 31, Loss: 0.6551970839500427, Accuracy: 0.79541015625\n",
      "Batch: 32, Loss: 0.6272366642951965, Accuracy: 0.8046875\n",
      "Batch: 33, Loss: 0.6043877601623535, Accuracy: 0.80517578125\n",
      "Batch: 34, Loss: 0.6069859266281128, Accuracy: 0.798828125\n",
      "Batch: 35, Loss: 0.6176193356513977, Accuracy: 0.7919921875\n",
      "Batch: 36, Loss: 0.5759902000427246, Accuracy: 0.8154296875\n",
      "Batch: 37, Loss: 0.5911063551902771, Accuracy: 0.79931640625\n",
      "Batch: 38, Loss: 0.6132150888442993, Accuracy: 0.79833984375\n",
      "Batch: 39, Loss: 0.5858353972434998, Accuracy: 0.81298828125\n",
      "Batch: 40, Loss: 0.60950767993927, Accuracy: 0.79736328125\n",
      "Batch: 41, Loss: 0.6114859580993652, Accuracy: 0.7998046875\n",
      "Batch: 42, Loss: 0.5970171093940735, Accuracy: 0.7978515625\n",
      "Batch: 43, Loss: 0.5718961358070374, Accuracy: 0.81201171875\n",
      "Batch: 44, Loss: 0.510840117931366, Accuracy: 0.8271484375\n",
      "Batch: 45, Loss: 0.5827330350875854, Accuracy: 0.814453125\n",
      "Batch: 46, Loss: 0.550906777381897, Accuracy: 0.81396484375\n",
      "Batch: 47, Loss: 0.5793769359588623, Accuracy: 0.80908203125\n",
      "Batch: 48, Loss: 0.5659195780754089, Accuracy: 0.8203125\n",
      "Batch: 49, Loss: 0.5748300552368164, Accuracy: 0.80859375\n",
      "Batch: 50, Loss: 0.5797204971313477, Accuracy: 0.81201171875\n",
      "Batch: 51, Loss: 0.5468540191650391, Accuracy: 0.8212890625\n",
      "Batch: 52, Loss: 0.5508444905281067, Accuracy: 0.81591796875\n",
      "Batch: 53, Loss: 0.5533323884010315, Accuracy: 0.82421875\n",
      "Batch: 54, Loss: 0.6022623777389526, Accuracy: 0.810546875\n",
      "Batch: 55, Loss: 0.5881271362304688, Accuracy: 0.80810546875\n",
      "Batch: 56, Loss: 0.5726650357246399, Accuracy: 0.80810546875\n",
      "Batch: 57, Loss: 0.62782222032547, Accuracy: 0.81005859375\n",
      "Batch: 58, Loss: 0.6003605127334595, Accuracy: 0.8037109375\n",
      "Batch: 59, Loss: 0.6868501305580139, Accuracy: 0.78662109375\n",
      "Batch: 60, Loss: 0.585429847240448, Accuracy: 0.8115234375\n",
      "Batch: 61, Loss: 0.5563424825668335, Accuracy: 0.8095703125\n",
      "Batch: 62, Loss: 0.5551493167877197, Accuracy: 0.82470703125\n",
      "Batch: 63, Loss: 0.5692837834358215, Accuracy: 0.8173828125\n",
      "Batch: 64, Loss: 0.5757789611816406, Accuracy: 0.80615234375\n",
      "Batch: 65, Loss: 0.6111829280853271, Accuracy: 0.79443359375\n",
      "Batch: 66, Loss: 0.5894776582717896, Accuracy: 0.81298828125\n",
      "Batch: 67, Loss: 0.6275193691253662, Accuracy: 0.7958984375\n",
      "Batch: 68, Loss: 0.5325921773910522, Accuracy: 0.82275390625\n",
      "Batch: 69, Loss: 0.599500298500061, Accuracy: 0.802734375\n",
      "Batch: 70, Loss: 0.5461312532424927, Accuracy: 0.82421875\n",
      "Batch: 71, Loss: 0.574916422367096, Accuracy: 0.81005859375\n",
      "Batch: 72, Loss: 0.6073728799819946, Accuracy: 0.798828125\n",
      "Batch: 73, Loss: 0.5951988697052002, Accuracy: 0.79345703125\n",
      "Batch: 74, Loss: 0.5922653675079346, Accuracy: 0.80517578125\n",
      "Batch: 75, Loss: 0.5572766661643982, Accuracy: 0.8134765625\n",
      "Batch: 76, Loss: 0.5412254929542542, Accuracy: 0.83251953125\n",
      "Batch: 77, Loss: 0.5521273016929626, Accuracy: 0.8271484375\n",
      "Batch: 78, Loss: 0.5820549726486206, Accuracy: 0.8154296875\n",
      "Batch: 79, Loss: 0.5879448652267456, Accuracy: 0.8115234375\n",
      "Batch: 80, Loss: 0.6077557802200317, Accuracy: 0.8056640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 81, Loss: 0.5773642659187317, Accuracy: 0.83056640625\n",
      "Batch: 82, Loss: 0.5614185333251953, Accuracy: 0.8154296875\n",
      "Batch: 83, Loss: 0.5247611403465271, Accuracy: 0.8291015625\n",
      "Batch: 84, Loss: 0.5446727871894836, Accuracy: 0.82861328125\n",
      "Batch: 85, Loss: 0.5781282186508179, Accuracy: 0.8115234375\n",
      "Batch: 86, Loss: 0.6285602450370789, Accuracy: 0.802734375\n",
      "Batch: 87, Loss: 0.5399847030639648, Accuracy: 0.83056640625\n",
      "Batch: 88, Loss: 0.5915144681930542, Accuracy: 0.81396484375\n",
      "Batch: 89, Loss: 0.5672701597213745, Accuracy: 0.80712890625\n",
      "Batch: 90, Loss: 0.5903943777084351, Accuracy: 0.7958984375\n",
      "Batch: 91, Loss: 0.5821593403816223, Accuracy: 0.81298828125\n",
      "Batch: 92, Loss: 0.6243101954460144, Accuracy: 0.79296875\n",
      "Batch: 93, Loss: 0.6433142423629761, Accuracy: 0.80224609375\n",
      "Batch: 94, Loss: 0.6047393083572388, Accuracy: 0.806640625\n",
      "Batch: 95, Loss: 0.6293734908103943, Accuracy: 0.794921875\n",
      "Batch: 96, Loss: 0.5798668265342712, Accuracy: 0.81982421875\n",
      "Batch: 97, Loss: 0.5482966899871826, Accuracy: 0.82568359375\n",
      "Batch: 98, Loss: 0.5698851346969604, Accuracy: 0.8173828125\n",
      "Batch: 99, Loss: 0.5655171871185303, Accuracy: 0.8115234375\n",
      "Batch: 100, Loss: 0.6237928867340088, Accuracy: 0.8037109375\n",
      "Batch: 101, Loss: 0.6177936792373657, Accuracy: 0.8037109375\n",
      "Batch: 102, Loss: 0.5543770790100098, Accuracy: 0.8212890625\n",
      "Batch: 103, Loss: 0.5746616721153259, Accuracy: 0.81494140625\n",
      "Batch: 104, Loss: 0.5610378384590149, Accuracy: 0.82177734375\n",
      "Batch: 105, Loss: 0.5640830397605896, Accuracy: 0.8173828125\n",
      "Batch: 106, Loss: 0.5604284405708313, Accuracy: 0.8154296875\n",
      "Batch: 107, Loss: 0.5766501426696777, Accuracy: 0.81005859375\n",
      "Batch: 108, Loss: 0.5390592813491821, Accuracy: 0.81982421875\n",
      "Batch: 109, Loss: 0.5444808602333069, Accuracy: 0.81884765625\n",
      "Batch: 110, Loss: 0.5207267999649048, Accuracy: 0.8271484375\n",
      "Batch: 111, Loss: 0.520665168762207, Accuracy: 0.82421875\n",
      "Batch: 112, Loss: 0.5351663827896118, Accuracy: 0.82763671875\n",
      "Batch: 113, Loss: 0.5894050598144531, Accuracy: 0.81298828125\n",
      "Batch: 114, Loss: 0.5927691459655762, Accuracy: 0.81103515625\n",
      "Batch: 115, Loss: 0.5707341432571411, Accuracy: 0.8193359375\n",
      "Batch: 116, Loss: 0.5624741911888123, Accuracy: 0.81591796875\n",
      "Batch: 117, Loss: 0.5377379655838013, Accuracy: 0.8251953125\n",
      "Batch: 118, Loss: 0.5949757695198059, Accuracy: 0.80908203125\n",
      "Batch: 119, Loss: 0.5471898317337036, Accuracy: 0.8271484375\n",
      "Batch: 120, Loss: 0.5469897985458374, Accuracy: 0.82568359375\n",
      "Batch: 121, Loss: 0.5538856387138367, Accuracy: 0.822265625\n",
      "Batch: 122, Loss: 0.5205888748168945, Accuracy: 0.8310546875\n",
      "Batch: 123, Loss: 0.5307540893554688, Accuracy: 0.8291015625\n",
      "Batch: 124, Loss: 0.539791464805603, Accuracy: 0.830078125\n",
      "Batch: 125, Loss: 0.5595030784606934, Accuracy: 0.82275390625\n",
      "Batch: 126, Loss: 0.529037594795227, Accuracy: 0.83203125\n",
      "Batch: 127, Loss: 0.5222842693328857, Accuracy: 0.833984375\n",
      "Batch: 128, Loss: 0.6215153932571411, Accuracy: 0.791015625\n",
      "Batch: 129, Loss: 0.6282198429107666, Accuracy: 0.798828125\n",
      "Batch: 130, Loss: 0.6432206034660339, Accuracy: 0.7919921875\n",
      "Batch: 131, Loss: 0.577460527420044, Accuracy: 0.814453125\n",
      "Batch: 132, Loss: 0.5305005311965942, Accuracy: 0.8232421875\n",
      "Batch: 133, Loss: 0.5170674324035645, Accuracy: 0.833984375\n",
      "Batch: 134, Loss: 0.5719899535179138, Accuracy: 0.80224609375\n",
      "Batch: 135, Loss: 0.5841348767280579, Accuracy: 0.810546875\n",
      "Batch: 136, Loss: 0.5366607904434204, Accuracy: 0.828125\n",
      "Batch: 137, Loss: 0.5668096542358398, Accuracy: 0.8134765625\n",
      "Batch: 138, Loss: 0.5227745771408081, Accuracy: 0.83544921875\n",
      "Batch: 139, Loss: 0.5351581573486328, Accuracy: 0.8232421875\n",
      "Batch: 140, Loss: 0.5083886384963989, Accuracy: 0.83740234375\n",
      "Batch: 141, Loss: 0.5886976718902588, Accuracy: 0.802734375\n",
      "Batch: 142, Loss: 0.5380871295928955, Accuracy: 0.8251953125\n",
      "Batch: 143, Loss: 0.5336675643920898, Accuracy: 0.8330078125\n",
      "Batch: 144, Loss: 0.6314702033996582, Accuracy: 0.7958984375\n",
      "Batch: 145, Loss: 0.5912165641784668, Accuracy: 0.80322265625\n",
      "Batch: 146, Loss: 0.5915785431861877, Accuracy: 0.806640625\n",
      "Batch: 147, Loss: 0.5677585601806641, Accuracy: 0.81787109375\n",
      "Batch: 148, Loss: 0.5960264205932617, Accuracy: 0.80810546875\n",
      "Batch: 149, Loss: 0.5916820764541626, Accuracy: 0.8076171875\n",
      "Batch: 150, Loss: 0.5083316564559937, Accuracy: 0.8388671875\n",
      "Batch: 151, Loss: 0.520750880241394, Accuracy: 0.828125\n",
      "Batch: 152, Loss: 0.5641508102416992, Accuracy: 0.81884765625\n",
      "Batch: 153, Loss: 0.551071047782898, Accuracy: 0.82666015625\n",
      "Batch: 154, Loss: 0.5587738752365112, Accuracy: 0.81640625\n",
      "Batch: 155, Loss: 0.636041522026062, Accuracy: 0.7958984375\n",
      "Batch: 156, Loss: 0.5380241274833679, Accuracy: 0.81201171875\n",
      "Batch: 157, Loss: 0.5013337731361389, Accuracy: 0.8271484375\n",
      "Batch: 158, Loss: 0.5408101081848145, Accuracy: 0.83251953125\n",
      "Batch: 159, Loss: 0.5565365552902222, Accuracy: 0.81884765625\n",
      "Batch: 160, Loss: 0.5405423641204834, Accuracy: 0.826171875\n",
      "Batch: 161, Loss: 0.5767614245414734, Accuracy: 0.8076171875\n",
      "Batch: 162, Loss: 0.5414731502532959, Accuracy: 0.8212890625\n",
      "Batch: 163, Loss: 0.5867331027984619, Accuracy: 0.80810546875\n",
      "Batch: 164, Loss: 0.6316962242126465, Accuracy: 0.80615234375\n",
      "Batch: 165, Loss: 0.5845686793327332, Accuracy: 0.81103515625\n",
      "Batch: 166, Loss: 0.5658982992172241, Accuracy: 0.81396484375\n",
      "Batch: 167, Loss: 0.5522825121879578, Accuracy: 0.82470703125\n",
      "Batch: 168, Loss: 0.504417896270752, Accuracy: 0.8447265625\n",
      "Batch: 169, Loss: 0.5609555244445801, Accuracy: 0.81982421875\n",
      "Batch: 170, Loss: 0.5696812272071838, Accuracy: 0.81494140625\n",
      "Batch: 171, Loss: 0.5498847961425781, Accuracy: 0.8271484375\n",
      "Batch: 172, Loss: 0.5332589149475098, Accuracy: 0.830078125\n",
      "Batch: 173, Loss: 0.6021079421043396, Accuracy: 0.802734375\n",
      "Batch: 174, Loss: 0.5033062696456909, Accuracy: 0.8310546875\n",
      "Batch: 175, Loss: 0.5704468488693237, Accuracy: 0.81689453125\n",
      "Batch: 176, Loss: 0.605131208896637, Accuracy: 0.8017578125\n",
      "Batch: 177, Loss: 0.5554081201553345, Accuracy: 0.82177734375\n",
      "Batch: 178, Loss: 0.5332604646682739, Accuracy: 0.828125\n",
      "Batch: 179, Loss: 0.5554901361465454, Accuracy: 0.82421875\n",
      "Batch: 180, Loss: 0.5772485733032227, Accuracy: 0.81787109375\n",
      "Epoch 75/200\n",
      "Batch: 1, Loss: 0.8710205554962158, Accuracy: 0.7490234375\n",
      "Batch: 2, Loss: 0.5624550580978394, Accuracy: 0.81396484375\n",
      "Batch: 3, Loss: 0.5620919466018677, Accuracy: 0.8173828125\n",
      "Batch: 4, Loss: 0.5872076749801636, Accuracy: 0.8095703125\n",
      "Batch: 5, Loss: 0.5833262205123901, Accuracy: 0.8134765625\n",
      "Batch: 6, Loss: 0.5858299136161804, Accuracy: 0.80908203125\n",
      "Batch: 7, Loss: 0.570716142654419, Accuracy: 0.81396484375\n",
      "Batch: 8, Loss: 0.5538575649261475, Accuracy: 0.82470703125\n",
      "Batch: 9, Loss: 0.5884019732475281, Accuracy: 0.81396484375\n",
      "Batch: 10, Loss: 0.5491003394126892, Accuracy: 0.8212890625\n",
      "Batch: 11, Loss: 0.5895124673843384, Accuracy: 0.81005859375\n",
      "Batch: 12, Loss: 0.5223401188850403, Accuracy: 0.8271484375\n",
      "Batch: 13, Loss: 0.5888222455978394, Accuracy: 0.81201171875\n",
      "Batch: 14, Loss: 0.5662885904312134, Accuracy: 0.82666015625\n",
      "Batch: 15, Loss: 0.5862780809402466, Accuracy: 0.7998046875\n",
      "Batch: 16, Loss: 0.6115696430206299, Accuracy: 0.80322265625\n",
      "Batch: 17, Loss: 0.5584883689880371, Accuracy: 0.81787109375\n",
      "Batch: 18, Loss: 0.5912842750549316, Accuracy: 0.80908203125\n",
      "Batch: 19, Loss: 0.6087746620178223, Accuracy: 0.8056640625\n",
      "Batch: 20, Loss: 0.5013852119445801, Accuracy: 0.8369140625\n",
      "Batch: 21, Loss: 0.5740540027618408, Accuracy: 0.81982421875\n",
      "Batch: 22, Loss: 0.5263075232505798, Accuracy: 0.8330078125\n",
      "Batch: 23, Loss: 0.525790810585022, Accuracy: 0.82373046875\n",
      "Batch: 24, Loss: 0.5521366596221924, Accuracy: 0.8212890625\n",
      "Batch: 25, Loss: 0.5436770915985107, Accuracy: 0.82958984375\n",
      "Batch: 26, Loss: 0.5535024404525757, Accuracy: 0.818359375\n",
      "Batch: 27, Loss: 0.5788228511810303, Accuracy: 0.81201171875\n",
      "Batch: 28, Loss: 0.5278485417366028, Accuracy: 0.826171875\n",
      "Batch: 29, Loss: 0.6207520961761475, Accuracy: 0.8037109375\n",
      "Batch: 30, Loss: 0.5799404382705688, Accuracy: 0.81640625\n",
      "Batch: 31, Loss: 0.6469537019729614, Accuracy: 0.7939453125\n",
      "Batch: 32, Loss: 0.6048374772071838, Accuracy: 0.8037109375\n",
      "Batch: 33, Loss: 0.5797245502471924, Accuracy: 0.81298828125\n",
      "Batch: 34, Loss: 0.6020311117172241, Accuracy: 0.80859375\n",
      "Batch: 35, Loss: 0.6262540817260742, Accuracy: 0.796875\n",
      "Batch: 36, Loss: 0.6013458371162415, Accuracy: 0.80224609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 37, Loss: 0.5878515243530273, Accuracy: 0.80615234375\n",
      "Batch: 38, Loss: 0.6035658121109009, Accuracy: 0.8076171875\n",
      "Batch: 39, Loss: 0.5758002996444702, Accuracy: 0.81494140625\n",
      "Batch: 40, Loss: 0.632057785987854, Accuracy: 0.7939453125\n",
      "Batch: 41, Loss: 0.589775025844574, Accuracy: 0.806640625\n",
      "Batch: 42, Loss: 0.5831776857376099, Accuracy: 0.80859375\n",
      "Batch: 43, Loss: 0.5302227735519409, Accuracy: 0.83203125\n",
      "Batch: 44, Loss: 0.5067906379699707, Accuracy: 0.8427734375\n",
      "Batch: 45, Loss: 0.563573956489563, Accuracy: 0.8203125\n",
      "Batch: 46, Loss: 0.5410734415054321, Accuracy: 0.81201171875\n",
      "Batch: 47, Loss: 0.5592377781867981, Accuracy: 0.828125\n",
      "Batch: 48, Loss: 0.5734231472015381, Accuracy: 0.81640625\n",
      "Batch: 49, Loss: 0.5672615766525269, Accuracy: 0.8232421875\n",
      "Batch: 50, Loss: 0.5771948099136353, Accuracy: 0.81298828125\n",
      "Batch: 51, Loss: 0.5557764768600464, Accuracy: 0.81640625\n",
      "Batch: 52, Loss: 0.5499939918518066, Accuracy: 0.8212890625\n",
      "Batch: 53, Loss: 0.5630785822868347, Accuracy: 0.81640625\n",
      "Batch: 54, Loss: 0.5885363817214966, Accuracy: 0.80419921875\n",
      "Batch: 55, Loss: 0.5828763246536255, Accuracy: 0.81591796875\n",
      "Batch: 56, Loss: 0.567166805267334, Accuracy: 0.8134765625\n",
      "Batch: 57, Loss: 0.6244454383850098, Accuracy: 0.80517578125\n",
      "Batch: 58, Loss: 0.5971251726150513, Accuracy: 0.7998046875\n",
      "Batch: 59, Loss: 0.688553512096405, Accuracy: 0.78076171875\n",
      "Batch: 60, Loss: 0.5471943020820618, Accuracy: 0.828125\n",
      "Batch: 61, Loss: 0.5441187024116516, Accuracy: 0.826171875\n",
      "Batch: 62, Loss: 0.5386414527893066, Accuracy: 0.828125\n",
      "Batch: 63, Loss: 0.5677876472473145, Accuracy: 0.80810546875\n",
      "Batch: 64, Loss: 0.5790005922317505, Accuracy: 0.81298828125\n",
      "Batch: 65, Loss: 0.5997330546379089, Accuracy: 0.80859375\n",
      "Batch: 66, Loss: 0.5949972867965698, Accuracy: 0.8076171875\n",
      "Batch: 67, Loss: 0.6101303696632385, Accuracy: 0.7958984375\n",
      "Batch: 68, Loss: 0.5446808338165283, Accuracy: 0.81884765625\n",
      "Batch: 69, Loss: 0.5641155242919922, Accuracy: 0.81396484375\n",
      "Batch: 70, Loss: 0.528771698474884, Accuracy: 0.82763671875\n",
      "Batch: 71, Loss: 0.5545006990432739, Accuracy: 0.81689453125\n",
      "Batch: 72, Loss: 0.6127439141273499, Accuracy: 0.78759765625\n",
      "Batch: 73, Loss: 0.5630964040756226, Accuracy: 0.81201171875\n",
      "Batch: 74, Loss: 0.6033021807670593, Accuracy: 0.81640625\n",
      "Batch: 75, Loss: 0.5507493019104004, Accuracy: 0.8193359375\n",
      "Batch: 76, Loss: 0.528468132019043, Accuracy: 0.83154296875\n",
      "Batch: 77, Loss: 0.5540739893913269, Accuracy: 0.826171875\n",
      "Batch: 78, Loss: 0.5828259587287903, Accuracy: 0.8115234375\n",
      "Batch: 79, Loss: 0.5825128555297852, Accuracy: 0.81689453125\n",
      "Batch: 80, Loss: 0.5993178486824036, Accuracy: 0.8125\n",
      "Batch: 81, Loss: 0.5870578289031982, Accuracy: 0.82470703125\n",
      "Batch: 82, Loss: 0.5549955368041992, Accuracy: 0.81689453125\n",
      "Batch: 83, Loss: 0.519010066986084, Accuracy: 0.83349609375\n",
      "Batch: 84, Loss: 0.5526853203773499, Accuracy: 0.81982421875\n",
      "Batch: 85, Loss: 0.5647892951965332, Accuracy: 0.80517578125\n",
      "Batch: 86, Loss: 0.6034049391746521, Accuracy: 0.8076171875\n",
      "Batch: 87, Loss: 0.5392324328422546, Accuracy: 0.826171875\n",
      "Batch: 88, Loss: 0.596935510635376, Accuracy: 0.814453125\n",
      "Batch: 89, Loss: 0.5770885944366455, Accuracy: 0.810546875\n",
      "Batch: 90, Loss: 0.595995306968689, Accuracy: 0.798828125\n",
      "Batch: 91, Loss: 0.5781646966934204, Accuracy: 0.81103515625\n",
      "Batch: 92, Loss: 0.6551735401153564, Accuracy: 0.77978515625\n",
      "Batch: 93, Loss: 0.6160615086555481, Accuracy: 0.79443359375\n",
      "Batch: 94, Loss: 0.61016446352005, Accuracy: 0.80712890625\n",
      "Batch: 95, Loss: 0.6358327269554138, Accuracy: 0.794921875\n",
      "Batch: 96, Loss: 0.5585582256317139, Accuracy: 0.82763671875\n",
      "Batch: 97, Loss: 0.5546243190765381, Accuracy: 0.8251953125\n",
      "Batch: 98, Loss: 0.5996354818344116, Accuracy: 0.81103515625\n",
      "Batch: 99, Loss: 0.545001745223999, Accuracy: 0.82080078125\n",
      "Batch: 100, Loss: 0.6187217831611633, Accuracy: 0.79541015625\n",
      "Batch: 101, Loss: 0.6484365463256836, Accuracy: 0.783203125\n",
      "Batch: 102, Loss: 0.547004759311676, Accuracy: 0.8193359375\n",
      "Batch: 103, Loss: 0.573710560798645, Accuracy: 0.81396484375\n",
      "Batch: 104, Loss: 0.5703774690628052, Accuracy: 0.8212890625\n",
      "Batch: 105, Loss: 0.5731278657913208, Accuracy: 0.81640625\n",
      "Batch: 106, Loss: 0.5393132567405701, Accuracy: 0.82421875\n",
      "Batch: 107, Loss: 0.5629297494888306, Accuracy: 0.8173828125\n",
      "Batch: 108, Loss: 0.5375406742095947, Accuracy: 0.81787109375\n",
      "Batch: 109, Loss: 0.5386055707931519, Accuracy: 0.8271484375\n",
      "Batch: 110, Loss: 0.5460814237594604, Accuracy: 0.82470703125\n",
      "Batch: 111, Loss: 0.5160719752311707, Accuracy: 0.82568359375\n",
      "Batch: 112, Loss: 0.5234124064445496, Accuracy: 0.82421875\n",
      "Batch: 113, Loss: 0.5827653408050537, Accuracy: 0.806640625\n",
      "Batch: 114, Loss: 0.571528971195221, Accuracy: 0.82275390625\n",
      "Batch: 115, Loss: 0.5610654950141907, Accuracy: 0.81884765625\n",
      "Batch: 116, Loss: 0.5352069139480591, Accuracy: 0.82080078125\n",
      "Batch: 117, Loss: 0.5363240838050842, Accuracy: 0.826171875\n",
      "Batch: 118, Loss: 0.5649913549423218, Accuracy: 0.82421875\n",
      "Batch: 119, Loss: 0.5428950190544128, Accuracy: 0.8212890625\n",
      "Batch: 120, Loss: 0.5428580045700073, Accuracy: 0.82470703125\n",
      "Batch: 121, Loss: 0.5483031272888184, Accuracy: 0.82861328125\n",
      "Batch: 122, Loss: 0.5194398164749146, Accuracy: 0.830078125\n",
      "Batch: 123, Loss: 0.5369287133216858, Accuracy: 0.82861328125\n",
      "Batch: 124, Loss: 0.5250758528709412, Accuracy: 0.83251953125\n",
      "Batch: 125, Loss: 0.5732624530792236, Accuracy: 0.818359375\n",
      "Batch: 126, Loss: 0.5464039444923401, Accuracy: 0.8232421875\n",
      "Batch: 127, Loss: 0.5222575664520264, Accuracy: 0.82763671875\n",
      "Batch: 128, Loss: 0.6264995336532593, Accuracy: 0.7978515625\n",
      "Batch: 129, Loss: 0.6418655514717102, Accuracy: 0.7900390625\n",
      "Batch: 130, Loss: 0.6561993956565857, Accuracy: 0.7861328125\n",
      "Batch: 131, Loss: 0.5671771764755249, Accuracy: 0.82080078125\n",
      "Batch: 132, Loss: 0.5285124778747559, Accuracy: 0.83251953125\n",
      "Batch: 133, Loss: 0.5114829540252686, Accuracy: 0.83642578125\n",
      "Batch: 134, Loss: 0.6070772409439087, Accuracy: 0.7919921875\n",
      "Batch: 135, Loss: 0.5867441892623901, Accuracy: 0.8095703125\n",
      "Batch: 136, Loss: 0.527141809463501, Accuracy: 0.82568359375\n",
      "Batch: 137, Loss: 0.56407630443573, Accuracy: 0.81591796875\n",
      "Batch: 138, Loss: 0.5214256048202515, Accuracy: 0.84326171875\n",
      "Batch: 139, Loss: 0.5355334281921387, Accuracy: 0.822265625\n",
      "Batch: 140, Loss: 0.5092998743057251, Accuracy: 0.83349609375\n",
      "Batch: 141, Loss: 0.5714578032493591, Accuracy: 0.82421875\n",
      "Batch: 142, Loss: 0.5351002216339111, Accuracy: 0.82421875\n",
      "Batch: 143, Loss: 0.5496217012405396, Accuracy: 0.8271484375\n",
      "Batch: 144, Loss: 0.6116980314254761, Accuracy: 0.7958984375\n",
      "Batch: 145, Loss: 0.5468447804450989, Accuracy: 0.82373046875\n",
      "Batch: 146, Loss: 0.5958089828491211, Accuracy: 0.81591796875\n",
      "Batch: 147, Loss: 0.5591225028038025, Accuracy: 0.81787109375\n",
      "Batch: 148, Loss: 0.5999361276626587, Accuracy: 0.8046875\n",
      "Batch: 149, Loss: 0.5977158546447754, Accuracy: 0.80615234375\n",
      "Batch: 150, Loss: 0.5149590969085693, Accuracy: 0.83984375\n",
      "Batch: 151, Loss: 0.5056737661361694, Accuracy: 0.84130859375\n",
      "Batch: 152, Loss: 0.5353798866271973, Accuracy: 0.826171875\n",
      "Batch: 153, Loss: 0.5439761877059937, Accuracy: 0.8212890625\n",
      "Batch: 154, Loss: 0.5656701922416687, Accuracy: 0.81591796875\n",
      "Batch: 155, Loss: 0.5860313773155212, Accuracy: 0.80810546875\n",
      "Batch: 156, Loss: 0.5225799679756165, Accuracy: 0.82666015625\n",
      "Batch: 157, Loss: 0.4963846206665039, Accuracy: 0.83642578125\n",
      "Batch: 158, Loss: 0.5293322801589966, Accuracy: 0.83203125\n",
      "Batch: 159, Loss: 0.5517867803573608, Accuracy: 0.81591796875\n",
      "Batch: 160, Loss: 0.5317100286483765, Accuracy: 0.83349609375\n",
      "Batch: 161, Loss: 0.5659555196762085, Accuracy: 0.8193359375\n",
      "Batch: 162, Loss: 0.5332789421081543, Accuracy: 0.82080078125\n",
      "Batch: 163, Loss: 0.5508623123168945, Accuracy: 0.8193359375\n",
      "Batch: 164, Loss: 0.622640073299408, Accuracy: 0.79736328125\n",
      "Batch: 165, Loss: 0.5587406158447266, Accuracy: 0.828125\n",
      "Batch: 166, Loss: 0.5912016034126282, Accuracy: 0.80712890625\n",
      "Batch: 167, Loss: 0.5505379438400269, Accuracy: 0.8203125\n",
      "Batch: 168, Loss: 0.4963521361351013, Accuracy: 0.83544921875\n",
      "Batch: 169, Loss: 0.5617872476577759, Accuracy: 0.8134765625\n",
      "Batch: 170, Loss: 0.5820634961128235, Accuracy: 0.8115234375\n",
      "Batch: 171, Loss: 0.5438268780708313, Accuracy: 0.8251953125\n",
      "Batch: 172, Loss: 0.5241876840591431, Accuracy: 0.8291015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 173, Loss: 0.5922402143478394, Accuracy: 0.806640625\n",
      "Batch: 174, Loss: 0.5066063404083252, Accuracy: 0.83203125\n",
      "Batch: 175, Loss: 0.5832141637802124, Accuracy: 0.80615234375\n",
      "Batch: 176, Loss: 0.6217009425163269, Accuracy: 0.80419921875\n",
      "Batch: 177, Loss: 0.5495771169662476, Accuracy: 0.82568359375\n",
      "Batch: 178, Loss: 0.5144624710083008, Accuracy: 0.8349609375\n",
      "Batch: 179, Loss: 0.570286750793457, Accuracy: 0.82275390625\n",
      "Batch: 180, Loss: 0.5731659531593323, Accuracy: 0.82373046875\n",
      "Epoch 76/200\n",
      "Batch: 1, Loss: 0.8484660983085632, Accuracy: 0.76806640625\n",
      "Batch: 2, Loss: 0.575727105140686, Accuracy: 0.80908203125\n",
      "Batch: 3, Loss: 0.5529706478118896, Accuracy: 0.81884765625\n",
      "Batch: 4, Loss: 0.619220495223999, Accuracy: 0.80517578125\n",
      "Batch: 5, Loss: 0.5565974712371826, Accuracy: 0.8232421875\n",
      "Batch: 6, Loss: 0.5819857120513916, Accuracy: 0.8154296875\n",
      "Batch: 7, Loss: 0.5683383941650391, Accuracy: 0.8154296875\n",
      "Batch: 8, Loss: 0.5640757083892822, Accuracy: 0.81103515625\n",
      "Batch: 9, Loss: 0.5723062753677368, Accuracy: 0.81982421875\n",
      "Batch: 10, Loss: 0.5333073735237122, Accuracy: 0.8271484375\n",
      "Batch: 11, Loss: 0.5877554416656494, Accuracy: 0.802734375\n",
      "Batch: 12, Loss: 0.5079354047775269, Accuracy: 0.83349609375\n",
      "Batch: 13, Loss: 0.5857729315757751, Accuracy: 0.81640625\n",
      "Batch: 14, Loss: 0.5556833148002625, Accuracy: 0.82373046875\n",
      "Batch: 15, Loss: 0.600676417350769, Accuracy: 0.8056640625\n",
      "Batch: 16, Loss: 0.6020447015762329, Accuracy: 0.79833984375\n",
      "Batch: 17, Loss: 0.5554980039596558, Accuracy: 0.81884765625\n",
      "Batch: 18, Loss: 0.5877863168716431, Accuracy: 0.81494140625\n",
      "Batch: 19, Loss: 0.5986052751541138, Accuracy: 0.8125\n",
      "Batch: 20, Loss: 0.5097562670707703, Accuracy: 0.82470703125\n",
      "Batch: 21, Loss: 0.5838032960891724, Accuracy: 0.81689453125\n",
      "Batch: 22, Loss: 0.5236231088638306, Accuracy: 0.8251953125\n",
      "Batch: 23, Loss: 0.5151603817939758, Accuracy: 0.8291015625\n",
      "Batch: 24, Loss: 0.5448375940322876, Accuracy: 0.82275390625\n",
      "Batch: 25, Loss: 0.5335717797279358, Accuracy: 0.833984375\n",
      "Batch: 26, Loss: 0.5453755855560303, Accuracy: 0.8115234375\n",
      "Batch: 27, Loss: 0.5766230821609497, Accuracy: 0.8193359375\n",
      "Batch: 28, Loss: 0.55595862865448, Accuracy: 0.81494140625\n",
      "Batch: 29, Loss: 0.5940442681312561, Accuracy: 0.81494140625\n",
      "Batch: 30, Loss: 0.6016499996185303, Accuracy: 0.8056640625\n",
      "Batch: 31, Loss: 0.6356356143951416, Accuracy: 0.80322265625\n",
      "Batch: 32, Loss: 0.625179648399353, Accuracy: 0.806640625\n",
      "Batch: 33, Loss: 0.5930202603340149, Accuracy: 0.81005859375\n",
      "Batch: 34, Loss: 0.5894711017608643, Accuracy: 0.81396484375\n",
      "Batch: 35, Loss: 0.6110442876815796, Accuracy: 0.8046875\n",
      "Batch: 36, Loss: 0.5539841651916504, Accuracy: 0.8125\n",
      "Batch: 37, Loss: 0.5884038209915161, Accuracy: 0.8037109375\n",
      "Batch: 38, Loss: 0.6130815744400024, Accuracy: 0.79931640625\n",
      "Batch: 39, Loss: 0.5661647319793701, Accuracy: 0.81396484375\n",
      "Batch: 40, Loss: 0.6186836361885071, Accuracy: 0.8076171875\n",
      "Batch: 41, Loss: 0.5875228643417358, Accuracy: 0.8076171875\n",
      "Batch: 42, Loss: 0.5822920799255371, Accuracy: 0.80029296875\n",
      "Batch: 43, Loss: 0.5470501184463501, Accuracy: 0.82275390625\n",
      "Batch: 44, Loss: 0.5164130926132202, Accuracy: 0.8330078125\n",
      "Batch: 45, Loss: 0.5586351156234741, Accuracy: 0.81396484375\n",
      "Batch: 46, Loss: 0.5299304723739624, Accuracy: 0.81640625\n",
      "Batch: 47, Loss: 0.572274386882782, Accuracy: 0.80126953125\n",
      "Batch: 48, Loss: 0.5756320953369141, Accuracy: 0.81396484375\n",
      "Batch: 49, Loss: 0.5579130053520203, Accuracy: 0.82275390625\n",
      "Batch: 50, Loss: 0.5824799537658691, Accuracy: 0.80810546875\n",
      "Batch: 51, Loss: 0.5390499830245972, Accuracy: 0.82080078125\n",
      "Batch: 52, Loss: 0.5368291139602661, Accuracy: 0.81689453125\n",
      "Batch: 53, Loss: 0.5559770464897156, Accuracy: 0.82275390625\n",
      "Batch: 54, Loss: 0.600901186466217, Accuracy: 0.80224609375\n",
      "Batch: 55, Loss: 0.5851688385009766, Accuracy: 0.81396484375\n",
      "Batch: 56, Loss: 0.5330650210380554, Accuracy: 0.82177734375\n",
      "Batch: 57, Loss: 0.6103829741477966, Accuracy: 0.798828125\n",
      "Batch: 58, Loss: 0.5593684911727905, Accuracy: 0.8173828125\n",
      "Batch: 59, Loss: 0.6697372198104858, Accuracy: 0.794921875\n",
      "Batch: 60, Loss: 0.5635346174240112, Accuracy: 0.826171875\n",
      "Batch: 61, Loss: 0.5221899747848511, Accuracy: 0.83251953125\n",
      "Batch: 62, Loss: 0.5375723242759705, Accuracy: 0.82275390625\n",
      "Batch: 63, Loss: 0.5473689436912537, Accuracy: 0.8125\n",
      "Batch: 64, Loss: 0.5622113347053528, Accuracy: 0.81689453125\n",
      "Batch: 65, Loss: 0.608898401260376, Accuracy: 0.802734375\n",
      "Batch: 66, Loss: 0.5610396265983582, Accuracy: 0.81884765625\n",
      "Batch: 67, Loss: 0.5921332836151123, Accuracy: 0.80712890625\n",
      "Batch: 68, Loss: 0.5162948369979858, Accuracy: 0.830078125\n",
      "Batch: 69, Loss: 0.5747926235198975, Accuracy: 0.82080078125\n",
      "Batch: 70, Loss: 0.5334892272949219, Accuracy: 0.82275390625\n",
      "Batch: 71, Loss: 0.5561754703521729, Accuracy: 0.80517578125\n",
      "Batch: 72, Loss: 0.5996580123901367, Accuracy: 0.798828125\n",
      "Batch: 73, Loss: 0.5639994144439697, Accuracy: 0.8056640625\n",
      "Batch: 74, Loss: 0.5720778107643127, Accuracy: 0.80712890625\n",
      "Batch: 75, Loss: 0.5265533328056335, Accuracy: 0.814453125\n",
      "Batch: 76, Loss: 0.5381506681442261, Accuracy: 0.83251953125\n",
      "Batch: 77, Loss: 0.5433799624443054, Accuracy: 0.83056640625\n",
      "Batch: 78, Loss: 0.5671709179878235, Accuracy: 0.81005859375\n",
      "Batch: 79, Loss: 0.5772411823272705, Accuracy: 0.81298828125\n",
      "Batch: 80, Loss: 0.5884672999382019, Accuracy: 0.80517578125\n",
      "Batch: 81, Loss: 0.5756676197052002, Accuracy: 0.8154296875\n",
      "Batch: 82, Loss: 0.5587616562843323, Accuracy: 0.818359375\n",
      "Batch: 83, Loss: 0.5086650252342224, Accuracy: 0.82666015625\n",
      "Batch: 84, Loss: 0.5329168438911438, Accuracy: 0.82421875\n",
      "Batch: 85, Loss: 0.5783162117004395, Accuracy: 0.81494140625\n",
      "Batch: 86, Loss: 0.5915936231613159, Accuracy: 0.81396484375\n",
      "Batch: 87, Loss: 0.5403825044631958, Accuracy: 0.82958984375\n",
      "Batch: 88, Loss: 0.6051846146583557, Accuracy: 0.7998046875\n",
      "Batch: 89, Loss: 0.5471316576004028, Accuracy: 0.81982421875\n",
      "Batch: 90, Loss: 0.5966194272041321, Accuracy: 0.8037109375\n",
      "Batch: 91, Loss: 0.5537326335906982, Accuracy: 0.82666015625\n",
      "Batch: 92, Loss: 0.6336534023284912, Accuracy: 0.7900390625\n",
      "Batch: 93, Loss: 0.6194107532501221, Accuracy: 0.79638671875\n",
      "Batch: 94, Loss: 0.5876219272613525, Accuracy: 0.81640625\n",
      "Batch: 95, Loss: 0.6282573938369751, Accuracy: 0.79443359375\n",
      "Batch: 96, Loss: 0.5703179240226746, Accuracy: 0.8193359375\n",
      "Batch: 97, Loss: 0.5596191883087158, Accuracy: 0.82373046875\n",
      "Batch: 98, Loss: 0.5997687578201294, Accuracy: 0.80078125\n",
      "Batch: 99, Loss: 0.5480402708053589, Accuracy: 0.83251953125\n",
      "Batch: 100, Loss: 0.6112437844276428, Accuracy: 0.80322265625\n",
      "Batch: 101, Loss: 0.6303282976150513, Accuracy: 0.7958984375\n",
      "Batch: 102, Loss: 0.5311213135719299, Accuracy: 0.82666015625\n",
      "Batch: 103, Loss: 0.5683634281158447, Accuracy: 0.814453125\n",
      "Batch: 104, Loss: 0.5517937541007996, Accuracy: 0.822265625\n",
      "Batch: 105, Loss: 0.5871980786323547, Accuracy: 0.802734375\n",
      "Batch: 106, Loss: 0.5422528386116028, Accuracy: 0.81787109375\n",
      "Batch: 107, Loss: 0.5811119079589844, Accuracy: 0.81884765625\n",
      "Batch: 108, Loss: 0.5513029098510742, Accuracy: 0.82568359375\n",
      "Batch: 109, Loss: 0.5303651094436646, Accuracy: 0.8359375\n",
      "Batch: 110, Loss: 0.542689323425293, Accuracy: 0.8095703125\n",
      "Batch: 111, Loss: 0.5318268537521362, Accuracy: 0.82763671875\n",
      "Batch: 112, Loss: 0.5429818630218506, Accuracy: 0.828125\n",
      "Batch: 113, Loss: 0.6032754182815552, Accuracy: 0.79638671875\n",
      "Batch: 114, Loss: 0.5517991781234741, Accuracy: 0.8212890625\n",
      "Batch: 115, Loss: 0.5665316581726074, Accuracy: 0.818359375\n",
      "Batch: 116, Loss: 0.5565129518508911, Accuracy: 0.8251953125\n",
      "Batch: 117, Loss: 0.5310701131820679, Accuracy: 0.83203125\n",
      "Batch: 118, Loss: 0.5611494183540344, Accuracy: 0.81982421875\n",
      "Batch: 119, Loss: 0.5549558401107788, Accuracy: 0.8193359375\n",
      "Batch: 120, Loss: 0.5306211709976196, Accuracy: 0.8271484375\n",
      "Batch: 121, Loss: 0.560229480266571, Accuracy: 0.8115234375\n",
      "Batch: 122, Loss: 0.5214765667915344, Accuracy: 0.818359375\n",
      "Batch: 123, Loss: 0.5375381708145142, Accuracy: 0.822265625\n",
      "Batch: 124, Loss: 0.5271670818328857, Accuracy: 0.82763671875\n",
      "Batch: 125, Loss: 0.5546149611473083, Accuracy: 0.822265625\n",
      "Batch: 126, Loss: 0.5554851293563843, Accuracy: 0.8232421875\n",
      "Batch: 127, Loss: 0.5091564655303955, Accuracy: 0.83447265625\n",
      "Batch: 128, Loss: 0.6155444979667664, Accuracy: 0.79296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 129, Loss: 0.6025159358978271, Accuracy: 0.802734375\n",
      "Batch: 130, Loss: 0.6458317041397095, Accuracy: 0.79248046875\n",
      "Batch: 131, Loss: 0.5742660760879517, Accuracy: 0.8095703125\n",
      "Batch: 132, Loss: 0.5252690315246582, Accuracy: 0.83251953125\n",
      "Batch: 133, Loss: 0.5337665677070618, Accuracy: 0.8310546875\n",
      "Batch: 134, Loss: 0.5804240703582764, Accuracy: 0.814453125\n",
      "Batch: 135, Loss: 0.5675129294395447, Accuracy: 0.80712890625\n",
      "Batch: 136, Loss: 0.5205658674240112, Accuracy: 0.8291015625\n",
      "Batch: 137, Loss: 0.574785053730011, Accuracy: 0.8076171875\n",
      "Batch: 138, Loss: 0.5040316581726074, Accuracy: 0.8408203125\n",
      "Batch: 139, Loss: 0.5431175827980042, Accuracy: 0.81982421875\n",
      "Batch: 140, Loss: 0.5030511617660522, Accuracy: 0.8359375\n",
      "Batch: 141, Loss: 0.5835062265396118, Accuracy: 0.8125\n",
      "Batch: 142, Loss: 0.5300507545471191, Accuracy: 0.83837890625\n",
      "Batch: 143, Loss: 0.5320896506309509, Accuracy: 0.83251953125\n",
      "Batch: 144, Loss: 0.6144956946372986, Accuracy: 0.8037109375\n",
      "Batch: 145, Loss: 0.5832417607307434, Accuracy: 0.81494140625\n",
      "Batch: 146, Loss: 0.601589560508728, Accuracy: 0.8046875\n",
      "Batch: 147, Loss: 0.5609328746795654, Accuracy: 0.814453125\n",
      "Batch: 148, Loss: 0.5980641841888428, Accuracy: 0.81298828125\n",
      "Batch: 149, Loss: 0.5873434543609619, Accuracy: 0.80810546875\n",
      "Batch: 150, Loss: 0.5074499845504761, Accuracy: 0.83935546875\n",
      "Batch: 151, Loss: 0.511522114276886, Accuracy: 0.8359375\n",
      "Batch: 152, Loss: 0.5319861769676208, Accuracy: 0.82861328125\n",
      "Batch: 153, Loss: 0.5561858415603638, Accuracy: 0.82373046875\n",
      "Batch: 154, Loss: 0.5587565302848816, Accuracy: 0.81005859375\n",
      "Batch: 155, Loss: 0.6117521524429321, Accuracy: 0.796875\n",
      "Batch: 156, Loss: 0.52165687084198, Accuracy: 0.826171875\n",
      "Batch: 157, Loss: 0.5030795931816101, Accuracy: 0.828125\n",
      "Batch: 158, Loss: 0.5038291811943054, Accuracy: 0.84521484375\n",
      "Batch: 159, Loss: 0.5254216194152832, Accuracy: 0.826171875\n",
      "Batch: 160, Loss: 0.553482711315155, Accuracy: 0.8251953125\n",
      "Batch: 161, Loss: 0.5742700099945068, Accuracy: 0.814453125\n",
      "Batch: 162, Loss: 0.5482696294784546, Accuracy: 0.818359375\n",
      "Batch: 163, Loss: 0.5878942608833313, Accuracy: 0.80419921875\n",
      "Batch: 164, Loss: 0.6316444873809814, Accuracy: 0.79833984375\n",
      "Batch: 165, Loss: 0.5606698989868164, Accuracy: 0.8232421875\n",
      "Batch: 166, Loss: 0.582480788230896, Accuracy: 0.81201171875\n",
      "Batch: 167, Loss: 0.5650404691696167, Accuracy: 0.82080078125\n",
      "Batch: 168, Loss: 0.5202617049217224, Accuracy: 0.8330078125\n",
      "Batch: 169, Loss: 0.5607089400291443, Accuracy: 0.81689453125\n",
      "Batch: 170, Loss: 0.5881767272949219, Accuracy: 0.81201171875\n",
      "Batch: 171, Loss: 0.5629043579101562, Accuracy: 0.8173828125\n",
      "Batch: 172, Loss: 0.5094860792160034, Accuracy: 0.8330078125\n",
      "Batch: 173, Loss: 0.5755290985107422, Accuracy: 0.81201171875\n",
      "Batch: 174, Loss: 0.49782800674438477, Accuracy: 0.8349609375\n",
      "Batch: 175, Loss: 0.5607603788375854, Accuracy: 0.81494140625\n",
      "Batch: 176, Loss: 0.5990853309631348, Accuracy: 0.8115234375\n",
      "Batch: 177, Loss: 0.5724371075630188, Accuracy: 0.82177734375\n",
      "Batch: 178, Loss: 0.5234062671661377, Accuracy: 0.83544921875\n",
      "Batch: 179, Loss: 0.5677773952484131, Accuracy: 0.8251953125\n",
      "Batch: 180, Loss: 0.573950469493866, Accuracy: 0.82373046875\n",
      "Epoch 77/200\n",
      "Batch: 1, Loss: 0.8500690460205078, Accuracy: 0.75439453125\n",
      "Batch: 2, Loss: 0.556437075138092, Accuracy: 0.822265625\n",
      "Batch: 3, Loss: 0.5576179027557373, Accuracy: 0.81640625\n",
      "Batch: 4, Loss: 0.5941235423088074, Accuracy: 0.79931640625\n",
      "Batch: 5, Loss: 0.5511306524276733, Accuracy: 0.8232421875\n",
      "Batch: 6, Loss: 0.5686361789703369, Accuracy: 0.81298828125\n",
      "Batch: 7, Loss: 0.5527632236480713, Accuracy: 0.82421875\n",
      "Batch: 8, Loss: 0.5323102474212646, Accuracy: 0.82177734375\n",
      "Batch: 9, Loss: 0.5909709930419922, Accuracy: 0.80810546875\n",
      "Batch: 10, Loss: 0.5470134019851685, Accuracy: 0.82177734375\n",
      "Batch: 11, Loss: 0.5751003623008728, Accuracy: 0.8134765625\n",
      "Batch: 12, Loss: 0.511040449142456, Accuracy: 0.83349609375\n",
      "Batch: 13, Loss: 0.5587577819824219, Accuracy: 0.82177734375\n",
      "Batch: 14, Loss: 0.5359982252120972, Accuracy: 0.8310546875\n",
      "Batch: 15, Loss: 0.5570693016052246, Accuracy: 0.8212890625\n",
      "Batch: 16, Loss: 0.5960092544555664, Accuracy: 0.80419921875\n",
      "Batch: 17, Loss: 0.5273059606552124, Accuracy: 0.8369140625\n",
      "Batch: 18, Loss: 0.598985493183136, Accuracy: 0.806640625\n",
      "Batch: 19, Loss: 0.5826973915100098, Accuracy: 0.8095703125\n",
      "Batch: 20, Loss: 0.4910820424556732, Accuracy: 0.84033203125\n",
      "Batch: 21, Loss: 0.5802182555198669, Accuracy: 0.822265625\n",
      "Batch: 22, Loss: 0.5242925882339478, Accuracy: 0.82666015625\n",
      "Batch: 23, Loss: 0.5127280950546265, Accuracy: 0.82373046875\n",
      "Batch: 24, Loss: 0.5381611585617065, Accuracy: 0.82373046875\n",
      "Batch: 25, Loss: 0.527095377445221, Accuracy: 0.8310546875\n",
      "Batch: 26, Loss: 0.5586416721343994, Accuracy: 0.81591796875\n",
      "Batch: 27, Loss: 0.5966231822967529, Accuracy: 0.80419921875\n",
      "Batch: 28, Loss: 0.5488170385360718, Accuracy: 0.82373046875\n",
      "Batch: 29, Loss: 0.5901248455047607, Accuracy: 0.81494140625\n",
      "Batch: 30, Loss: 0.5723351836204529, Accuracy: 0.81982421875\n",
      "Batch: 31, Loss: 0.6452916264533997, Accuracy: 0.802734375\n",
      "Batch: 32, Loss: 0.5865486860275269, Accuracy: 0.8134765625\n",
      "Batch: 33, Loss: 0.5929093360900879, Accuracy: 0.8076171875\n",
      "Batch: 34, Loss: 0.6115336418151855, Accuracy: 0.79541015625\n",
      "Batch: 35, Loss: 0.6160702109336853, Accuracy: 0.8056640625\n",
      "Batch: 36, Loss: 0.5672501921653748, Accuracy: 0.8203125\n",
      "Batch: 37, Loss: 0.5727707743644714, Accuracy: 0.80322265625\n",
      "Batch: 38, Loss: 0.5808168649673462, Accuracy: 0.8154296875\n",
      "Batch: 39, Loss: 0.5506024360656738, Accuracy: 0.8232421875\n",
      "Batch: 40, Loss: 0.6161654591560364, Accuracy: 0.79736328125\n",
      "Batch: 41, Loss: 0.5683444738388062, Accuracy: 0.80908203125\n",
      "Batch: 42, Loss: 0.5682400465011597, Accuracy: 0.80908203125\n",
      "Batch: 43, Loss: 0.5373326539993286, Accuracy: 0.8349609375\n",
      "Batch: 44, Loss: 0.5053764581680298, Accuracy: 0.8369140625\n",
      "Batch: 45, Loss: 0.5534287095069885, Accuracy: 0.82177734375\n",
      "Batch: 46, Loss: 0.5290453433990479, Accuracy: 0.8115234375\n",
      "Batch: 47, Loss: 0.5823105573654175, Accuracy: 0.814453125\n",
      "Batch: 48, Loss: 0.5541446805000305, Accuracy: 0.8203125\n",
      "Batch: 49, Loss: 0.5507575273513794, Accuracy: 0.82568359375\n",
      "Batch: 50, Loss: 0.5641096830368042, Accuracy: 0.81591796875\n",
      "Batch: 51, Loss: 0.5498079061508179, Accuracy: 0.82080078125\n",
      "Batch: 52, Loss: 0.5522028207778931, Accuracy: 0.8173828125\n",
      "Batch: 53, Loss: 0.5563453435897827, Accuracy: 0.81005859375\n",
      "Batch: 54, Loss: 0.5803698301315308, Accuracy: 0.81591796875\n",
      "Batch: 55, Loss: 0.571758508682251, Accuracy: 0.81787109375\n",
      "Batch: 56, Loss: 0.549485445022583, Accuracy: 0.8232421875\n",
      "Batch: 57, Loss: 0.5861377716064453, Accuracy: 0.80615234375\n",
      "Batch: 58, Loss: 0.5843411684036255, Accuracy: 0.806640625\n",
      "Batch: 59, Loss: 0.6524369120597839, Accuracy: 0.802734375\n",
      "Batch: 60, Loss: 0.5769349336624146, Accuracy: 0.822265625\n",
      "Batch: 61, Loss: 0.5647321939468384, Accuracy: 0.81982421875\n",
      "Batch: 62, Loss: 0.5489600896835327, Accuracy: 0.8251953125\n",
      "Batch: 63, Loss: 0.5557264089584351, Accuracy: 0.81591796875\n",
      "Batch: 64, Loss: 0.5805888772010803, Accuracy: 0.81396484375\n",
      "Batch: 65, Loss: 0.6115660667419434, Accuracy: 0.79931640625\n",
      "Batch: 66, Loss: 0.5698078870773315, Accuracy: 0.81591796875\n",
      "Batch: 67, Loss: 0.5976470708847046, Accuracy: 0.8017578125\n",
      "Batch: 68, Loss: 0.5382272601127625, Accuracy: 0.82421875\n",
      "Batch: 69, Loss: 0.5614629983901978, Accuracy: 0.81591796875\n",
      "Batch: 70, Loss: 0.5316652059555054, Accuracy: 0.81982421875\n",
      "Batch: 71, Loss: 0.5438216924667358, Accuracy: 0.82763671875\n",
      "Batch: 72, Loss: 0.5971615314483643, Accuracy: 0.80322265625\n",
      "Batch: 73, Loss: 0.5782779455184937, Accuracy: 0.81298828125\n",
      "Batch: 74, Loss: 0.5918254256248474, Accuracy: 0.81640625\n",
      "Batch: 75, Loss: 0.5298968553543091, Accuracy: 0.83642578125\n",
      "Batch: 76, Loss: 0.49681800603866577, Accuracy: 0.85107421875\n",
      "Batch: 77, Loss: 0.5281802415847778, Accuracy: 0.83447265625\n",
      "Batch: 78, Loss: 0.5693358182907104, Accuracy: 0.81884765625\n",
      "Batch: 79, Loss: 0.5706465244293213, Accuracy: 0.814453125\n",
      "Batch: 80, Loss: 0.5800055265426636, Accuracy: 0.806640625\n",
      "Batch: 81, Loss: 0.5862118005752563, Accuracy: 0.8125\n",
      "Batch: 82, Loss: 0.5481297969818115, Accuracy: 0.806640625\n",
      "Batch: 83, Loss: 0.507741391658783, Accuracy: 0.82861328125\n",
      "Batch: 84, Loss: 0.5424381494522095, Accuracy: 0.82861328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 85, Loss: 0.5511766672134399, Accuracy: 0.8125\n",
      "Batch: 86, Loss: 0.5944775342941284, Accuracy: 0.81640625\n",
      "Batch: 87, Loss: 0.5191227197647095, Accuracy: 0.8359375\n",
      "Batch: 88, Loss: 0.5732066631317139, Accuracy: 0.81640625\n",
      "Batch: 89, Loss: 0.5688906311988831, Accuracy: 0.81884765625\n",
      "Batch: 90, Loss: 0.5995659828186035, Accuracy: 0.80810546875\n",
      "Batch: 91, Loss: 0.5678337812423706, Accuracy: 0.8232421875\n",
      "Batch: 92, Loss: 0.6428229808807373, Accuracy: 0.79443359375\n",
      "Batch: 93, Loss: 0.6090342998504639, Accuracy: 0.796875\n",
      "Batch: 94, Loss: 0.5798202753067017, Accuracy: 0.81640625\n",
      "Batch: 95, Loss: 0.616012692451477, Accuracy: 0.8046875\n",
      "Batch: 96, Loss: 0.5546808838844299, Accuracy: 0.82080078125\n",
      "Batch: 97, Loss: 0.5567232370376587, Accuracy: 0.82763671875\n",
      "Batch: 98, Loss: 0.5763609409332275, Accuracy: 0.81494140625\n",
      "Batch: 99, Loss: 0.5381167531013489, Accuracy: 0.828125\n",
      "Batch: 100, Loss: 0.6145071983337402, Accuracy: 0.8037109375\n",
      "Batch: 101, Loss: 0.613119900226593, Accuracy: 0.80859375\n",
      "Batch: 102, Loss: 0.5188827514648438, Accuracy: 0.82763671875\n",
      "Batch: 103, Loss: 0.5692830681800842, Accuracy: 0.81640625\n",
      "Batch: 104, Loss: 0.5437983870506287, Accuracy: 0.828125\n",
      "Batch: 105, Loss: 0.5589125156402588, Accuracy: 0.82958984375\n",
      "Batch: 106, Loss: 0.5415165424346924, Accuracy: 0.8291015625\n",
      "Batch: 107, Loss: 0.5868188738822937, Accuracy: 0.8095703125\n",
      "Batch: 108, Loss: 0.5315407514572144, Accuracy: 0.82275390625\n",
      "Batch: 109, Loss: 0.5325974225997925, Accuracy: 0.8330078125\n",
      "Batch: 110, Loss: 0.5185105800628662, Accuracy: 0.8271484375\n",
      "Batch: 111, Loss: 0.5131200551986694, Accuracy: 0.82275390625\n",
      "Batch: 112, Loss: 0.5313407778739929, Accuracy: 0.83349609375\n",
      "Batch: 113, Loss: 0.5778464078903198, Accuracy: 0.80615234375\n",
      "Batch: 114, Loss: 0.5605796575546265, Accuracy: 0.81787109375\n",
      "Batch: 115, Loss: 0.5510203242301941, Accuracy: 0.82080078125\n",
      "Batch: 116, Loss: 0.5442312955856323, Accuracy: 0.8251953125\n",
      "Batch: 117, Loss: 0.5314566493034363, Accuracy: 0.82421875\n",
      "Batch: 118, Loss: 0.5631358623504639, Accuracy: 0.8203125\n",
      "Batch: 119, Loss: 0.5553312301635742, Accuracy: 0.80419921875\n",
      "Batch: 120, Loss: 0.5309666395187378, Accuracy: 0.83154296875\n",
      "Batch: 121, Loss: 0.5562448501586914, Accuracy: 0.8173828125\n",
      "Batch: 122, Loss: 0.53385329246521, Accuracy: 0.8154296875\n",
      "Batch: 123, Loss: 0.5310338139533997, Accuracy: 0.8349609375\n",
      "Batch: 124, Loss: 0.5117791891098022, Accuracy: 0.83251953125\n",
      "Batch: 125, Loss: 0.556364893913269, Accuracy: 0.8232421875\n",
      "Batch: 126, Loss: 0.5383056998252869, Accuracy: 0.83251953125\n",
      "Batch: 127, Loss: 0.49299153685569763, Accuracy: 0.84228515625\n",
      "Batch: 128, Loss: 0.5898433327674866, Accuracy: 0.81640625\n",
      "Batch: 129, Loss: 0.614310085773468, Accuracy: 0.810546875\n",
      "Batch: 130, Loss: 0.6420085430145264, Accuracy: 0.78564453125\n",
      "Batch: 131, Loss: 0.5704110860824585, Accuracy: 0.81298828125\n",
      "Batch: 132, Loss: 0.5299450159072876, Accuracy: 0.83056640625\n",
      "Batch: 133, Loss: 0.520461916923523, Accuracy: 0.8330078125\n",
      "Batch: 134, Loss: 0.5713635683059692, Accuracy: 0.818359375\n",
      "Batch: 135, Loss: 0.543864369392395, Accuracy: 0.81884765625\n",
      "Batch: 136, Loss: 0.5189436674118042, Accuracy: 0.84033203125\n",
      "Batch: 137, Loss: 0.5771843194961548, Accuracy: 0.81005859375\n",
      "Batch: 138, Loss: 0.5093955993652344, Accuracy: 0.8369140625\n",
      "Batch: 139, Loss: 0.5283433198928833, Accuracy: 0.8310546875\n",
      "Batch: 140, Loss: 0.514445424079895, Accuracy: 0.8291015625\n",
      "Batch: 141, Loss: 0.5702947378158569, Accuracy: 0.810546875\n",
      "Batch: 142, Loss: 0.5381585359573364, Accuracy: 0.81396484375\n",
      "Batch: 143, Loss: 0.5190737247467041, Accuracy: 0.8388671875\n",
      "Batch: 144, Loss: 0.6103476285934448, Accuracy: 0.80029296875\n",
      "Batch: 145, Loss: 0.5860974788665771, Accuracy: 0.8076171875\n",
      "Batch: 146, Loss: 0.5938400626182556, Accuracy: 0.806640625\n",
      "Batch: 147, Loss: 0.5417547225952148, Accuracy: 0.82470703125\n",
      "Batch: 148, Loss: 0.6005939245223999, Accuracy: 0.80517578125\n",
      "Batch: 149, Loss: 0.5846251249313354, Accuracy: 0.81591796875\n",
      "Batch: 150, Loss: 0.5064374804496765, Accuracy: 0.833984375\n",
      "Batch: 151, Loss: 0.5069877505302429, Accuracy: 0.83837890625\n",
      "Batch: 152, Loss: 0.5378071069717407, Accuracy: 0.82958984375\n",
      "Batch: 153, Loss: 0.5375398397445679, Accuracy: 0.822265625\n",
      "Batch: 154, Loss: 0.5459209680557251, Accuracy: 0.82177734375\n",
      "Batch: 155, Loss: 0.5883357524871826, Accuracy: 0.80810546875\n",
      "Batch: 156, Loss: 0.5068709254264832, Accuracy: 0.82763671875\n",
      "Batch: 157, Loss: 0.4862329661846161, Accuracy: 0.83740234375\n",
      "Batch: 158, Loss: 0.505316972732544, Accuracy: 0.8466796875\n",
      "Batch: 159, Loss: 0.5336151123046875, Accuracy: 0.82763671875\n",
      "Batch: 160, Loss: 0.5643575191497803, Accuracy: 0.8251953125\n",
      "Batch: 161, Loss: 0.564942479133606, Accuracy: 0.81689453125\n",
      "Batch: 162, Loss: 0.5255078077316284, Accuracy: 0.82421875\n",
      "Batch: 163, Loss: 0.5835596919059753, Accuracy: 0.81103515625\n",
      "Batch: 164, Loss: 0.6275306940078735, Accuracy: 0.7998046875\n",
      "Batch: 165, Loss: 0.5688114166259766, Accuracy: 0.82080078125\n",
      "Batch: 166, Loss: 0.5840882658958435, Accuracy: 0.8115234375\n",
      "Batch: 167, Loss: 0.5586972832679749, Accuracy: 0.81884765625\n",
      "Batch: 168, Loss: 0.5106762647628784, Accuracy: 0.837890625\n",
      "Batch: 169, Loss: 0.5604387521743774, Accuracy: 0.82177734375\n",
      "Batch: 170, Loss: 0.5863007307052612, Accuracy: 0.8115234375\n",
      "Batch: 171, Loss: 0.5303767919540405, Accuracy: 0.826171875\n",
      "Batch: 172, Loss: 0.522621214389801, Accuracy: 0.8291015625\n",
      "Batch: 173, Loss: 0.5658153295516968, Accuracy: 0.81640625\n",
      "Batch: 174, Loss: 0.5073664784431458, Accuracy: 0.8310546875\n",
      "Batch: 175, Loss: 0.5807005167007446, Accuracy: 0.802734375\n",
      "Batch: 176, Loss: 0.5909802317619324, Accuracy: 0.8076171875\n",
      "Batch: 177, Loss: 0.5508323907852173, Accuracy: 0.8251953125\n",
      "Batch: 178, Loss: 0.510517954826355, Accuracy: 0.83447265625\n",
      "Batch: 179, Loss: 0.5499416589736938, Accuracy: 0.82080078125\n",
      "Batch: 180, Loss: 0.5742151141166687, Accuracy: 0.82177734375\n",
      "Epoch 78/200\n",
      "Batch: 1, Loss: 0.8485583662986755, Accuracy: 0.75537109375\n",
      "Batch: 2, Loss: 0.5572397708892822, Accuracy: 0.8212890625\n",
      "Batch: 3, Loss: 0.5606099367141724, Accuracy: 0.81298828125\n",
      "Batch: 4, Loss: 0.5916380882263184, Accuracy: 0.80615234375\n",
      "Batch: 5, Loss: 0.5536243915557861, Accuracy: 0.82080078125\n",
      "Batch: 6, Loss: 0.5766461491584778, Accuracy: 0.81640625\n",
      "Batch: 7, Loss: 0.5570929050445557, Accuracy: 0.8154296875\n",
      "Batch: 8, Loss: 0.54360032081604, Accuracy: 0.82958984375\n",
      "Batch: 9, Loss: 0.5732461214065552, Accuracy: 0.818359375\n",
      "Batch: 10, Loss: 0.5417816638946533, Accuracy: 0.83203125\n",
      "Batch: 11, Loss: 0.6027613282203674, Accuracy: 0.802734375\n",
      "Batch: 12, Loss: 0.5024805665016174, Accuracy: 0.83447265625\n",
      "Batch: 13, Loss: 0.5521798729896545, Accuracy: 0.81494140625\n",
      "Batch: 14, Loss: 0.547010600566864, Accuracy: 0.8271484375\n",
      "Batch: 15, Loss: 0.5703194737434387, Accuracy: 0.81689453125\n",
      "Batch: 16, Loss: 0.5894482135772705, Accuracy: 0.80810546875\n",
      "Batch: 17, Loss: 0.5594348907470703, Accuracy: 0.818359375\n",
      "Batch: 18, Loss: 0.573729395866394, Accuracy: 0.82373046875\n",
      "Batch: 19, Loss: 0.6001551747322083, Accuracy: 0.81396484375\n",
      "Batch: 20, Loss: 0.4691500663757324, Accuracy: 0.84375\n",
      "Batch: 21, Loss: 0.5675288438796997, Accuracy: 0.81982421875\n",
      "Batch: 22, Loss: 0.5367387533187866, Accuracy: 0.82373046875\n",
      "Batch: 23, Loss: 0.5170942544937134, Accuracy: 0.82861328125\n",
      "Batch: 24, Loss: 0.5414754748344421, Accuracy: 0.82275390625\n",
      "Batch: 25, Loss: 0.5234203338623047, Accuracy: 0.82861328125\n",
      "Batch: 26, Loss: 0.5373117327690125, Accuracy: 0.814453125\n",
      "Batch: 27, Loss: 0.5657212734222412, Accuracy: 0.8125\n",
      "Batch: 28, Loss: 0.5339244604110718, Accuracy: 0.83349609375\n",
      "Batch: 29, Loss: 0.5754387378692627, Accuracy: 0.81787109375\n",
      "Batch: 30, Loss: 0.5785247683525085, Accuracy: 0.8173828125\n",
      "Batch: 31, Loss: 0.6246058940887451, Accuracy: 0.79638671875\n",
      "Batch: 32, Loss: 0.5981960296630859, Accuracy: 0.80078125\n",
      "Batch: 33, Loss: 0.5754135251045227, Accuracy: 0.8076171875\n",
      "Batch: 34, Loss: 0.5960180163383484, Accuracy: 0.81298828125\n",
      "Batch: 35, Loss: 0.6054406762123108, Accuracy: 0.8017578125\n",
      "Batch: 36, Loss: 0.5786522626876831, Accuracy: 0.8154296875\n",
      "Batch: 37, Loss: 0.5919685959815979, Accuracy: 0.81201171875\n",
      "Batch: 38, Loss: 0.5992666482925415, Accuracy: 0.806640625\n",
      "Batch: 39, Loss: 0.570156991481781, Accuracy: 0.818359375\n",
      "Batch: 40, Loss: 0.5980738401412964, Accuracy: 0.8037109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 41, Loss: 0.5757806301116943, Accuracy: 0.81884765625\n",
      "Batch: 42, Loss: 0.559650719165802, Accuracy: 0.8134765625\n",
      "Batch: 43, Loss: 0.5149274468421936, Accuracy: 0.82958984375\n",
      "Batch: 44, Loss: 0.48795291781425476, Accuracy: 0.8447265625\n",
      "Batch: 45, Loss: 0.5660333633422852, Accuracy: 0.81591796875\n",
      "Batch: 46, Loss: 0.5375358462333679, Accuracy: 0.8193359375\n",
      "Batch: 47, Loss: 0.55793297290802, Accuracy: 0.81640625\n",
      "Batch: 48, Loss: 0.5513886213302612, Accuracy: 0.82666015625\n",
      "Batch: 49, Loss: 0.5518964529037476, Accuracy: 0.81591796875\n",
      "Batch: 50, Loss: 0.5645730495452881, Accuracy: 0.8193359375\n",
      "Batch: 51, Loss: 0.5291792750358582, Accuracy: 0.83056640625\n",
      "Batch: 52, Loss: 0.5442548394203186, Accuracy: 0.81787109375\n",
      "Batch: 53, Loss: 0.5648097395896912, Accuracy: 0.81982421875\n",
      "Batch: 54, Loss: 0.5948421955108643, Accuracy: 0.7900390625\n",
      "Batch: 55, Loss: 0.5763406157493591, Accuracy: 0.810546875\n",
      "Batch: 56, Loss: 0.5618157386779785, Accuracy: 0.814453125\n",
      "Batch: 57, Loss: 0.6226097345352173, Accuracy: 0.80322265625\n",
      "Batch: 58, Loss: 0.5648297071456909, Accuracy: 0.8154296875\n",
      "Batch: 59, Loss: 0.6524015069007874, Accuracy: 0.79931640625\n",
      "Batch: 60, Loss: 0.5453089475631714, Accuracy: 0.83056640625\n",
      "Batch: 61, Loss: 0.5242189168930054, Accuracy: 0.8349609375\n",
      "Batch: 62, Loss: 0.5530470013618469, Accuracy: 0.82666015625\n",
      "Batch: 63, Loss: 0.5559966564178467, Accuracy: 0.822265625\n",
      "Batch: 64, Loss: 0.5653396844863892, Accuracy: 0.80615234375\n",
      "Batch: 65, Loss: 0.5864512920379639, Accuracy: 0.81103515625\n",
      "Batch: 66, Loss: 0.5766952037811279, Accuracy: 0.8203125\n",
      "Batch: 67, Loss: 0.5995621681213379, Accuracy: 0.81298828125\n",
      "Batch: 68, Loss: 0.513005256652832, Accuracy: 0.83642578125\n",
      "Batch: 69, Loss: 0.5837720632553101, Accuracy: 0.8115234375\n",
      "Batch: 70, Loss: 0.535979151725769, Accuracy: 0.83447265625\n",
      "Batch: 71, Loss: 0.5447748899459839, Accuracy: 0.82568359375\n",
      "Batch: 72, Loss: 0.5868959426879883, Accuracy: 0.7919921875\n",
      "Batch: 73, Loss: 0.56252521276474, Accuracy: 0.8134765625\n",
      "Batch: 74, Loss: 0.55305016040802, Accuracy: 0.833984375\n",
      "Batch: 75, Loss: 0.5274671912193298, Accuracy: 0.830078125\n",
      "Batch: 76, Loss: 0.5111367106437683, Accuracy: 0.8359375\n",
      "Batch: 77, Loss: 0.5194001197814941, Accuracy: 0.8427734375\n",
      "Batch: 78, Loss: 0.5744896531105042, Accuracy: 0.814453125\n",
      "Batch: 79, Loss: 0.5760544538497925, Accuracy: 0.806640625\n",
      "Batch: 80, Loss: 0.5898417830467224, Accuracy: 0.81884765625\n",
      "Batch: 81, Loss: 0.5643578767776489, Accuracy: 0.8251953125\n",
      "Batch: 82, Loss: 0.5560170412063599, Accuracy: 0.8154296875\n",
      "Batch: 83, Loss: 0.49635380506515503, Accuracy: 0.83837890625\n",
      "Batch: 84, Loss: 0.5066144466400146, Accuracy: 0.837890625\n",
      "Batch: 85, Loss: 0.5546275973320007, Accuracy: 0.81640625\n",
      "Batch: 86, Loss: 0.6058090925216675, Accuracy: 0.81103515625\n",
      "Batch: 87, Loss: 0.5134387612342834, Accuracy: 0.83544921875\n",
      "Batch: 88, Loss: 0.5777280330657959, Accuracy: 0.80810546875\n",
      "Batch: 89, Loss: 0.536815881729126, Accuracy: 0.818359375\n",
      "Batch: 90, Loss: 0.5966435670852661, Accuracy: 0.7978515625\n",
      "Batch: 91, Loss: 0.5627985000610352, Accuracy: 0.81298828125\n",
      "Batch: 92, Loss: 0.6150289177894592, Accuracy: 0.7958984375\n",
      "Batch: 93, Loss: 0.6197934746742249, Accuracy: 0.7998046875\n",
      "Batch: 94, Loss: 0.5722078680992126, Accuracy: 0.81787109375\n",
      "Batch: 95, Loss: 0.6009721755981445, Accuracy: 0.80322265625\n",
      "Batch: 96, Loss: 0.5515263080596924, Accuracy: 0.82568359375\n",
      "Batch: 97, Loss: 0.5426797866821289, Accuracy: 0.82470703125\n",
      "Batch: 98, Loss: 0.5661029815673828, Accuracy: 0.81884765625\n",
      "Batch: 99, Loss: 0.5435241460800171, Accuracy: 0.8330078125\n",
      "Batch: 100, Loss: 0.6046504378318787, Accuracy: 0.80224609375\n",
      "Batch: 101, Loss: 0.5896064043045044, Accuracy: 0.81103515625\n",
      "Batch: 102, Loss: 0.5111864805221558, Accuracy: 0.83349609375\n",
      "Batch: 103, Loss: 0.5766238570213318, Accuracy: 0.81103515625\n",
      "Batch: 104, Loss: 0.556978166103363, Accuracy: 0.82470703125\n",
      "Batch: 105, Loss: 0.5698638558387756, Accuracy: 0.81396484375\n",
      "Batch: 106, Loss: 0.5299526453018188, Accuracy: 0.82958984375\n",
      "Batch: 107, Loss: 0.5738996267318726, Accuracy: 0.8095703125\n",
      "Batch: 108, Loss: 0.5404744148254395, Accuracy: 0.8232421875\n",
      "Batch: 109, Loss: 0.5334171056747437, Accuracy: 0.8291015625\n",
      "Batch: 110, Loss: 0.5359739065170288, Accuracy: 0.8310546875\n",
      "Batch: 111, Loss: 0.5171933174133301, Accuracy: 0.826171875\n",
      "Batch: 112, Loss: 0.5275657773017883, Accuracy: 0.83056640625\n",
      "Batch: 113, Loss: 0.5912988781929016, Accuracy: 0.80810546875\n",
      "Batch: 114, Loss: 0.5627424120903015, Accuracy: 0.8291015625\n",
      "Batch: 115, Loss: 0.562318742275238, Accuracy: 0.8173828125\n",
      "Batch: 116, Loss: 0.5485299825668335, Accuracy: 0.82080078125\n",
      "Batch: 117, Loss: 0.5413190722465515, Accuracy: 0.8173828125\n",
      "Batch: 118, Loss: 0.5439208745956421, Accuracy: 0.826171875\n",
      "Batch: 119, Loss: 0.5199034810066223, Accuracy: 0.82861328125\n",
      "Batch: 120, Loss: 0.5327244997024536, Accuracy: 0.82763671875\n",
      "Batch: 121, Loss: 0.5466316938400269, Accuracy: 0.82080078125\n",
      "Batch: 122, Loss: 0.5173563361167908, Accuracy: 0.826171875\n",
      "Batch: 123, Loss: 0.5299505591392517, Accuracy: 0.83544921875\n",
      "Batch: 124, Loss: 0.5053486824035645, Accuracy: 0.82861328125\n",
      "Batch: 125, Loss: 0.5429326295852661, Accuracy: 0.82763671875\n",
      "Batch: 126, Loss: 0.5472142696380615, Accuracy: 0.8291015625\n",
      "Batch: 127, Loss: 0.5091587901115417, Accuracy: 0.83251953125\n",
      "Batch: 128, Loss: 0.6156495809555054, Accuracy: 0.79931640625\n",
      "Batch: 129, Loss: 0.6163251399993896, Accuracy: 0.80419921875\n",
      "Batch: 130, Loss: 0.634882390499115, Accuracy: 0.79638671875\n",
      "Batch: 131, Loss: 0.5459871292114258, Accuracy: 0.81884765625\n",
      "Batch: 132, Loss: 0.5108657479286194, Accuracy: 0.83984375\n",
      "Batch: 133, Loss: 0.5240898132324219, Accuracy: 0.82470703125\n",
      "Batch: 134, Loss: 0.5537354946136475, Accuracy: 0.81689453125\n",
      "Batch: 135, Loss: 0.5590870380401611, Accuracy: 0.81591796875\n",
      "Batch: 136, Loss: 0.5035306215286255, Accuracy: 0.8310546875\n",
      "Batch: 137, Loss: 0.5702807307243347, Accuracy: 0.8193359375\n",
      "Batch: 138, Loss: 0.498637318611145, Accuracy: 0.8408203125\n",
      "Batch: 139, Loss: 0.5256963968276978, Accuracy: 0.83203125\n",
      "Batch: 140, Loss: 0.4980846345424652, Accuracy: 0.84912109375\n",
      "Batch: 141, Loss: 0.5626695156097412, Accuracy: 0.81591796875\n",
      "Batch: 142, Loss: 0.5289165377616882, Accuracy: 0.82421875\n",
      "Batch: 143, Loss: 0.511590838432312, Accuracy: 0.8271484375\n",
      "Batch: 144, Loss: 0.5968379378318787, Accuracy: 0.80517578125\n",
      "Batch: 145, Loss: 0.5541778802871704, Accuracy: 0.82080078125\n",
      "Batch: 146, Loss: 0.57007896900177, Accuracy: 0.8212890625\n",
      "Batch: 147, Loss: 0.5506811738014221, Accuracy: 0.82421875\n",
      "Batch: 148, Loss: 0.5763412714004517, Accuracy: 0.79931640625\n",
      "Batch: 149, Loss: 0.5573227405548096, Accuracy: 0.8203125\n",
      "Batch: 150, Loss: 0.5074598789215088, Accuracy: 0.837890625\n",
      "Batch: 151, Loss: 0.4908045530319214, Accuracy: 0.84228515625\n",
      "Batch: 152, Loss: 0.5388916730880737, Accuracy: 0.8212890625\n",
      "Batch: 153, Loss: 0.5446443557739258, Accuracy: 0.82861328125\n",
      "Batch: 154, Loss: 0.5429781079292297, Accuracy: 0.818359375\n",
      "Batch: 155, Loss: 0.5888745188713074, Accuracy: 0.80810546875\n",
      "Batch: 156, Loss: 0.5255502462387085, Accuracy: 0.830078125\n",
      "Batch: 157, Loss: 0.4990401566028595, Accuracy: 0.82763671875\n",
      "Batch: 158, Loss: 0.5135555863380432, Accuracy: 0.837890625\n",
      "Batch: 159, Loss: 0.5233408808708191, Accuracy: 0.8310546875\n",
      "Batch: 160, Loss: 0.5403561592102051, Accuracy: 0.83349609375\n",
      "Batch: 161, Loss: 0.5569512844085693, Accuracy: 0.81396484375\n",
      "Batch: 162, Loss: 0.520748496055603, Accuracy: 0.82958984375\n",
      "Batch: 163, Loss: 0.5614588856697083, Accuracy: 0.82080078125\n",
      "Batch: 164, Loss: 0.6221888065338135, Accuracy: 0.80859375\n",
      "Batch: 165, Loss: 0.5688478946685791, Accuracy: 0.8232421875\n",
      "Batch: 166, Loss: 0.6018093824386597, Accuracy: 0.8056640625\n",
      "Batch: 167, Loss: 0.5634666085243225, Accuracy: 0.82177734375\n",
      "Batch: 168, Loss: 0.4891878366470337, Accuracy: 0.8359375\n",
      "Batch: 169, Loss: 0.5632871985435486, Accuracy: 0.8134765625\n",
      "Batch: 170, Loss: 0.5664647817611694, Accuracy: 0.81982421875\n",
      "Batch: 171, Loss: 0.5349617004394531, Accuracy: 0.82958984375\n",
      "Batch: 172, Loss: 0.5399330854415894, Accuracy: 0.818359375\n",
      "Batch: 173, Loss: 0.589823842048645, Accuracy: 0.8076171875\n",
      "Batch: 174, Loss: 0.4900991916656494, Accuracy: 0.84521484375\n",
      "Batch: 175, Loss: 0.5651077628135681, Accuracy: 0.8095703125\n",
      "Batch: 176, Loss: 0.6018977165222168, Accuracy: 0.80126953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 177, Loss: 0.5798391699790955, Accuracy: 0.8173828125\n",
      "Batch: 178, Loss: 0.5148224234580994, Accuracy: 0.828125\n",
      "Batch: 179, Loss: 0.534730076789856, Accuracy: 0.83642578125\n",
      "Batch: 180, Loss: 0.5585739612579346, Accuracy: 0.82861328125\n",
      "Epoch 79/200\n",
      "Batch: 1, Loss: 0.8319829702377319, Accuracy: 0.76416015625\n",
      "Batch: 2, Loss: 0.5743155479431152, Accuracy: 0.810546875\n",
      "Batch: 3, Loss: 0.5554381608963013, Accuracy: 0.8193359375\n",
      "Batch: 4, Loss: 0.586424708366394, Accuracy: 0.80859375\n",
      "Batch: 5, Loss: 0.5634690523147583, Accuracy: 0.82763671875\n",
      "Batch: 6, Loss: 0.5446045398712158, Accuracy: 0.8251953125\n",
      "Batch: 7, Loss: 0.5421902537345886, Accuracy: 0.82421875\n",
      "Batch: 8, Loss: 0.5384095907211304, Accuracy: 0.8212890625\n",
      "Batch: 9, Loss: 0.5852829217910767, Accuracy: 0.81103515625\n",
      "Batch: 10, Loss: 0.5172389149665833, Accuracy: 0.83203125\n",
      "Batch: 11, Loss: 0.5598845481872559, Accuracy: 0.8193359375\n",
      "Batch: 12, Loss: 0.49551764130592346, Accuracy: 0.8388671875\n",
      "Batch: 13, Loss: 0.5556434392929077, Accuracy: 0.8173828125\n",
      "Batch: 14, Loss: 0.5364770889282227, Accuracy: 0.8291015625\n",
      "Batch: 15, Loss: 0.5573315620422363, Accuracy: 0.81689453125\n",
      "Batch: 16, Loss: 0.5790644884109497, Accuracy: 0.8076171875\n",
      "Batch: 17, Loss: 0.5213678479194641, Accuracy: 0.83203125\n",
      "Batch: 18, Loss: 0.5596801042556763, Accuracy: 0.8251953125\n",
      "Batch: 19, Loss: 0.5813132524490356, Accuracy: 0.81298828125\n",
      "Batch: 20, Loss: 0.4894458055496216, Accuracy: 0.8359375\n",
      "Batch: 21, Loss: 0.5475693941116333, Accuracy: 0.8291015625\n",
      "Batch: 22, Loss: 0.5350308418273926, Accuracy: 0.81884765625\n",
      "Batch: 23, Loss: 0.5166201591491699, Accuracy: 0.83251953125\n",
      "Batch: 24, Loss: 0.527418851852417, Accuracy: 0.83203125\n",
      "Batch: 25, Loss: 0.5404902696609497, Accuracy: 0.8359375\n",
      "Batch: 26, Loss: 0.5244552493095398, Accuracy: 0.82958984375\n",
      "Batch: 27, Loss: 0.5425119996070862, Accuracy: 0.830078125\n",
      "Batch: 28, Loss: 0.5162540078163147, Accuracy: 0.83056640625\n",
      "Batch: 29, Loss: 0.5777949094772339, Accuracy: 0.80615234375\n",
      "Batch: 30, Loss: 0.5865118503570557, Accuracy: 0.81201171875\n",
      "Batch: 31, Loss: 0.6245734691619873, Accuracy: 0.7998046875\n",
      "Batch: 32, Loss: 0.605414867401123, Accuracy: 0.80419921875\n",
      "Batch: 33, Loss: 0.5486928224563599, Accuracy: 0.82861328125\n",
      "Batch: 34, Loss: 0.5698796510696411, Accuracy: 0.818359375\n",
      "Batch: 35, Loss: 0.6049500703811646, Accuracy: 0.80322265625\n",
      "Batch: 36, Loss: 0.56545090675354, Accuracy: 0.81103515625\n",
      "Batch: 37, Loss: 0.5934064388275146, Accuracy: 0.8046875\n",
      "Batch: 38, Loss: 0.594457745552063, Accuracy: 0.802734375\n",
      "Batch: 39, Loss: 0.5548213720321655, Accuracy: 0.81982421875\n",
      "Batch: 40, Loss: 0.5913793444633484, Accuracy: 0.80810546875\n",
      "Batch: 41, Loss: 0.5907906293869019, Accuracy: 0.8076171875\n",
      "Batch: 42, Loss: 0.574063777923584, Accuracy: 0.7998046875\n",
      "Batch: 43, Loss: 0.5270347595214844, Accuracy: 0.828125\n",
      "Batch: 44, Loss: 0.505335807800293, Accuracy: 0.8349609375\n",
      "Batch: 45, Loss: 0.5611472129821777, Accuracy: 0.814453125\n",
      "Batch: 46, Loss: 0.5240110754966736, Accuracy: 0.81494140625\n",
      "Batch: 47, Loss: 0.5386691093444824, Accuracy: 0.82861328125\n",
      "Batch: 48, Loss: 0.5541012287139893, Accuracy: 0.818359375\n",
      "Batch: 49, Loss: 0.528342604637146, Accuracy: 0.830078125\n",
      "Batch: 50, Loss: 0.5593835115432739, Accuracy: 0.81494140625\n",
      "Batch: 51, Loss: 0.5463531613349915, Accuracy: 0.81494140625\n",
      "Batch: 52, Loss: 0.5765689015388489, Accuracy: 0.8134765625\n",
      "Batch: 53, Loss: 0.5254977941513062, Accuracy: 0.8291015625\n",
      "Batch: 54, Loss: 0.5962092876434326, Accuracy: 0.81103515625\n",
      "Batch: 55, Loss: 0.5698947310447693, Accuracy: 0.81201171875\n",
      "Batch: 56, Loss: 0.5332281589508057, Accuracy: 0.8203125\n",
      "Batch: 57, Loss: 0.6011218428611755, Accuracy: 0.8095703125\n",
      "Batch: 58, Loss: 0.5628443360328674, Accuracy: 0.814453125\n",
      "Batch: 59, Loss: 0.6480907797813416, Accuracy: 0.794921875\n",
      "Batch: 60, Loss: 0.5561889410018921, Accuracy: 0.82275390625\n",
      "Batch: 61, Loss: 0.5286038517951965, Accuracy: 0.83056640625\n",
      "Batch: 62, Loss: 0.5302966833114624, Accuracy: 0.8271484375\n",
      "Batch: 63, Loss: 0.5509282350540161, Accuracy: 0.81640625\n",
      "Batch: 64, Loss: 0.5526894330978394, Accuracy: 0.8193359375\n",
      "Batch: 65, Loss: 0.5783945322036743, Accuracy: 0.810546875\n",
      "Batch: 66, Loss: 0.5628998279571533, Accuracy: 0.81591796875\n",
      "Batch: 67, Loss: 0.5971630811691284, Accuracy: 0.8076171875\n",
      "Batch: 68, Loss: 0.5120100975036621, Accuracy: 0.83056640625\n",
      "Batch: 69, Loss: 0.5544042587280273, Accuracy: 0.8203125\n",
      "Batch: 70, Loss: 0.5349682569503784, Accuracy: 0.822265625\n",
      "Batch: 71, Loss: 0.5432120561599731, Accuracy: 0.81982421875\n",
      "Batch: 72, Loss: 0.5871384143829346, Accuracy: 0.80322265625\n",
      "Batch: 73, Loss: 0.5676612854003906, Accuracy: 0.8076171875\n",
      "Batch: 74, Loss: 0.5853197574615479, Accuracy: 0.80126953125\n",
      "Batch: 75, Loss: 0.5105074048042297, Accuracy: 0.82080078125\n",
      "Batch: 76, Loss: 0.5164787769317627, Accuracy: 0.84326171875\n",
      "Batch: 77, Loss: 0.5378210544586182, Accuracy: 0.82958984375\n",
      "Batch: 78, Loss: 0.5634866952896118, Accuracy: 0.8154296875\n",
      "Batch: 79, Loss: 0.5652929544448853, Accuracy: 0.8134765625\n",
      "Batch: 80, Loss: 0.5794872045516968, Accuracy: 0.818359375\n",
      "Batch: 81, Loss: 0.5735047459602356, Accuracy: 0.814453125\n",
      "Batch: 82, Loss: 0.5528875589370728, Accuracy: 0.81591796875\n",
      "Batch: 83, Loss: 0.49702829122543335, Accuracy: 0.83740234375\n",
      "Batch: 84, Loss: 0.5322964191436768, Accuracy: 0.828125\n",
      "Batch: 85, Loss: 0.5555053949356079, Accuracy: 0.82470703125\n",
      "Batch: 86, Loss: 0.5944432616233826, Accuracy: 0.8134765625\n",
      "Batch: 87, Loss: 0.5202890038490295, Accuracy: 0.8291015625\n",
      "Batch: 88, Loss: 0.572625994682312, Accuracy: 0.81494140625\n",
      "Batch: 89, Loss: 0.5391560792922974, Accuracy: 0.8232421875\n",
      "Batch: 90, Loss: 0.5825164318084717, Accuracy: 0.80908203125\n",
      "Batch: 91, Loss: 0.553751528263092, Accuracy: 0.81787109375\n",
      "Batch: 92, Loss: 0.6190640926361084, Accuracy: 0.79296875\n",
      "Batch: 93, Loss: 0.6019783020019531, Accuracy: 0.80517578125\n",
      "Batch: 94, Loss: 0.5834783315658569, Accuracy: 0.8125\n",
      "Batch: 95, Loss: 0.5996326208114624, Accuracy: 0.81005859375\n",
      "Batch: 96, Loss: 0.5553896427154541, Accuracy: 0.82421875\n",
      "Batch: 97, Loss: 0.561659574508667, Accuracy: 0.8291015625\n",
      "Batch: 98, Loss: 0.5713977813720703, Accuracy: 0.81689453125\n",
      "Batch: 99, Loss: 0.5369160175323486, Accuracy: 0.82763671875\n",
      "Batch: 100, Loss: 0.5810402631759644, Accuracy: 0.8125\n",
      "Batch: 101, Loss: 0.607245147228241, Accuracy: 0.80712890625\n",
      "Batch: 102, Loss: 0.5191991329193115, Accuracy: 0.8349609375\n",
      "Batch: 103, Loss: 0.5714454650878906, Accuracy: 0.81591796875\n",
      "Batch: 104, Loss: 0.5391947031021118, Accuracy: 0.8271484375\n",
      "Batch: 105, Loss: 0.5683943033218384, Accuracy: 0.822265625\n",
      "Batch: 106, Loss: 0.5345069169998169, Accuracy: 0.82373046875\n",
      "Batch: 107, Loss: 0.5570555329322815, Accuracy: 0.81396484375\n",
      "Batch: 108, Loss: 0.5197324156761169, Accuracy: 0.82763671875\n",
      "Batch: 109, Loss: 0.525856614112854, Accuracy: 0.830078125\n",
      "Batch: 110, Loss: 0.527167797088623, Accuracy: 0.82421875\n",
      "Batch: 111, Loss: 0.4998527765274048, Accuracy: 0.83984375\n",
      "Batch: 112, Loss: 0.5216057300567627, Accuracy: 0.83203125\n",
      "Batch: 113, Loss: 0.5549513101577759, Accuracy: 0.80859375\n",
      "Batch: 114, Loss: 0.56126469373703, Accuracy: 0.82373046875\n",
      "Batch: 115, Loss: 0.5452176332473755, Accuracy: 0.81787109375\n",
      "Batch: 116, Loss: 0.540637195110321, Accuracy: 0.81884765625\n",
      "Batch: 117, Loss: 0.5056596994400024, Accuracy: 0.83056640625\n",
      "Batch: 118, Loss: 0.549506664276123, Accuracy: 0.81640625\n",
      "Batch: 119, Loss: 0.5051989555358887, Accuracy: 0.837890625\n",
      "Batch: 120, Loss: 0.5234493613243103, Accuracy: 0.82421875\n",
      "Batch: 121, Loss: 0.5425584316253662, Accuracy: 0.8310546875\n",
      "Batch: 122, Loss: 0.5092089176177979, Accuracy: 0.83056640625\n",
      "Batch: 123, Loss: 0.5118245482444763, Accuracy: 0.84130859375\n",
      "Batch: 124, Loss: 0.5135065317153931, Accuracy: 0.82861328125\n",
      "Batch: 125, Loss: 0.5371745824813843, Accuracy: 0.83349609375\n",
      "Batch: 126, Loss: 0.518347442150116, Accuracy: 0.83642578125\n",
      "Batch: 127, Loss: 0.48421889543533325, Accuracy: 0.85595703125\n",
      "Batch: 128, Loss: 0.5851010680198669, Accuracy: 0.80615234375\n",
      "Batch: 129, Loss: 0.6103745698928833, Accuracy: 0.8056640625\n",
      "Batch: 130, Loss: 0.6448992490768433, Accuracy: 0.791015625\n",
      "Batch: 131, Loss: 0.5745155811309814, Accuracy: 0.8134765625\n",
      "Batch: 132, Loss: 0.5197927951812744, Accuracy: 0.83251953125\n",
      "Batch: 133, Loss: 0.5080969333648682, Accuracy: 0.83349609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 134, Loss: 0.5565187931060791, Accuracy: 0.8232421875\n",
      "Batch: 135, Loss: 0.5525240898132324, Accuracy: 0.81103515625\n",
      "Batch: 136, Loss: 0.5133926868438721, Accuracy: 0.83544921875\n",
      "Batch: 137, Loss: 0.5732241868972778, Accuracy: 0.8154296875\n",
      "Batch: 138, Loss: 0.5119987726211548, Accuracy: 0.83984375\n",
      "Batch: 139, Loss: 0.49945348501205444, Accuracy: 0.8330078125\n",
      "Batch: 140, Loss: 0.4679121673107147, Accuracy: 0.845703125\n",
      "Batch: 141, Loss: 0.5419954657554626, Accuracy: 0.8330078125\n",
      "Batch: 142, Loss: 0.5074179768562317, Accuracy: 0.83984375\n",
      "Batch: 143, Loss: 0.5205644369125366, Accuracy: 0.826171875\n",
      "Batch: 144, Loss: 0.6059930324554443, Accuracy: 0.7958984375\n",
      "Batch: 145, Loss: 0.5359706282615662, Accuracy: 0.82861328125\n",
      "Batch: 146, Loss: 0.5671899318695068, Accuracy: 0.81982421875\n",
      "Batch: 147, Loss: 0.5421260595321655, Accuracy: 0.82958984375\n",
      "Batch: 148, Loss: 0.5879217386245728, Accuracy: 0.80712890625\n",
      "Batch: 149, Loss: 0.5641554594039917, Accuracy: 0.8095703125\n",
      "Batch: 150, Loss: 0.4960319399833679, Accuracy: 0.83837890625\n",
      "Batch: 151, Loss: 0.4893495440483093, Accuracy: 0.8388671875\n",
      "Batch: 152, Loss: 0.5252513885498047, Accuracy: 0.826171875\n",
      "Batch: 153, Loss: 0.5520504117012024, Accuracy: 0.82568359375\n",
      "Batch: 154, Loss: 0.5284910202026367, Accuracy: 0.82177734375\n",
      "Batch: 155, Loss: 0.5859858393669128, Accuracy: 0.80810546875\n",
      "Batch: 156, Loss: 0.5021379590034485, Accuracy: 0.82958984375\n",
      "Batch: 157, Loss: 0.49783414602279663, Accuracy: 0.8349609375\n",
      "Batch: 158, Loss: 0.5120184421539307, Accuracy: 0.8427734375\n",
      "Batch: 159, Loss: 0.5356671810150146, Accuracy: 0.8271484375\n",
      "Batch: 160, Loss: 0.532931923866272, Accuracy: 0.82421875\n",
      "Batch: 161, Loss: 0.5570443272590637, Accuracy: 0.8115234375\n",
      "Batch: 162, Loss: 0.5275853872299194, Accuracy: 0.826171875\n",
      "Batch: 163, Loss: 0.5530935525894165, Accuracy: 0.8154296875\n",
      "Batch: 164, Loss: 0.5908015966415405, Accuracy: 0.8046875\n",
      "Batch: 165, Loss: 0.5265352725982666, Accuracy: 0.82666015625\n",
      "Batch: 166, Loss: 0.5542576313018799, Accuracy: 0.8203125\n",
      "Batch: 167, Loss: 0.5482531785964966, Accuracy: 0.82763671875\n",
      "Batch: 168, Loss: 0.4995652437210083, Accuracy: 0.82763671875\n",
      "Batch: 169, Loss: 0.5210329294204712, Accuracy: 0.8330078125\n",
      "Batch: 170, Loss: 0.5434320569038391, Accuracy: 0.8251953125\n",
      "Batch: 171, Loss: 0.5381450653076172, Accuracy: 0.82568359375\n",
      "Batch: 172, Loss: 0.5195820331573486, Accuracy: 0.8251953125\n",
      "Batch: 173, Loss: 0.5811638832092285, Accuracy: 0.8076171875\n",
      "Batch: 174, Loss: 0.49523502588272095, Accuracy: 0.82470703125\n",
      "Batch: 175, Loss: 0.5599838495254517, Accuracy: 0.81103515625\n",
      "Batch: 176, Loss: 0.5604817867279053, Accuracy: 0.8193359375\n",
      "Batch: 177, Loss: 0.5552319288253784, Accuracy: 0.81982421875\n",
      "Batch: 178, Loss: 0.5313265323638916, Accuracy: 0.8291015625\n",
      "Batch: 179, Loss: 0.5292316675186157, Accuracy: 0.83837890625\n",
      "Batch: 180, Loss: 0.5609096884727478, Accuracy: 0.83056640625\n",
      "Epoch 80/200\n",
      "Batch: 1, Loss: 0.8251309990882874, Accuracy: 0.76953125\n",
      "Batch: 2, Loss: 0.5578356385231018, Accuracy: 0.81201171875\n",
      "Batch: 3, Loss: 0.5461443066596985, Accuracy: 0.81982421875\n",
      "Batch: 4, Loss: 0.5653364658355713, Accuracy: 0.8134765625\n",
      "Batch: 5, Loss: 0.5469030141830444, Accuracy: 0.830078125\n",
      "Batch: 6, Loss: 0.5652720928192139, Accuracy: 0.8095703125\n",
      "Batch: 7, Loss: 0.5447268486022949, Accuracy: 0.8212890625\n",
      "Batch: 8, Loss: 0.5598338842391968, Accuracy: 0.8212890625\n",
      "Batch: 9, Loss: 0.5731509327888489, Accuracy: 0.81396484375\n",
      "Batch: 10, Loss: 0.4994352459907532, Accuracy: 0.83447265625\n",
      "Batch: 11, Loss: 0.5676491856575012, Accuracy: 0.80615234375\n",
      "Batch: 12, Loss: 0.5022576451301575, Accuracy: 0.84228515625\n",
      "Batch: 13, Loss: 0.5567430853843689, Accuracy: 0.8203125\n",
      "Batch: 14, Loss: 0.5427072644233704, Accuracy: 0.82861328125\n",
      "Batch: 15, Loss: 0.5647952556610107, Accuracy: 0.8154296875\n",
      "Batch: 16, Loss: 0.5757977962493896, Accuracy: 0.81494140625\n",
      "Batch: 17, Loss: 0.5261511206626892, Accuracy: 0.830078125\n",
      "Batch: 18, Loss: 0.5711480379104614, Accuracy: 0.8193359375\n",
      "Batch: 19, Loss: 0.5685790777206421, Accuracy: 0.81982421875\n",
      "Batch: 20, Loss: 0.4834928512573242, Accuracy: 0.84716796875\n",
      "Batch: 21, Loss: 0.5671555995941162, Accuracy: 0.8173828125\n",
      "Batch: 22, Loss: 0.521467924118042, Accuracy: 0.83837890625\n",
      "Batch: 23, Loss: 0.49645018577575684, Accuracy: 0.83251953125\n",
      "Batch: 24, Loss: 0.5247437953948975, Accuracy: 0.8310546875\n",
      "Batch: 25, Loss: 0.5163705348968506, Accuracy: 0.8310546875\n",
      "Batch: 26, Loss: 0.53324294090271, Accuracy: 0.82568359375\n",
      "Batch: 27, Loss: 0.57676100730896, Accuracy: 0.80712890625\n",
      "Batch: 28, Loss: 0.5330434441566467, Accuracy: 0.83056640625\n",
      "Batch: 29, Loss: 0.5820417404174805, Accuracy: 0.798828125\n",
      "Batch: 30, Loss: 0.5440043210983276, Accuracy: 0.8310546875\n",
      "Batch: 31, Loss: 0.6138813495635986, Accuracy: 0.80322265625\n",
      "Batch: 32, Loss: 0.5786915421485901, Accuracy: 0.8154296875\n",
      "Batch: 33, Loss: 0.5461573004722595, Accuracy: 0.8203125\n",
      "Batch: 34, Loss: 0.5868682861328125, Accuracy: 0.81396484375\n",
      "Batch: 35, Loss: 0.5833921432495117, Accuracy: 0.806640625\n",
      "Batch: 36, Loss: 0.5640197992324829, Accuracy: 0.81982421875\n",
      "Batch: 37, Loss: 0.5843140482902527, Accuracy: 0.8056640625\n",
      "Batch: 38, Loss: 0.6010736227035522, Accuracy: 0.79736328125\n",
      "Batch: 39, Loss: 0.5292614698410034, Accuracy: 0.82763671875\n",
      "Batch: 40, Loss: 0.6042103171348572, Accuracy: 0.80859375\n",
      "Batch: 41, Loss: 0.5742930173873901, Accuracy: 0.8056640625\n",
      "Batch: 42, Loss: 0.5694716572761536, Accuracy: 0.81298828125\n",
      "Batch: 43, Loss: 0.5425481796264648, Accuracy: 0.82275390625\n",
      "Batch: 44, Loss: 0.5109007358551025, Accuracy: 0.8359375\n",
      "Batch: 45, Loss: 0.5374563932418823, Accuracy: 0.82275390625\n",
      "Batch: 46, Loss: 0.5177533626556396, Accuracy: 0.818359375\n",
      "Batch: 47, Loss: 0.5475993156433105, Accuracy: 0.81396484375\n",
      "Batch: 48, Loss: 0.5581070184707642, Accuracy: 0.8212890625\n",
      "Batch: 49, Loss: 0.5363912582397461, Accuracy: 0.82763671875\n",
      "Batch: 50, Loss: 0.5328548550605774, Accuracy: 0.82470703125\n",
      "Batch: 51, Loss: 0.5339580774307251, Accuracy: 0.8212890625\n",
      "Batch: 52, Loss: 0.5439873933792114, Accuracy: 0.81689453125\n",
      "Batch: 53, Loss: 0.541451096534729, Accuracy: 0.82275390625\n",
      "Batch: 54, Loss: 0.5738678574562073, Accuracy: 0.81201171875\n",
      "Batch: 55, Loss: 0.5593233108520508, Accuracy: 0.8212890625\n",
      "Batch: 56, Loss: 0.5331701040267944, Accuracy: 0.8212890625\n",
      "Batch: 57, Loss: 0.6100705862045288, Accuracy: 0.80615234375\n",
      "Batch: 58, Loss: 0.5598398447036743, Accuracy: 0.81396484375\n",
      "Batch: 59, Loss: 0.6292119026184082, Accuracy: 0.796875\n",
      "Batch: 60, Loss: 0.5403552055358887, Accuracy: 0.83740234375\n",
      "Batch: 61, Loss: 0.5092107057571411, Accuracy: 0.82861328125\n",
      "Batch: 62, Loss: 0.5107041597366333, Accuracy: 0.84130859375\n",
      "Batch: 63, Loss: 0.5479656457901001, Accuracy: 0.81005859375\n",
      "Batch: 64, Loss: 0.5630024671554565, Accuracy: 0.81689453125\n",
      "Batch: 65, Loss: 0.5769078135490417, Accuracy: 0.8115234375\n",
      "Batch: 66, Loss: 0.566805362701416, Accuracy: 0.8173828125\n",
      "Batch: 67, Loss: 0.5672643780708313, Accuracy: 0.8115234375\n",
      "Batch: 68, Loss: 0.5092018842697144, Accuracy: 0.83837890625\n",
      "Batch: 69, Loss: 0.5529483556747437, Accuracy: 0.81884765625\n",
      "Batch: 70, Loss: 0.5254490375518799, Accuracy: 0.82421875\n",
      "Batch: 71, Loss: 0.5330337882041931, Accuracy: 0.81982421875\n",
      "Batch: 72, Loss: 0.5916188955307007, Accuracy: 0.79736328125\n",
      "Batch: 73, Loss: 0.5371431708335876, Accuracy: 0.8291015625\n",
      "Batch: 74, Loss: 0.5586080551147461, Accuracy: 0.82275390625\n",
      "Batch: 75, Loss: 0.5179773569107056, Accuracy: 0.830078125\n",
      "Batch: 76, Loss: 0.516535758972168, Accuracy: 0.83984375\n",
      "Batch: 77, Loss: 0.515049934387207, Accuracy: 0.83203125\n",
      "Batch: 78, Loss: 0.5489046573638916, Accuracy: 0.82373046875\n",
      "Batch: 79, Loss: 0.5657969117164612, Accuracy: 0.8154296875\n",
      "Batch: 80, Loss: 0.5651275515556335, Accuracy: 0.81591796875\n",
      "Batch: 81, Loss: 0.5599859356880188, Accuracy: 0.81982421875\n",
      "Batch: 82, Loss: 0.5421409606933594, Accuracy: 0.82177734375\n",
      "Batch: 83, Loss: 0.49459242820739746, Accuracy: 0.83837890625\n",
      "Batch: 84, Loss: 0.5089243650436401, Accuracy: 0.83642578125\n",
      "Batch: 85, Loss: 0.5341507196426392, Accuracy: 0.8232421875\n",
      "Batch: 86, Loss: 0.5963124632835388, Accuracy: 0.80615234375\n",
      "Batch: 87, Loss: 0.5278058648109436, Accuracy: 0.82373046875\n",
      "Batch: 88, Loss: 0.5632840394973755, Accuracy: 0.82421875\n",
      "Batch: 89, Loss: 0.5546718835830688, Accuracy: 0.8154296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 90, Loss: 0.5629584789276123, Accuracy: 0.8125\n",
      "Batch: 91, Loss: 0.5473714470863342, Accuracy: 0.82177734375\n",
      "Batch: 92, Loss: 0.6055791974067688, Accuracy: 0.806640625\n",
      "Batch: 93, Loss: 0.5906488299369812, Accuracy: 0.8095703125\n",
      "Batch: 94, Loss: 0.5852184891700745, Accuracy: 0.810546875\n",
      "Batch: 95, Loss: 0.6087480783462524, Accuracy: 0.80615234375\n",
      "Batch: 96, Loss: 0.5233480334281921, Accuracy: 0.83544921875\n",
      "Batch: 97, Loss: 0.5392213463783264, Accuracy: 0.82666015625\n",
      "Batch: 98, Loss: 0.5350084900856018, Accuracy: 0.828125\n",
      "Batch: 99, Loss: 0.5307721495628357, Accuracy: 0.81787109375\n",
      "Batch: 100, Loss: 0.5951520800590515, Accuracy: 0.81298828125\n",
      "Batch: 101, Loss: 0.5939905643463135, Accuracy: 0.80419921875\n",
      "Batch: 102, Loss: 0.5146856307983398, Accuracy: 0.83251953125\n",
      "Batch: 103, Loss: 0.5835933685302734, Accuracy: 0.8095703125\n",
      "Batch: 104, Loss: 0.5705499649047852, Accuracy: 0.81201171875\n",
      "Batch: 105, Loss: 0.556922197341919, Accuracy: 0.8125\n",
      "Batch: 106, Loss: 0.5252707004547119, Accuracy: 0.8271484375\n",
      "Batch: 107, Loss: 0.5563244819641113, Accuracy: 0.822265625\n",
      "Batch: 108, Loss: 0.5278188586235046, Accuracy: 0.82568359375\n",
      "Batch: 109, Loss: 0.536344587802887, Accuracy: 0.8291015625\n",
      "Batch: 110, Loss: 0.5164186954498291, Accuracy: 0.82373046875\n",
      "Batch: 111, Loss: 0.4749712646007538, Accuracy: 0.84228515625\n",
      "Batch: 112, Loss: 0.5189542770385742, Accuracy: 0.8291015625\n",
      "Batch: 113, Loss: 0.5690604448318481, Accuracy: 0.8076171875\n",
      "Batch: 114, Loss: 0.5574768781661987, Accuracy: 0.81884765625\n",
      "Batch: 115, Loss: 0.5265628695487976, Accuracy: 0.8271484375\n",
      "Batch: 116, Loss: 0.5258821249008179, Accuracy: 0.82763671875\n",
      "Batch: 117, Loss: 0.5205754041671753, Accuracy: 0.82470703125\n",
      "Batch: 118, Loss: 0.5417593121528625, Accuracy: 0.82568359375\n",
      "Batch: 119, Loss: 0.5232202410697937, Accuracy: 0.82666015625\n",
      "Batch: 120, Loss: 0.5199394822120667, Accuracy: 0.83935546875\n",
      "Batch: 121, Loss: 0.5331361293792725, Accuracy: 0.82763671875\n",
      "Batch: 122, Loss: 0.5058526396751404, Accuracy: 0.83837890625\n",
      "Batch: 123, Loss: 0.5074084997177124, Accuracy: 0.84375\n",
      "Batch: 124, Loss: 0.5001617670059204, Accuracy: 0.830078125\n",
      "Batch: 125, Loss: 0.5345204472541809, Accuracy: 0.83251953125\n",
      "Batch: 126, Loss: 0.5463477373123169, Accuracy: 0.82177734375\n",
      "Batch: 127, Loss: 0.5082565546035767, Accuracy: 0.83935546875\n",
      "Batch: 128, Loss: 0.6041253805160522, Accuracy: 0.8134765625\n",
      "Batch: 129, Loss: 0.6303620338439941, Accuracy: 0.802734375\n",
      "Batch: 130, Loss: 0.604410707950592, Accuracy: 0.8046875\n",
      "Batch: 131, Loss: 0.5627199411392212, Accuracy: 0.8154296875\n",
      "Batch: 132, Loss: 0.5091071128845215, Accuracy: 0.833984375\n",
      "Batch: 133, Loss: 0.5043115019798279, Accuracy: 0.83935546875\n",
      "Batch: 134, Loss: 0.5535125732421875, Accuracy: 0.82470703125\n",
      "Batch: 135, Loss: 0.5537261366844177, Accuracy: 0.8173828125\n",
      "Batch: 136, Loss: 0.5098373889923096, Accuracy: 0.8330078125\n",
      "Batch: 137, Loss: 0.5508172512054443, Accuracy: 0.82177734375\n",
      "Batch: 138, Loss: 0.49587172269821167, Accuracy: 0.8505859375\n",
      "Batch: 139, Loss: 0.49862486124038696, Accuracy: 0.83642578125\n",
      "Batch: 140, Loss: 0.4848693609237671, Accuracy: 0.84228515625\n",
      "Batch: 141, Loss: 0.5434476137161255, Accuracy: 0.8251953125\n",
      "Batch: 142, Loss: 0.514384388923645, Accuracy: 0.83740234375\n",
      "Batch: 143, Loss: 0.5037447214126587, Accuracy: 0.837890625\n",
      "Batch: 144, Loss: 0.595969557762146, Accuracy: 0.80810546875\n",
      "Batch: 145, Loss: 0.5370521545410156, Accuracy: 0.82958984375\n",
      "Batch: 146, Loss: 0.559766411781311, Accuracy: 0.8173828125\n",
      "Batch: 147, Loss: 0.547929584980011, Accuracy: 0.8212890625\n",
      "Batch: 148, Loss: 0.596717119216919, Accuracy: 0.80419921875\n",
      "Batch: 149, Loss: 0.5907737016677856, Accuracy: 0.81005859375\n",
      "Batch: 150, Loss: 0.48715531826019287, Accuracy: 0.845703125\n",
      "Batch: 151, Loss: 0.5012809038162231, Accuracy: 0.83935546875\n",
      "Batch: 152, Loss: 0.5238432884216309, Accuracy: 0.82666015625\n",
      "Batch: 153, Loss: 0.5304813385009766, Accuracy: 0.83154296875\n",
      "Batch: 154, Loss: 0.5490621328353882, Accuracy: 0.81640625\n",
      "Batch: 155, Loss: 0.5887480974197388, Accuracy: 0.796875\n",
      "Batch: 156, Loss: 0.513642430305481, Accuracy: 0.8330078125\n",
      "Batch: 157, Loss: 0.48000568151474, Accuracy: 0.83203125\n",
      "Batch: 158, Loss: 0.4992232322692871, Accuracy: 0.84375\n",
      "Batch: 159, Loss: 0.5089520215988159, Accuracy: 0.8310546875\n",
      "Batch: 160, Loss: 0.5357552170753479, Accuracy: 0.828125\n",
      "Batch: 161, Loss: 0.5661534070968628, Accuracy: 0.81396484375\n",
      "Batch: 162, Loss: 0.517186164855957, Accuracy: 0.828125\n",
      "Batch: 163, Loss: 0.5391157269477844, Accuracy: 0.82080078125\n",
      "Batch: 164, Loss: 0.6192101836204529, Accuracy: 0.79541015625\n",
      "Batch: 165, Loss: 0.5369743704795837, Accuracy: 0.82373046875\n",
      "Batch: 166, Loss: 0.5704902410507202, Accuracy: 0.822265625\n",
      "Batch: 167, Loss: 0.5447280406951904, Accuracy: 0.83251953125\n",
      "Batch: 168, Loss: 0.4930728077888489, Accuracy: 0.84228515625\n",
      "Batch: 169, Loss: 0.5562416315078735, Accuracy: 0.81591796875\n",
      "Batch: 170, Loss: 0.5846143960952759, Accuracy: 0.79638671875\n",
      "Batch: 171, Loss: 0.5486276149749756, Accuracy: 0.8232421875\n",
      "Batch: 172, Loss: 0.5199334621429443, Accuracy: 0.83154296875\n",
      "Batch: 173, Loss: 0.5859952569007874, Accuracy: 0.8173828125\n",
      "Batch: 174, Loss: 0.4835337996482849, Accuracy: 0.82666015625\n",
      "Batch: 175, Loss: 0.5716333389282227, Accuracy: 0.80810546875\n",
      "Batch: 176, Loss: 0.5606312155723572, Accuracy: 0.8251953125\n",
      "Batch: 177, Loss: 0.5439199209213257, Accuracy: 0.828125\n",
      "Batch: 178, Loss: 0.5024343132972717, Accuracy: 0.84033203125\n",
      "Batch: 179, Loss: 0.5335178971290588, Accuracy: 0.837890625\n",
      "Batch: 180, Loss: 0.5586102604866028, Accuracy: 0.8212890625\n",
      "Saved Weights at epoch 80 to file Weights_80.h5\n",
      "Epoch 81/200\n",
      "Batch: 1, Loss: 0.7966616749763489, Accuracy: 0.771484375\n",
      "Batch: 2, Loss: 0.5514897704124451, Accuracy: 0.8203125\n",
      "Batch: 3, Loss: 0.547236442565918, Accuracy: 0.8232421875\n",
      "Batch: 4, Loss: 0.5910221338272095, Accuracy: 0.806640625\n",
      "Batch: 5, Loss: 0.5617588758468628, Accuracy: 0.82470703125\n",
      "Batch: 6, Loss: 0.5527086853981018, Accuracy: 0.8173828125\n",
      "Batch: 7, Loss: 0.535733699798584, Accuracy: 0.8115234375\n",
      "Batch: 8, Loss: 0.5198730230331421, Accuracy: 0.82861328125\n",
      "Batch: 9, Loss: 0.5524725914001465, Accuracy: 0.8232421875\n",
      "Batch: 10, Loss: 0.5211780071258545, Accuracy: 0.833984375\n",
      "Batch: 11, Loss: 0.565578818321228, Accuracy: 0.82177734375\n",
      "Batch: 12, Loss: 0.5052900314331055, Accuracy: 0.83544921875\n",
      "Batch: 13, Loss: 0.5318776369094849, Accuracy: 0.83154296875\n",
      "Batch: 14, Loss: 0.5458196401596069, Accuracy: 0.82470703125\n",
      "Batch: 15, Loss: 0.5875052809715271, Accuracy: 0.8125\n",
      "Batch: 16, Loss: 0.5703829526901245, Accuracy: 0.810546875\n",
      "Batch: 17, Loss: 0.5239145755767822, Accuracy: 0.82470703125\n",
      "Batch: 18, Loss: 0.5665783286094666, Accuracy: 0.8154296875\n",
      "Batch: 19, Loss: 0.5452558398246765, Accuracy: 0.8251953125\n",
      "Batch: 20, Loss: 0.4730474054813385, Accuracy: 0.84228515625\n",
      "Batch: 21, Loss: 0.5553854703903198, Accuracy: 0.82470703125\n",
      "Batch: 22, Loss: 0.5015662908554077, Accuracy: 0.83984375\n",
      "Batch: 23, Loss: 0.4999283254146576, Accuracy: 0.8349609375\n",
      "Batch: 24, Loss: 0.5388615131378174, Accuracy: 0.8291015625\n",
      "Batch: 25, Loss: 0.5088958144187927, Accuracy: 0.8427734375\n",
      "Batch: 26, Loss: 0.5279207229614258, Accuracy: 0.83154296875\n",
      "Batch: 27, Loss: 0.5802564024925232, Accuracy: 0.8125\n",
      "Batch: 28, Loss: 0.5298413634300232, Accuracy: 0.8271484375\n",
      "Batch: 29, Loss: 0.5724111199378967, Accuracy: 0.81591796875\n",
      "Batch: 30, Loss: 0.5622140169143677, Accuracy: 0.822265625\n",
      "Batch: 31, Loss: 0.6222596168518066, Accuracy: 0.80224609375\n",
      "Batch: 32, Loss: 0.5826692581176758, Accuracy: 0.8193359375\n",
      "Batch: 33, Loss: 0.5325907468795776, Accuracy: 0.82958984375\n",
      "Batch: 34, Loss: 0.577709436416626, Accuracy: 0.806640625\n",
      "Batch: 35, Loss: 0.6073835492134094, Accuracy: 0.8017578125\n",
      "Batch: 36, Loss: 0.5402575731277466, Accuracy: 0.830078125\n",
      "Batch: 37, Loss: 0.5943846702575684, Accuracy: 0.8115234375\n",
      "Batch: 38, Loss: 0.5572831630706787, Accuracy: 0.82080078125\n",
      "Batch: 39, Loss: 0.5374681949615479, Accuracy: 0.82666015625\n",
      "Batch: 40, Loss: 0.5970278978347778, Accuracy: 0.7998046875\n",
      "Batch: 41, Loss: 0.5734748244285583, Accuracy: 0.8076171875\n",
      "Batch: 42, Loss: 0.5612429976463318, Accuracy: 0.81640625\n",
      "Batch: 43, Loss: 0.5270312428474426, Accuracy: 0.83203125\n",
      "Batch: 44, Loss: 0.5032458305358887, Accuracy: 0.84375\n",
      "Batch: 45, Loss: 0.5489561557769775, Accuracy: 0.8134765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 46, Loss: 0.5053320527076721, Accuracy: 0.82763671875\n",
      "Batch: 47, Loss: 0.5660010576248169, Accuracy: 0.81787109375\n",
      "Batch: 48, Loss: 0.5603201389312744, Accuracy: 0.81005859375\n",
      "Batch: 49, Loss: 0.537608802318573, Accuracy: 0.8203125\n",
      "Batch: 50, Loss: 0.5448402166366577, Accuracy: 0.82470703125\n",
      "Batch: 51, Loss: 0.5319913029670715, Accuracy: 0.81787109375\n",
      "Batch: 52, Loss: 0.5403380393981934, Accuracy: 0.8193359375\n",
      "Batch: 53, Loss: 0.5445206165313721, Accuracy: 0.82421875\n",
      "Batch: 54, Loss: 0.5761677026748657, Accuracy: 0.8125\n",
      "Batch: 55, Loss: 0.5722311735153198, Accuracy: 0.8173828125\n",
      "Batch: 56, Loss: 0.5181546807289124, Accuracy: 0.8310546875\n",
      "Batch: 57, Loss: 0.5790054798126221, Accuracy: 0.8212890625\n",
      "Batch: 58, Loss: 0.5606504678726196, Accuracy: 0.82080078125\n",
      "Batch: 59, Loss: 0.6559763550758362, Accuracy: 0.79638671875\n",
      "Batch: 60, Loss: 0.5446120500564575, Accuracy: 0.82275390625\n",
      "Batch: 61, Loss: 0.5422795414924622, Accuracy: 0.8310546875\n",
      "Batch: 62, Loss: 0.5237829685211182, Accuracy: 0.828125\n",
      "Batch: 63, Loss: 0.5395456552505493, Accuracy: 0.82568359375\n",
      "Batch: 64, Loss: 0.5918600559234619, Accuracy: 0.8046875\n",
      "Batch: 65, Loss: 0.5853655338287354, Accuracy: 0.8037109375\n",
      "Batch: 66, Loss: 0.5334188938140869, Accuracy: 0.8251953125\n",
      "Batch: 67, Loss: 0.5872658491134644, Accuracy: 0.82080078125\n",
      "Batch: 68, Loss: 0.5079508423805237, Accuracy: 0.83251953125\n",
      "Batch: 69, Loss: 0.5605897903442383, Accuracy: 0.81787109375\n",
      "Batch: 70, Loss: 0.5373963117599487, Accuracy: 0.828125\n",
      "Batch: 71, Loss: 0.5348947048187256, Accuracy: 0.828125\n",
      "Batch: 72, Loss: 0.5912690162658691, Accuracy: 0.798828125\n",
      "Batch: 73, Loss: 0.56989586353302, Accuracy: 0.8095703125\n",
      "Batch: 74, Loss: 0.554744303226471, Accuracy: 0.8212890625\n",
      "Batch: 75, Loss: 0.5149900913238525, Accuracy: 0.8349609375\n",
      "Batch: 76, Loss: 0.49646854400634766, Accuracy: 0.84716796875\n",
      "Batch: 77, Loss: 0.5180532336235046, Accuracy: 0.84033203125\n",
      "Batch: 78, Loss: 0.5486733913421631, Accuracy: 0.82470703125\n",
      "Batch: 79, Loss: 0.5449262261390686, Accuracy: 0.82080078125\n",
      "Batch: 80, Loss: 0.5644911527633667, Accuracy: 0.81982421875\n",
      "Batch: 81, Loss: 0.5778224468231201, Accuracy: 0.8203125\n",
      "Batch: 82, Loss: 0.5289244651794434, Accuracy: 0.81591796875\n",
      "Batch: 83, Loss: 0.48333004117012024, Accuracy: 0.845703125\n",
      "Batch: 84, Loss: 0.5238721370697021, Accuracy: 0.83349609375\n",
      "Batch: 85, Loss: 0.5610653162002563, Accuracy: 0.80908203125\n",
      "Batch: 86, Loss: 0.5682043433189392, Accuracy: 0.82421875\n",
      "Batch: 87, Loss: 0.5212416052818298, Accuracy: 0.82421875\n",
      "Batch: 88, Loss: 0.5693025588989258, Accuracy: 0.81640625\n",
      "Batch: 89, Loss: 0.5285282135009766, Accuracy: 0.82861328125\n",
      "Batch: 90, Loss: 0.5807189345359802, Accuracy: 0.8056640625\n",
      "Batch: 91, Loss: 0.547559380531311, Accuracy: 0.82666015625\n",
      "Batch: 92, Loss: 0.6180800795555115, Accuracy: 0.79541015625\n",
      "Batch: 93, Loss: 0.5816843509674072, Accuracy: 0.810546875\n",
      "Batch: 94, Loss: 0.557830810546875, Accuracy: 0.82666015625\n",
      "Batch: 95, Loss: 0.5964508056640625, Accuracy: 0.80517578125\n",
      "Batch: 96, Loss: 0.5492277145385742, Accuracy: 0.8212890625\n",
      "Batch: 97, Loss: 0.5384974479675293, Accuracy: 0.83154296875\n",
      "Batch: 98, Loss: 0.5537545680999756, Accuracy: 0.814453125\n",
      "Batch: 99, Loss: 0.5232921838760376, Accuracy: 0.8310546875\n",
      "Batch: 100, Loss: 0.5871948003768921, Accuracy: 0.81396484375\n",
      "Batch: 101, Loss: 0.5878244638442993, Accuracy: 0.8232421875\n",
      "Batch: 102, Loss: 0.5210565328598022, Accuracy: 0.82763671875\n",
      "Batch: 103, Loss: 0.5353870391845703, Accuracy: 0.82568359375\n",
      "Batch: 104, Loss: 0.5184792876243591, Accuracy: 0.83447265625\n",
      "Batch: 105, Loss: 0.56281578540802, Accuracy: 0.81396484375\n",
      "Batch: 106, Loss: 0.5200163125991821, Accuracy: 0.8310546875\n",
      "Batch: 107, Loss: 0.5509926080703735, Accuracy: 0.82275390625\n",
      "Batch: 108, Loss: 0.5181828737258911, Accuracy: 0.82177734375\n",
      "Batch: 109, Loss: 0.5163389444351196, Accuracy: 0.8291015625\n",
      "Batch: 110, Loss: 0.5120950937271118, Accuracy: 0.8369140625\n",
      "Batch: 111, Loss: 0.4925675690174103, Accuracy: 0.83251953125\n",
      "Batch: 112, Loss: 0.5232604146003723, Accuracy: 0.83251953125\n",
      "Batch: 113, Loss: 0.5601845383644104, Accuracy: 0.8125\n",
      "Batch: 114, Loss: 0.5535820722579956, Accuracy: 0.8154296875\n",
      "Batch: 115, Loss: 0.5225887298583984, Accuracy: 0.8232421875\n",
      "Batch: 116, Loss: 0.5208550691604614, Accuracy: 0.83056640625\n",
      "Batch: 117, Loss: 0.5336732268333435, Accuracy: 0.82470703125\n",
      "Batch: 118, Loss: 0.5320544242858887, Accuracy: 0.83056640625\n",
      "Batch: 119, Loss: 0.5074190497398376, Accuracy: 0.8271484375\n",
      "Batch: 120, Loss: 0.5110535025596619, Accuracy: 0.83251953125\n",
      "Batch: 121, Loss: 0.5287952423095703, Accuracy: 0.8291015625\n",
      "Batch: 122, Loss: 0.4840521812438965, Accuracy: 0.83740234375\n",
      "Batch: 123, Loss: 0.484409362077713, Accuracy: 0.83740234375\n",
      "Batch: 124, Loss: 0.5033243894577026, Accuracy: 0.83154296875\n",
      "Batch: 125, Loss: 0.5366182327270508, Accuracy: 0.82373046875\n",
      "Batch: 126, Loss: 0.5399346947669983, Accuracy: 0.82568359375\n",
      "Batch: 127, Loss: 0.48886024951934814, Accuracy: 0.837890625\n",
      "Batch: 128, Loss: 0.5880094170570374, Accuracy: 0.81201171875\n",
      "Batch: 129, Loss: 0.6183810234069824, Accuracy: 0.79833984375\n",
      "Batch: 130, Loss: 0.6135945320129395, Accuracy: 0.8056640625\n",
      "Batch: 131, Loss: 0.5659936666488647, Accuracy: 0.822265625\n",
      "Batch: 132, Loss: 0.5094332695007324, Accuracy: 0.83349609375\n",
      "Batch: 133, Loss: 0.5026545524597168, Accuracy: 0.8408203125\n",
      "Batch: 134, Loss: 0.5543192028999329, Accuracy: 0.8251953125\n",
      "Batch: 135, Loss: 0.5437817573547363, Accuracy: 0.8173828125\n",
      "Batch: 136, Loss: 0.5077790021896362, Accuracy: 0.83251953125\n",
      "Batch: 137, Loss: 0.5493609309196472, Accuracy: 0.82275390625\n",
      "Batch: 138, Loss: 0.4896726608276367, Accuracy: 0.84228515625\n",
      "Batch: 139, Loss: 0.5152760148048401, Accuracy: 0.828125\n",
      "Batch: 140, Loss: 0.48398318886756897, Accuracy: 0.85009765625\n",
      "Batch: 141, Loss: 0.5451747179031372, Accuracy: 0.81884765625\n",
      "Batch: 142, Loss: 0.5008940100669861, Accuracy: 0.8349609375\n",
      "Batch: 143, Loss: 0.496212899684906, Accuracy: 0.845703125\n",
      "Batch: 144, Loss: 0.5974773168563843, Accuracy: 0.8017578125\n",
      "Batch: 145, Loss: 0.5414533019065857, Accuracy: 0.8310546875\n",
      "Batch: 146, Loss: 0.555914580821991, Accuracy: 0.81396484375\n",
      "Batch: 147, Loss: 0.5174093842506409, Accuracy: 0.83740234375\n",
      "Batch: 148, Loss: 0.5741912126541138, Accuracy: 0.81103515625\n",
      "Batch: 149, Loss: 0.5672312378883362, Accuracy: 0.814453125\n",
      "Batch: 150, Loss: 0.47853124141693115, Accuracy: 0.8466796875\n",
      "Batch: 151, Loss: 0.48899412155151367, Accuracy: 0.8466796875\n",
      "Batch: 152, Loss: 0.5082362294197083, Accuracy: 0.837890625\n",
      "Batch: 153, Loss: 0.5183342099189758, Accuracy: 0.83203125\n",
      "Batch: 154, Loss: 0.5222916603088379, Accuracy: 0.82421875\n",
      "Batch: 155, Loss: 0.5754789113998413, Accuracy: 0.81884765625\n",
      "Batch: 156, Loss: 0.5007913112640381, Accuracy: 0.82861328125\n",
      "Batch: 157, Loss: 0.46564847230911255, Accuracy: 0.84130859375\n",
      "Batch: 158, Loss: 0.4930446147918701, Accuracy: 0.8505859375\n",
      "Batch: 159, Loss: 0.5273102521896362, Accuracy: 0.8271484375\n",
      "Batch: 160, Loss: 0.5065866112709045, Accuracy: 0.83056640625\n",
      "Batch: 161, Loss: 0.5672513246536255, Accuracy: 0.82373046875\n",
      "Batch: 162, Loss: 0.5082675814628601, Accuracy: 0.84326171875\n",
      "Batch: 163, Loss: 0.5522830486297607, Accuracy: 0.8203125\n",
      "Batch: 164, Loss: 0.5925419330596924, Accuracy: 0.8134765625\n",
      "Batch: 165, Loss: 0.5679489374160767, Accuracy: 0.82275390625\n",
      "Batch: 166, Loss: 0.541520357131958, Accuracy: 0.82275390625\n",
      "Batch: 167, Loss: 0.5520547032356262, Accuracy: 0.818359375\n",
      "Batch: 168, Loss: 0.47430676221847534, Accuracy: 0.84912109375\n",
      "Batch: 169, Loss: 0.5473842620849609, Accuracy: 0.81494140625\n",
      "Batch: 170, Loss: 0.5544717311859131, Accuracy: 0.82275390625\n",
      "Batch: 171, Loss: 0.5188915729522705, Accuracy: 0.828125\n",
      "Batch: 172, Loss: 0.5194007158279419, Accuracy: 0.818359375\n",
      "Batch: 173, Loss: 0.5669717788696289, Accuracy: 0.80859375\n",
      "Batch: 174, Loss: 0.47424668073654175, Accuracy: 0.849609375\n",
      "Batch: 175, Loss: 0.5578211545944214, Accuracy: 0.81298828125\n",
      "Batch: 176, Loss: 0.5755826234817505, Accuracy: 0.81494140625\n",
      "Batch: 177, Loss: 0.531791090965271, Accuracy: 0.82275390625\n",
      "Batch: 178, Loss: 0.4922032952308655, Accuracy: 0.84326171875\n",
      "Batch: 179, Loss: 0.5288369655609131, Accuracy: 0.82421875\n",
      "Batch: 180, Loss: 0.5494881868362427, Accuracy: 0.81884765625\n",
      "Epoch 82/200\n",
      "Batch: 1, Loss: 0.7967458367347717, Accuracy: 0.7822265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2, Loss: 0.5482255220413208, Accuracy: 0.81982421875\n",
      "Batch: 3, Loss: 0.5484783053398132, Accuracy: 0.822265625\n",
      "Batch: 4, Loss: 0.5675481557846069, Accuracy: 0.81494140625\n",
      "Batch: 5, Loss: 0.540740966796875, Accuracy: 0.8212890625\n",
      "Batch: 6, Loss: 0.5614399909973145, Accuracy: 0.8193359375\n",
      "Batch: 7, Loss: 0.5482841730117798, Accuracy: 0.81591796875\n",
      "Batch: 8, Loss: 0.5225486159324646, Accuracy: 0.8271484375\n",
      "Batch: 9, Loss: 0.549446702003479, Accuracy: 0.82080078125\n",
      "Batch: 10, Loss: 0.5063998699188232, Accuracy: 0.837890625\n",
      "Batch: 11, Loss: 0.568543553352356, Accuracy: 0.8076171875\n",
      "Batch: 12, Loss: 0.5145249962806702, Accuracy: 0.83251953125\n",
      "Batch: 13, Loss: 0.5258206129074097, Accuracy: 0.833984375\n",
      "Batch: 14, Loss: 0.5506516695022583, Accuracy: 0.8173828125\n",
      "Batch: 15, Loss: 0.5481222867965698, Accuracy: 0.82958984375\n",
      "Batch: 16, Loss: 0.5583662986755371, Accuracy: 0.814453125\n",
      "Batch: 17, Loss: 0.5264275074005127, Accuracy: 0.83203125\n",
      "Batch: 18, Loss: 0.5692826509475708, Accuracy: 0.82177734375\n",
      "Batch: 19, Loss: 0.5683693289756775, Accuracy: 0.8212890625\n",
      "Batch: 20, Loss: 0.4764458239078522, Accuracy: 0.83935546875\n",
      "Batch: 21, Loss: 0.5530081987380981, Accuracy: 0.82177734375\n",
      "Batch: 22, Loss: 0.4876769185066223, Accuracy: 0.84716796875\n",
      "Batch: 23, Loss: 0.4902995824813843, Accuracy: 0.84130859375\n",
      "Batch: 24, Loss: 0.5356127023696899, Accuracy: 0.82666015625\n",
      "Batch: 25, Loss: 0.5109423398971558, Accuracy: 0.82763671875\n",
      "Batch: 26, Loss: 0.5310107469558716, Accuracy: 0.830078125\n",
      "Batch: 27, Loss: 0.5468899011611938, Accuracy: 0.81787109375\n",
      "Batch: 28, Loss: 0.528113842010498, Accuracy: 0.8330078125\n",
      "Batch: 29, Loss: 0.5705200433731079, Accuracy: 0.8193359375\n",
      "Batch: 30, Loss: 0.5676476955413818, Accuracy: 0.81689453125\n",
      "Batch: 31, Loss: 0.6064778566360474, Accuracy: 0.80419921875\n",
      "Batch: 32, Loss: 0.5789960622787476, Accuracy: 0.8076171875\n",
      "Batch: 33, Loss: 0.5626765489578247, Accuracy: 0.8154296875\n",
      "Batch: 34, Loss: 0.574570894241333, Accuracy: 0.8154296875\n",
      "Batch: 35, Loss: 0.5739150047302246, Accuracy: 0.82080078125\n",
      "Batch: 36, Loss: 0.5433415174484253, Accuracy: 0.82275390625\n",
      "Batch: 37, Loss: 0.5829696655273438, Accuracy: 0.81298828125\n",
      "Batch: 38, Loss: 0.5695644617080688, Accuracy: 0.80859375\n",
      "Batch: 39, Loss: 0.5189120769500732, Accuracy: 0.82666015625\n",
      "Batch: 40, Loss: 0.5901235938072205, Accuracy: 0.8037109375\n",
      "Batch: 41, Loss: 0.5682955980300903, Accuracy: 0.81103515625\n",
      "Batch: 42, Loss: 0.5464456081390381, Accuracy: 0.81396484375\n",
      "Batch: 43, Loss: 0.524514377117157, Accuracy: 0.82958984375\n",
      "Batch: 44, Loss: 0.48340484499931335, Accuracy: 0.8505859375\n",
      "Batch: 45, Loss: 0.5471550822257996, Accuracy: 0.82080078125\n",
      "Batch: 46, Loss: 0.5215146541595459, Accuracy: 0.82470703125\n",
      "Batch: 47, Loss: 0.5356793999671936, Accuracy: 0.81689453125\n",
      "Batch: 48, Loss: 0.5325957536697388, Accuracy: 0.828125\n",
      "Batch: 49, Loss: 0.5269359350204468, Accuracy: 0.8369140625\n",
      "Batch: 50, Loss: 0.5527710914611816, Accuracy: 0.81884765625\n",
      "Batch: 51, Loss: 0.5299261808395386, Accuracy: 0.8310546875\n",
      "Batch: 52, Loss: 0.540185272693634, Accuracy: 0.818359375\n",
      "Batch: 53, Loss: 0.5405746698379517, Accuracy: 0.826171875\n",
      "Batch: 54, Loss: 0.5661411285400391, Accuracy: 0.8125\n",
      "Batch: 55, Loss: 0.5503699779510498, Accuracy: 0.82080078125\n",
      "Batch: 56, Loss: 0.5294249057769775, Accuracy: 0.822265625\n",
      "Batch: 57, Loss: 0.5837205052375793, Accuracy: 0.81591796875\n",
      "Batch: 58, Loss: 0.5698767304420471, Accuracy: 0.8134765625\n",
      "Batch: 59, Loss: 0.6424595713615417, Accuracy: 0.79248046875\n",
      "Batch: 60, Loss: 0.5408446192741394, Accuracy: 0.82080078125\n",
      "Batch: 61, Loss: 0.5091598033905029, Accuracy: 0.83203125\n",
      "Batch: 62, Loss: 0.5242142677307129, Accuracy: 0.82373046875\n",
      "Batch: 63, Loss: 0.5367602109909058, Accuracy: 0.8173828125\n",
      "Batch: 64, Loss: 0.5492870211601257, Accuracy: 0.81884765625\n",
      "Batch: 65, Loss: 0.5579881072044373, Accuracy: 0.822265625\n",
      "Batch: 66, Loss: 0.5282509326934814, Accuracy: 0.83349609375\n",
      "Batch: 67, Loss: 0.5591393709182739, Accuracy: 0.81982421875\n",
      "Batch: 68, Loss: 0.4999884366989136, Accuracy: 0.83642578125\n",
      "Batch: 69, Loss: 0.547308087348938, Accuracy: 0.8173828125\n",
      "Batch: 70, Loss: 0.5154695510864258, Accuracy: 0.82763671875\n",
      "Batch: 71, Loss: 0.5210647583007812, Accuracy: 0.82763671875\n",
      "Batch: 72, Loss: 0.5724275708198547, Accuracy: 0.814453125\n",
      "Batch: 73, Loss: 0.5289779901504517, Accuracy: 0.82421875\n",
      "Batch: 74, Loss: 0.5497361421585083, Accuracy: 0.8203125\n",
      "Batch: 75, Loss: 0.5029440522193909, Accuracy: 0.841796875\n",
      "Batch: 76, Loss: 0.5065484642982483, Accuracy: 0.84326171875\n",
      "Batch: 77, Loss: 0.5399880409240723, Accuracy: 0.830078125\n",
      "Batch: 78, Loss: 0.5484752655029297, Accuracy: 0.826171875\n",
      "Batch: 79, Loss: 0.5409635901451111, Accuracy: 0.83447265625\n",
      "Batch: 80, Loss: 0.5694941282272339, Accuracy: 0.82373046875\n",
      "Batch: 81, Loss: 0.548263430595398, Accuracy: 0.822265625\n",
      "Batch: 82, Loss: 0.530768871307373, Accuracy: 0.8251953125\n",
      "Batch: 83, Loss: 0.48766955733299255, Accuracy: 0.841796875\n",
      "Batch: 84, Loss: 0.5279832482337952, Accuracy: 0.833984375\n",
      "Batch: 85, Loss: 0.5576584935188293, Accuracy: 0.8154296875\n",
      "Batch: 86, Loss: 0.570749044418335, Accuracy: 0.82763671875\n",
      "Batch: 87, Loss: 0.5101122260093689, Accuracy: 0.828125\n",
      "Batch: 88, Loss: 0.5869860053062439, Accuracy: 0.81787109375\n",
      "Batch: 89, Loss: 0.5062676668167114, Accuracy: 0.8447265625\n",
      "Batch: 90, Loss: 0.5720186233520508, Accuracy: 0.81494140625\n",
      "Batch: 91, Loss: 0.5411396026611328, Accuracy: 0.82177734375\n",
      "Batch: 92, Loss: 0.6095640063285828, Accuracy: 0.7919921875\n",
      "Batch: 93, Loss: 0.5962399840354919, Accuracy: 0.796875\n",
      "Batch: 94, Loss: 0.5608621835708618, Accuracy: 0.82373046875\n",
      "Batch: 95, Loss: 0.603144645690918, Accuracy: 0.80615234375\n",
      "Batch: 96, Loss: 0.5312953591346741, Accuracy: 0.828125\n",
      "Batch: 97, Loss: 0.5398725271224976, Accuracy: 0.82666015625\n",
      "Batch: 98, Loss: 0.5542619228363037, Accuracy: 0.82568359375\n",
      "Batch: 99, Loss: 0.5133903622627258, Accuracy: 0.83154296875\n",
      "Batch: 100, Loss: 0.5908514261245728, Accuracy: 0.8076171875\n",
      "Batch: 101, Loss: 0.58124840259552, Accuracy: 0.8076171875\n",
      "Batch: 102, Loss: 0.49588897824287415, Accuracy: 0.8427734375\n",
      "Batch: 103, Loss: 0.569787859916687, Accuracy: 0.82177734375\n",
      "Batch: 104, Loss: 0.548457682132721, Accuracy: 0.81982421875\n",
      "Batch: 105, Loss: 0.5406451225280762, Accuracy: 0.828125\n",
      "Batch: 106, Loss: 0.5164687633514404, Accuracy: 0.83544921875\n",
      "Batch: 107, Loss: 0.5687709450721741, Accuracy: 0.8173828125\n",
      "Batch: 108, Loss: 0.5295586585998535, Accuracy: 0.8251953125\n",
      "Batch: 109, Loss: 0.512603759765625, Accuracy: 0.84130859375\n",
      "Batch: 110, Loss: 0.5176030397415161, Accuracy: 0.82666015625\n",
      "Batch: 111, Loss: 0.49805691838264465, Accuracy: 0.82666015625\n",
      "Batch: 112, Loss: 0.4961758852005005, Accuracy: 0.83544921875\n",
      "Batch: 113, Loss: 0.547967791557312, Accuracy: 0.810546875\n",
      "Batch: 114, Loss: 0.542545735836029, Accuracy: 0.83056640625\n",
      "Batch: 115, Loss: 0.503639817237854, Accuracy: 0.83984375\n",
      "Batch: 116, Loss: 0.5244731903076172, Accuracy: 0.82861328125\n",
      "Batch: 117, Loss: 0.479297012090683, Accuracy: 0.8427734375\n",
      "Batch: 118, Loss: 0.5281494855880737, Accuracy: 0.830078125\n",
      "Batch: 119, Loss: 0.5163261890411377, Accuracy: 0.82763671875\n",
      "Batch: 120, Loss: 0.4990515112876892, Accuracy: 0.83740234375\n",
      "Batch: 121, Loss: 0.5235974192619324, Accuracy: 0.82763671875\n",
      "Batch: 122, Loss: 0.4959638714790344, Accuracy: 0.833984375\n",
      "Batch: 123, Loss: 0.503815770149231, Accuracy: 0.85009765625\n",
      "Batch: 124, Loss: 0.4881511330604553, Accuracy: 0.83935546875\n",
      "Batch: 125, Loss: 0.5297073721885681, Accuracy: 0.8271484375\n",
      "Batch: 126, Loss: 0.5231936573982239, Accuracy: 0.830078125\n",
      "Batch: 127, Loss: 0.4869018495082855, Accuracy: 0.84423828125\n",
      "Batch: 128, Loss: 0.5884833931922913, Accuracy: 0.8037109375\n",
      "Batch: 129, Loss: 0.5704582929611206, Accuracy: 0.822265625\n",
      "Batch: 130, Loss: 0.6131410598754883, Accuracy: 0.79736328125\n",
      "Batch: 131, Loss: 0.54898601770401, Accuracy: 0.8173828125\n",
      "Batch: 132, Loss: 0.5221368074417114, Accuracy: 0.8271484375\n",
      "Batch: 133, Loss: 0.5049619674682617, Accuracy: 0.84814453125\n",
      "Batch: 134, Loss: 0.5499235987663269, Accuracy: 0.8291015625\n",
      "Batch: 135, Loss: 0.5669450163841248, Accuracy: 0.81005859375\n",
      "Batch: 136, Loss: 0.49396467208862305, Accuracy: 0.83837890625\n",
      "Batch: 137, Loss: 0.5316559076309204, Accuracy: 0.8330078125\n",
      "Batch: 138, Loss: 0.4842352867126465, Accuracy: 0.8486328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 139, Loss: 0.5171670913696289, Accuracy: 0.82861328125\n",
      "Batch: 140, Loss: 0.469082772731781, Accuracy: 0.84033203125\n",
      "Batch: 141, Loss: 0.5450202226638794, Accuracy: 0.8251953125\n",
      "Batch: 142, Loss: 0.4894164800643921, Accuracy: 0.845703125\n",
      "Batch: 143, Loss: 0.5092633962631226, Accuracy: 0.8408203125\n",
      "Batch: 144, Loss: 0.5685792565345764, Accuracy: 0.8115234375\n",
      "Batch: 145, Loss: 0.5331245064735413, Accuracy: 0.828125\n",
      "Batch: 146, Loss: 0.5532431602478027, Accuracy: 0.8232421875\n",
      "Batch: 147, Loss: 0.5158833265304565, Accuracy: 0.83984375\n",
      "Batch: 148, Loss: 0.5600049495697021, Accuracy: 0.81201171875\n",
      "Batch: 149, Loss: 0.5554901361465454, Accuracy: 0.810546875\n",
      "Batch: 150, Loss: 0.478052020072937, Accuracy: 0.8388671875\n",
      "Batch: 151, Loss: 0.4962990880012512, Accuracy: 0.84423828125\n",
      "Batch: 152, Loss: 0.5282469391822815, Accuracy: 0.82861328125\n",
      "Batch: 153, Loss: 0.5264369249343872, Accuracy: 0.8349609375\n",
      "Batch: 154, Loss: 0.5515480041503906, Accuracy: 0.8251953125\n",
      "Batch: 155, Loss: 0.5790547132492065, Accuracy: 0.8125\n",
      "Batch: 156, Loss: 0.500206708908081, Accuracy: 0.83447265625\n",
      "Batch: 157, Loss: 0.4871385395526886, Accuracy: 0.83740234375\n",
      "Batch: 158, Loss: 0.5097393989562988, Accuracy: 0.83935546875\n",
      "Batch: 159, Loss: 0.5240809917449951, Accuracy: 0.83251953125\n",
      "Batch: 160, Loss: 0.5348562002182007, Accuracy: 0.82470703125\n",
      "Batch: 161, Loss: 0.5471663475036621, Accuracy: 0.8193359375\n",
      "Batch: 162, Loss: 0.5103496313095093, Accuracy: 0.83251953125\n",
      "Batch: 163, Loss: 0.5497393608093262, Accuracy: 0.82080078125\n",
      "Batch: 164, Loss: 0.591943085193634, Accuracy: 0.80712890625\n",
      "Batch: 165, Loss: 0.5423024296760559, Accuracy: 0.830078125\n",
      "Batch: 166, Loss: 0.5656870007514954, Accuracy: 0.81640625\n",
      "Batch: 167, Loss: 0.5312454700469971, Accuracy: 0.8359375\n",
      "Batch: 168, Loss: 0.4776834547519684, Accuracy: 0.849609375\n",
      "Batch: 169, Loss: 0.5212458372116089, Accuracy: 0.82373046875\n",
      "Batch: 170, Loss: 0.5644071102142334, Accuracy: 0.8125\n",
      "Batch: 171, Loss: 0.5069875717163086, Accuracy: 0.828125\n",
      "Batch: 172, Loss: 0.5052443146705627, Accuracy: 0.83203125\n",
      "Batch: 173, Loss: 0.5562725067138672, Accuracy: 0.8134765625\n",
      "Batch: 174, Loss: 0.4870731830596924, Accuracy: 0.8310546875\n",
      "Batch: 175, Loss: 0.5570982694625854, Accuracy: 0.80615234375\n",
      "Batch: 176, Loss: 0.5752631425857544, Accuracy: 0.81005859375\n",
      "Batch: 177, Loss: 0.5555825233459473, Accuracy: 0.826171875\n",
      "Batch: 178, Loss: 0.4931383430957794, Accuracy: 0.84130859375\n",
      "Batch: 179, Loss: 0.5395547151565552, Accuracy: 0.82470703125\n",
      "Batch: 180, Loss: 0.5379800200462341, Accuracy: 0.8232421875\n",
      "Epoch 83/200\n",
      "Batch: 1, Loss: 0.7970654964447021, Accuracy: 0.78369140625\n",
      "Batch: 2, Loss: 0.5192419290542603, Accuracy: 0.8232421875\n",
      "Batch: 3, Loss: 0.5321984887123108, Accuracy: 0.826171875\n",
      "Batch: 4, Loss: 0.545058012008667, Accuracy: 0.8193359375\n",
      "Batch: 5, Loss: 0.5176908373832703, Accuracy: 0.83984375\n",
      "Batch: 6, Loss: 0.5519246459007263, Accuracy: 0.81494140625\n",
      "Batch: 7, Loss: 0.5327997803688049, Accuracy: 0.83203125\n",
      "Batch: 8, Loss: 0.53022301197052, Accuracy: 0.8310546875\n",
      "Batch: 9, Loss: 0.5766474008560181, Accuracy: 0.818359375\n",
      "Batch: 10, Loss: 0.5266934633255005, Accuracy: 0.83154296875\n",
      "Batch: 11, Loss: 0.5273993611335754, Accuracy: 0.830078125\n",
      "Batch: 12, Loss: 0.48008978366851807, Accuracy: 0.83984375\n",
      "Batch: 13, Loss: 0.5245380401611328, Accuracy: 0.8271484375\n",
      "Batch: 14, Loss: 0.5156232714653015, Accuracy: 0.8359375\n",
      "Batch: 15, Loss: 0.5621249079704285, Accuracy: 0.8193359375\n",
      "Batch: 16, Loss: 0.5754611492156982, Accuracy: 0.80419921875\n",
      "Batch: 17, Loss: 0.5087128281593323, Accuracy: 0.8349609375\n",
      "Batch: 18, Loss: 0.5565294623374939, Accuracy: 0.81640625\n",
      "Batch: 19, Loss: 0.5574131011962891, Accuracy: 0.81884765625\n",
      "Batch: 20, Loss: 0.48228949308395386, Accuracy: 0.8486328125\n",
      "Batch: 21, Loss: 0.557698130607605, Accuracy: 0.8251953125\n",
      "Batch: 22, Loss: 0.5175027847290039, Accuracy: 0.82958984375\n",
      "Batch: 23, Loss: 0.5037814378738403, Accuracy: 0.83349609375\n",
      "Batch: 24, Loss: 0.5097048878669739, Accuracy: 0.8408203125\n",
      "Batch: 25, Loss: 0.5022214651107788, Accuracy: 0.83544921875\n",
      "Batch: 26, Loss: 0.511954665184021, Accuracy: 0.83203125\n",
      "Batch: 27, Loss: 0.5620267391204834, Accuracy: 0.8232421875\n",
      "Batch: 28, Loss: 0.5043551921844482, Accuracy: 0.8369140625\n",
      "Batch: 29, Loss: 0.5743314027786255, Accuracy: 0.81640625\n",
      "Batch: 30, Loss: 0.5587482452392578, Accuracy: 0.82177734375\n",
      "Batch: 31, Loss: 0.6150222420692444, Accuracy: 0.80859375\n",
      "Batch: 32, Loss: 0.5856027603149414, Accuracy: 0.81103515625\n",
      "Batch: 33, Loss: 0.5503587126731873, Accuracy: 0.82177734375\n",
      "Batch: 34, Loss: 0.5750404596328735, Accuracy: 0.81787109375\n",
      "Batch: 35, Loss: 0.6042807102203369, Accuracy: 0.81103515625\n",
      "Batch: 36, Loss: 0.5543026328086853, Accuracy: 0.8212890625\n",
      "Batch: 37, Loss: 0.5773375630378723, Accuracy: 0.814453125\n",
      "Batch: 38, Loss: 0.577021598815918, Accuracy: 0.81640625\n",
      "Batch: 39, Loss: 0.5613098740577698, Accuracy: 0.81689453125\n",
      "Batch: 40, Loss: 0.5862927436828613, Accuracy: 0.81201171875\n",
      "Batch: 41, Loss: 0.5570370554924011, Accuracy: 0.82080078125\n",
      "Batch: 42, Loss: 0.5352869033813477, Accuracy: 0.82421875\n",
      "Batch: 43, Loss: 0.5314939618110657, Accuracy: 0.8271484375\n",
      "Batch: 44, Loss: 0.4896559715270996, Accuracy: 0.8369140625\n",
      "Batch: 45, Loss: 0.5370281934738159, Accuracy: 0.826171875\n",
      "Batch: 46, Loss: 0.5182831883430481, Accuracy: 0.81982421875\n",
      "Batch: 47, Loss: 0.5346725583076477, Accuracy: 0.8251953125\n",
      "Batch: 48, Loss: 0.5278784036636353, Accuracy: 0.83447265625\n",
      "Batch: 49, Loss: 0.5344403982162476, Accuracy: 0.83349609375\n",
      "Batch: 50, Loss: 0.5347168445587158, Accuracy: 0.82666015625\n",
      "Batch: 51, Loss: 0.5392343401908875, Accuracy: 0.81591796875\n",
      "Batch: 52, Loss: 0.5264375805854797, Accuracy: 0.83056640625\n",
      "Batch: 53, Loss: 0.5356471538543701, Accuracy: 0.8212890625\n",
      "Batch: 54, Loss: 0.5546259880065918, Accuracy: 0.81787109375\n",
      "Batch: 55, Loss: 0.5497635006904602, Accuracy: 0.82275390625\n",
      "Batch: 56, Loss: 0.5030386447906494, Accuracy: 0.833984375\n",
      "Batch: 57, Loss: 0.5930337905883789, Accuracy: 0.8115234375\n",
      "Batch: 58, Loss: 0.5461357831954956, Accuracy: 0.822265625\n",
      "Batch: 59, Loss: 0.6282864212989807, Accuracy: 0.79638671875\n",
      "Batch: 60, Loss: 0.5416759848594666, Accuracy: 0.82763671875\n",
      "Batch: 61, Loss: 0.5072557926177979, Accuracy: 0.828125\n",
      "Batch: 62, Loss: 0.5161309242248535, Accuracy: 0.828125\n",
      "Batch: 63, Loss: 0.5284841060638428, Accuracy: 0.82568359375\n",
      "Batch: 64, Loss: 0.5619218945503235, Accuracy: 0.81884765625\n",
      "Batch: 65, Loss: 0.5802589654922485, Accuracy: 0.8095703125\n",
      "Batch: 66, Loss: 0.5413811206817627, Accuracy: 0.82421875\n",
      "Batch: 67, Loss: 0.5646260380744934, Accuracy: 0.8173828125\n",
      "Batch: 68, Loss: 0.510887861251831, Accuracy: 0.8359375\n",
      "Batch: 69, Loss: 0.525044322013855, Accuracy: 0.8203125\n",
      "Batch: 70, Loss: 0.5028635263442993, Accuracy: 0.833984375\n",
      "Batch: 71, Loss: 0.5356215834617615, Accuracy: 0.83203125\n",
      "Batch: 72, Loss: 0.5656478404998779, Accuracy: 0.81103515625\n",
      "Batch: 73, Loss: 0.540898323059082, Accuracy: 0.8203125\n",
      "Batch: 74, Loss: 0.5536909103393555, Accuracy: 0.8232421875\n",
      "Batch: 75, Loss: 0.5121469497680664, Accuracy: 0.82763671875\n",
      "Batch: 76, Loss: 0.49864572286605835, Accuracy: 0.84375\n",
      "Batch: 77, Loss: 0.4944809675216675, Accuracy: 0.845703125\n",
      "Batch: 78, Loss: 0.5159655809402466, Accuracy: 0.828125\n",
      "Batch: 79, Loss: 0.5330970287322998, Accuracy: 0.81787109375\n",
      "Batch: 80, Loss: 0.557461142539978, Accuracy: 0.826171875\n",
      "Batch: 81, Loss: 0.5530887246131897, Accuracy: 0.83056640625\n",
      "Batch: 82, Loss: 0.5446449518203735, Accuracy: 0.81298828125\n",
      "Batch: 83, Loss: 0.5090782046318054, Accuracy: 0.8408203125\n",
      "Batch: 84, Loss: 0.5323665142059326, Accuracy: 0.84033203125\n",
      "Batch: 85, Loss: 0.5476398468017578, Accuracy: 0.82080078125\n",
      "Batch: 86, Loss: 0.5683983564376831, Accuracy: 0.81982421875\n",
      "Batch: 87, Loss: 0.4954909384250641, Accuracy: 0.83642578125\n",
      "Batch: 88, Loss: 0.569687008857727, Accuracy: 0.81689453125\n",
      "Batch: 89, Loss: 0.49692487716674805, Accuracy: 0.83154296875\n",
      "Batch: 90, Loss: 0.561219334602356, Accuracy: 0.8115234375\n",
      "Batch: 91, Loss: 0.5372227430343628, Accuracy: 0.82080078125\n",
      "Batch: 92, Loss: 0.6035779714584351, Accuracy: 0.8017578125\n",
      "Batch: 93, Loss: 0.5707085728645325, Accuracy: 0.8173828125\n",
      "Batch: 94, Loss: 0.5619069337844849, Accuracy: 0.81689453125\n",
      "Batch: 95, Loss: 0.5980294346809387, Accuracy: 0.80859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 96, Loss: 0.5487781167030334, Accuracy: 0.8330078125\n",
      "Batch: 97, Loss: 0.5451229810714722, Accuracy: 0.83154296875\n",
      "Batch: 98, Loss: 0.5369287729263306, Accuracy: 0.833984375\n",
      "Batch: 99, Loss: 0.5291315913200378, Accuracy: 0.83642578125\n",
      "Batch: 100, Loss: 0.5639321804046631, Accuracy: 0.81298828125\n",
      "Batch: 101, Loss: 0.5986112952232361, Accuracy: 0.8125\n",
      "Batch: 102, Loss: 0.522037148475647, Accuracy: 0.82861328125\n",
      "Batch: 103, Loss: 0.5504940152168274, Accuracy: 0.8212890625\n",
      "Batch: 104, Loss: 0.5363917350769043, Accuracy: 0.83203125\n",
      "Batch: 105, Loss: 0.5464572906494141, Accuracy: 0.82568359375\n",
      "Batch: 106, Loss: 0.5124295353889465, Accuracy: 0.833984375\n",
      "Batch: 107, Loss: 0.560698390007019, Accuracy: 0.82666015625\n",
      "Batch: 108, Loss: 0.5270425081253052, Accuracy: 0.83154296875\n",
      "Batch: 109, Loss: 0.5202124714851379, Accuracy: 0.8359375\n",
      "Batch: 110, Loss: 0.5040805339813232, Accuracy: 0.83447265625\n",
      "Batch: 111, Loss: 0.4877365529537201, Accuracy: 0.84375\n",
      "Batch: 112, Loss: 0.5160433650016785, Accuracy: 0.83251953125\n",
      "Batch: 113, Loss: 0.539305567741394, Accuracy: 0.826171875\n",
      "Batch: 114, Loss: 0.5425608158111572, Accuracy: 0.82421875\n",
      "Batch: 115, Loss: 0.5233657360076904, Accuracy: 0.830078125\n",
      "Batch: 116, Loss: 0.5062529444694519, Accuracy: 0.8349609375\n",
      "Batch: 117, Loss: 0.49638959765434265, Accuracy: 0.83203125\n",
      "Batch: 118, Loss: 0.5262250900268555, Accuracy: 0.8232421875\n",
      "Batch: 119, Loss: 0.5008214712142944, Accuracy: 0.8369140625\n",
      "Batch: 120, Loss: 0.4941902756690979, Accuracy: 0.83740234375\n",
      "Batch: 121, Loss: 0.5356791019439697, Accuracy: 0.8251953125\n",
      "Batch: 122, Loss: 0.5103475451469421, Accuracy: 0.83837890625\n",
      "Batch: 123, Loss: 0.5077766180038452, Accuracy: 0.84521484375\n",
      "Batch: 124, Loss: 0.48895853757858276, Accuracy: 0.83984375\n",
      "Batch: 125, Loss: 0.5303473472595215, Accuracy: 0.83544921875\n",
      "Batch: 126, Loss: 0.5262973308563232, Accuracy: 0.8291015625\n",
      "Batch: 127, Loss: 0.4734005630016327, Accuracy: 0.84619140625\n",
      "Batch: 128, Loss: 0.5649582743644714, Accuracy: 0.818359375\n",
      "Batch: 129, Loss: 0.5971975326538086, Accuracy: 0.81787109375\n",
      "Batch: 130, Loss: 0.5963956713676453, Accuracy: 0.80859375\n",
      "Batch: 131, Loss: 0.5418292284011841, Accuracy: 0.83056640625\n",
      "Batch: 132, Loss: 0.5083822011947632, Accuracy: 0.83447265625\n",
      "Batch: 133, Loss: 0.49695754051208496, Accuracy: 0.84033203125\n",
      "Batch: 134, Loss: 0.5563714504241943, Accuracy: 0.8173828125\n",
      "Batch: 135, Loss: 0.5185775756835938, Accuracy: 0.82958984375\n",
      "Batch: 136, Loss: 0.5013056993484497, Accuracy: 0.8466796875\n",
      "Batch: 137, Loss: 0.5392870306968689, Accuracy: 0.82958984375\n",
      "Batch: 138, Loss: 0.4796546399593353, Accuracy: 0.845703125\n",
      "Batch: 139, Loss: 0.4991978704929352, Accuracy: 0.83349609375\n",
      "Batch: 140, Loss: 0.44979947805404663, Accuracy: 0.85546875\n",
      "Batch: 141, Loss: 0.543245792388916, Accuracy: 0.8154296875\n",
      "Batch: 142, Loss: 0.4885399341583252, Accuracy: 0.83984375\n",
      "Batch: 143, Loss: 0.5072581768035889, Accuracy: 0.8349609375\n",
      "Batch: 144, Loss: 0.5669773817062378, Accuracy: 0.814453125\n",
      "Batch: 145, Loss: 0.5195445418357849, Accuracy: 0.8330078125\n",
      "Batch: 146, Loss: 0.5425829887390137, Accuracy: 0.82763671875\n",
      "Batch: 147, Loss: 0.5274275541305542, Accuracy: 0.83642578125\n",
      "Batch: 148, Loss: 0.5624897480010986, Accuracy: 0.8056640625\n",
      "Batch: 149, Loss: 0.5516871809959412, Accuracy: 0.822265625\n",
      "Batch: 150, Loss: 0.4865874946117401, Accuracy: 0.85498046875\n",
      "Batch: 151, Loss: 0.4839516878128052, Accuracy: 0.8359375\n",
      "Batch: 152, Loss: 0.5195081830024719, Accuracy: 0.82177734375\n",
      "Batch: 153, Loss: 0.5236953496932983, Accuracy: 0.8388671875\n",
      "Batch: 154, Loss: 0.5369396805763245, Accuracy: 0.826171875\n",
      "Batch: 155, Loss: 0.569636344909668, Accuracy: 0.81298828125\n",
      "Batch: 156, Loss: 0.4887704849243164, Accuracy: 0.8427734375\n",
      "Batch: 157, Loss: 0.46792101860046387, Accuracy: 0.84375\n",
      "Batch: 158, Loss: 0.492026150226593, Accuracy: 0.8505859375\n",
      "Batch: 159, Loss: 0.5098057985305786, Accuracy: 0.837890625\n",
      "Batch: 160, Loss: 0.512813150882721, Accuracy: 0.833984375\n",
      "Batch: 161, Loss: 0.5477125644683838, Accuracy: 0.8212890625\n",
      "Batch: 162, Loss: 0.5037868022918701, Accuracy: 0.83642578125\n",
      "Batch: 163, Loss: 0.527341365814209, Accuracy: 0.83642578125\n",
      "Batch: 164, Loss: 0.5871404409408569, Accuracy: 0.81201171875\n",
      "Batch: 165, Loss: 0.5404239296913147, Accuracy: 0.82080078125\n",
      "Batch: 166, Loss: 0.550208330154419, Accuracy: 0.822265625\n",
      "Batch: 167, Loss: 0.5276170372962952, Accuracy: 0.83251953125\n",
      "Batch: 168, Loss: 0.47567084431648254, Accuracy: 0.83984375\n",
      "Batch: 169, Loss: 0.5496916770935059, Accuracy: 0.82080078125\n",
      "Batch: 170, Loss: 0.5751844644546509, Accuracy: 0.8134765625\n",
      "Batch: 171, Loss: 0.5012001991271973, Accuracy: 0.83984375\n",
      "Batch: 172, Loss: 0.5132995843887329, Accuracy: 0.82666015625\n",
      "Batch: 173, Loss: 0.5597858428955078, Accuracy: 0.81494140625\n",
      "Batch: 174, Loss: 0.4860574007034302, Accuracy: 0.833984375\n",
      "Batch: 175, Loss: 0.5543007850646973, Accuracy: 0.81298828125\n",
      "Batch: 176, Loss: 0.5779809951782227, Accuracy: 0.81494140625\n",
      "Batch: 177, Loss: 0.5314886569976807, Accuracy: 0.82666015625\n",
      "Batch: 178, Loss: 0.5088027715682983, Accuracy: 0.8349609375\n",
      "Batch: 179, Loss: 0.5564019680023193, Accuracy: 0.8359375\n",
      "Batch: 180, Loss: 0.5355755090713501, Accuracy: 0.82568359375\n",
      "Epoch 84/200\n",
      "Batch: 1, Loss: 0.8048534989356995, Accuracy: 0.77490234375\n",
      "Batch: 2, Loss: 0.5467002391815186, Accuracy: 0.8203125\n",
      "Batch: 3, Loss: 0.5305123925209045, Accuracy: 0.82373046875\n",
      "Batch: 4, Loss: 0.5531532764434814, Accuracy: 0.8134765625\n",
      "Batch: 5, Loss: 0.5617040395736694, Accuracy: 0.82470703125\n",
      "Batch: 6, Loss: 0.5473678112030029, Accuracy: 0.82666015625\n",
      "Batch: 7, Loss: 0.5150778293609619, Accuracy: 0.8310546875\n",
      "Batch: 8, Loss: 0.5235821008682251, Accuracy: 0.82177734375\n",
      "Batch: 9, Loss: 0.5400863885879517, Accuracy: 0.82666015625\n",
      "Batch: 10, Loss: 0.499675452709198, Accuracy: 0.85107421875\n",
      "Batch: 11, Loss: 0.5626923441886902, Accuracy: 0.81982421875\n",
      "Batch: 12, Loss: 0.48470890522003174, Accuracy: 0.84521484375\n",
      "Batch: 13, Loss: 0.5448275804519653, Accuracy: 0.82275390625\n",
      "Batch: 14, Loss: 0.5375204086303711, Accuracy: 0.8330078125\n",
      "Batch: 15, Loss: 0.5304332971572876, Accuracy: 0.82421875\n",
      "Batch: 16, Loss: 0.5515374541282654, Accuracy: 0.81884765625\n",
      "Batch: 17, Loss: 0.4982096552848816, Accuracy: 0.8359375\n",
      "Batch: 18, Loss: 0.5364117622375488, Accuracy: 0.8232421875\n",
      "Batch: 19, Loss: 0.5209538340568542, Accuracy: 0.83349609375\n",
      "Batch: 20, Loss: 0.46469101309776306, Accuracy: 0.84228515625\n",
      "Batch: 21, Loss: 0.5720126628875732, Accuracy: 0.8173828125\n",
      "Batch: 22, Loss: 0.5060257315635681, Accuracy: 0.8359375\n",
      "Batch: 23, Loss: 0.48692697286605835, Accuracy: 0.8359375\n",
      "Batch: 24, Loss: 0.525543212890625, Accuracy: 0.82421875\n",
      "Batch: 25, Loss: 0.49770718812942505, Accuracy: 0.83837890625\n",
      "Batch: 26, Loss: 0.5150984525680542, Accuracy: 0.8291015625\n",
      "Batch: 27, Loss: 0.551397979259491, Accuracy: 0.818359375\n",
      "Batch: 28, Loss: 0.5209013223648071, Accuracy: 0.83154296875\n",
      "Batch: 29, Loss: 0.5505343675613403, Accuracy: 0.83056640625\n",
      "Batch: 30, Loss: 0.554374635219574, Accuracy: 0.8310546875\n",
      "Batch: 31, Loss: 0.602307915687561, Accuracy: 0.8154296875\n",
      "Batch: 32, Loss: 0.5708739161491394, Accuracy: 0.82470703125\n",
      "Batch: 33, Loss: 0.5308877229690552, Accuracy: 0.82080078125\n",
      "Batch: 34, Loss: 0.5734543204307556, Accuracy: 0.806640625\n",
      "Batch: 35, Loss: 0.5938827991485596, Accuracy: 0.8115234375\n",
      "Batch: 36, Loss: 0.5315307974815369, Accuracy: 0.81982421875\n",
      "Batch: 37, Loss: 0.5805503129959106, Accuracy: 0.80712890625\n",
      "Batch: 38, Loss: 0.5534724593162537, Accuracy: 0.82080078125\n",
      "Batch: 39, Loss: 0.5094844102859497, Accuracy: 0.83349609375\n",
      "Batch: 40, Loss: 0.5756363868713379, Accuracy: 0.818359375\n",
      "Batch: 41, Loss: 0.5655109286308289, Accuracy: 0.8134765625\n",
      "Batch: 42, Loss: 0.5311716794967651, Accuracy: 0.8251953125\n",
      "Batch: 43, Loss: 0.5005364418029785, Accuracy: 0.83642578125\n",
      "Batch: 44, Loss: 0.46210116147994995, Accuracy: 0.849609375\n",
      "Batch: 45, Loss: 0.5311328172683716, Accuracy: 0.8291015625\n",
      "Batch: 46, Loss: 0.524661123752594, Accuracy: 0.81298828125\n",
      "Batch: 47, Loss: 0.5130699872970581, Accuracy: 0.841796875\n",
      "Batch: 48, Loss: 0.528484046459198, Accuracy: 0.8359375\n",
      "Batch: 49, Loss: 0.5281785726547241, Accuracy: 0.8251953125\n",
      "Batch: 50, Loss: 0.5502784848213196, Accuracy: 0.82080078125\n",
      "Batch: 51, Loss: 0.5223501324653625, Accuracy: 0.82373046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 52, Loss: 0.5339729189872742, Accuracy: 0.81787109375\n",
      "Batch: 53, Loss: 0.538424551486969, Accuracy: 0.82666015625\n",
      "Batch: 54, Loss: 0.5604265928268433, Accuracy: 0.80517578125\n",
      "Batch: 55, Loss: 0.5463826656341553, Accuracy: 0.8125\n",
      "Batch: 56, Loss: 0.5290217399597168, Accuracy: 0.822265625\n",
      "Batch: 57, Loss: 0.5890558958053589, Accuracy: 0.81005859375\n",
      "Batch: 58, Loss: 0.5478330254554749, Accuracy: 0.82763671875\n",
      "Batch: 59, Loss: 0.6248435974121094, Accuracy: 0.80712890625\n",
      "Batch: 60, Loss: 0.5029579997062683, Accuracy: 0.83251953125\n",
      "Batch: 61, Loss: 0.5093158483505249, Accuracy: 0.83349609375\n",
      "Batch: 62, Loss: 0.5311399698257446, Accuracy: 0.8359375\n",
      "Batch: 63, Loss: 0.5300629138946533, Accuracy: 0.8271484375\n",
      "Batch: 64, Loss: 0.5734069347381592, Accuracy: 0.80322265625\n",
      "Batch: 65, Loss: 0.5752419233322144, Accuracy: 0.80126953125\n",
      "Batch: 66, Loss: 0.524353563785553, Accuracy: 0.82568359375\n",
      "Batch: 67, Loss: 0.5635049939155579, Accuracy: 0.8212890625\n",
      "Batch: 68, Loss: 0.4881080985069275, Accuracy: 0.84716796875\n",
      "Batch: 69, Loss: 0.5353783369064331, Accuracy: 0.82763671875\n",
      "Batch: 70, Loss: 0.4983212351799011, Accuracy: 0.83984375\n",
      "Batch: 71, Loss: 0.5282281041145325, Accuracy: 0.83056640625\n",
      "Batch: 72, Loss: 0.5514979362487793, Accuracy: 0.80908203125\n",
      "Batch: 73, Loss: 0.5450401306152344, Accuracy: 0.8154296875\n",
      "Batch: 74, Loss: 0.5454457998275757, Accuracy: 0.8203125\n",
      "Batch: 75, Loss: 0.503318190574646, Accuracy: 0.82958984375\n",
      "Batch: 76, Loss: 0.4836984872817993, Accuracy: 0.85009765625\n",
      "Batch: 77, Loss: 0.49154603481292725, Accuracy: 0.8486328125\n",
      "Batch: 78, Loss: 0.5250077247619629, Accuracy: 0.83154296875\n",
      "Batch: 79, Loss: 0.5234029293060303, Accuracy: 0.8349609375\n",
      "Batch: 80, Loss: 0.5530693531036377, Accuracy: 0.82373046875\n",
      "Batch: 81, Loss: 0.5445047616958618, Accuracy: 0.82958984375\n",
      "Batch: 82, Loss: 0.5209883451461792, Accuracy: 0.82177734375\n",
      "Batch: 83, Loss: 0.4857414960861206, Accuracy: 0.841796875\n",
      "Batch: 84, Loss: 0.5178065299987793, Accuracy: 0.8271484375\n",
      "Batch: 85, Loss: 0.548693835735321, Accuracy: 0.82177734375\n",
      "Batch: 86, Loss: 0.5509273409843445, Accuracy: 0.8271484375\n",
      "Batch: 87, Loss: 0.5066826939582825, Accuracy: 0.8232421875\n",
      "Batch: 88, Loss: 0.5577595233917236, Accuracy: 0.81298828125\n",
      "Batch: 89, Loss: 0.5287803411483765, Accuracy: 0.822265625\n",
      "Batch: 90, Loss: 0.5671802759170532, Accuracy: 0.81103515625\n",
      "Batch: 91, Loss: 0.5404204726219177, Accuracy: 0.8291015625\n",
      "Batch: 92, Loss: 0.5954908728599548, Accuracy: 0.79931640625\n",
      "Batch: 93, Loss: 0.605987548828125, Accuracy: 0.80029296875\n",
      "Batch: 94, Loss: 0.5687413215637207, Accuracy: 0.8193359375\n",
      "Batch: 95, Loss: 0.5729653835296631, Accuracy: 0.8037109375\n",
      "Batch: 96, Loss: 0.5277629494667053, Accuracy: 0.82958984375\n",
      "Batch: 97, Loss: 0.5248138904571533, Accuracy: 0.8388671875\n",
      "Batch: 98, Loss: 0.5557777285575867, Accuracy: 0.81689453125\n",
      "Batch: 99, Loss: 0.5147120952606201, Accuracy: 0.83642578125\n",
      "Batch: 100, Loss: 0.5981003046035767, Accuracy: 0.80859375\n",
      "Batch: 101, Loss: 0.5810699462890625, Accuracy: 0.80908203125\n",
      "Batch: 102, Loss: 0.5082398653030396, Accuracy: 0.8330078125\n",
      "Batch: 103, Loss: 0.5268552303314209, Accuracy: 0.83544921875\n",
      "Batch: 104, Loss: 0.5385578870773315, Accuracy: 0.82373046875\n",
      "Batch: 105, Loss: 0.5370047688484192, Accuracy: 0.83203125\n",
      "Batch: 106, Loss: 0.5169152021408081, Accuracy: 0.8369140625\n",
      "Batch: 107, Loss: 0.5472964644432068, Accuracy: 0.82080078125\n",
      "Batch: 108, Loss: 0.5109958648681641, Accuracy: 0.830078125\n",
      "Batch: 109, Loss: 0.4956333637237549, Accuracy: 0.8349609375\n",
      "Batch: 110, Loss: 0.5326707363128662, Accuracy: 0.82470703125\n",
      "Batch: 111, Loss: 0.4809383153915405, Accuracy: 0.83544921875\n",
      "Batch: 112, Loss: 0.5060591697692871, Accuracy: 0.83056640625\n",
      "Batch: 113, Loss: 0.5585151314735413, Accuracy: 0.81591796875\n",
      "Batch: 114, Loss: 0.5328977108001709, Accuracy: 0.82568359375\n",
      "Batch: 115, Loss: 0.5383840203285217, Accuracy: 0.82177734375\n",
      "Batch: 116, Loss: 0.5073246359825134, Accuracy: 0.8359375\n",
      "Batch: 117, Loss: 0.5072638988494873, Accuracy: 0.8310546875\n",
      "Batch: 118, Loss: 0.5367245078086853, Accuracy: 0.830078125\n",
      "Batch: 119, Loss: 0.5240254402160645, Accuracy: 0.82568359375\n",
      "Batch: 120, Loss: 0.4883072078227997, Accuracy: 0.8359375\n",
      "Batch: 121, Loss: 0.5264604091644287, Accuracy: 0.82568359375\n",
      "Batch: 122, Loss: 0.4909065365791321, Accuracy: 0.8427734375\n",
      "Batch: 123, Loss: 0.49276772141456604, Accuracy: 0.84814453125\n",
      "Batch: 124, Loss: 0.48168081045150757, Accuracy: 0.841796875\n",
      "Batch: 125, Loss: 0.5266802310943604, Accuracy: 0.82763671875\n",
      "Batch: 126, Loss: 0.5274779796600342, Accuracy: 0.8330078125\n",
      "Batch: 127, Loss: 0.47534897923469543, Accuracy: 0.8466796875\n",
      "Batch: 128, Loss: 0.5854145884513855, Accuracy: 0.81298828125\n",
      "Batch: 129, Loss: 0.5791807770729065, Accuracy: 0.80712890625\n",
      "Batch: 130, Loss: 0.5958958864212036, Accuracy: 0.81005859375\n",
      "Batch: 131, Loss: 0.5452262163162231, Accuracy: 0.81884765625\n",
      "Batch: 132, Loss: 0.501181960105896, Accuracy: 0.8388671875\n",
      "Batch: 133, Loss: 0.49629372358322144, Accuracy: 0.837890625\n",
      "Batch: 134, Loss: 0.5466221570968628, Accuracy: 0.8310546875\n",
      "Batch: 135, Loss: 0.5322219729423523, Accuracy: 0.822265625\n",
      "Batch: 136, Loss: 0.4908718764781952, Accuracy: 0.84130859375\n",
      "Batch: 137, Loss: 0.5407181978225708, Accuracy: 0.82177734375\n",
      "Batch: 138, Loss: 0.4755029082298279, Accuracy: 0.85205078125\n",
      "Batch: 139, Loss: 0.4958493113517761, Accuracy: 0.83935546875\n",
      "Batch: 140, Loss: 0.4653566777706146, Accuracy: 0.84716796875\n",
      "Batch: 141, Loss: 0.5508531928062439, Accuracy: 0.8212890625\n",
      "Batch: 142, Loss: 0.4955444931983948, Accuracy: 0.8466796875\n",
      "Batch: 143, Loss: 0.48895198106765747, Accuracy: 0.8447265625\n",
      "Batch: 144, Loss: 0.5826952457427979, Accuracy: 0.8193359375\n",
      "Batch: 145, Loss: 0.5358294248580933, Accuracy: 0.83203125\n",
      "Batch: 146, Loss: 0.5325623750686646, Accuracy: 0.826171875\n",
      "Batch: 147, Loss: 0.5406598448753357, Accuracy: 0.8271484375\n",
      "Batch: 148, Loss: 0.5611226558685303, Accuracy: 0.80810546875\n",
      "Batch: 149, Loss: 0.5257399082183838, Accuracy: 0.830078125\n",
      "Batch: 150, Loss: 0.4741935133934021, Accuracy: 0.8447265625\n",
      "Batch: 151, Loss: 0.4702647924423218, Accuracy: 0.84521484375\n",
      "Batch: 152, Loss: 0.541138231754303, Accuracy: 0.82470703125\n",
      "Batch: 153, Loss: 0.5413500666618347, Accuracy: 0.82861328125\n",
      "Batch: 154, Loss: 0.5149056911468506, Accuracy: 0.822265625\n",
      "Batch: 155, Loss: 0.5914897918701172, Accuracy: 0.8134765625\n",
      "Batch: 156, Loss: 0.4902171492576599, Accuracy: 0.84130859375\n",
      "Batch: 157, Loss: 0.48347750306129456, Accuracy: 0.833984375\n",
      "Batch: 158, Loss: 0.4942278265953064, Accuracy: 0.84228515625\n",
      "Batch: 159, Loss: 0.5014054775238037, Accuracy: 0.83642578125\n",
      "Batch: 160, Loss: 0.5431622862815857, Accuracy: 0.82470703125\n",
      "Batch: 161, Loss: 0.5498316287994385, Accuracy: 0.83251953125\n",
      "Batch: 162, Loss: 0.48339465260505676, Accuracy: 0.84814453125\n",
      "Batch: 163, Loss: 0.540687084197998, Accuracy: 0.82666015625\n",
      "Batch: 164, Loss: 0.5717063546180725, Accuracy: 0.810546875\n",
      "Batch: 165, Loss: 0.5420836210250854, Accuracy: 0.8310546875\n",
      "Batch: 166, Loss: 0.544326663017273, Accuracy: 0.82373046875\n",
      "Batch: 167, Loss: 0.524846613407135, Accuracy: 0.8388671875\n",
      "Batch: 168, Loss: 0.4810885787010193, Accuracy: 0.84375\n",
      "Batch: 169, Loss: 0.5228751301765442, Accuracy: 0.8349609375\n",
      "Batch: 170, Loss: 0.5483578443527222, Accuracy: 0.81689453125\n",
      "Batch: 171, Loss: 0.5077228546142578, Accuracy: 0.8388671875\n",
      "Batch: 172, Loss: 0.5066909790039062, Accuracy: 0.833984375\n",
      "Batch: 173, Loss: 0.5454621315002441, Accuracy: 0.81494140625\n",
      "Batch: 174, Loss: 0.4820374846458435, Accuracy: 0.83203125\n",
      "Batch: 175, Loss: 0.541968822479248, Accuracy: 0.82080078125\n",
      "Batch: 176, Loss: 0.5775250196456909, Accuracy: 0.81396484375\n",
      "Batch: 177, Loss: 0.5271754264831543, Accuracy: 0.83349609375\n",
      "Batch: 178, Loss: 0.5062242746353149, Accuracy: 0.83154296875\n",
      "Batch: 179, Loss: 0.5099039077758789, Accuracy: 0.83251953125\n",
      "Batch: 180, Loss: 0.5300264358520508, Accuracy: 0.83056640625\n",
      "Epoch 85/200\n",
      "Batch: 1, Loss: 0.8017833828926086, Accuracy: 0.77587890625\n",
      "Batch: 2, Loss: 0.5296887159347534, Accuracy: 0.826171875\n",
      "Batch: 3, Loss: 0.5329270362854004, Accuracy: 0.8193359375\n",
      "Batch: 4, Loss: 0.5367646217346191, Accuracy: 0.822265625\n",
      "Batch: 5, Loss: 0.5208591222763062, Accuracy: 0.8388671875\n",
      "Batch: 6, Loss: 0.5223057866096497, Accuracy: 0.8291015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 7, Loss: 0.5144854784011841, Accuracy: 0.83740234375\n",
      "Batch: 8, Loss: 0.534696102142334, Accuracy: 0.828125\n",
      "Batch: 9, Loss: 0.5699030160903931, Accuracy: 0.8115234375\n",
      "Batch: 10, Loss: 0.526870608329773, Accuracy: 0.83203125\n",
      "Batch: 11, Loss: 0.5674381852149963, Accuracy: 0.81982421875\n",
      "Batch: 12, Loss: 0.47203683853149414, Accuracy: 0.84765625\n",
      "Batch: 13, Loss: 0.5263755321502686, Accuracy: 0.82861328125\n",
      "Batch: 14, Loss: 0.5174257159233093, Accuracy: 0.83984375\n",
      "Batch: 15, Loss: 0.5601811408996582, Accuracy: 0.82080078125\n",
      "Batch: 16, Loss: 0.5694167613983154, Accuracy: 0.81494140625\n",
      "Batch: 17, Loss: 0.4918736219406128, Accuracy: 0.84521484375\n",
      "Batch: 18, Loss: 0.5657283067703247, Accuracy: 0.822265625\n",
      "Batch: 19, Loss: 0.5426548719406128, Accuracy: 0.82666015625\n",
      "Batch: 20, Loss: 0.44733360409736633, Accuracy: 0.85009765625\n",
      "Batch: 21, Loss: 0.5283699631690979, Accuracy: 0.8330078125\n",
      "Batch: 22, Loss: 0.4925819933414459, Accuracy: 0.833984375\n",
      "Batch: 23, Loss: 0.49298200011253357, Accuracy: 0.83642578125\n",
      "Batch: 24, Loss: 0.5235201120376587, Accuracy: 0.8349609375\n",
      "Batch: 25, Loss: 0.509535551071167, Accuracy: 0.83740234375\n",
      "Batch: 26, Loss: 0.5016891360282898, Accuracy: 0.83349609375\n",
      "Batch: 27, Loss: 0.5472781658172607, Accuracy: 0.82080078125\n",
      "Batch: 28, Loss: 0.5288870334625244, Accuracy: 0.8251953125\n",
      "Batch: 29, Loss: 0.5358625054359436, Accuracy: 0.8291015625\n",
      "Batch: 30, Loss: 0.534706711769104, Accuracy: 0.8251953125\n",
      "Batch: 31, Loss: 0.5974050760269165, Accuracy: 0.8095703125\n",
      "Batch: 32, Loss: 0.5845473408699036, Accuracy: 0.818359375\n",
      "Batch: 33, Loss: 0.522130012512207, Accuracy: 0.8251953125\n",
      "Batch: 34, Loss: 0.551237940788269, Accuracy: 0.82666015625\n",
      "Batch: 35, Loss: 0.5798713564872742, Accuracy: 0.82177734375\n",
      "Batch: 36, Loss: 0.5418380498886108, Accuracy: 0.82861328125\n",
      "Batch: 37, Loss: 0.5720738172531128, Accuracy: 0.80810546875\n",
      "Batch: 38, Loss: 0.5629562139511108, Accuracy: 0.814453125\n",
      "Batch: 39, Loss: 0.514756977558136, Accuracy: 0.837890625\n",
      "Batch: 40, Loss: 0.5878524780273438, Accuracy: 0.8046875\n",
      "Batch: 41, Loss: 0.5537716150283813, Accuracy: 0.8251953125\n",
      "Batch: 42, Loss: 0.5512675046920776, Accuracy: 0.8212890625\n",
      "Batch: 43, Loss: 0.48231178522109985, Accuracy: 0.84765625\n",
      "Batch: 44, Loss: 0.4687570333480835, Accuracy: 0.845703125\n",
      "Batch: 45, Loss: 0.5141254663467407, Accuracy: 0.83154296875\n",
      "Batch: 46, Loss: 0.5047274827957153, Accuracy: 0.830078125\n",
      "Batch: 47, Loss: 0.5152134895324707, Accuracy: 0.82763671875\n",
      "Batch: 48, Loss: 0.525356650352478, Accuracy: 0.82470703125\n",
      "Batch: 49, Loss: 0.506832480430603, Accuracy: 0.83642578125\n",
      "Batch: 50, Loss: 0.5336290597915649, Accuracy: 0.8349609375\n",
      "Batch: 51, Loss: 0.5122323036193848, Accuracy: 0.83251953125\n",
      "Batch: 52, Loss: 0.5211308002471924, Accuracy: 0.828125\n",
      "Batch: 53, Loss: 0.5421319007873535, Accuracy: 0.826171875\n",
      "Batch: 54, Loss: 0.5325605869293213, Accuracy: 0.82373046875\n",
      "Batch: 55, Loss: 0.5370789170265198, Accuracy: 0.83203125\n",
      "Batch: 56, Loss: 0.5052224397659302, Accuracy: 0.833984375\n",
      "Batch: 57, Loss: 0.5626828670501709, Accuracy: 0.82470703125\n",
      "Batch: 58, Loss: 0.5214402675628662, Accuracy: 0.8271484375\n",
      "Batch: 59, Loss: 0.621933102607727, Accuracy: 0.802734375\n",
      "Batch: 60, Loss: 0.5264081358909607, Accuracy: 0.82470703125\n",
      "Batch: 61, Loss: 0.5161174535751343, Accuracy: 0.83447265625\n",
      "Batch: 62, Loss: 0.543899416923523, Accuracy: 0.82080078125\n",
      "Batch: 63, Loss: 0.5085037350654602, Accuracy: 0.82861328125\n",
      "Batch: 64, Loss: 0.5495500564575195, Accuracy: 0.82666015625\n",
      "Batch: 65, Loss: 0.5459635853767395, Accuracy: 0.83056640625\n",
      "Batch: 66, Loss: 0.5352112054824829, Accuracy: 0.8271484375\n",
      "Batch: 67, Loss: 0.5348613858222961, Accuracy: 0.81982421875\n",
      "Batch: 68, Loss: 0.48428797721862793, Accuracy: 0.83935546875\n",
      "Batch: 69, Loss: 0.5158438682556152, Accuracy: 0.83251953125\n",
      "Batch: 70, Loss: 0.49239110946655273, Accuracy: 0.83740234375\n",
      "Batch: 71, Loss: 0.4968854784965515, Accuracy: 0.8291015625\n",
      "Batch: 72, Loss: 0.5644565224647522, Accuracy: 0.80712890625\n",
      "Batch: 73, Loss: 0.5181210041046143, Accuracy: 0.82958984375\n",
      "Batch: 74, Loss: 0.5431643724441528, Accuracy: 0.818359375\n",
      "Batch: 75, Loss: 0.5086334347724915, Accuracy: 0.83740234375\n",
      "Batch: 76, Loss: 0.5047925710678101, Accuracy: 0.83447265625\n",
      "Batch: 77, Loss: 0.5083731412887573, Accuracy: 0.83740234375\n",
      "Batch: 78, Loss: 0.5227712988853455, Accuracy: 0.8310546875\n",
      "Batch: 79, Loss: 0.5254004597663879, Accuracy: 0.83251953125\n",
      "Batch: 80, Loss: 0.5363286733627319, Accuracy: 0.8291015625\n",
      "Batch: 81, Loss: 0.5457463264465332, Accuracy: 0.8349609375\n",
      "Batch: 82, Loss: 0.5302255749702454, Accuracy: 0.8251953125\n",
      "Batch: 83, Loss: 0.48180121183395386, Accuracy: 0.8408203125\n",
      "Batch: 84, Loss: 0.5104078054428101, Accuracy: 0.8330078125\n",
      "Batch: 85, Loss: 0.5581408739089966, Accuracy: 0.81396484375\n",
      "Batch: 86, Loss: 0.5847073793411255, Accuracy: 0.8203125\n",
      "Batch: 87, Loss: 0.5157696008682251, Accuracy: 0.8349609375\n",
      "Batch: 88, Loss: 0.5600923299789429, Accuracy: 0.818359375\n",
      "Batch: 89, Loss: 0.5077551603317261, Accuracy: 0.83447265625\n",
      "Batch: 90, Loss: 0.5397372245788574, Accuracy: 0.82275390625\n",
      "Batch: 91, Loss: 0.5369825959205627, Accuracy: 0.83056640625\n",
      "Batch: 92, Loss: 0.5911403894424438, Accuracy: 0.810546875\n",
      "Batch: 93, Loss: 0.5884503126144409, Accuracy: 0.810546875\n",
      "Batch: 94, Loss: 0.5737855434417725, Accuracy: 0.8251953125\n",
      "Batch: 95, Loss: 0.5700390338897705, Accuracy: 0.81494140625\n",
      "Batch: 96, Loss: 0.5417189002037048, Accuracy: 0.82861328125\n",
      "Batch: 97, Loss: 0.5075723528862, Accuracy: 0.84033203125\n",
      "Batch: 98, Loss: 0.5346381664276123, Accuracy: 0.82275390625\n",
      "Batch: 99, Loss: 0.5073856711387634, Accuracy: 0.8349609375\n",
      "Batch: 100, Loss: 0.5596088171005249, Accuracy: 0.8203125\n",
      "Batch: 101, Loss: 0.5740995407104492, Accuracy: 0.8056640625\n",
      "Batch: 102, Loss: 0.49231332540512085, Accuracy: 0.83984375\n",
      "Batch: 103, Loss: 0.5223842859268188, Accuracy: 0.83154296875\n",
      "Batch: 104, Loss: 0.5250512957572937, Accuracy: 0.8359375\n",
      "Batch: 105, Loss: 0.5477429628372192, Accuracy: 0.828125\n",
      "Batch: 106, Loss: 0.5148696899414062, Accuracy: 0.8291015625\n",
      "Batch: 107, Loss: 0.5524755120277405, Accuracy: 0.8310546875\n",
      "Batch: 108, Loss: 0.5118964314460754, Accuracy: 0.83251953125\n",
      "Batch: 109, Loss: 0.4965572953224182, Accuracy: 0.8369140625\n",
      "Batch: 110, Loss: 0.5107128620147705, Accuracy: 0.82568359375\n",
      "Batch: 111, Loss: 0.48545292019844055, Accuracy: 0.84423828125\n",
      "Batch: 112, Loss: 0.49982088804244995, Accuracy: 0.83837890625\n",
      "Batch: 113, Loss: 0.5359771251678467, Accuracy: 0.82080078125\n",
      "Batch: 114, Loss: 0.5430775880813599, Accuracy: 0.8212890625\n",
      "Batch: 115, Loss: 0.5204927921295166, Accuracy: 0.82763671875\n",
      "Batch: 116, Loss: 0.5119504928588867, Accuracy: 0.8388671875\n",
      "Batch: 117, Loss: 0.5014925599098206, Accuracy: 0.837890625\n",
      "Batch: 118, Loss: 0.5422741770744324, Accuracy: 0.82958984375\n",
      "Batch: 119, Loss: 0.4985576570034027, Accuracy: 0.83984375\n",
      "Batch: 120, Loss: 0.4915217161178589, Accuracy: 0.8427734375\n",
      "Batch: 121, Loss: 0.5228643417358398, Accuracy: 0.83740234375\n",
      "Batch: 122, Loss: 0.490182101726532, Accuracy: 0.8349609375\n",
      "Batch: 123, Loss: 0.4984833598136902, Accuracy: 0.8447265625\n",
      "Batch: 124, Loss: 0.4881117343902588, Accuracy: 0.837890625\n",
      "Batch: 125, Loss: 0.5184177756309509, Accuracy: 0.8359375\n",
      "Batch: 126, Loss: 0.5181655883789062, Accuracy: 0.828125\n",
      "Batch: 127, Loss: 0.47590720653533936, Accuracy: 0.84814453125\n",
      "Batch: 128, Loss: 0.5867369771003723, Accuracy: 0.80810546875\n",
      "Batch: 129, Loss: 0.5731140375137329, Accuracy: 0.8095703125\n",
      "Batch: 130, Loss: 0.6005064249038696, Accuracy: 0.80517578125\n",
      "Batch: 131, Loss: 0.5194341540336609, Accuracy: 0.8359375\n",
      "Batch: 132, Loss: 0.5049512386322021, Accuracy: 0.83935546875\n",
      "Batch: 133, Loss: 0.4989946484565735, Accuracy: 0.837890625\n",
      "Batch: 134, Loss: 0.5566763877868652, Accuracy: 0.82080078125\n",
      "Batch: 135, Loss: 0.5424073934555054, Accuracy: 0.81689453125\n",
      "Batch: 136, Loss: 0.5064287185668945, Accuracy: 0.8408203125\n",
      "Batch: 137, Loss: 0.5498506426811218, Accuracy: 0.82470703125\n",
      "Batch: 138, Loss: 0.47978052496910095, Accuracy: 0.84375\n",
      "Batch: 139, Loss: 0.5033887028694153, Accuracy: 0.83544921875\n",
      "Batch: 140, Loss: 0.4658045768737793, Accuracy: 0.84814453125\n",
      "Batch: 141, Loss: 0.5436429381370544, Accuracy: 0.82275390625\n",
      "Batch: 142, Loss: 0.48791444301605225, Accuracy: 0.83154296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 143, Loss: 0.5068559646606445, Accuracy: 0.84033203125\n",
      "Batch: 144, Loss: 0.5692660808563232, Accuracy: 0.81689453125\n",
      "Batch: 145, Loss: 0.5146387815475464, Accuracy: 0.8349609375\n",
      "Batch: 146, Loss: 0.5513587594032288, Accuracy: 0.82275390625\n",
      "Batch: 147, Loss: 0.5074224472045898, Accuracy: 0.84033203125\n",
      "Batch: 148, Loss: 0.5423908829689026, Accuracy: 0.81591796875\n",
      "Batch: 149, Loss: 0.5427853465080261, Accuracy: 0.81396484375\n",
      "Batch: 150, Loss: 0.469251811504364, Accuracy: 0.85205078125\n",
      "Batch: 151, Loss: 0.4985774755477905, Accuracy: 0.83203125\n",
      "Batch: 152, Loss: 0.5114706754684448, Accuracy: 0.8310546875\n",
      "Batch: 153, Loss: 0.5245214104652405, Accuracy: 0.83544921875\n",
      "Batch: 154, Loss: 0.5162196159362793, Accuracy: 0.833984375\n",
      "Batch: 155, Loss: 0.5669556260108948, Accuracy: 0.81103515625\n",
      "Batch: 156, Loss: 0.47797754406929016, Accuracy: 0.84423828125\n",
      "Batch: 157, Loss: 0.4770303964614868, Accuracy: 0.84423828125\n",
      "Batch: 158, Loss: 0.479512095451355, Accuracy: 0.8486328125\n",
      "Batch: 159, Loss: 0.5022121071815491, Accuracy: 0.83935546875\n",
      "Batch: 160, Loss: 0.517552375793457, Accuracy: 0.8349609375\n",
      "Batch: 161, Loss: 0.5265630483627319, Accuracy: 0.83203125\n",
      "Batch: 162, Loss: 0.5014330148696899, Accuracy: 0.8466796875\n",
      "Batch: 163, Loss: 0.5214316844940186, Accuracy: 0.8349609375\n",
      "Batch: 164, Loss: 0.5745961666107178, Accuracy: 0.81591796875\n",
      "Batch: 165, Loss: 0.5267248153686523, Accuracy: 0.83251953125\n",
      "Batch: 166, Loss: 0.5457019209861755, Accuracy: 0.8232421875\n",
      "Batch: 167, Loss: 0.5146267414093018, Accuracy: 0.83837890625\n",
      "Batch: 168, Loss: 0.4895135164260864, Accuracy: 0.84521484375\n",
      "Batch: 169, Loss: 0.5310600996017456, Accuracy: 0.828125\n",
      "Batch: 170, Loss: 0.5554853677749634, Accuracy: 0.82177734375\n",
      "Batch: 171, Loss: 0.5028282999992371, Accuracy: 0.83447265625\n",
      "Batch: 172, Loss: 0.5078340768814087, Accuracy: 0.83154296875\n",
      "Batch: 173, Loss: 0.5609093904495239, Accuracy: 0.81640625\n",
      "Batch: 174, Loss: 0.483289897441864, Accuracy: 0.841796875\n",
      "Batch: 175, Loss: 0.5282278060913086, Accuracy: 0.82763671875\n",
      "Batch: 176, Loss: 0.5581122636795044, Accuracy: 0.8173828125\n",
      "Batch: 177, Loss: 0.5281485915184021, Accuracy: 0.83544921875\n",
      "Batch: 178, Loss: 0.49091482162475586, Accuracy: 0.83740234375\n",
      "Batch: 179, Loss: 0.5150402188301086, Accuracy: 0.84033203125\n",
      "Batch: 180, Loss: 0.530762791633606, Accuracy: 0.83056640625\n",
      "Epoch 86/200\n",
      "Batch: 1, Loss: 0.7758442163467407, Accuracy: 0.7861328125\n",
      "Batch: 2, Loss: 0.5270886421203613, Accuracy: 0.826171875\n",
      "Batch: 3, Loss: 0.5215123295783997, Accuracy: 0.83056640625\n",
      "Batch: 4, Loss: 0.5383353233337402, Accuracy: 0.8212890625\n",
      "Batch: 5, Loss: 0.5150749683380127, Accuracy: 0.837890625\n",
      "Batch: 6, Loss: 0.5270439386367798, Accuracy: 0.82763671875\n",
      "Batch: 7, Loss: 0.5192854404449463, Accuracy: 0.83740234375\n",
      "Batch: 8, Loss: 0.4878406226634979, Accuracy: 0.8427734375\n",
      "Batch: 9, Loss: 0.559353232383728, Accuracy: 0.81298828125\n",
      "Batch: 10, Loss: 0.48189258575439453, Accuracy: 0.83984375\n",
      "Batch: 11, Loss: 0.5286996364593506, Accuracy: 0.82666015625\n",
      "Batch: 12, Loss: 0.46261066198349, Accuracy: 0.85302734375\n",
      "Batch: 13, Loss: 0.5126060247421265, Accuracy: 0.82958984375\n",
      "Batch: 14, Loss: 0.5083186626434326, Accuracy: 0.83544921875\n",
      "Batch: 15, Loss: 0.5090898275375366, Accuracy: 0.8427734375\n",
      "Batch: 16, Loss: 0.5617910027503967, Accuracy: 0.8134765625\n",
      "Batch: 17, Loss: 0.499192476272583, Accuracy: 0.837890625\n",
      "Batch: 18, Loss: 0.5333126783370972, Accuracy: 0.83056640625\n",
      "Batch: 19, Loss: 0.562644362449646, Accuracy: 0.82177734375\n",
      "Batch: 20, Loss: 0.4463660717010498, Accuracy: 0.85546875\n",
      "Batch: 21, Loss: 0.5404956340789795, Accuracy: 0.82470703125\n",
      "Batch: 22, Loss: 0.479214608669281, Accuracy: 0.8408203125\n",
      "Batch: 23, Loss: 0.47030359506607056, Accuracy: 0.8349609375\n",
      "Batch: 24, Loss: 0.5157296657562256, Accuracy: 0.8349609375\n",
      "Batch: 25, Loss: 0.5134369134902954, Accuracy: 0.8447265625\n",
      "Batch: 26, Loss: 0.5183210372924805, Accuracy: 0.830078125\n",
      "Batch: 27, Loss: 0.552118182182312, Accuracy: 0.82470703125\n",
      "Batch: 28, Loss: 0.5086162090301514, Accuracy: 0.8330078125\n",
      "Batch: 29, Loss: 0.5314216017723083, Accuracy: 0.8232421875\n",
      "Batch: 30, Loss: 0.5390332937240601, Accuracy: 0.83056640625\n",
      "Batch: 31, Loss: 0.5647486448287964, Accuracy: 0.81494140625\n",
      "Batch: 32, Loss: 0.5506415367126465, Accuracy: 0.8271484375\n",
      "Batch: 33, Loss: 0.5320016145706177, Accuracy: 0.81884765625\n",
      "Batch: 34, Loss: 0.5512629151344299, Accuracy: 0.8251953125\n",
      "Batch: 35, Loss: 0.5623781681060791, Accuracy: 0.8232421875\n",
      "Batch: 36, Loss: 0.5272470712661743, Accuracy: 0.828125\n",
      "Batch: 37, Loss: 0.5746994018554688, Accuracy: 0.8134765625\n",
      "Batch: 38, Loss: 0.5599590539932251, Accuracy: 0.81884765625\n",
      "Batch: 39, Loss: 0.5148140788078308, Accuracy: 0.83642578125\n",
      "Batch: 40, Loss: 0.5731395483016968, Accuracy: 0.81494140625\n",
      "Batch: 41, Loss: 0.5529961585998535, Accuracy: 0.82373046875\n",
      "Batch: 42, Loss: 0.5320343971252441, Accuracy: 0.81884765625\n",
      "Batch: 43, Loss: 0.49481984972953796, Accuracy: 0.84033203125\n",
      "Batch: 44, Loss: 0.4737235903739929, Accuracy: 0.84619140625\n",
      "Batch: 45, Loss: 0.512893795967102, Accuracy: 0.83447265625\n",
      "Batch: 46, Loss: 0.5017600655555725, Accuracy: 0.8251953125\n",
      "Batch: 47, Loss: 0.5181761980056763, Accuracy: 0.83203125\n",
      "Batch: 48, Loss: 0.5112621188163757, Accuracy: 0.8369140625\n",
      "Batch: 49, Loss: 0.523486852645874, Accuracy: 0.8271484375\n",
      "Batch: 50, Loss: 0.5276802778244019, Accuracy: 0.83447265625\n",
      "Batch: 51, Loss: 0.4989684224128723, Accuracy: 0.83544921875\n",
      "Batch: 52, Loss: 0.5356498956680298, Accuracy: 0.81689453125\n",
      "Batch: 53, Loss: 0.5180368423461914, Accuracy: 0.8349609375\n",
      "Batch: 54, Loss: 0.5721816420555115, Accuracy: 0.80712890625\n",
      "Batch: 55, Loss: 0.5367623567581177, Accuracy: 0.83056640625\n",
      "Batch: 56, Loss: 0.5081712007522583, Accuracy: 0.8359375\n",
      "Batch: 57, Loss: 0.5818270444869995, Accuracy: 0.80810546875\n",
      "Batch: 58, Loss: 0.5298789739608765, Accuracy: 0.830078125\n",
      "Batch: 59, Loss: 0.605095624923706, Accuracy: 0.81005859375\n",
      "Batch: 60, Loss: 0.5013886094093323, Accuracy: 0.8349609375\n",
      "Batch: 61, Loss: 0.5253413915634155, Accuracy: 0.826171875\n",
      "Batch: 62, Loss: 0.5119345188140869, Accuracy: 0.8330078125\n",
      "Batch: 63, Loss: 0.5058306455612183, Accuracy: 0.826171875\n",
      "Batch: 64, Loss: 0.5499986410140991, Accuracy: 0.81884765625\n",
      "Batch: 65, Loss: 0.5534458756446838, Accuracy: 0.81298828125\n",
      "Batch: 66, Loss: 0.4874275326728821, Accuracy: 0.8359375\n",
      "Batch: 67, Loss: 0.5450274348258972, Accuracy: 0.822265625\n",
      "Batch: 68, Loss: 0.47837433218955994, Accuracy: 0.841796875\n",
      "Batch: 69, Loss: 0.5316752195358276, Accuracy: 0.82177734375\n",
      "Batch: 70, Loss: 0.4994537830352783, Accuracy: 0.83642578125\n",
      "Batch: 71, Loss: 0.5013383626937866, Accuracy: 0.83984375\n",
      "Batch: 72, Loss: 0.5414800643920898, Accuracy: 0.8125\n",
      "Batch: 73, Loss: 0.5385429263114929, Accuracy: 0.8271484375\n",
      "Batch: 74, Loss: 0.545121431350708, Accuracy: 0.8232421875\n",
      "Batch: 75, Loss: 0.49312904477119446, Accuracy: 0.84228515625\n",
      "Batch: 76, Loss: 0.4747343361377716, Accuracy: 0.8515625\n",
      "Batch: 77, Loss: 0.4889832139015198, Accuracy: 0.841796875\n",
      "Batch: 78, Loss: 0.511001706123352, Accuracy: 0.83349609375\n",
      "Batch: 79, Loss: 0.5496283769607544, Accuracy: 0.82373046875\n",
      "Batch: 80, Loss: 0.553287148475647, Accuracy: 0.82470703125\n",
      "Batch: 81, Loss: 0.5263183116912842, Accuracy: 0.8369140625\n",
      "Batch: 82, Loss: 0.5315306782722473, Accuracy: 0.826171875\n",
      "Batch: 83, Loss: 0.47185224294662476, Accuracy: 0.84765625\n",
      "Batch: 84, Loss: 0.49236583709716797, Accuracy: 0.83984375\n",
      "Batch: 85, Loss: 0.5339269042015076, Accuracy: 0.82080078125\n",
      "Batch: 86, Loss: 0.5795048475265503, Accuracy: 0.8212890625\n",
      "Batch: 87, Loss: 0.4858512282371521, Accuracy: 0.8388671875\n",
      "Batch: 88, Loss: 0.5444467663764954, Accuracy: 0.8271484375\n",
      "Batch: 89, Loss: 0.5091677904129028, Accuracy: 0.83740234375\n",
      "Batch: 90, Loss: 0.5388800501823425, Accuracy: 0.818359375\n",
      "Batch: 91, Loss: 0.5322562456130981, Accuracy: 0.82666015625\n",
      "Batch: 92, Loss: 0.5830983519554138, Accuracy: 0.79931640625\n",
      "Batch: 93, Loss: 0.5925948023796082, Accuracy: 0.7998046875\n",
      "Batch: 94, Loss: 0.5446587204933167, Accuracy: 0.8291015625\n",
      "Batch: 95, Loss: 0.5860438346862793, Accuracy: 0.80859375\n",
      "Batch: 96, Loss: 0.5241349935531616, Accuracy: 0.830078125\n",
      "Batch: 97, Loss: 0.5274003744125366, Accuracy: 0.830078125\n",
      "Batch: 98, Loss: 0.536450982093811, Accuracy: 0.830078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 99, Loss: 0.5072887539863586, Accuracy: 0.841796875\n",
      "Batch: 100, Loss: 0.5688399076461792, Accuracy: 0.82275390625\n",
      "Batch: 101, Loss: 0.5467086434364319, Accuracy: 0.82666015625\n",
      "Batch: 102, Loss: 0.522563636302948, Accuracy: 0.83056640625\n",
      "Batch: 103, Loss: 0.5478715300559998, Accuracy: 0.81689453125\n",
      "Batch: 104, Loss: 0.5095764398574829, Accuracy: 0.83349609375\n",
      "Batch: 105, Loss: 0.5335451364517212, Accuracy: 0.8203125\n",
      "Batch: 106, Loss: 0.5082658529281616, Accuracy: 0.833984375\n",
      "Batch: 107, Loss: 0.5432562828063965, Accuracy: 0.81640625\n",
      "Batch: 108, Loss: 0.512995719909668, Accuracy: 0.83056640625\n",
      "Batch: 109, Loss: 0.5036910772323608, Accuracy: 0.84130859375\n",
      "Batch: 110, Loss: 0.5073985457420349, Accuracy: 0.82373046875\n",
      "Batch: 111, Loss: 0.48519790172576904, Accuracy: 0.837890625\n",
      "Batch: 112, Loss: 0.4924418330192566, Accuracy: 0.83642578125\n",
      "Batch: 113, Loss: 0.5136929750442505, Accuracy: 0.82666015625\n",
      "Batch: 114, Loss: 0.5316882729530334, Accuracy: 0.82861328125\n",
      "Batch: 115, Loss: 0.5175706744194031, Accuracy: 0.82763671875\n",
      "Batch: 116, Loss: 0.5077658891677856, Accuracy: 0.83837890625\n",
      "Batch: 117, Loss: 0.4908783435821533, Accuracy: 0.83447265625\n",
      "Batch: 118, Loss: 0.538637638092041, Accuracy: 0.8212890625\n",
      "Batch: 119, Loss: 0.5090210437774658, Accuracy: 0.833984375\n",
      "Batch: 120, Loss: 0.506844162940979, Accuracy: 0.83984375\n",
      "Batch: 121, Loss: 0.5279116630554199, Accuracy: 0.826171875\n",
      "Batch: 122, Loss: 0.47834721207618713, Accuracy: 0.83984375\n",
      "Batch: 123, Loss: 0.4767928719520569, Accuracy: 0.845703125\n",
      "Batch: 124, Loss: 0.4925043284893036, Accuracy: 0.84521484375\n",
      "Batch: 125, Loss: 0.5174599885940552, Accuracy: 0.82861328125\n",
      "Batch: 126, Loss: 0.5137168765068054, Accuracy: 0.83740234375\n",
      "Batch: 127, Loss: 0.4623895287513733, Accuracy: 0.84521484375\n",
      "Batch: 128, Loss: 0.5603946447372437, Accuracy: 0.81787109375\n",
      "Batch: 129, Loss: 0.5815131068229675, Accuracy: 0.81396484375\n",
      "Batch: 130, Loss: 0.590496838092804, Accuracy: 0.8115234375\n",
      "Batch: 131, Loss: 0.5332320332527161, Accuracy: 0.828125\n",
      "Batch: 132, Loss: 0.49955934286117554, Accuracy: 0.84326171875\n",
      "Batch: 133, Loss: 0.4898429214954376, Accuracy: 0.84765625\n",
      "Batch: 134, Loss: 0.5541689395904541, Accuracy: 0.818359375\n",
      "Batch: 135, Loss: 0.5391737222671509, Accuracy: 0.82373046875\n",
      "Batch: 136, Loss: 0.5074657797813416, Accuracy: 0.8310546875\n",
      "Batch: 137, Loss: 0.5342016816139221, Accuracy: 0.8330078125\n",
      "Batch: 138, Loss: 0.4889298379421234, Accuracy: 0.85302734375\n",
      "Batch: 139, Loss: 0.4982726275920868, Accuracy: 0.8330078125\n",
      "Batch: 140, Loss: 0.44887280464172363, Accuracy: 0.849609375\n",
      "Batch: 141, Loss: 0.5195630788803101, Accuracy: 0.8359375\n",
      "Batch: 142, Loss: 0.469245970249176, Accuracy: 0.853515625\n",
      "Batch: 143, Loss: 0.4855954051017761, Accuracy: 0.84228515625\n",
      "Batch: 144, Loss: 0.5632308721542358, Accuracy: 0.82080078125\n",
      "Batch: 145, Loss: 0.5128986239433289, Accuracy: 0.8359375\n",
      "Batch: 146, Loss: 0.5261272192001343, Accuracy: 0.8330078125\n",
      "Batch: 147, Loss: 0.5215169787406921, Accuracy: 0.8349609375\n",
      "Batch: 148, Loss: 0.5522053837776184, Accuracy: 0.818359375\n",
      "Batch: 149, Loss: 0.5551300644874573, Accuracy: 0.8212890625\n",
      "Batch: 150, Loss: 0.45446768403053284, Accuracy: 0.85400390625\n",
      "Batch: 151, Loss: 0.48666292428970337, Accuracy: 0.84375\n",
      "Batch: 152, Loss: 0.4889918565750122, Accuracy: 0.83837890625\n",
      "Batch: 153, Loss: 0.4830361604690552, Accuracy: 0.85205078125\n",
      "Batch: 154, Loss: 0.5254185199737549, Accuracy: 0.82421875\n",
      "Batch: 155, Loss: 0.5769168138504028, Accuracy: 0.81591796875\n",
      "Batch: 156, Loss: 0.46532920002937317, Accuracy: 0.84521484375\n",
      "Batch: 157, Loss: 0.47402289509773254, Accuracy: 0.83935546875\n",
      "Batch: 158, Loss: 0.4893348217010498, Accuracy: 0.84375\n",
      "Batch: 159, Loss: 0.49313104152679443, Accuracy: 0.83984375\n",
      "Batch: 160, Loss: 0.5073768496513367, Accuracy: 0.83740234375\n",
      "Batch: 161, Loss: 0.5110426545143127, Accuracy: 0.83056640625\n",
      "Batch: 162, Loss: 0.5025035738945007, Accuracy: 0.83740234375\n",
      "Batch: 163, Loss: 0.5267789363861084, Accuracy: 0.837890625\n",
      "Batch: 164, Loss: 0.5726817846298218, Accuracy: 0.814453125\n",
      "Batch: 165, Loss: 0.5153610706329346, Accuracy: 0.82861328125\n",
      "Batch: 166, Loss: 0.5770394802093506, Accuracy: 0.81787109375\n",
      "Batch: 167, Loss: 0.5096088647842407, Accuracy: 0.8359375\n",
      "Batch: 168, Loss: 0.46737706661224365, Accuracy: 0.849609375\n",
      "Batch: 169, Loss: 0.500432550907135, Accuracy: 0.837890625\n",
      "Batch: 170, Loss: 0.54059898853302, Accuracy: 0.8291015625\n",
      "Batch: 171, Loss: 0.5116385221481323, Accuracy: 0.828125\n",
      "Batch: 172, Loss: 0.4954005479812622, Accuracy: 0.83203125\n",
      "Batch: 173, Loss: 0.5566037893295288, Accuracy: 0.81982421875\n",
      "Batch: 174, Loss: 0.4506903290748596, Accuracy: 0.8388671875\n",
      "Batch: 175, Loss: 0.5430905818939209, Accuracy: 0.8203125\n",
      "Batch: 176, Loss: 0.5715035200119019, Accuracy: 0.8134765625\n",
      "Batch: 177, Loss: 0.5492258071899414, Accuracy: 0.8203125\n",
      "Batch: 178, Loss: 0.505241870880127, Accuracy: 0.83447265625\n",
      "Batch: 179, Loss: 0.5106920599937439, Accuracy: 0.83935546875\n",
      "Batch: 180, Loss: 0.5301810503005981, Accuracy: 0.8330078125\n",
      "Epoch 87/200\n",
      "Batch: 1, Loss: 0.793480396270752, Accuracy: 0.7734375\n",
      "Batch: 2, Loss: 0.5392341017723083, Accuracy: 0.826171875\n",
      "Batch: 3, Loss: 0.5316815376281738, Accuracy: 0.8291015625\n",
      "Batch: 4, Loss: 0.5415893793106079, Accuracy: 0.82421875\n",
      "Batch: 5, Loss: 0.5152934789657593, Accuracy: 0.83203125\n",
      "Batch: 6, Loss: 0.534761905670166, Accuracy: 0.828125\n",
      "Batch: 7, Loss: 0.5315902233123779, Accuracy: 0.8251953125\n",
      "Batch: 8, Loss: 0.5186351537704468, Accuracy: 0.8359375\n",
      "Batch: 9, Loss: 0.5546681880950928, Accuracy: 0.82373046875\n",
      "Batch: 10, Loss: 0.517733633518219, Accuracy: 0.83203125\n",
      "Batch: 11, Loss: 0.521620512008667, Accuracy: 0.82421875\n",
      "Batch: 12, Loss: 0.4740470349788666, Accuracy: 0.83837890625\n",
      "Batch: 13, Loss: 0.5122763514518738, Accuracy: 0.82470703125\n",
      "Batch: 14, Loss: 0.5332720279693604, Accuracy: 0.8359375\n",
      "Batch: 15, Loss: 0.5191344022750854, Accuracy: 0.830078125\n",
      "Batch: 16, Loss: 0.5468575954437256, Accuracy: 0.81591796875\n",
      "Batch: 17, Loss: 0.4989808201789856, Accuracy: 0.8330078125\n",
      "Batch: 18, Loss: 0.5565353631973267, Accuracy: 0.81591796875\n",
      "Batch: 19, Loss: 0.5434157848358154, Accuracy: 0.83251953125\n",
      "Batch: 20, Loss: 0.4458891749382019, Accuracy: 0.8515625\n",
      "Batch: 21, Loss: 0.5288099050521851, Accuracy: 0.83056640625\n",
      "Batch: 22, Loss: 0.5005069375038147, Accuracy: 0.83349609375\n",
      "Batch: 23, Loss: 0.4800414443016052, Accuracy: 0.841796875\n",
      "Batch: 24, Loss: 0.5151962637901306, Accuracy: 0.830078125\n",
      "Batch: 25, Loss: 0.4912172555923462, Accuracy: 0.841796875\n",
      "Batch: 26, Loss: 0.5094655752182007, Accuracy: 0.8359375\n",
      "Batch: 27, Loss: 0.5142626762390137, Accuracy: 0.83740234375\n",
      "Batch: 28, Loss: 0.504449725151062, Accuracy: 0.84521484375\n",
      "Batch: 29, Loss: 0.5511680841445923, Accuracy: 0.82568359375\n",
      "Batch: 30, Loss: 0.5298493504524231, Accuracy: 0.82958984375\n",
      "Batch: 31, Loss: 0.5775629281997681, Accuracy: 0.814453125\n",
      "Batch: 32, Loss: 0.5450536012649536, Accuracy: 0.82177734375\n",
      "Batch: 33, Loss: 0.5328664779663086, Accuracy: 0.8212890625\n",
      "Batch: 34, Loss: 0.5537168979644775, Accuracy: 0.81591796875\n",
      "Batch: 35, Loss: 0.5867732167243958, Accuracy: 0.8095703125\n",
      "Batch: 36, Loss: 0.5423559546470642, Accuracy: 0.82080078125\n",
      "Batch: 37, Loss: 0.5525097250938416, Accuracy: 0.8173828125\n",
      "Batch: 38, Loss: 0.5763653516769409, Accuracy: 0.81298828125\n",
      "Batch: 39, Loss: 0.5199143290519714, Accuracy: 0.8388671875\n",
      "Batch: 40, Loss: 0.5788668394088745, Accuracy: 0.80908203125\n",
      "Batch: 41, Loss: 0.5438987016677856, Accuracy: 0.82421875\n",
      "Batch: 42, Loss: 0.5388453006744385, Accuracy: 0.81689453125\n",
      "Batch: 43, Loss: 0.481505423784256, Accuracy: 0.84375\n",
      "Batch: 44, Loss: 0.4705810844898224, Accuracy: 0.85400390625\n",
      "Batch: 45, Loss: 0.5169432759284973, Accuracy: 0.8271484375\n",
      "Batch: 46, Loss: 0.49758845567703247, Accuracy: 0.83203125\n",
      "Batch: 47, Loss: 0.5037441849708557, Accuracy: 0.83935546875\n",
      "Batch: 48, Loss: 0.5314679145812988, Accuracy: 0.83056640625\n",
      "Batch: 49, Loss: 0.5272173285484314, Accuracy: 0.83642578125\n",
      "Batch: 50, Loss: 0.5310221910476685, Accuracy: 0.83056640625\n",
      "Batch: 51, Loss: 0.5151903629302979, Accuracy: 0.8369140625\n",
      "Batch: 52, Loss: 0.5293799042701721, Accuracy: 0.83203125\n",
      "Batch: 53, Loss: 0.5258090496063232, Accuracy: 0.82470703125\n",
      "Batch: 54, Loss: 0.5469970703125, Accuracy: 0.81201171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 55, Loss: 0.5373589992523193, Accuracy: 0.8203125\n",
      "Batch: 56, Loss: 0.5057470798492432, Accuracy: 0.8359375\n",
      "Batch: 57, Loss: 0.5457415580749512, Accuracy: 0.8251953125\n",
      "Batch: 58, Loss: 0.5216867923736572, Accuracy: 0.83203125\n",
      "Batch: 59, Loss: 0.6115627288818359, Accuracy: 0.8076171875\n",
      "Batch: 60, Loss: 0.5022975206375122, Accuracy: 0.8369140625\n",
      "Batch: 61, Loss: 0.5012675523757935, Accuracy: 0.84326171875\n",
      "Batch: 62, Loss: 0.5273686051368713, Accuracy: 0.8291015625\n",
      "Batch: 63, Loss: 0.5044330954551697, Accuracy: 0.83056640625\n",
      "Batch: 64, Loss: 0.525822639465332, Accuracy: 0.82666015625\n",
      "Batch: 65, Loss: 0.5586602687835693, Accuracy: 0.822265625\n",
      "Batch: 66, Loss: 0.5186139345169067, Accuracy: 0.833984375\n",
      "Batch: 67, Loss: 0.551838219165802, Accuracy: 0.8173828125\n",
      "Batch: 68, Loss: 0.4901348948478699, Accuracy: 0.833984375\n",
      "Batch: 69, Loss: 0.5195071697235107, Accuracy: 0.83251953125\n",
      "Batch: 70, Loss: 0.4810422360897064, Accuracy: 0.83984375\n",
      "Batch: 71, Loss: 0.5038395524024963, Accuracy: 0.83740234375\n",
      "Batch: 72, Loss: 0.5445376634597778, Accuracy: 0.81103515625\n",
      "Batch: 73, Loss: 0.5068590641021729, Accuracy: 0.83837890625\n",
      "Batch: 74, Loss: 0.5321936011314392, Accuracy: 0.82568359375\n",
      "Batch: 75, Loss: 0.4932878613471985, Accuracy: 0.8330078125\n",
      "Batch: 76, Loss: 0.4634976387023926, Accuracy: 0.85546875\n",
      "Batch: 77, Loss: 0.4873994290828705, Accuracy: 0.8515625\n",
      "Batch: 78, Loss: 0.5091060400009155, Accuracy: 0.83642578125\n",
      "Batch: 79, Loss: 0.5382789969444275, Accuracy: 0.826171875\n",
      "Batch: 80, Loss: 0.5328129529953003, Accuracy: 0.837890625\n",
      "Batch: 81, Loss: 0.5420968532562256, Accuracy: 0.83056640625\n",
      "Batch: 82, Loss: 0.5121994614601135, Accuracy: 0.82666015625\n",
      "Batch: 83, Loss: 0.466266006231308, Accuracy: 0.84716796875\n",
      "Batch: 84, Loss: 0.4869643449783325, Accuracy: 0.8447265625\n",
      "Batch: 85, Loss: 0.5407624244689941, Accuracy: 0.82568359375\n",
      "Batch: 86, Loss: 0.5497370958328247, Accuracy: 0.82958984375\n",
      "Batch: 87, Loss: 0.5179420113563538, Accuracy: 0.82861328125\n",
      "Batch: 88, Loss: 0.5289690494537354, Accuracy: 0.82958984375\n",
      "Batch: 89, Loss: 0.5160123705863953, Accuracy: 0.828125\n",
      "Batch: 90, Loss: 0.5302112698554993, Accuracy: 0.822265625\n",
      "Batch: 91, Loss: 0.536299467086792, Accuracy: 0.833984375\n",
      "Batch: 92, Loss: 0.581505298614502, Accuracy: 0.80810546875\n",
      "Batch: 93, Loss: 0.5746262669563293, Accuracy: 0.810546875\n",
      "Batch: 94, Loss: 0.5550225973129272, Accuracy: 0.828125\n",
      "Batch: 95, Loss: 0.566685140132904, Accuracy: 0.81640625\n",
      "Batch: 96, Loss: 0.5250390768051147, Accuracy: 0.83447265625\n",
      "Batch: 97, Loss: 0.5155062675476074, Accuracy: 0.84033203125\n",
      "Batch: 98, Loss: 0.5070220232009888, Accuracy: 0.8447265625\n",
      "Batch: 99, Loss: 0.5118110179901123, Accuracy: 0.82666015625\n",
      "Batch: 100, Loss: 0.5872100591659546, Accuracy: 0.8125\n",
      "Batch: 101, Loss: 0.5762293934822083, Accuracy: 0.8173828125\n",
      "Batch: 102, Loss: 0.49624356627464294, Accuracy: 0.8359375\n",
      "Batch: 103, Loss: 0.521483302116394, Accuracy: 0.82470703125\n",
      "Batch: 104, Loss: 0.5174156427383423, Accuracy: 0.830078125\n",
      "Batch: 105, Loss: 0.5366086959838867, Accuracy: 0.8271484375\n",
      "Batch: 106, Loss: 0.5161325931549072, Accuracy: 0.83056640625\n",
      "Batch: 107, Loss: 0.5462867021560669, Accuracy: 0.8359375\n",
      "Batch: 108, Loss: 0.5066224932670593, Accuracy: 0.82958984375\n",
      "Batch: 109, Loss: 0.4937671422958374, Accuracy: 0.84423828125\n",
      "Batch: 110, Loss: 0.49072742462158203, Accuracy: 0.83935546875\n",
      "Batch: 111, Loss: 0.44745564460754395, Accuracy: 0.8515625\n",
      "Batch: 112, Loss: 0.5024595260620117, Accuracy: 0.837890625\n",
      "Batch: 113, Loss: 0.5303921699523926, Accuracy: 0.8193359375\n",
      "Batch: 114, Loss: 0.5462471842765808, Accuracy: 0.81591796875\n",
      "Batch: 115, Loss: 0.4976429045200348, Accuracy: 0.83251953125\n",
      "Batch: 116, Loss: 0.510393500328064, Accuracy: 0.8369140625\n",
      "Batch: 117, Loss: 0.49074429273605347, Accuracy: 0.833984375\n",
      "Batch: 118, Loss: 0.516249418258667, Accuracy: 0.83544921875\n",
      "Batch: 119, Loss: 0.48790243268013, Accuracy: 0.8447265625\n",
      "Batch: 120, Loss: 0.48978275060653687, Accuracy: 0.84326171875\n",
      "Batch: 121, Loss: 0.48181164264678955, Accuracy: 0.84716796875\n",
      "Batch: 122, Loss: 0.48634999990463257, Accuracy: 0.83935546875\n",
      "Batch: 123, Loss: 0.479110449552536, Accuracy: 0.84716796875\n",
      "Batch: 124, Loss: 0.47853171825408936, Accuracy: 0.8466796875\n",
      "Batch: 125, Loss: 0.5222458243370056, Accuracy: 0.83544921875\n",
      "Batch: 126, Loss: 0.5170007348060608, Accuracy: 0.83984375\n",
      "Batch: 127, Loss: 0.46015095710754395, Accuracy: 0.8564453125\n",
      "Batch: 128, Loss: 0.5589244961738586, Accuracy: 0.8203125\n",
      "Batch: 129, Loss: 0.5906614065170288, Accuracy: 0.81103515625\n",
      "Batch: 130, Loss: 0.6141262054443359, Accuracy: 0.80517578125\n",
      "Batch: 131, Loss: 0.5404822826385498, Accuracy: 0.82275390625\n",
      "Batch: 132, Loss: 0.5146809220314026, Accuracy: 0.837890625\n",
      "Batch: 133, Loss: 0.47747933864593506, Accuracy: 0.84765625\n",
      "Batch: 134, Loss: 0.5365185737609863, Accuracy: 0.8271484375\n",
      "Batch: 135, Loss: 0.5378679633140564, Accuracy: 0.82421875\n",
      "Batch: 136, Loss: 0.5143539905548096, Accuracy: 0.8251953125\n",
      "Batch: 137, Loss: 0.5324718952178955, Accuracy: 0.82861328125\n",
      "Batch: 138, Loss: 0.4696902930736542, Accuracy: 0.849609375\n",
      "Batch: 139, Loss: 0.48831599950790405, Accuracy: 0.83544921875\n",
      "Batch: 140, Loss: 0.46185851097106934, Accuracy: 0.8505859375\n",
      "Batch: 141, Loss: 0.4992637634277344, Accuracy: 0.8466796875\n",
      "Batch: 142, Loss: 0.47007977962493896, Accuracy: 0.845703125\n",
      "Batch: 143, Loss: 0.496706485748291, Accuracy: 0.841796875\n",
      "Batch: 144, Loss: 0.548696756362915, Accuracy: 0.82080078125\n",
      "Batch: 145, Loss: 0.5285001993179321, Accuracy: 0.82470703125\n",
      "Batch: 146, Loss: 0.5231813788414001, Accuracy: 0.83447265625\n",
      "Batch: 147, Loss: 0.5007514953613281, Accuracy: 0.8388671875\n",
      "Batch: 148, Loss: 0.5425955653190613, Accuracy: 0.82080078125\n",
      "Batch: 149, Loss: 0.5230803489685059, Accuracy: 0.82373046875\n",
      "Batch: 150, Loss: 0.4545639157295227, Accuracy: 0.85693359375\n",
      "Batch: 151, Loss: 0.481636643409729, Accuracy: 0.84716796875\n",
      "Batch: 152, Loss: 0.49882715940475464, Accuracy: 0.83642578125\n",
      "Batch: 153, Loss: 0.513140082359314, Accuracy: 0.82568359375\n",
      "Batch: 154, Loss: 0.5245535969734192, Accuracy: 0.82421875\n",
      "Batch: 155, Loss: 0.5722865462303162, Accuracy: 0.8134765625\n",
      "Batch: 156, Loss: 0.46166348457336426, Accuracy: 0.84716796875\n",
      "Batch: 157, Loss: 0.477363646030426, Accuracy: 0.8427734375\n",
      "Batch: 158, Loss: 0.47396960854530334, Accuracy: 0.85986328125\n",
      "Batch: 159, Loss: 0.4959953725337982, Accuracy: 0.83544921875\n",
      "Batch: 160, Loss: 0.5285197496414185, Accuracy: 0.8291015625\n",
      "Batch: 161, Loss: 0.5482758283615112, Accuracy: 0.8251953125\n",
      "Batch: 162, Loss: 0.4826506972312927, Accuracy: 0.8447265625\n",
      "Batch: 163, Loss: 0.531683087348938, Accuracy: 0.8203125\n",
      "Batch: 164, Loss: 0.5762391090393066, Accuracy: 0.81396484375\n",
      "Batch: 165, Loss: 0.5137689113616943, Accuracy: 0.83349609375\n",
      "Batch: 166, Loss: 0.5286413431167603, Accuracy: 0.8330078125\n",
      "Batch: 167, Loss: 0.5279163122177124, Accuracy: 0.83544921875\n",
      "Batch: 168, Loss: 0.4640626013278961, Accuracy: 0.85205078125\n",
      "Batch: 169, Loss: 0.5095655918121338, Accuracy: 0.8369140625\n",
      "Batch: 170, Loss: 0.5481266975402832, Accuracy: 0.82421875\n",
      "Batch: 171, Loss: 0.49322211742401123, Accuracy: 0.8369140625\n",
      "Batch: 172, Loss: 0.5030087828636169, Accuracy: 0.82958984375\n",
      "Batch: 173, Loss: 0.5400282144546509, Accuracy: 0.8271484375\n",
      "Batch: 174, Loss: 0.4491996169090271, Accuracy: 0.853515625\n",
      "Batch: 175, Loss: 0.5297470092773438, Accuracy: 0.8271484375\n",
      "Batch: 176, Loss: 0.5529823303222656, Accuracy: 0.81787109375\n",
      "Batch: 177, Loss: 0.5300809144973755, Accuracy: 0.82861328125\n",
      "Batch: 178, Loss: 0.49325263500213623, Accuracy: 0.833984375\n",
      "Batch: 179, Loss: 0.5366631746292114, Accuracy: 0.8203125\n",
      "Batch: 180, Loss: 0.5321028232574463, Accuracy: 0.82861328125\n",
      "Epoch 88/200\n",
      "Batch: 1, Loss: 0.7589266300201416, Accuracy: 0.79345703125\n",
      "Batch: 2, Loss: 0.5381923913955688, Accuracy: 0.8251953125\n",
      "Batch: 3, Loss: 0.5048607587814331, Accuracy: 0.82958984375\n",
      "Batch: 4, Loss: 0.5368529558181763, Accuracy: 0.82666015625\n",
      "Batch: 5, Loss: 0.5013892650604248, Accuracy: 0.8369140625\n",
      "Batch: 6, Loss: 0.5259522795677185, Accuracy: 0.82763671875\n",
      "Batch: 7, Loss: 0.5314518213272095, Accuracy: 0.8271484375\n",
      "Batch: 8, Loss: 0.5074984431266785, Accuracy: 0.83203125\n",
      "Batch: 9, Loss: 0.5346019268035889, Accuracy: 0.8251953125\n",
      "Batch: 10, Loss: 0.501935601234436, Accuracy: 0.83935546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 11, Loss: 0.5485741496086121, Accuracy: 0.81787109375\n",
      "Batch: 12, Loss: 0.4778243899345398, Accuracy: 0.84716796875\n",
      "Batch: 13, Loss: 0.5075682401657104, Accuracy: 0.833984375\n",
      "Batch: 14, Loss: 0.5133150815963745, Accuracy: 0.8359375\n",
      "Batch: 15, Loss: 0.527159571647644, Accuracy: 0.8369140625\n",
      "Batch: 16, Loss: 0.5427345037460327, Accuracy: 0.81591796875\n",
      "Batch: 17, Loss: 0.5064330101013184, Accuracy: 0.83447265625\n",
      "Batch: 18, Loss: 0.5490385293960571, Accuracy: 0.8232421875\n",
      "Batch: 19, Loss: 0.5307823419570923, Accuracy: 0.83544921875\n",
      "Batch: 20, Loss: 0.44217079877853394, Accuracy: 0.857421875\n",
      "Batch: 21, Loss: 0.5301985740661621, Accuracy: 0.8291015625\n",
      "Batch: 22, Loss: 0.4610706865787506, Accuracy: 0.84619140625\n",
      "Batch: 23, Loss: 0.4725129008293152, Accuracy: 0.8544921875\n",
      "Batch: 24, Loss: 0.503387451171875, Accuracy: 0.83203125\n",
      "Batch: 25, Loss: 0.47519323229789734, Accuracy: 0.8486328125\n",
      "Batch: 26, Loss: 0.5049965381622314, Accuracy: 0.83447265625\n",
      "Batch: 27, Loss: 0.5419135093688965, Accuracy: 0.82470703125\n",
      "Batch: 28, Loss: 0.49920034408569336, Accuracy: 0.84423828125\n",
      "Batch: 29, Loss: 0.5433431267738342, Accuracy: 0.83203125\n",
      "Batch: 30, Loss: 0.5314631462097168, Accuracy: 0.83740234375\n",
      "Batch: 31, Loss: 0.604647159576416, Accuracy: 0.80615234375\n",
      "Batch: 32, Loss: 0.5770169496536255, Accuracy: 0.818359375\n",
      "Batch: 33, Loss: 0.5398341417312622, Accuracy: 0.822265625\n",
      "Batch: 34, Loss: 0.5542831420898438, Accuracy: 0.82421875\n",
      "Batch: 35, Loss: 0.5578863620758057, Accuracy: 0.81982421875\n",
      "Batch: 36, Loss: 0.5332988500595093, Accuracy: 0.830078125\n",
      "Batch: 37, Loss: 0.5694643259048462, Accuracy: 0.80517578125\n",
      "Batch: 38, Loss: 0.5536055564880371, Accuracy: 0.81640625\n",
      "Batch: 39, Loss: 0.5099167823791504, Accuracy: 0.83642578125\n",
      "Batch: 40, Loss: 0.5596110820770264, Accuracy: 0.8203125\n",
      "Batch: 41, Loss: 0.5619277954101562, Accuracy: 0.8193359375\n",
      "Batch: 42, Loss: 0.5100464224815369, Accuracy: 0.83056640625\n",
      "Batch: 43, Loss: 0.49371662735939026, Accuracy: 0.845703125\n",
      "Batch: 44, Loss: 0.48402729630470276, Accuracy: 0.84130859375\n",
      "Batch: 45, Loss: 0.5046682953834534, Accuracy: 0.83154296875\n",
      "Batch: 46, Loss: 0.49386706948280334, Accuracy: 0.83203125\n",
      "Batch: 47, Loss: 0.5232900381088257, Accuracy: 0.828125\n",
      "Batch: 48, Loss: 0.5295013189315796, Accuracy: 0.828125\n",
      "Batch: 49, Loss: 0.5040509700775146, Accuracy: 0.8349609375\n",
      "Batch: 50, Loss: 0.5365098714828491, Accuracy: 0.826171875\n",
      "Batch: 51, Loss: 0.525686502456665, Accuracy: 0.830078125\n",
      "Batch: 52, Loss: 0.5240792632102966, Accuracy: 0.82421875\n",
      "Batch: 53, Loss: 0.5257785320281982, Accuracy: 0.8271484375\n",
      "Batch: 54, Loss: 0.5508754253387451, Accuracy: 0.8193359375\n",
      "Batch: 55, Loss: 0.5388215780258179, Accuracy: 0.81884765625\n",
      "Batch: 56, Loss: 0.5032547116279602, Accuracy: 0.8310546875\n",
      "Batch: 57, Loss: 0.5627569556236267, Accuracy: 0.8251953125\n",
      "Batch: 58, Loss: 0.5429279804229736, Accuracy: 0.82421875\n",
      "Batch: 59, Loss: 0.5936064124107361, Accuracy: 0.8115234375\n",
      "Batch: 60, Loss: 0.5117110013961792, Accuracy: 0.83544921875\n",
      "Batch: 61, Loss: 0.47597819566726685, Accuracy: 0.83837890625\n",
      "Batch: 62, Loss: 0.499960720539093, Accuracy: 0.84423828125\n",
      "Batch: 63, Loss: 0.5138603448867798, Accuracy: 0.83349609375\n",
      "Batch: 64, Loss: 0.5271010994911194, Accuracy: 0.818359375\n",
      "Batch: 65, Loss: 0.5520510077476501, Accuracy: 0.8271484375\n",
      "Batch: 66, Loss: 0.5223742127418518, Accuracy: 0.830078125\n",
      "Batch: 67, Loss: 0.561681866645813, Accuracy: 0.8232421875\n",
      "Batch: 68, Loss: 0.49016064405441284, Accuracy: 0.8388671875\n",
      "Batch: 69, Loss: 0.529566764831543, Accuracy: 0.830078125\n",
      "Batch: 70, Loss: 0.49590781331062317, Accuracy: 0.83056640625\n",
      "Batch: 71, Loss: 0.4944843053817749, Accuracy: 0.8330078125\n",
      "Batch: 72, Loss: 0.5590528249740601, Accuracy: 0.81640625\n",
      "Batch: 73, Loss: 0.5356794595718384, Accuracy: 0.81884765625\n",
      "Batch: 74, Loss: 0.5478066205978394, Accuracy: 0.82666015625\n",
      "Batch: 75, Loss: 0.4737536907196045, Accuracy: 0.84228515625\n",
      "Batch: 76, Loss: 0.4723968505859375, Accuracy: 0.8505859375\n",
      "Batch: 77, Loss: 0.4722360074520111, Accuracy: 0.853515625\n",
      "Batch: 78, Loss: 0.5242905616760254, Accuracy: 0.83251953125\n",
      "Batch: 79, Loss: 0.5291948914527893, Accuracy: 0.82568359375\n",
      "Batch: 80, Loss: 0.5366557240486145, Accuracy: 0.83447265625\n",
      "Batch: 81, Loss: 0.5401245355606079, Accuracy: 0.82958984375\n",
      "Batch: 82, Loss: 0.5297350883483887, Accuracy: 0.8212890625\n",
      "Batch: 83, Loss: 0.4963834583759308, Accuracy: 0.837890625\n",
      "Batch: 84, Loss: 0.49601417779922485, Accuracy: 0.837890625\n",
      "Batch: 85, Loss: 0.5268738865852356, Accuracy: 0.83154296875\n",
      "Batch: 86, Loss: 0.5781208276748657, Accuracy: 0.8193359375\n",
      "Batch: 87, Loss: 0.48304903507232666, Accuracy: 0.84619140625\n",
      "Batch: 88, Loss: 0.5277255773544312, Accuracy: 0.8349609375\n",
      "Batch: 89, Loss: 0.5006569027900696, Accuracy: 0.84130859375\n",
      "Batch: 90, Loss: 0.516991913318634, Accuracy: 0.82275390625\n",
      "Batch: 91, Loss: 0.513242244720459, Accuracy: 0.83837890625\n",
      "Batch: 92, Loss: 0.5887030363082886, Accuracy: 0.7998046875\n",
      "Batch: 93, Loss: 0.5716221332550049, Accuracy: 0.81103515625\n",
      "Batch: 94, Loss: 0.5597690939903259, Accuracy: 0.81982421875\n",
      "Batch: 95, Loss: 0.5628244876861572, Accuracy: 0.81396484375\n",
      "Batch: 96, Loss: 0.5401821732521057, Accuracy: 0.8232421875\n",
      "Batch: 97, Loss: 0.5123575925827026, Accuracy: 0.8369140625\n",
      "Batch: 98, Loss: 0.5523571968078613, Accuracy: 0.83056640625\n",
      "Batch: 99, Loss: 0.501758337020874, Accuracy: 0.8359375\n",
      "Batch: 100, Loss: 0.5671038031578064, Accuracy: 0.81298828125\n",
      "Batch: 101, Loss: 0.5671125054359436, Accuracy: 0.81494140625\n",
      "Batch: 102, Loss: 0.49073684215545654, Accuracy: 0.83203125\n",
      "Batch: 103, Loss: 0.515717625617981, Accuracy: 0.83837890625\n",
      "Batch: 104, Loss: 0.49865904450416565, Accuracy: 0.84033203125\n",
      "Batch: 105, Loss: 0.5193973779678345, Accuracy: 0.830078125\n",
      "Batch: 106, Loss: 0.5018327832221985, Accuracy: 0.83154296875\n",
      "Batch: 107, Loss: 0.5207884311676025, Accuracy: 0.83251953125\n",
      "Batch: 108, Loss: 0.4986860156059265, Accuracy: 0.837890625\n",
      "Batch: 109, Loss: 0.4917011857032776, Accuracy: 0.84521484375\n",
      "Batch: 110, Loss: 0.5000650882720947, Accuracy: 0.833984375\n",
      "Batch: 111, Loss: 0.48083260655403137, Accuracy: 0.8369140625\n",
      "Batch: 112, Loss: 0.5009536147117615, Accuracy: 0.83544921875\n",
      "Batch: 113, Loss: 0.5161163806915283, Accuracy: 0.82763671875\n",
      "Batch: 114, Loss: 0.5311788320541382, Accuracy: 0.841796875\n",
      "Batch: 115, Loss: 0.5051121711730957, Accuracy: 0.83837890625\n",
      "Batch: 116, Loss: 0.5165184736251831, Accuracy: 0.82666015625\n",
      "Batch: 117, Loss: 0.5003437995910645, Accuracy: 0.833984375\n",
      "Batch: 118, Loss: 0.543428897857666, Accuracy: 0.82568359375\n",
      "Batch: 119, Loss: 0.5071609616279602, Accuracy: 0.83056640625\n",
      "Batch: 120, Loss: 0.4818522036075592, Accuracy: 0.84033203125\n",
      "Batch: 121, Loss: 0.48179948329925537, Accuracy: 0.84716796875\n",
      "Batch: 122, Loss: 0.49328362941741943, Accuracy: 0.8359375\n",
      "Batch: 123, Loss: 0.48203712701797485, Accuracy: 0.83984375\n",
      "Batch: 124, Loss: 0.47422850131988525, Accuracy: 0.83740234375\n",
      "Batch: 125, Loss: 0.4836047291755676, Accuracy: 0.85009765625\n",
      "Batch: 126, Loss: 0.5070006847381592, Accuracy: 0.83447265625\n",
      "Batch: 127, Loss: 0.48067474365234375, Accuracy: 0.84521484375\n",
      "Batch: 128, Loss: 0.5711694955825806, Accuracy: 0.81396484375\n",
      "Batch: 129, Loss: 0.5844351053237915, Accuracy: 0.81591796875\n",
      "Batch: 130, Loss: 0.5936808586120605, Accuracy: 0.8056640625\n",
      "Batch: 131, Loss: 0.5076320171356201, Accuracy: 0.83544921875\n",
      "Batch: 132, Loss: 0.48614606261253357, Accuracy: 0.84326171875\n",
      "Batch: 133, Loss: 0.4732585549354553, Accuracy: 0.84765625\n",
      "Batch: 134, Loss: 0.5260698795318604, Accuracy: 0.837890625\n",
      "Batch: 135, Loss: 0.5194188356399536, Accuracy: 0.828125\n",
      "Batch: 136, Loss: 0.4883004128932953, Accuracy: 0.84375\n",
      "Batch: 137, Loss: 0.5148099660873413, Accuracy: 0.83740234375\n",
      "Batch: 138, Loss: 0.4830683767795563, Accuracy: 0.84521484375\n",
      "Batch: 139, Loss: 0.5094015002250671, Accuracy: 0.833984375\n",
      "Batch: 140, Loss: 0.46022239327430725, Accuracy: 0.84375\n",
      "Batch: 141, Loss: 0.5354536771774292, Accuracy: 0.8291015625\n",
      "Batch: 142, Loss: 0.45908108353614807, Accuracy: 0.84375\n",
      "Batch: 143, Loss: 0.4785141050815582, Accuracy: 0.84521484375\n",
      "Batch: 144, Loss: 0.5592954158782959, Accuracy: 0.81201171875\n",
      "Batch: 145, Loss: 0.5288743376731873, Accuracy: 0.83349609375\n",
      "Batch: 146, Loss: 0.5271755456924438, Accuracy: 0.83203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 147, Loss: 0.5202910900115967, Accuracy: 0.82861328125\n",
      "Batch: 148, Loss: 0.5370455384254456, Accuracy: 0.83056640625\n",
      "Batch: 149, Loss: 0.5285525918006897, Accuracy: 0.828125\n",
      "Batch: 150, Loss: 0.4478292465209961, Accuracy: 0.8583984375\n",
      "Batch: 151, Loss: 0.47406452894210815, Accuracy: 0.85205078125\n",
      "Batch: 152, Loss: 0.4960741698741913, Accuracy: 0.8330078125\n",
      "Batch: 153, Loss: 0.5227261185646057, Accuracy: 0.8330078125\n",
      "Batch: 154, Loss: 0.5018033981323242, Accuracy: 0.83447265625\n",
      "Batch: 155, Loss: 0.5740879774093628, Accuracy: 0.81201171875\n",
      "Batch: 156, Loss: 0.4666399657726288, Accuracy: 0.84130859375\n",
      "Batch: 157, Loss: 0.4673144221305847, Accuracy: 0.83837890625\n",
      "Batch: 158, Loss: 0.4736858010292053, Accuracy: 0.8515625\n",
      "Batch: 159, Loss: 0.47826024889945984, Accuracy: 0.8427734375\n",
      "Batch: 160, Loss: 0.505728006362915, Accuracy: 0.8349609375\n",
      "Batch: 161, Loss: 0.5313587188720703, Accuracy: 0.83154296875\n",
      "Batch: 162, Loss: 0.4700115919113159, Accuracy: 0.845703125\n",
      "Batch: 163, Loss: 0.5370352268218994, Accuracy: 0.8330078125\n",
      "Batch: 164, Loss: 0.5723086595535278, Accuracy: 0.81884765625\n",
      "Batch: 165, Loss: 0.49801212549209595, Accuracy: 0.84130859375\n",
      "Batch: 166, Loss: 0.5466490983963013, Accuracy: 0.830078125\n",
      "Batch: 167, Loss: 0.4894792437553406, Accuracy: 0.84228515625\n",
      "Batch: 168, Loss: 0.4667477607727051, Accuracy: 0.84912109375\n",
      "Batch: 169, Loss: 0.5208688974380493, Accuracy: 0.82666015625\n",
      "Batch: 170, Loss: 0.5656673312187195, Accuracy: 0.8193359375\n",
      "Batch: 171, Loss: 0.49647438526153564, Accuracy: 0.8359375\n",
      "Batch: 172, Loss: 0.49190688133239746, Accuracy: 0.83349609375\n",
      "Batch: 173, Loss: 0.5387035608291626, Accuracy: 0.8193359375\n",
      "Batch: 174, Loss: 0.4550750255584717, Accuracy: 0.83984375\n",
      "Batch: 175, Loss: 0.521467924118042, Accuracy: 0.82763671875\n",
      "Batch: 176, Loss: 0.561958372592926, Accuracy: 0.8251953125\n",
      "Batch: 177, Loss: 0.527632474899292, Accuracy: 0.83203125\n",
      "Batch: 178, Loss: 0.4966512620449066, Accuracy: 0.84033203125\n",
      "Batch: 179, Loss: 0.5275946855545044, Accuracy: 0.8310546875\n",
      "Batch: 180, Loss: 0.5088801383972168, Accuracy: 0.83837890625\n",
      "Epoch 89/200\n",
      "Batch: 1, Loss: 0.7845203280448914, Accuracy: 0.77392578125\n",
      "Batch: 2, Loss: 0.500485897064209, Accuracy: 0.83447265625\n",
      "Batch: 3, Loss: 0.5188401937484741, Accuracy: 0.82470703125\n",
      "Batch: 4, Loss: 0.5359376668930054, Accuracy: 0.822265625\n",
      "Batch: 5, Loss: 0.4904906749725342, Accuracy: 0.84326171875\n",
      "Batch: 6, Loss: 0.5269748568534851, Accuracy: 0.828125\n",
      "Batch: 7, Loss: 0.4995097219944, Accuracy: 0.833984375\n",
      "Batch: 8, Loss: 0.4971289038658142, Accuracy: 0.83154296875\n",
      "Batch: 9, Loss: 0.5347281694412231, Accuracy: 0.83056640625\n",
      "Batch: 10, Loss: 0.47328871488571167, Accuracy: 0.8505859375\n",
      "Batch: 11, Loss: 0.5103012919425964, Accuracy: 0.83203125\n",
      "Batch: 12, Loss: 0.4821801781654358, Accuracy: 0.84912109375\n",
      "Batch: 13, Loss: 0.5219401121139526, Accuracy: 0.83984375\n",
      "Batch: 14, Loss: 0.4992586076259613, Accuracy: 0.83837890625\n",
      "Batch: 15, Loss: 0.5414793491363525, Accuracy: 0.8349609375\n",
      "Batch: 16, Loss: 0.5538804531097412, Accuracy: 0.81201171875\n",
      "Batch: 17, Loss: 0.48342186212539673, Accuracy: 0.8427734375\n",
      "Batch: 18, Loss: 0.5353999733924866, Accuracy: 0.83203125\n",
      "Batch: 19, Loss: 0.5283498167991638, Accuracy: 0.8291015625\n",
      "Batch: 20, Loss: 0.4396612346172333, Accuracy: 0.85986328125\n",
      "Batch: 21, Loss: 0.5421642065048218, Accuracy: 0.82666015625\n",
      "Batch: 22, Loss: 0.47777366638183594, Accuracy: 0.83984375\n",
      "Batch: 23, Loss: 0.45474085211753845, Accuracy: 0.85302734375\n",
      "Batch: 24, Loss: 0.5410919189453125, Accuracy: 0.818359375\n",
      "Batch: 25, Loss: 0.497760534286499, Accuracy: 0.8486328125\n",
      "Batch: 26, Loss: 0.4703174829483032, Accuracy: 0.83935546875\n",
      "Batch: 27, Loss: 0.5293821096420288, Accuracy: 0.8330078125\n",
      "Batch: 28, Loss: 0.5221191048622131, Accuracy: 0.82861328125\n",
      "Batch: 29, Loss: 0.5418547987937927, Accuracy: 0.83447265625\n",
      "Batch: 30, Loss: 0.5310336351394653, Accuracy: 0.82958984375\n",
      "Batch: 31, Loss: 0.566239595413208, Accuracy: 0.8134765625\n",
      "Batch: 32, Loss: 0.5501582026481628, Accuracy: 0.82373046875\n",
      "Batch: 33, Loss: 0.5097037553787231, Accuracy: 0.82568359375\n",
      "Batch: 34, Loss: 0.5447555780410767, Accuracy: 0.82470703125\n",
      "Batch: 35, Loss: 0.5728046298027039, Accuracy: 0.8134765625\n",
      "Batch: 36, Loss: 0.5205692052841187, Accuracy: 0.82861328125\n",
      "Batch: 37, Loss: 0.5522280335426331, Accuracy: 0.82666015625\n",
      "Batch: 38, Loss: 0.5409561991691589, Accuracy: 0.81884765625\n",
      "Batch: 39, Loss: 0.5111111998558044, Accuracy: 0.8369140625\n",
      "Batch: 40, Loss: 0.5723721385002136, Accuracy: 0.822265625\n",
      "Batch: 41, Loss: 0.550406277179718, Accuracy: 0.828125\n",
      "Batch: 42, Loss: 0.5373784303665161, Accuracy: 0.82080078125\n",
      "Batch: 43, Loss: 0.4880969822406769, Accuracy: 0.84130859375\n",
      "Batch: 44, Loss: 0.46797797083854675, Accuracy: 0.85302734375\n",
      "Batch: 45, Loss: 0.49477383494377136, Accuracy: 0.83837890625\n",
      "Batch: 46, Loss: 0.5108652114868164, Accuracy: 0.82568359375\n",
      "Batch: 47, Loss: 0.5076993703842163, Accuracy: 0.8359375\n",
      "Batch: 48, Loss: 0.5186446905136108, Accuracy: 0.8330078125\n",
      "Batch: 49, Loss: 0.5254165530204773, Accuracy: 0.8310546875\n",
      "Batch: 50, Loss: 0.5209508538246155, Accuracy: 0.830078125\n",
      "Batch: 51, Loss: 0.5062355995178223, Accuracy: 0.84375\n",
      "Batch: 52, Loss: 0.5186973810195923, Accuracy: 0.82568359375\n",
      "Batch: 53, Loss: 0.4957695007324219, Accuracy: 0.8349609375\n",
      "Batch: 54, Loss: 0.5776284337043762, Accuracy: 0.80908203125\n",
      "Batch: 55, Loss: 0.530544638633728, Accuracy: 0.82568359375\n",
      "Batch: 56, Loss: 0.5070186853408813, Accuracy: 0.8310546875\n",
      "Batch: 57, Loss: 0.542481541633606, Accuracy: 0.830078125\n",
      "Batch: 58, Loss: 0.5290772318840027, Accuracy: 0.8193359375\n",
      "Batch: 59, Loss: 0.5924278497695923, Accuracy: 0.81591796875\n",
      "Batch: 60, Loss: 0.528677225112915, Accuracy: 0.8310546875\n",
      "Batch: 61, Loss: 0.4805397093296051, Accuracy: 0.84423828125\n",
      "Batch: 62, Loss: 0.5131523609161377, Accuracy: 0.8369140625\n",
      "Batch: 63, Loss: 0.49459537863731384, Accuracy: 0.83642578125\n",
      "Batch: 64, Loss: 0.518897533416748, Accuracy: 0.8310546875\n",
      "Batch: 65, Loss: 0.5599534511566162, Accuracy: 0.81689453125\n",
      "Batch: 66, Loss: 0.5214993953704834, Accuracy: 0.83251953125\n",
      "Batch: 67, Loss: 0.5595672726631165, Accuracy: 0.82568359375\n",
      "Batch: 68, Loss: 0.47366249561309814, Accuracy: 0.841796875\n",
      "Batch: 69, Loss: 0.5163155198097229, Accuracy: 0.830078125\n",
      "Batch: 70, Loss: 0.4811701774597168, Accuracy: 0.8388671875\n",
      "Batch: 71, Loss: 0.5008863806724548, Accuracy: 0.8388671875\n",
      "Batch: 72, Loss: 0.5314415693283081, Accuracy: 0.8115234375\n",
      "Batch: 73, Loss: 0.5194535851478577, Accuracy: 0.83154296875\n",
      "Batch: 74, Loss: 0.5300391912460327, Accuracy: 0.822265625\n",
      "Batch: 75, Loss: 0.4905165433883667, Accuracy: 0.8447265625\n",
      "Batch: 76, Loss: 0.4895687699317932, Accuracy: 0.841796875\n",
      "Batch: 77, Loss: 0.4869540333747864, Accuracy: 0.84912109375\n",
      "Batch: 78, Loss: 0.500362753868103, Accuracy: 0.8310546875\n",
      "Batch: 79, Loss: 0.5157216191291809, Accuracy: 0.8310546875\n",
      "Batch: 80, Loss: 0.5476199388504028, Accuracy: 0.81982421875\n",
      "Batch: 81, Loss: 0.5494939684867859, Accuracy: 0.82666015625\n",
      "Batch: 82, Loss: 0.4995096027851105, Accuracy: 0.83154296875\n",
      "Batch: 83, Loss: 0.4779861569404602, Accuracy: 0.84716796875\n",
      "Batch: 84, Loss: 0.5180008411407471, Accuracy: 0.83056640625\n",
      "Batch: 85, Loss: 0.5147433280944824, Accuracy: 0.8203125\n",
      "Batch: 86, Loss: 0.5720738768577576, Accuracy: 0.82470703125\n",
      "Batch: 87, Loss: 0.504944920539856, Accuracy: 0.82763671875\n",
      "Batch: 88, Loss: 0.528701901435852, Accuracy: 0.828125\n",
      "Batch: 89, Loss: 0.4925185739994049, Accuracy: 0.837890625\n",
      "Batch: 90, Loss: 0.5117772221565247, Accuracy: 0.83203125\n",
      "Batch: 91, Loss: 0.5167442560195923, Accuracy: 0.8369140625\n",
      "Batch: 92, Loss: 0.5942187905311584, Accuracy: 0.802734375\n",
      "Batch: 93, Loss: 0.5681067705154419, Accuracy: 0.8154296875\n",
      "Batch: 94, Loss: 0.551228404045105, Accuracy: 0.82861328125\n",
      "Batch: 95, Loss: 0.5772489309310913, Accuracy: 0.80908203125\n",
      "Batch: 96, Loss: 0.5233407020568848, Accuracy: 0.82958984375\n",
      "Batch: 97, Loss: 0.48678869009017944, Accuracy: 0.8466796875\n",
      "Batch: 98, Loss: 0.5115846395492554, Accuracy: 0.8310546875\n",
      "Batch: 99, Loss: 0.502142608165741, Accuracy: 0.84033203125\n",
      "Batch: 100, Loss: 0.546904444694519, Accuracy: 0.82373046875\n",
      "Batch: 101, Loss: 0.5431530475616455, Accuracy: 0.82568359375\n",
      "Batch: 102, Loss: 0.49099764227867126, Accuracy: 0.83447265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 103, Loss: 0.5347487926483154, Accuracy: 0.826171875\n",
      "Batch: 104, Loss: 0.5056481957435608, Accuracy: 0.83544921875\n",
      "Batch: 105, Loss: 0.5319879055023193, Accuracy: 0.83056640625\n",
      "Batch: 106, Loss: 0.48535987734794617, Accuracy: 0.8310546875\n",
      "Batch: 107, Loss: 0.5323834419250488, Accuracy: 0.82080078125\n",
      "Batch: 108, Loss: 0.4965263605117798, Accuracy: 0.83642578125\n",
      "Batch: 109, Loss: 0.48542267084121704, Accuracy: 0.845703125\n",
      "Batch: 110, Loss: 0.4979357421398163, Accuracy: 0.8447265625\n",
      "Batch: 111, Loss: 0.4698486924171448, Accuracy: 0.84228515625\n",
      "Batch: 112, Loss: 0.4795685410499573, Accuracy: 0.84228515625\n",
      "Batch: 113, Loss: 0.5114486813545227, Accuracy: 0.82666015625\n",
      "Batch: 114, Loss: 0.5287328958511353, Accuracy: 0.83251953125\n",
      "Batch: 115, Loss: 0.5038110613822937, Accuracy: 0.83349609375\n",
      "Batch: 116, Loss: 0.5081290006637573, Accuracy: 0.83984375\n",
      "Batch: 117, Loss: 0.483761191368103, Accuracy: 0.83837890625\n",
      "Batch: 118, Loss: 0.5282492637634277, Accuracy: 0.82763671875\n",
      "Batch: 119, Loss: 0.4855663776397705, Accuracy: 0.83984375\n",
      "Batch: 120, Loss: 0.5060368180274963, Accuracy: 0.83935546875\n",
      "Batch: 121, Loss: 0.5025556683540344, Accuracy: 0.833984375\n",
      "Batch: 122, Loss: 0.47631627321243286, Accuracy: 0.833984375\n",
      "Batch: 123, Loss: 0.4799111783504486, Accuracy: 0.84716796875\n",
      "Batch: 124, Loss: 0.4661787748336792, Accuracy: 0.84716796875\n",
      "Batch: 125, Loss: 0.48491549491882324, Accuracy: 0.84228515625\n",
      "Batch: 126, Loss: 0.5045461654663086, Accuracy: 0.837890625\n",
      "Batch: 127, Loss: 0.4708200693130493, Accuracy: 0.84912109375\n",
      "Batch: 128, Loss: 0.5686016082763672, Accuracy: 0.8193359375\n",
      "Batch: 129, Loss: 0.5496680736541748, Accuracy: 0.81787109375\n",
      "Batch: 130, Loss: 0.5807382464408875, Accuracy: 0.806640625\n",
      "Batch: 131, Loss: 0.5320683717727661, Accuracy: 0.822265625\n",
      "Batch: 132, Loss: 0.49214839935302734, Accuracy: 0.84326171875\n",
      "Batch: 133, Loss: 0.4791978597640991, Accuracy: 0.841796875\n",
      "Batch: 134, Loss: 0.5367629528045654, Accuracy: 0.81982421875\n",
      "Batch: 135, Loss: 0.5109394192695618, Accuracy: 0.8310546875\n",
      "Batch: 136, Loss: 0.4798056483268738, Accuracy: 0.8466796875\n",
      "Batch: 137, Loss: 0.5050779581069946, Accuracy: 0.83984375\n",
      "Batch: 138, Loss: 0.4602660536766052, Accuracy: 0.85546875\n",
      "Batch: 139, Loss: 0.48660340905189514, Accuracy: 0.84521484375\n",
      "Batch: 140, Loss: 0.43865811824798584, Accuracy: 0.8447265625\n",
      "Batch: 141, Loss: 0.5170623064041138, Accuracy: 0.826171875\n",
      "Batch: 142, Loss: 0.48971545696258545, Accuracy: 0.84375\n",
      "Batch: 143, Loss: 0.4761659502983093, Accuracy: 0.85302734375\n",
      "Batch: 144, Loss: 0.533734142780304, Accuracy: 0.82470703125\n",
      "Batch: 145, Loss: 0.5481103658676147, Accuracy: 0.82470703125\n",
      "Batch: 146, Loss: 0.5349783897399902, Accuracy: 0.8271484375\n",
      "Batch: 147, Loss: 0.5145776271820068, Accuracy: 0.828125\n",
      "Batch: 148, Loss: 0.5411617755889893, Accuracy: 0.828125\n",
      "Batch: 149, Loss: 0.521355390548706, Accuracy: 0.82861328125\n",
      "Batch: 150, Loss: 0.4699958562850952, Accuracy: 0.85107421875\n",
      "Batch: 151, Loss: 0.47413018345832825, Accuracy: 0.84619140625\n",
      "Batch: 152, Loss: 0.4797489047050476, Accuracy: 0.8427734375\n",
      "Batch: 153, Loss: 0.526360273361206, Accuracy: 0.82421875\n",
      "Batch: 154, Loss: 0.5075024366378784, Accuracy: 0.83251953125\n",
      "Batch: 155, Loss: 0.5659486055374146, Accuracy: 0.8095703125\n",
      "Batch: 156, Loss: 0.4791455566883087, Accuracy: 0.84033203125\n",
      "Batch: 157, Loss: 0.460407555103302, Accuracy: 0.8427734375\n",
      "Batch: 158, Loss: 0.46676814556121826, Accuracy: 0.8486328125\n",
      "Batch: 159, Loss: 0.4943600594997406, Accuracy: 0.83251953125\n",
      "Batch: 160, Loss: 0.5131231546401978, Accuracy: 0.837890625\n",
      "Batch: 161, Loss: 0.5218227505683899, Accuracy: 0.82421875\n",
      "Batch: 162, Loss: 0.47961363196372986, Accuracy: 0.84375\n",
      "Batch: 163, Loss: 0.5211775898933411, Accuracy: 0.8271484375\n",
      "Batch: 164, Loss: 0.5853481888771057, Accuracy: 0.810546875\n",
      "Batch: 165, Loss: 0.5083603858947754, Accuracy: 0.83447265625\n",
      "Batch: 166, Loss: 0.5307788848876953, Accuracy: 0.8310546875\n",
      "Batch: 167, Loss: 0.5255774259567261, Accuracy: 0.83642578125\n",
      "Batch: 168, Loss: 0.4527602791786194, Accuracy: 0.8583984375\n",
      "Batch: 169, Loss: 0.520380437374115, Accuracy: 0.81884765625\n",
      "Batch: 170, Loss: 0.5432541966438293, Accuracy: 0.82080078125\n",
      "Batch: 171, Loss: 0.5047867894172668, Accuracy: 0.83447265625\n",
      "Batch: 172, Loss: 0.4831774830818176, Accuracy: 0.8310546875\n",
      "Batch: 173, Loss: 0.5481806993484497, Accuracy: 0.822265625\n",
      "Batch: 174, Loss: 0.45342177152633667, Accuracy: 0.85205078125\n",
      "Batch: 175, Loss: 0.5184333324432373, Accuracy: 0.8369140625\n",
      "Batch: 176, Loss: 0.5438989400863647, Accuracy: 0.82470703125\n",
      "Batch: 177, Loss: 0.5317524075508118, Accuracy: 0.83203125\n",
      "Batch: 178, Loss: 0.4719190001487732, Accuracy: 0.84814453125\n",
      "Batch: 179, Loss: 0.5213571786880493, Accuracy: 0.8369140625\n",
      "Batch: 180, Loss: 0.5073993802070618, Accuracy: 0.83935546875\n",
      "Epoch 90/200\n",
      "Batch: 1, Loss: 0.765411376953125, Accuracy: 0.78564453125\n",
      "Batch: 2, Loss: 0.5224959254264832, Accuracy: 0.82373046875\n",
      "Batch: 3, Loss: 0.5167853832244873, Accuracy: 0.82763671875\n",
      "Batch: 4, Loss: 0.5264424681663513, Accuracy: 0.81982421875\n",
      "Batch: 5, Loss: 0.49599698185920715, Accuracy: 0.84130859375\n",
      "Batch: 6, Loss: 0.5163984298706055, Accuracy: 0.833984375\n",
      "Batch: 7, Loss: 0.510871410369873, Accuracy: 0.833984375\n",
      "Batch: 8, Loss: 0.48263347148895264, Accuracy: 0.841796875\n",
      "Batch: 9, Loss: 0.5377506017684937, Accuracy: 0.8291015625\n",
      "Batch: 10, Loss: 0.47013789415359497, Accuracy: 0.8525390625\n",
      "Batch: 11, Loss: 0.5241836905479431, Accuracy: 0.83447265625\n",
      "Batch: 12, Loss: 0.4520787000656128, Accuracy: 0.85693359375\n",
      "Batch: 13, Loss: 0.5256199836730957, Accuracy: 0.82666015625\n",
      "Batch: 14, Loss: 0.5149106979370117, Accuracy: 0.8388671875\n",
      "Batch: 15, Loss: 0.5014445185661316, Accuracy: 0.84130859375\n",
      "Batch: 16, Loss: 0.5320563912391663, Accuracy: 0.82421875\n",
      "Batch: 17, Loss: 0.4773290753364563, Accuracy: 0.84521484375\n",
      "Batch: 18, Loss: 0.5226931571960449, Accuracy: 0.83349609375\n",
      "Batch: 19, Loss: 0.5282670855522156, Accuracy: 0.83203125\n",
      "Batch: 20, Loss: 0.4388389587402344, Accuracy: 0.84912109375\n",
      "Batch: 21, Loss: 0.5050238370895386, Accuracy: 0.833984375\n",
      "Batch: 22, Loss: 0.4659121036529541, Accuracy: 0.84619140625\n",
      "Batch: 23, Loss: 0.45673489570617676, Accuracy: 0.857421875\n",
      "Batch: 24, Loss: 0.5110141038894653, Accuracy: 0.830078125\n",
      "Batch: 25, Loss: 0.48787248134613037, Accuracy: 0.84423828125\n",
      "Batch: 26, Loss: 0.49811071157455444, Accuracy: 0.837890625\n",
      "Batch: 27, Loss: 0.5129879713058472, Accuracy: 0.82958984375\n",
      "Batch: 28, Loss: 0.5018523931503296, Accuracy: 0.83837890625\n",
      "Batch: 29, Loss: 0.5429134964942932, Accuracy: 0.82763671875\n",
      "Batch: 30, Loss: 0.5243211984634399, Accuracy: 0.8310546875\n",
      "Batch: 31, Loss: 0.567592978477478, Accuracy: 0.8203125\n",
      "Batch: 32, Loss: 0.5481753349304199, Accuracy: 0.828125\n",
      "Batch: 33, Loss: 0.5248714685440063, Accuracy: 0.82666015625\n",
      "Batch: 34, Loss: 0.5355536937713623, Accuracy: 0.83203125\n",
      "Batch: 35, Loss: 0.5570697784423828, Accuracy: 0.818359375\n",
      "Batch: 36, Loss: 0.5402683019638062, Accuracy: 0.8193359375\n",
      "Batch: 37, Loss: 0.552215576171875, Accuracy: 0.81787109375\n",
      "Batch: 38, Loss: 0.5516468286514282, Accuracy: 0.8271484375\n",
      "Batch: 39, Loss: 0.5102130174636841, Accuracy: 0.833984375\n",
      "Batch: 40, Loss: 0.5766918659210205, Accuracy: 0.81201171875\n",
      "Batch: 41, Loss: 0.5187288522720337, Accuracy: 0.82666015625\n",
      "Batch: 42, Loss: 0.5194562673568726, Accuracy: 0.8251953125\n",
      "Batch: 43, Loss: 0.4747965335845947, Accuracy: 0.84814453125\n",
      "Batch: 44, Loss: 0.4657994508743286, Accuracy: 0.84716796875\n",
      "Batch: 45, Loss: 0.5051586627960205, Accuracy: 0.83056640625\n",
      "Batch: 46, Loss: 0.4919673800468445, Accuracy: 0.8291015625\n",
      "Batch: 47, Loss: 0.5149186253547668, Accuracy: 0.83056640625\n",
      "Batch: 48, Loss: 0.5199780464172363, Accuracy: 0.83154296875\n",
      "Batch: 49, Loss: 0.4954020380973816, Accuracy: 0.8427734375\n",
      "Batch: 50, Loss: 0.5095680952072144, Accuracy: 0.82666015625\n",
      "Batch: 51, Loss: 0.49733373522758484, Accuracy: 0.8330078125\n",
      "Batch: 52, Loss: 0.5266444683074951, Accuracy: 0.82568359375\n",
      "Batch: 53, Loss: 0.5205543041229248, Accuracy: 0.833984375\n",
      "Batch: 54, Loss: 0.5303955674171448, Accuracy: 0.82861328125\n",
      "Batch: 55, Loss: 0.5151622891426086, Accuracy: 0.82373046875\n",
      "Batch: 56, Loss: 0.4879855811595917, Accuracy: 0.83544921875\n",
      "Batch: 57, Loss: 0.5678051710128784, Accuracy: 0.82177734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 58, Loss: 0.5357331037521362, Accuracy: 0.8232421875\n",
      "Batch: 59, Loss: 0.6182857751846313, Accuracy: 0.806640625\n",
      "Batch: 60, Loss: 0.506503701210022, Accuracy: 0.82958984375\n",
      "Batch: 61, Loss: 0.481804758310318, Accuracy: 0.845703125\n",
      "Batch: 62, Loss: 0.4815726578235626, Accuracy: 0.84130859375\n",
      "Batch: 63, Loss: 0.5002219676971436, Accuracy: 0.83203125\n",
      "Batch: 64, Loss: 0.5387075543403625, Accuracy: 0.82275390625\n",
      "Batch: 65, Loss: 0.5266545414924622, Accuracy: 0.82666015625\n",
      "Batch: 66, Loss: 0.5164327621459961, Accuracy: 0.8349609375\n",
      "Batch: 67, Loss: 0.5351077914237976, Accuracy: 0.82421875\n",
      "Batch: 68, Loss: 0.47305482625961304, Accuracy: 0.84765625\n",
      "Batch: 69, Loss: 0.5025385022163391, Accuracy: 0.828125\n",
      "Batch: 70, Loss: 0.49219584465026855, Accuracy: 0.8388671875\n",
      "Batch: 71, Loss: 0.5033618211746216, Accuracy: 0.83642578125\n",
      "Batch: 72, Loss: 0.5535365343093872, Accuracy: 0.81103515625\n",
      "Batch: 73, Loss: 0.5183283686637878, Accuracy: 0.8271484375\n",
      "Batch: 74, Loss: 0.5439798831939697, Accuracy: 0.8251953125\n",
      "Batch: 75, Loss: 0.47680991888046265, Accuracy: 0.84033203125\n",
      "Batch: 76, Loss: 0.46772557497024536, Accuracy: 0.859375\n",
      "Batch: 77, Loss: 0.47583842277526855, Accuracy: 0.85546875\n",
      "Batch: 78, Loss: 0.5057497620582581, Accuracy: 0.84033203125\n",
      "Batch: 79, Loss: 0.5114321708679199, Accuracy: 0.83349609375\n",
      "Batch: 80, Loss: 0.5338548421859741, Accuracy: 0.8291015625\n",
      "Batch: 81, Loss: 0.5239447355270386, Accuracy: 0.833984375\n",
      "Batch: 82, Loss: 0.5222374796867371, Accuracy: 0.8193359375\n",
      "Batch: 83, Loss: 0.4627731442451477, Accuracy: 0.84716796875\n",
      "Batch: 84, Loss: 0.49914324283599854, Accuracy: 0.83984375\n",
      "Batch: 85, Loss: 0.533947229385376, Accuracy: 0.82666015625\n",
      "Batch: 86, Loss: 0.5708761215209961, Accuracy: 0.826171875\n",
      "Batch: 87, Loss: 0.5090726017951965, Accuracy: 0.83154296875\n",
      "Batch: 88, Loss: 0.5336046814918518, Accuracy: 0.833984375\n",
      "Batch: 89, Loss: 0.49122944474220276, Accuracy: 0.83740234375\n",
      "Batch: 90, Loss: 0.5313587784767151, Accuracy: 0.82568359375\n",
      "Batch: 91, Loss: 0.5109966993331909, Accuracy: 0.84326171875\n",
      "Batch: 92, Loss: 0.5569536685943604, Accuracy: 0.8134765625\n",
      "Batch: 93, Loss: 0.5608880519866943, Accuracy: 0.81298828125\n",
      "Batch: 94, Loss: 0.5700958967208862, Accuracy: 0.82080078125\n",
      "Batch: 95, Loss: 0.5602816343307495, Accuracy: 0.8193359375\n",
      "Batch: 96, Loss: 0.5180233716964722, Accuracy: 0.833984375\n",
      "Batch: 97, Loss: 0.5011295080184937, Accuracy: 0.8408203125\n",
      "Batch: 98, Loss: 0.5163639783859253, Accuracy: 0.83837890625\n",
      "Batch: 99, Loss: 0.4986950755119324, Accuracy: 0.84423828125\n",
      "Batch: 100, Loss: 0.5438404083251953, Accuracy: 0.82666015625\n",
      "Batch: 101, Loss: 0.569181501865387, Accuracy: 0.8203125\n",
      "Batch: 102, Loss: 0.47447025775909424, Accuracy: 0.8466796875\n",
      "Batch: 103, Loss: 0.5127344727516174, Accuracy: 0.83154296875\n",
      "Batch: 104, Loss: 0.5086438059806824, Accuracy: 0.833984375\n",
      "Batch: 105, Loss: 0.5211833715438843, Accuracy: 0.8349609375\n",
      "Batch: 106, Loss: 0.4829227924346924, Accuracy: 0.84130859375\n",
      "Batch: 107, Loss: 0.5279498100280762, Accuracy: 0.830078125\n",
      "Batch: 108, Loss: 0.4924249053001404, Accuracy: 0.84033203125\n",
      "Batch: 109, Loss: 0.48191168904304504, Accuracy: 0.8427734375\n",
      "Batch: 110, Loss: 0.4874102473258972, Accuracy: 0.8359375\n",
      "Batch: 111, Loss: 0.47615984082221985, Accuracy: 0.84619140625\n",
      "Batch: 112, Loss: 0.4981932044029236, Accuracy: 0.83740234375\n",
      "Batch: 113, Loss: 0.5270751118659973, Accuracy: 0.83056640625\n",
      "Batch: 114, Loss: 0.5097477436065674, Accuracy: 0.83203125\n",
      "Batch: 115, Loss: 0.5033385753631592, Accuracy: 0.83349609375\n",
      "Batch: 116, Loss: 0.49088460206985474, Accuracy: 0.84228515625\n",
      "Batch: 117, Loss: 0.4717879295349121, Accuracy: 0.845703125\n",
      "Batch: 118, Loss: 0.5094123482704163, Accuracy: 0.83642578125\n",
      "Batch: 119, Loss: 0.49724069237709045, Accuracy: 0.83642578125\n",
      "Batch: 120, Loss: 0.4716055691242218, Accuracy: 0.8525390625\n",
      "Batch: 121, Loss: 0.495697557926178, Accuracy: 0.8408203125\n",
      "Batch: 122, Loss: 0.4511910676956177, Accuracy: 0.8544921875\n",
      "Batch: 123, Loss: 0.4708248972892761, Accuracy: 0.8544921875\n",
      "Batch: 124, Loss: 0.460669606924057, Accuracy: 0.85009765625\n",
      "Batch: 125, Loss: 0.4809979498386383, Accuracy: 0.8486328125\n",
      "Batch: 126, Loss: 0.5120581984519958, Accuracy: 0.833984375\n",
      "Batch: 127, Loss: 0.4817544221878052, Accuracy: 0.84716796875\n",
      "Batch: 128, Loss: 0.5813674926757812, Accuracy: 0.80810546875\n",
      "Batch: 129, Loss: 0.5582841634750366, Accuracy: 0.818359375\n",
      "Batch: 130, Loss: 0.5930977463722229, Accuracy: 0.80859375\n",
      "Batch: 131, Loss: 0.5069458484649658, Accuracy: 0.841796875\n",
      "Batch: 132, Loss: 0.508479118347168, Accuracy: 0.837890625\n",
      "Batch: 133, Loss: 0.4741969108581543, Accuracy: 0.8525390625\n",
      "Batch: 134, Loss: 0.5226525068283081, Accuracy: 0.83544921875\n",
      "Batch: 135, Loss: 0.509294867515564, Accuracy: 0.83642578125\n",
      "Batch: 136, Loss: 0.4604497253894806, Accuracy: 0.84765625\n",
      "Batch: 137, Loss: 0.5026630759239197, Accuracy: 0.82763671875\n",
      "Batch: 138, Loss: 0.47326457500457764, Accuracy: 0.84765625\n",
      "Batch: 139, Loss: 0.48452359437942505, Accuracy: 0.84130859375\n",
      "Batch: 140, Loss: 0.44693392515182495, Accuracy: 0.8515625\n",
      "Batch: 141, Loss: 0.5191975235939026, Accuracy: 0.8310546875\n",
      "Batch: 142, Loss: 0.45799827575683594, Accuracy: 0.845703125\n",
      "Batch: 143, Loss: 0.476801335811615, Accuracy: 0.85693359375\n",
      "Batch: 144, Loss: 0.5393409729003906, Accuracy: 0.8251953125\n",
      "Batch: 145, Loss: 0.5038801431655884, Accuracy: 0.84130859375\n",
      "Batch: 146, Loss: 0.5239371657371521, Accuracy: 0.84033203125\n",
      "Batch: 147, Loss: 0.49808257818222046, Accuracy: 0.833984375\n",
      "Batch: 148, Loss: 0.5457762479782104, Accuracy: 0.82177734375\n",
      "Batch: 149, Loss: 0.5362699031829834, Accuracy: 0.8291015625\n",
      "Batch: 150, Loss: 0.45201176404953003, Accuracy: 0.85546875\n",
      "Batch: 151, Loss: 0.47379279136657715, Accuracy: 0.85400390625\n",
      "Batch: 152, Loss: 0.5039329528808594, Accuracy: 0.83544921875\n",
      "Batch: 153, Loss: 0.5319059491157532, Accuracy: 0.828125\n",
      "Batch: 154, Loss: 0.5137166976928711, Accuracy: 0.83056640625\n",
      "Batch: 155, Loss: 0.5486792922019958, Accuracy: 0.8154296875\n",
      "Batch: 156, Loss: 0.4828845262527466, Accuracy: 0.841796875\n",
      "Batch: 157, Loss: 0.4699268937110901, Accuracy: 0.84033203125\n",
      "Batch: 158, Loss: 0.4881281852722168, Accuracy: 0.84326171875\n",
      "Batch: 159, Loss: 0.4804244935512543, Accuracy: 0.84130859375\n",
      "Batch: 160, Loss: 0.4980672001838684, Accuracy: 0.84765625\n",
      "Batch: 161, Loss: 0.5345703363418579, Accuracy: 0.83447265625\n",
      "Batch: 162, Loss: 0.47933027148246765, Accuracy: 0.84326171875\n",
      "Batch: 163, Loss: 0.5160790681838989, Accuracy: 0.8359375\n",
      "Batch: 164, Loss: 0.5540331602096558, Accuracy: 0.81005859375\n",
      "Batch: 165, Loss: 0.4996193051338196, Accuracy: 0.84130859375\n",
      "Batch: 166, Loss: 0.5370922684669495, Accuracy: 0.82861328125\n",
      "Batch: 167, Loss: 0.516903281211853, Accuracy: 0.8359375\n",
      "Batch: 168, Loss: 0.4557398855686188, Accuracy: 0.85302734375\n",
      "Batch: 169, Loss: 0.5007205009460449, Accuracy: 0.8369140625\n",
      "Batch: 170, Loss: 0.5531069040298462, Accuracy: 0.82470703125\n",
      "Batch: 171, Loss: 0.4972725808620453, Accuracy: 0.83837890625\n",
      "Batch: 172, Loss: 0.489795058965683, Accuracy: 0.8369140625\n",
      "Batch: 173, Loss: 0.5342569351196289, Accuracy: 0.8232421875\n",
      "Batch: 174, Loss: 0.46389007568359375, Accuracy: 0.84619140625\n",
      "Batch: 175, Loss: 0.5133782625198364, Accuracy: 0.81884765625\n",
      "Batch: 176, Loss: 0.5628056526184082, Accuracy: 0.81689453125\n",
      "Batch: 177, Loss: 0.5141555666923523, Accuracy: 0.8349609375\n",
      "Batch: 178, Loss: 0.4781567454338074, Accuracy: 0.85107421875\n",
      "Batch: 179, Loss: 0.48841434717178345, Accuracy: 0.8330078125\n",
      "Batch: 180, Loss: 0.5107547044754028, Accuracy: 0.8408203125\n",
      "Saved Weights at epoch 90 to file Weights_90.h5\n",
      "Epoch 91/200\n",
      "Batch: 1, Loss: 0.7736309766769409, Accuracy: 0.7841796875\n",
      "Batch: 2, Loss: 0.5182636380195618, Accuracy: 0.82666015625\n",
      "Batch: 3, Loss: 0.5176116228103638, Accuracy: 0.837890625\n",
      "Batch: 4, Loss: 0.5172462463378906, Accuracy: 0.82861328125\n",
      "Batch: 5, Loss: 0.4947656989097595, Accuracy: 0.8388671875\n",
      "Batch: 6, Loss: 0.5052326917648315, Accuracy: 0.8388671875\n",
      "Batch: 7, Loss: 0.5038793087005615, Accuracy: 0.83251953125\n",
      "Batch: 8, Loss: 0.48593670129776, Accuracy: 0.841796875\n",
      "Batch: 9, Loss: 0.5301722288131714, Accuracy: 0.833984375\n",
      "Batch: 10, Loss: 0.4709949195384979, Accuracy: 0.84228515625\n",
      "Batch: 11, Loss: 0.5461286902427673, Accuracy: 0.81787109375\n",
      "Batch: 12, Loss: 0.4380868077278137, Accuracy: 0.85205078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 13, Loss: 0.5123924016952515, Accuracy: 0.83154296875\n",
      "Batch: 14, Loss: 0.49847573041915894, Accuracy: 0.83544921875\n",
      "Batch: 15, Loss: 0.5317429304122925, Accuracy: 0.8359375\n",
      "Batch: 16, Loss: 0.5301817655563354, Accuracy: 0.8271484375\n",
      "Batch: 17, Loss: 0.4975486695766449, Accuracy: 0.84521484375\n",
      "Batch: 18, Loss: 0.5220410823822021, Accuracy: 0.83837890625\n",
      "Batch: 19, Loss: 0.5229403972625732, Accuracy: 0.8310546875\n",
      "Batch: 20, Loss: 0.4156903624534607, Accuracy: 0.86328125\n",
      "Batch: 21, Loss: 0.5390303730964661, Accuracy: 0.8291015625\n",
      "Batch: 22, Loss: 0.4666115343570709, Accuracy: 0.8505859375\n",
      "Batch: 23, Loss: 0.4748591184616089, Accuracy: 0.83984375\n",
      "Batch: 24, Loss: 0.4905939996242523, Accuracy: 0.8369140625\n",
      "Batch: 25, Loss: 0.46897104382514954, Accuracy: 0.84326171875\n",
      "Batch: 26, Loss: 0.4684121012687683, Accuracy: 0.845703125\n",
      "Batch: 27, Loss: 0.5055180191993713, Accuracy: 0.8330078125\n",
      "Batch: 28, Loss: 0.48609623312950134, Accuracy: 0.837890625\n",
      "Batch: 29, Loss: 0.536726176738739, Accuracy: 0.83203125\n",
      "Batch: 30, Loss: 0.5063236355781555, Accuracy: 0.8349609375\n",
      "Batch: 31, Loss: 0.5699163675308228, Accuracy: 0.82275390625\n",
      "Batch: 32, Loss: 0.5205944776535034, Accuracy: 0.8310546875\n",
      "Batch: 33, Loss: 0.5221247673034668, Accuracy: 0.8291015625\n",
      "Batch: 34, Loss: 0.5311110615730286, Accuracy: 0.83251953125\n",
      "Batch: 35, Loss: 0.5562894344329834, Accuracy: 0.81884765625\n",
      "Batch: 36, Loss: 0.5191468000411987, Accuracy: 0.828125\n",
      "Batch: 37, Loss: 0.569633960723877, Accuracy: 0.8056640625\n",
      "Batch: 38, Loss: 0.5497199296951294, Accuracy: 0.82373046875\n",
      "Batch: 39, Loss: 0.5031222105026245, Accuracy: 0.84033203125\n",
      "Batch: 40, Loss: 0.5585225820541382, Accuracy: 0.8056640625\n",
      "Batch: 41, Loss: 0.5399720668792725, Accuracy: 0.82763671875\n",
      "Batch: 42, Loss: 0.5091351270675659, Accuracy: 0.8310546875\n",
      "Batch: 43, Loss: 0.4738156199455261, Accuracy: 0.85546875\n",
      "Batch: 44, Loss: 0.45276734232902527, Accuracy: 0.85107421875\n",
      "Batch: 45, Loss: 0.5320584774017334, Accuracy: 0.82763671875\n",
      "Batch: 46, Loss: 0.4840579032897949, Accuracy: 0.8330078125\n",
      "Batch: 47, Loss: 0.5034980773925781, Accuracy: 0.837890625\n",
      "Batch: 48, Loss: 0.4906519651412964, Accuracy: 0.84521484375\n",
      "Batch: 49, Loss: 0.4919314682483673, Accuracy: 0.84375\n",
      "Batch: 50, Loss: 0.4865531921386719, Accuracy: 0.83935546875\n",
      "Batch: 51, Loss: 0.4993990957736969, Accuracy: 0.833984375\n",
      "Batch: 52, Loss: 0.4886605143547058, Accuracy: 0.83056640625\n",
      "Batch: 53, Loss: 0.526488184928894, Accuracy: 0.830078125\n",
      "Batch: 54, Loss: 0.5540579557418823, Accuracy: 0.8154296875\n",
      "Batch: 55, Loss: 0.5362244248390198, Accuracy: 0.81640625\n",
      "Batch: 56, Loss: 0.48234954476356506, Accuracy: 0.84033203125\n",
      "Batch: 57, Loss: 0.545172393321991, Accuracy: 0.8271484375\n",
      "Batch: 58, Loss: 0.5093059539794922, Accuracy: 0.830078125\n",
      "Batch: 59, Loss: 0.5902872085571289, Accuracy: 0.81640625\n",
      "Batch: 60, Loss: 0.4838300347328186, Accuracy: 0.841796875\n",
      "Batch: 61, Loss: 0.47983789443969727, Accuracy: 0.84228515625\n",
      "Batch: 62, Loss: 0.5066473484039307, Accuracy: 0.83251953125\n",
      "Batch: 63, Loss: 0.5041391253471375, Accuracy: 0.830078125\n",
      "Batch: 64, Loss: 0.5299919247627258, Accuracy: 0.830078125\n",
      "Batch: 65, Loss: 0.5403918027877808, Accuracy: 0.830078125\n",
      "Batch: 66, Loss: 0.5170530080795288, Accuracy: 0.83203125\n",
      "Batch: 67, Loss: 0.52593994140625, Accuracy: 0.82470703125\n",
      "Batch: 68, Loss: 0.4655073881149292, Accuracy: 0.83837890625\n",
      "Batch: 69, Loss: 0.5026869177818298, Accuracy: 0.83740234375\n",
      "Batch: 70, Loss: 0.4549095332622528, Accuracy: 0.8505859375\n",
      "Batch: 71, Loss: 0.4931419789791107, Accuracy: 0.8359375\n",
      "Batch: 72, Loss: 0.5470272302627563, Accuracy: 0.8193359375\n",
      "Batch: 73, Loss: 0.4947632849216461, Accuracy: 0.83544921875\n",
      "Batch: 74, Loss: 0.5140495300292969, Accuracy: 0.833984375\n",
      "Batch: 75, Loss: 0.46374496817588806, Accuracy: 0.8525390625\n",
      "Batch: 76, Loss: 0.463763028383255, Accuracy: 0.8486328125\n",
      "Batch: 77, Loss: 0.47284430265426636, Accuracy: 0.8505859375\n",
      "Batch: 78, Loss: 0.5181338787078857, Accuracy: 0.83544921875\n",
      "Batch: 79, Loss: 0.53742915391922, Accuracy: 0.82763671875\n",
      "Batch: 80, Loss: 0.5512729287147522, Accuracy: 0.83349609375\n",
      "Batch: 81, Loss: 0.5152479410171509, Accuracy: 0.84033203125\n",
      "Batch: 82, Loss: 0.478337824344635, Accuracy: 0.84375\n",
      "Batch: 83, Loss: 0.4609364867210388, Accuracy: 0.85400390625\n",
      "Batch: 84, Loss: 0.5038120746612549, Accuracy: 0.841796875\n",
      "Batch: 85, Loss: 0.5310813784599304, Accuracy: 0.822265625\n",
      "Batch: 86, Loss: 0.5722569823265076, Accuracy: 0.82373046875\n",
      "Batch: 87, Loss: 0.47825896739959717, Accuracy: 0.84765625\n",
      "Batch: 88, Loss: 0.5423846244812012, Accuracy: 0.8271484375\n",
      "Batch: 89, Loss: 0.4706876277923584, Accuracy: 0.8427734375\n",
      "Batch: 90, Loss: 0.5204219222068787, Accuracy: 0.826171875\n",
      "Batch: 91, Loss: 0.494051456451416, Accuracy: 0.83642578125\n",
      "Batch: 92, Loss: 0.5666254758834839, Accuracy: 0.81982421875\n",
      "Batch: 93, Loss: 0.5654839277267456, Accuracy: 0.82177734375\n",
      "Batch: 94, Loss: 0.5540642142295837, Accuracy: 0.81689453125\n",
      "Batch: 95, Loss: 0.5749558210372925, Accuracy: 0.82177734375\n",
      "Batch: 96, Loss: 0.5254756212234497, Accuracy: 0.82763671875\n",
      "Batch: 97, Loss: 0.5125105977058411, Accuracy: 0.8369140625\n",
      "Batch: 98, Loss: 0.5259349346160889, Accuracy: 0.83349609375\n",
      "Batch: 99, Loss: 0.49192187190055847, Accuracy: 0.8408203125\n",
      "Batch: 100, Loss: 0.5630966424942017, Accuracy: 0.822265625\n",
      "Batch: 101, Loss: 0.5625502467155457, Accuracy: 0.80810546875\n",
      "Batch: 102, Loss: 0.47836509346961975, Accuracy: 0.8505859375\n",
      "Batch: 103, Loss: 0.5333620309829712, Accuracy: 0.8349609375\n",
      "Batch: 104, Loss: 0.5020930767059326, Accuracy: 0.8369140625\n",
      "Batch: 105, Loss: 0.5170525312423706, Accuracy: 0.8310546875\n",
      "Batch: 106, Loss: 0.4812246561050415, Accuracy: 0.8427734375\n",
      "Batch: 107, Loss: 0.5439625978469849, Accuracy: 0.82568359375\n",
      "Batch: 108, Loss: 0.4995487332344055, Accuracy: 0.84033203125\n",
      "Batch: 109, Loss: 0.49852490425109863, Accuracy: 0.84033203125\n",
      "Batch: 110, Loss: 0.47151899337768555, Accuracy: 0.83935546875\n",
      "Batch: 111, Loss: 0.4681553840637207, Accuracy: 0.84326171875\n",
      "Batch: 112, Loss: 0.4950406849384308, Accuracy: 0.841796875\n",
      "Batch: 113, Loss: 0.5070904493331909, Accuracy: 0.830078125\n",
      "Batch: 114, Loss: 0.5040668249130249, Accuracy: 0.83984375\n",
      "Batch: 115, Loss: 0.48816561698913574, Accuracy: 0.83447265625\n",
      "Batch: 116, Loss: 0.4958302080631256, Accuracy: 0.841796875\n",
      "Batch: 117, Loss: 0.4672832787036896, Accuracy: 0.84130859375\n",
      "Batch: 118, Loss: 0.5074585676193237, Accuracy: 0.84619140625\n",
      "Batch: 119, Loss: 0.5076344013214111, Accuracy: 0.8251953125\n",
      "Batch: 120, Loss: 0.49334877729415894, Accuracy: 0.84375\n",
      "Batch: 121, Loss: 0.49344271421432495, Accuracy: 0.8291015625\n",
      "Batch: 122, Loss: 0.468441903591156, Accuracy: 0.85107421875\n",
      "Batch: 123, Loss: 0.47570738196372986, Accuracy: 0.85546875\n",
      "Batch: 124, Loss: 0.46565982699394226, Accuracy: 0.8486328125\n",
      "Batch: 125, Loss: 0.4878450930118561, Accuracy: 0.84326171875\n",
      "Batch: 126, Loss: 0.4915265738964081, Accuracy: 0.84033203125\n",
      "Batch: 127, Loss: 0.44530224800109863, Accuracy: 0.8525390625\n",
      "Batch: 128, Loss: 0.5190233588218689, Accuracy: 0.83447265625\n",
      "Batch: 129, Loss: 0.5418311953544617, Accuracy: 0.81787109375\n",
      "Batch: 130, Loss: 0.5963847637176514, Accuracy: 0.81103515625\n",
      "Batch: 131, Loss: 0.5014825463294983, Accuracy: 0.83984375\n",
      "Batch: 132, Loss: 0.4787546694278717, Accuracy: 0.8447265625\n",
      "Batch: 133, Loss: 0.4627284109592438, Accuracy: 0.8505859375\n",
      "Batch: 134, Loss: 0.4956361651420593, Accuracy: 0.841796875\n",
      "Batch: 135, Loss: 0.5326348543167114, Accuracy: 0.814453125\n",
      "Batch: 136, Loss: 0.4754233956336975, Accuracy: 0.84130859375\n",
      "Batch: 137, Loss: 0.510595977306366, Accuracy: 0.83642578125\n",
      "Batch: 138, Loss: 0.47260603308677673, Accuracy: 0.845703125\n",
      "Batch: 139, Loss: 0.4907025098800659, Accuracy: 0.83984375\n",
      "Batch: 140, Loss: 0.45570823550224304, Accuracy: 0.8486328125\n",
      "Batch: 141, Loss: 0.5210220813751221, Accuracy: 0.8330078125\n",
      "Batch: 142, Loss: 0.45174556970596313, Accuracy: 0.8466796875\n",
      "Batch: 143, Loss: 0.45441174507141113, Accuracy: 0.85498046875\n",
      "Batch: 144, Loss: 0.5512222647666931, Accuracy: 0.8154296875\n",
      "Batch: 145, Loss: 0.5269314646720886, Accuracy: 0.83056640625\n",
      "Batch: 146, Loss: 0.520560622215271, Accuracy: 0.82958984375\n",
      "Batch: 147, Loss: 0.5064482688903809, Accuracy: 0.84228515625\n",
      "Batch: 148, Loss: 0.5062792301177979, Accuracy: 0.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 149, Loss: 0.5048588514328003, Accuracy: 0.83056640625\n",
      "Batch: 150, Loss: 0.4689224362373352, Accuracy: 0.845703125\n",
      "Batch: 151, Loss: 0.4638559818267822, Accuracy: 0.85205078125\n",
      "Batch: 152, Loss: 0.47218215465545654, Accuracy: 0.85205078125\n",
      "Batch: 153, Loss: 0.49944639205932617, Accuracy: 0.83740234375\n",
      "Batch: 154, Loss: 0.510852575302124, Accuracy: 0.8271484375\n",
      "Batch: 155, Loss: 0.5385070443153381, Accuracy: 0.82666015625\n",
      "Batch: 156, Loss: 0.4489299952983856, Accuracy: 0.84716796875\n",
      "Batch: 157, Loss: 0.45563530921936035, Accuracy: 0.84619140625\n",
      "Batch: 158, Loss: 0.48838409781455994, Accuracy: 0.8447265625\n",
      "Batch: 159, Loss: 0.47864532470703125, Accuracy: 0.84033203125\n",
      "Batch: 160, Loss: 0.5118510723114014, Accuracy: 0.83984375\n",
      "Batch: 161, Loss: 0.5187167525291443, Accuracy: 0.8193359375\n",
      "Batch: 162, Loss: 0.4874407947063446, Accuracy: 0.84716796875\n",
      "Batch: 163, Loss: 0.5132191777229309, Accuracy: 0.837890625\n",
      "Batch: 164, Loss: 0.5567678213119507, Accuracy: 0.81884765625\n",
      "Batch: 165, Loss: 0.5185143947601318, Accuracy: 0.84228515625\n",
      "Batch: 166, Loss: 0.5103878974914551, Accuracy: 0.83203125\n",
      "Batch: 167, Loss: 0.4870045781135559, Accuracy: 0.84033203125\n",
      "Batch: 168, Loss: 0.4880297780036926, Accuracy: 0.84033203125\n",
      "Batch: 169, Loss: 0.5025213360786438, Accuracy: 0.83349609375\n",
      "Batch: 170, Loss: 0.5284091234207153, Accuracy: 0.830078125\n",
      "Batch: 171, Loss: 0.5016295313835144, Accuracy: 0.8291015625\n",
      "Batch: 172, Loss: 0.48202192783355713, Accuracy: 0.8388671875\n",
      "Batch: 173, Loss: 0.5406947135925293, Accuracy: 0.8251953125\n",
      "Batch: 174, Loss: 0.4556422829627991, Accuracy: 0.84912109375\n",
      "Batch: 175, Loss: 0.5168653726577759, Accuracy: 0.826171875\n",
      "Batch: 176, Loss: 0.5420739650726318, Accuracy: 0.826171875\n",
      "Batch: 177, Loss: 0.5037011504173279, Accuracy: 0.8369140625\n",
      "Batch: 178, Loss: 0.48870792984962463, Accuracy: 0.83740234375\n",
      "Batch: 179, Loss: 0.4989047646522522, Accuracy: 0.84912109375\n",
      "Batch: 180, Loss: 0.5337092280387878, Accuracy: 0.8310546875\n",
      "Epoch 92/200\n",
      "Batch: 1, Loss: 0.7305267453193665, Accuracy: 0.7890625\n",
      "Batch: 2, Loss: 0.5020301342010498, Accuracy: 0.83203125\n",
      "Batch: 3, Loss: 0.495267391204834, Accuracy: 0.84130859375\n",
      "Batch: 4, Loss: 0.5270832777023315, Accuracy: 0.822265625\n",
      "Batch: 5, Loss: 0.4900348484516144, Accuracy: 0.84423828125\n",
      "Batch: 6, Loss: 0.5113703608512878, Accuracy: 0.8291015625\n",
      "Batch: 7, Loss: 0.4922848045825958, Accuracy: 0.84765625\n",
      "Batch: 8, Loss: 0.48591819405555725, Accuracy: 0.8466796875\n",
      "Batch: 9, Loss: 0.5159715414047241, Accuracy: 0.83349609375\n",
      "Batch: 10, Loss: 0.4798187017440796, Accuracy: 0.8408203125\n",
      "Batch: 11, Loss: 0.5401597023010254, Accuracy: 0.82421875\n",
      "Batch: 12, Loss: 0.45456308126449585, Accuracy: 0.849609375\n",
      "Batch: 13, Loss: 0.49839097261428833, Accuracy: 0.8486328125\n",
      "Batch: 14, Loss: 0.4935859441757202, Accuracy: 0.8369140625\n",
      "Batch: 15, Loss: 0.4930685758590698, Accuracy: 0.84423828125\n",
      "Batch: 16, Loss: 0.5359725952148438, Accuracy: 0.833984375\n",
      "Batch: 17, Loss: 0.4805658459663391, Accuracy: 0.8447265625\n",
      "Batch: 18, Loss: 0.5281330943107605, Accuracy: 0.83203125\n",
      "Batch: 19, Loss: 0.5112359523773193, Accuracy: 0.84228515625\n",
      "Batch: 20, Loss: 0.4293968677520752, Accuracy: 0.86572265625\n",
      "Batch: 21, Loss: 0.49452105164527893, Accuracy: 0.83984375\n",
      "Batch: 22, Loss: 0.4870758652687073, Accuracy: 0.83984375\n",
      "Batch: 23, Loss: 0.4596397578716278, Accuracy: 0.84716796875\n",
      "Batch: 24, Loss: 0.5089925527572632, Accuracy: 0.83642578125\n",
      "Batch: 25, Loss: 0.4789159893989563, Accuracy: 0.853515625\n",
      "Batch: 26, Loss: 0.4944987893104553, Accuracy: 0.8388671875\n",
      "Batch: 27, Loss: 0.548211932182312, Accuracy: 0.83154296875\n",
      "Batch: 28, Loss: 0.48755234479904175, Accuracy: 0.84716796875\n",
      "Batch: 29, Loss: 0.5281264781951904, Accuracy: 0.83154296875\n",
      "Batch: 30, Loss: 0.5124605298042297, Accuracy: 0.8388671875\n",
      "Batch: 31, Loss: 0.5636729001998901, Accuracy: 0.81689453125\n",
      "Batch: 32, Loss: 0.5379544496536255, Accuracy: 0.8232421875\n",
      "Batch: 33, Loss: 0.49445390701293945, Accuracy: 0.8369140625\n",
      "Batch: 34, Loss: 0.5242784023284912, Accuracy: 0.8291015625\n",
      "Batch: 35, Loss: 0.5475363731384277, Accuracy: 0.8271484375\n",
      "Batch: 36, Loss: 0.5258673429489136, Accuracy: 0.837890625\n",
      "Batch: 37, Loss: 0.5696640014648438, Accuracy: 0.81494140625\n",
      "Batch: 38, Loss: 0.5447925925254822, Accuracy: 0.82666015625\n",
      "Batch: 39, Loss: 0.5085868239402771, Accuracy: 0.83935546875\n",
      "Batch: 40, Loss: 0.5615040063858032, Accuracy: 0.81005859375\n",
      "Batch: 41, Loss: 0.5335166454315186, Accuracy: 0.81298828125\n",
      "Batch: 42, Loss: 0.5150564908981323, Accuracy: 0.82666015625\n",
      "Batch: 43, Loss: 0.48603859543800354, Accuracy: 0.85205078125\n",
      "Batch: 44, Loss: 0.45436573028564453, Accuracy: 0.86181640625\n",
      "Batch: 45, Loss: 0.5087192058563232, Accuracy: 0.8330078125\n",
      "Batch: 46, Loss: 0.47821879386901855, Accuracy: 0.837890625\n",
      "Batch: 47, Loss: 0.4927203059196472, Accuracy: 0.84521484375\n",
      "Batch: 48, Loss: 0.506009578704834, Accuracy: 0.83984375\n",
      "Batch: 49, Loss: 0.4954032599925995, Accuracy: 0.83984375\n",
      "Batch: 50, Loss: 0.5088032484054565, Accuracy: 0.830078125\n",
      "Batch: 51, Loss: 0.5012871026992798, Accuracy: 0.8349609375\n",
      "Batch: 52, Loss: 0.5037033557891846, Accuracy: 0.833984375\n",
      "Batch: 53, Loss: 0.5250293016433716, Accuracy: 0.83544921875\n",
      "Batch: 54, Loss: 0.5383673906326294, Accuracy: 0.82666015625\n",
      "Batch: 55, Loss: 0.5211460590362549, Accuracy: 0.82861328125\n",
      "Batch: 56, Loss: 0.4766238331794739, Accuracy: 0.8388671875\n",
      "Batch: 57, Loss: 0.5598491430282593, Accuracy: 0.81640625\n",
      "Batch: 58, Loss: 0.5138452053070068, Accuracy: 0.83740234375\n",
      "Batch: 59, Loss: 0.5959981679916382, Accuracy: 0.8095703125\n",
      "Batch: 60, Loss: 0.5011487603187561, Accuracy: 0.8427734375\n",
      "Batch: 61, Loss: 0.48795652389526367, Accuracy: 0.84375\n",
      "Batch: 62, Loss: 0.49637889862060547, Accuracy: 0.833984375\n",
      "Batch: 63, Loss: 0.49270904064178467, Accuracy: 0.83447265625\n",
      "Batch: 64, Loss: 0.5162565112113953, Accuracy: 0.83203125\n",
      "Batch: 65, Loss: 0.5227283835411072, Accuracy: 0.83837890625\n",
      "Batch: 66, Loss: 0.4832373559474945, Accuracy: 0.84228515625\n",
      "Batch: 67, Loss: 0.537116289138794, Accuracy: 0.82275390625\n",
      "Batch: 68, Loss: 0.46432989835739136, Accuracy: 0.8515625\n",
      "Batch: 69, Loss: 0.4962082505226135, Accuracy: 0.826171875\n",
      "Batch: 70, Loss: 0.4755069613456726, Accuracy: 0.84423828125\n",
      "Batch: 71, Loss: 0.48289746046066284, Accuracy: 0.830078125\n",
      "Batch: 72, Loss: 0.5399714112281799, Accuracy: 0.81298828125\n",
      "Batch: 73, Loss: 0.5317096710205078, Accuracy: 0.82421875\n",
      "Batch: 74, Loss: 0.5154759883880615, Accuracy: 0.8388671875\n",
      "Batch: 75, Loss: 0.46918612718582153, Accuracy: 0.84130859375\n",
      "Batch: 76, Loss: 0.4596790075302124, Accuracy: 0.85498046875\n",
      "Batch: 77, Loss: 0.4687594771385193, Accuracy: 0.8525390625\n",
      "Batch: 78, Loss: 0.49511560797691345, Accuracy: 0.84326171875\n",
      "Batch: 79, Loss: 0.5010969638824463, Accuracy: 0.841796875\n",
      "Batch: 80, Loss: 0.5202888250350952, Accuracy: 0.8349609375\n",
      "Batch: 81, Loss: 0.4991741478443146, Accuracy: 0.84033203125\n",
      "Batch: 82, Loss: 0.49756166338920593, Accuracy: 0.83984375\n",
      "Batch: 83, Loss: 0.459250807762146, Accuracy: 0.8515625\n",
      "Batch: 84, Loss: 0.49269604682922363, Accuracy: 0.84033203125\n",
      "Batch: 85, Loss: 0.5268559455871582, Accuracy: 0.83203125\n",
      "Batch: 86, Loss: 0.5461641550064087, Accuracy: 0.8310546875\n",
      "Batch: 87, Loss: 0.4794251322746277, Accuracy: 0.84765625\n",
      "Batch: 88, Loss: 0.5353063344955444, Accuracy: 0.83447265625\n",
      "Batch: 89, Loss: 0.4564237594604492, Accuracy: 0.85205078125\n",
      "Batch: 90, Loss: 0.5131433010101318, Accuracy: 0.83251953125\n",
      "Batch: 91, Loss: 0.49054867029190063, Accuracy: 0.84326171875\n",
      "Batch: 92, Loss: 0.5599422454833984, Accuracy: 0.80859375\n",
      "Batch: 93, Loss: 0.5484679937362671, Accuracy: 0.8193359375\n",
      "Batch: 94, Loss: 0.5454756021499634, Accuracy: 0.82861328125\n",
      "Batch: 95, Loss: 0.5578319430351257, Accuracy: 0.81640625\n",
      "Batch: 96, Loss: 0.5405926704406738, Accuracy: 0.83447265625\n",
      "Batch: 97, Loss: 0.4978613555431366, Accuracy: 0.845703125\n",
      "Batch: 98, Loss: 0.49669378995895386, Accuracy: 0.83837890625\n",
      "Batch: 99, Loss: 0.4747268557548523, Accuracy: 0.83740234375\n",
      "Batch: 100, Loss: 0.5337569117546082, Accuracy: 0.830078125\n",
      "Batch: 101, Loss: 0.546763002872467, Accuracy: 0.826171875\n",
      "Batch: 102, Loss: 0.4655812382698059, Accuracy: 0.8505859375\n",
      "Batch: 103, Loss: 0.5019031763076782, Accuracy: 0.83349609375\n",
      "Batch: 104, Loss: 0.4834211468696594, Accuracy: 0.8466796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 105, Loss: 0.5186488032341003, Accuracy: 0.8330078125\n",
      "Batch: 106, Loss: 0.47979918122291565, Accuracy: 0.85107421875\n",
      "Batch: 107, Loss: 0.5297552347183228, Accuracy: 0.83203125\n",
      "Batch: 108, Loss: 0.4774675965309143, Accuracy: 0.83740234375\n",
      "Batch: 109, Loss: 0.47682565450668335, Accuracy: 0.84912109375\n",
      "Batch: 110, Loss: 0.48561418056488037, Accuracy: 0.84375\n",
      "Batch: 111, Loss: 0.4584638476371765, Accuracy: 0.84912109375\n",
      "Batch: 112, Loss: 0.4724958539009094, Accuracy: 0.84423828125\n",
      "Batch: 113, Loss: 0.511836051940918, Accuracy: 0.82861328125\n",
      "Batch: 114, Loss: 0.513198733329773, Accuracy: 0.83642578125\n",
      "Batch: 115, Loss: 0.5016562938690186, Accuracy: 0.8369140625\n",
      "Batch: 116, Loss: 0.48761820793151855, Accuracy: 0.84619140625\n",
      "Batch: 117, Loss: 0.4845508635044098, Accuracy: 0.8369140625\n",
      "Batch: 118, Loss: 0.49852293729782104, Accuracy: 0.83935546875\n",
      "Batch: 119, Loss: 0.48707297444343567, Accuracy: 0.845703125\n",
      "Batch: 120, Loss: 0.45815324783325195, Accuracy: 0.8583984375\n",
      "Batch: 121, Loss: 0.4734119176864624, Accuracy: 0.84375\n",
      "Batch: 122, Loss: 0.4561580419540405, Accuracy: 0.85693359375\n",
      "Batch: 123, Loss: 0.47148141264915466, Accuracy: 0.849609375\n",
      "Batch: 124, Loss: 0.43900322914123535, Accuracy: 0.85009765625\n",
      "Batch: 125, Loss: 0.48714399337768555, Accuracy: 0.84326171875\n",
      "Batch: 126, Loss: 0.49360209703445435, Accuracy: 0.84423828125\n",
      "Batch: 127, Loss: 0.4658728837966919, Accuracy: 0.8544921875\n",
      "Batch: 128, Loss: 0.5497480034828186, Accuracy: 0.82421875\n",
      "Batch: 129, Loss: 0.5903104543685913, Accuracy: 0.8212890625\n",
      "Batch: 130, Loss: 0.5676502585411072, Accuracy: 0.81591796875\n",
      "Batch: 131, Loss: 0.5206617116928101, Accuracy: 0.8369140625\n",
      "Batch: 132, Loss: 0.4856954514980316, Accuracy: 0.84423828125\n",
      "Batch: 133, Loss: 0.46974119544029236, Accuracy: 0.8515625\n",
      "Batch: 134, Loss: 0.5430864095687866, Accuracy: 0.82763671875\n",
      "Batch: 135, Loss: 0.5145704746246338, Accuracy: 0.8291015625\n",
      "Batch: 136, Loss: 0.49644792079925537, Accuracy: 0.841796875\n",
      "Batch: 137, Loss: 0.5121819972991943, Accuracy: 0.833984375\n",
      "Batch: 138, Loss: 0.47900694608688354, Accuracy: 0.8515625\n",
      "Batch: 139, Loss: 0.4970131516456604, Accuracy: 0.8271484375\n",
      "Batch: 140, Loss: 0.43779832124710083, Accuracy: 0.857421875\n",
      "Batch: 141, Loss: 0.5120619535446167, Accuracy: 0.8232421875\n",
      "Batch: 142, Loss: 0.4606415629386902, Accuracy: 0.84521484375\n",
      "Batch: 143, Loss: 0.48488539457321167, Accuracy: 0.85009765625\n",
      "Batch: 144, Loss: 0.5369260311126709, Accuracy: 0.8271484375\n",
      "Batch: 145, Loss: 0.5131041407585144, Accuracy: 0.83154296875\n",
      "Batch: 146, Loss: 0.5296851992607117, Accuracy: 0.82470703125\n",
      "Batch: 147, Loss: 0.4787977337837219, Accuracy: 0.83984375\n",
      "Batch: 148, Loss: 0.5112149119377136, Accuracy: 0.8251953125\n",
      "Batch: 149, Loss: 0.5358240604400635, Accuracy: 0.81396484375\n",
      "Batch: 150, Loss: 0.4462447762489319, Accuracy: 0.853515625\n",
      "Batch: 151, Loss: 0.4696771800518036, Accuracy: 0.84619140625\n",
      "Batch: 152, Loss: 0.46596434712409973, Accuracy: 0.85205078125\n",
      "Batch: 153, Loss: 0.5093151330947876, Accuracy: 0.833984375\n",
      "Batch: 154, Loss: 0.4956497550010681, Accuracy: 0.84130859375\n",
      "Batch: 155, Loss: 0.5450081825256348, Accuracy: 0.82373046875\n",
      "Batch: 156, Loss: 0.45045366883277893, Accuracy: 0.8447265625\n",
      "Batch: 157, Loss: 0.45458802580833435, Accuracy: 0.85205078125\n",
      "Batch: 158, Loss: 0.4913922846317291, Accuracy: 0.8486328125\n",
      "Batch: 159, Loss: 0.504039466381073, Accuracy: 0.83251953125\n",
      "Batch: 160, Loss: 0.514298677444458, Accuracy: 0.83837890625\n",
      "Batch: 161, Loss: 0.5062460899353027, Accuracy: 0.841796875\n",
      "Batch: 162, Loss: 0.47919130325317383, Accuracy: 0.84423828125\n",
      "Batch: 163, Loss: 0.49716901779174805, Accuracy: 0.83056640625\n",
      "Batch: 164, Loss: 0.553855299949646, Accuracy: 0.82568359375\n",
      "Batch: 165, Loss: 0.48248887062072754, Accuracy: 0.84619140625\n",
      "Batch: 166, Loss: 0.5118541121482849, Accuracy: 0.83837890625\n",
      "Batch: 167, Loss: 0.5016548037528992, Accuracy: 0.841796875\n",
      "Batch: 168, Loss: 0.45495161414146423, Accuracy: 0.86376953125\n",
      "Batch: 169, Loss: 0.5126134157180786, Accuracy: 0.83251953125\n",
      "Batch: 170, Loss: 0.5263530015945435, Accuracy: 0.8271484375\n",
      "Batch: 171, Loss: 0.4798206686973572, Accuracy: 0.841796875\n",
      "Batch: 172, Loss: 0.46236273646354675, Accuracy: 0.84716796875\n",
      "Batch: 173, Loss: 0.5464888215065002, Accuracy: 0.81640625\n",
      "Batch: 174, Loss: 0.4277956485748291, Accuracy: 0.8564453125\n",
      "Batch: 175, Loss: 0.5173816084861755, Accuracy: 0.81591796875\n",
      "Batch: 176, Loss: 0.529674768447876, Accuracy: 0.82568359375\n",
      "Batch: 177, Loss: 0.5039271712303162, Accuracy: 0.845703125\n",
      "Batch: 178, Loss: 0.4744555354118347, Accuracy: 0.845703125\n",
      "Batch: 179, Loss: 0.5073550939559937, Accuracy: 0.84033203125\n",
      "Batch: 180, Loss: 0.4967617094516754, Accuracy: 0.83203125\n",
      "Epoch 93/200\n",
      "Batch: 1, Loss: 0.7449751496315002, Accuracy: 0.7890625\n",
      "Batch: 2, Loss: 0.5103954672813416, Accuracy: 0.833984375\n",
      "Batch: 3, Loss: 0.49106088280677795, Accuracy: 0.84033203125\n",
      "Batch: 4, Loss: 0.5261770486831665, Accuracy: 0.8291015625\n",
      "Batch: 5, Loss: 0.5186810493469238, Accuracy: 0.83740234375\n",
      "Batch: 6, Loss: 0.5157084465026855, Accuracy: 0.828125\n",
      "Batch: 7, Loss: 0.5051487684249878, Accuracy: 0.84130859375\n",
      "Batch: 8, Loss: 0.49127092957496643, Accuracy: 0.8388671875\n",
      "Batch: 9, Loss: 0.5230818390846252, Accuracy: 0.8330078125\n",
      "Batch: 10, Loss: 0.481980562210083, Accuracy: 0.84375\n",
      "Batch: 11, Loss: 0.5185009837150574, Accuracy: 0.83056640625\n",
      "Batch: 12, Loss: 0.4547489881515503, Accuracy: 0.8544921875\n",
      "Batch: 13, Loss: 0.4898796081542969, Accuracy: 0.83544921875\n",
      "Batch: 14, Loss: 0.49084872007369995, Accuracy: 0.8466796875\n",
      "Batch: 15, Loss: 0.5170454978942871, Accuracy: 0.83349609375\n",
      "Batch: 16, Loss: 0.5400839447975159, Accuracy: 0.82666015625\n",
      "Batch: 17, Loss: 0.48726099729537964, Accuracy: 0.83935546875\n",
      "Batch: 18, Loss: 0.5229958295822144, Accuracy: 0.8359375\n",
      "Batch: 19, Loss: 0.5252894163131714, Accuracy: 0.8349609375\n",
      "Batch: 20, Loss: 0.42508310079574585, Accuracy: 0.86767578125\n",
      "Batch: 21, Loss: 0.4893282651901245, Accuracy: 0.8447265625\n",
      "Batch: 22, Loss: 0.456184446811676, Accuracy: 0.8505859375\n",
      "Batch: 23, Loss: 0.46486696600914, Accuracy: 0.8408203125\n",
      "Batch: 24, Loss: 0.5074722766876221, Accuracy: 0.8330078125\n",
      "Batch: 25, Loss: 0.47007516026496887, Accuracy: 0.85302734375\n",
      "Batch: 26, Loss: 0.4639524519443512, Accuracy: 0.8447265625\n",
      "Batch: 27, Loss: 0.5156645774841309, Accuracy: 0.82958984375\n",
      "Batch: 28, Loss: 0.48782846331596375, Accuracy: 0.8388671875\n",
      "Batch: 29, Loss: 0.5359203815460205, Accuracy: 0.82275390625\n",
      "Batch: 30, Loss: 0.5048051476478577, Accuracy: 0.828125\n",
      "Batch: 31, Loss: 0.5450459718704224, Accuracy: 0.82666015625\n",
      "Batch: 32, Loss: 0.5366990566253662, Accuracy: 0.82763671875\n",
      "Batch: 33, Loss: 0.5168972015380859, Accuracy: 0.82763671875\n",
      "Batch: 34, Loss: 0.5325371623039246, Accuracy: 0.8271484375\n",
      "Batch: 35, Loss: 0.557212769985199, Accuracy: 0.814453125\n",
      "Batch: 36, Loss: 0.4970102906227112, Accuracy: 0.8369140625\n",
      "Batch: 37, Loss: 0.562279224395752, Accuracy: 0.81640625\n",
      "Batch: 38, Loss: 0.533888578414917, Accuracy: 0.8291015625\n",
      "Batch: 39, Loss: 0.49890050292015076, Accuracy: 0.83984375\n",
      "Batch: 40, Loss: 0.5589469075202942, Accuracy: 0.8173828125\n",
      "Batch: 41, Loss: 0.5386538505554199, Accuracy: 0.81884765625\n",
      "Batch: 42, Loss: 0.5069822072982788, Accuracy: 0.83447265625\n",
      "Batch: 43, Loss: 0.4778342843055725, Accuracy: 0.849609375\n",
      "Batch: 44, Loss: 0.47608646750450134, Accuracy: 0.84814453125\n",
      "Batch: 45, Loss: 0.5074801445007324, Accuracy: 0.83349609375\n",
      "Batch: 46, Loss: 0.4814002513885498, Accuracy: 0.83837890625\n",
      "Batch: 47, Loss: 0.48688462376594543, Accuracy: 0.8447265625\n",
      "Batch: 48, Loss: 0.5012643933296204, Accuracy: 0.8388671875\n",
      "Batch: 49, Loss: 0.4946644902229309, Accuracy: 0.8369140625\n",
      "Batch: 50, Loss: 0.5153325796127319, Accuracy: 0.8369140625\n",
      "Batch: 51, Loss: 0.5027557611465454, Accuracy: 0.833984375\n",
      "Batch: 52, Loss: 0.49830302596092224, Accuracy: 0.83251953125\n",
      "Batch: 53, Loss: 0.48681849241256714, Accuracy: 0.8505859375\n",
      "Batch: 54, Loss: 0.5318291187286377, Accuracy: 0.82421875\n",
      "Batch: 55, Loss: 0.5302920341491699, Accuracy: 0.82861328125\n",
      "Batch: 56, Loss: 0.47931230068206787, Accuracy: 0.84765625\n",
      "Batch: 57, Loss: 0.5443524122238159, Accuracy: 0.8271484375\n",
      "Batch: 58, Loss: 0.520621657371521, Accuracy: 0.83154296875\n",
      "Batch: 59, Loss: 0.5973510146141052, Accuracy: 0.8154296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 60, Loss: 0.5107275247573853, Accuracy: 0.837890625\n",
      "Batch: 61, Loss: 0.4834749698638916, Accuracy: 0.8349609375\n",
      "Batch: 62, Loss: 0.5019089579582214, Accuracy: 0.84033203125\n",
      "Batch: 63, Loss: 0.5044670104980469, Accuracy: 0.82763671875\n",
      "Batch: 64, Loss: 0.5232241153717041, Accuracy: 0.8251953125\n",
      "Batch: 65, Loss: 0.5333418250083923, Accuracy: 0.8212890625\n",
      "Batch: 66, Loss: 0.5083327293395996, Accuracy: 0.830078125\n",
      "Batch: 67, Loss: 0.546745777130127, Accuracy: 0.8291015625\n",
      "Batch: 68, Loss: 0.48843640089035034, Accuracy: 0.84375\n",
      "Batch: 69, Loss: 0.49430423974990845, Accuracy: 0.83837890625\n",
      "Batch: 70, Loss: 0.4578808546066284, Accuracy: 0.85302734375\n",
      "Batch: 71, Loss: 0.48074454069137573, Accuracy: 0.83544921875\n",
      "Batch: 72, Loss: 0.5353391170501709, Accuracy: 0.81689453125\n",
      "Batch: 73, Loss: 0.508796215057373, Accuracy: 0.83740234375\n",
      "Batch: 74, Loss: 0.5269212126731873, Accuracy: 0.830078125\n",
      "Batch: 75, Loss: 0.4822208285331726, Accuracy: 0.83642578125\n",
      "Batch: 76, Loss: 0.4853021502494812, Accuracy: 0.84521484375\n",
      "Batch: 77, Loss: 0.4787834584712982, Accuracy: 0.84716796875\n",
      "Batch: 78, Loss: 0.5172792673110962, Accuracy: 0.84326171875\n",
      "Batch: 79, Loss: 0.5185465812683105, Accuracy: 0.82568359375\n",
      "Batch: 80, Loss: 0.5439117550849915, Accuracy: 0.828125\n",
      "Batch: 81, Loss: 0.5144422054290771, Accuracy: 0.841796875\n",
      "Batch: 82, Loss: 0.4968119263648987, Accuracy: 0.8349609375\n",
      "Batch: 83, Loss: 0.46211934089660645, Accuracy: 0.84814453125\n",
      "Batch: 84, Loss: 0.49686843156814575, Accuracy: 0.83984375\n",
      "Batch: 85, Loss: 0.5131645798683167, Accuracy: 0.82958984375\n",
      "Batch: 86, Loss: 0.5159112215042114, Accuracy: 0.8427734375\n",
      "Batch: 87, Loss: 0.46663331985473633, Accuracy: 0.84912109375\n",
      "Batch: 88, Loss: 0.5065088868141174, Accuracy: 0.84375\n",
      "Batch: 89, Loss: 0.4923151135444641, Accuracy: 0.83984375\n",
      "Batch: 90, Loss: 0.5078246593475342, Accuracy: 0.828125\n",
      "Batch: 91, Loss: 0.4995182454586029, Accuracy: 0.83447265625\n",
      "Batch: 92, Loss: 0.5799715518951416, Accuracy: 0.80029296875\n",
      "Batch: 93, Loss: 0.5767883062362671, Accuracy: 0.80615234375\n",
      "Batch: 94, Loss: 0.5463609099388123, Accuracy: 0.81689453125\n",
      "Batch: 95, Loss: 0.5565390586853027, Accuracy: 0.81982421875\n",
      "Batch: 96, Loss: 0.5157769918441772, Accuracy: 0.83056640625\n",
      "Batch: 97, Loss: 0.4935283362865448, Accuracy: 0.841796875\n",
      "Batch: 98, Loss: 0.5052489638328552, Accuracy: 0.82763671875\n",
      "Batch: 99, Loss: 0.48885592818260193, Accuracy: 0.8427734375\n",
      "Batch: 100, Loss: 0.5649019479751587, Accuracy: 0.81787109375\n",
      "Batch: 101, Loss: 0.5384922027587891, Accuracy: 0.82470703125\n",
      "Batch: 102, Loss: 0.4798462986946106, Accuracy: 0.84912109375\n",
      "Batch: 103, Loss: 0.5052632093429565, Accuracy: 0.8310546875\n",
      "Batch: 104, Loss: 0.49745088815689087, Accuracy: 0.83251953125\n",
      "Batch: 105, Loss: 0.5142664909362793, Accuracy: 0.84130859375\n",
      "Batch: 106, Loss: 0.47599807381629944, Accuracy: 0.85107421875\n",
      "Batch: 107, Loss: 0.5107359886169434, Accuracy: 0.84423828125\n",
      "Batch: 108, Loss: 0.48674511909484863, Accuracy: 0.8408203125\n",
      "Batch: 109, Loss: 0.46262943744659424, Accuracy: 0.8544921875\n",
      "Batch: 110, Loss: 0.48888176679611206, Accuracy: 0.8447265625\n",
      "Batch: 111, Loss: 0.4826863408088684, Accuracy: 0.8427734375\n",
      "Batch: 112, Loss: 0.4876576066017151, Accuracy: 0.8427734375\n",
      "Batch: 113, Loss: 0.5154336094856262, Accuracy: 0.82958984375\n",
      "Batch: 114, Loss: 0.502361536026001, Accuracy: 0.84033203125\n",
      "Batch: 115, Loss: 0.4952210485935211, Accuracy: 0.8408203125\n",
      "Batch: 116, Loss: 0.48775312304496765, Accuracy: 0.83203125\n",
      "Batch: 117, Loss: 0.4657655358314514, Accuracy: 0.84326171875\n",
      "Batch: 118, Loss: 0.49463117122650146, Accuracy: 0.84423828125\n",
      "Batch: 119, Loss: 0.4718746244907379, Accuracy: 0.84619140625\n",
      "Batch: 120, Loss: 0.4822845458984375, Accuracy: 0.84765625\n",
      "Batch: 121, Loss: 0.48954153060913086, Accuracy: 0.84716796875\n",
      "Batch: 122, Loss: 0.4689473509788513, Accuracy: 0.84130859375\n",
      "Batch: 123, Loss: 0.46130454540252686, Accuracy: 0.853515625\n",
      "Batch: 124, Loss: 0.4462991952896118, Accuracy: 0.84912109375\n",
      "Batch: 125, Loss: 0.49979230761528015, Accuracy: 0.8427734375\n",
      "Batch: 126, Loss: 0.4815196096897125, Accuracy: 0.83837890625\n",
      "Batch: 127, Loss: 0.4492650628089905, Accuracy: 0.8544921875\n",
      "Batch: 128, Loss: 0.5481218695640564, Accuracy: 0.82080078125\n",
      "Batch: 129, Loss: 0.5489180088043213, Accuracy: 0.822265625\n",
      "Batch: 130, Loss: 0.5651775002479553, Accuracy: 0.81689453125\n",
      "Batch: 131, Loss: 0.5123882293701172, Accuracy: 0.828125\n",
      "Batch: 132, Loss: 0.47097983956336975, Accuracy: 0.8466796875\n",
      "Batch: 133, Loss: 0.47869405150413513, Accuracy: 0.84423828125\n",
      "Batch: 134, Loss: 0.5113897919654846, Accuracy: 0.8310546875\n",
      "Batch: 135, Loss: 0.5030649900436401, Accuracy: 0.83544921875\n",
      "Batch: 136, Loss: 0.46854737401008606, Accuracy: 0.84716796875\n",
      "Batch: 137, Loss: 0.49727293848991394, Accuracy: 0.83837890625\n",
      "Batch: 138, Loss: 0.4701661467552185, Accuracy: 0.85302734375\n",
      "Batch: 139, Loss: 0.48649969696998596, Accuracy: 0.84130859375\n",
      "Batch: 140, Loss: 0.43525388836860657, Accuracy: 0.85205078125\n",
      "Batch: 141, Loss: 0.5018671751022339, Accuracy: 0.83544921875\n",
      "Batch: 142, Loss: 0.4589385688304901, Accuracy: 0.84375\n",
      "Batch: 143, Loss: 0.4688519537448883, Accuracy: 0.84521484375\n",
      "Batch: 144, Loss: 0.5464673042297363, Accuracy: 0.82470703125\n",
      "Batch: 145, Loss: 0.5130375623703003, Accuracy: 0.8388671875\n",
      "Batch: 146, Loss: 0.509199321269989, Accuracy: 0.8447265625\n",
      "Batch: 147, Loss: 0.4990186095237732, Accuracy: 0.8330078125\n",
      "Batch: 148, Loss: 0.5366811156272888, Accuracy: 0.81689453125\n",
      "Batch: 149, Loss: 0.5125820636749268, Accuracy: 0.82421875\n",
      "Batch: 150, Loss: 0.4323294162750244, Accuracy: 0.85595703125\n",
      "Batch: 151, Loss: 0.4470037817955017, Accuracy: 0.857421875\n",
      "Batch: 152, Loss: 0.47342705726623535, Accuracy: 0.8447265625\n",
      "Batch: 153, Loss: 0.503652811050415, Accuracy: 0.830078125\n",
      "Batch: 154, Loss: 0.4970710575580597, Accuracy: 0.83935546875\n",
      "Batch: 155, Loss: 0.5496503114700317, Accuracy: 0.8232421875\n",
      "Batch: 156, Loss: 0.4520770311355591, Accuracy: 0.8515625\n",
      "Batch: 157, Loss: 0.43894290924072266, Accuracy: 0.85302734375\n",
      "Batch: 158, Loss: 0.44779229164123535, Accuracy: 0.85546875\n",
      "Batch: 159, Loss: 0.4931071400642395, Accuracy: 0.83154296875\n",
      "Batch: 160, Loss: 0.5042921304702759, Accuracy: 0.84033203125\n",
      "Batch: 161, Loss: 0.5324162244796753, Accuracy: 0.83642578125\n",
      "Batch: 162, Loss: 0.4733230173587799, Accuracy: 0.8505859375\n",
      "Batch: 163, Loss: 0.5176193118095398, Accuracy: 0.8466796875\n",
      "Batch: 164, Loss: 0.5511965751647949, Accuracy: 0.82470703125\n",
      "Batch: 165, Loss: 0.5240326523780823, Accuracy: 0.83349609375\n",
      "Batch: 166, Loss: 0.502744197845459, Accuracy: 0.83740234375\n",
      "Batch: 167, Loss: 0.4872483015060425, Accuracy: 0.845703125\n",
      "Batch: 168, Loss: 0.47469770908355713, Accuracy: 0.8447265625\n",
      "Batch: 169, Loss: 0.49163496494293213, Accuracy: 0.83251953125\n",
      "Batch: 170, Loss: 0.5266009569168091, Accuracy: 0.83056640625\n",
      "Batch: 171, Loss: 0.49781113862991333, Accuracy: 0.84228515625\n",
      "Batch: 172, Loss: 0.47318658232688904, Accuracy: 0.845703125\n",
      "Batch: 173, Loss: 0.533822774887085, Accuracy: 0.83349609375\n",
      "Batch: 174, Loss: 0.44874638319015503, Accuracy: 0.84423828125\n",
      "Batch: 175, Loss: 0.5003562569618225, Accuracy: 0.830078125\n",
      "Batch: 176, Loss: 0.5194045305252075, Accuracy: 0.83154296875\n",
      "Batch: 177, Loss: 0.5211267471313477, Accuracy: 0.83203125\n",
      "Batch: 178, Loss: 0.4814097285270691, Accuracy: 0.84130859375\n",
      "Batch: 179, Loss: 0.5056968927383423, Accuracy: 0.8369140625\n",
      "Batch: 180, Loss: 0.5215577483177185, Accuracy: 0.83447265625\n",
      "Epoch 94/200\n",
      "Batch: 1, Loss: 0.7427971363067627, Accuracy: 0.79052734375\n",
      "Batch: 2, Loss: 0.47730737924575806, Accuracy: 0.841796875\n",
      "Batch: 3, Loss: 0.5134486556053162, Accuracy: 0.83203125\n",
      "Batch: 4, Loss: 0.5223343372344971, Accuracy: 0.83447265625\n",
      "Batch: 5, Loss: 0.5126222372055054, Accuracy: 0.837890625\n",
      "Batch: 6, Loss: 0.5210731029510498, Accuracy: 0.82568359375\n",
      "Batch: 7, Loss: 0.49011343717575073, Accuracy: 0.845703125\n",
      "Batch: 8, Loss: 0.4657606780529022, Accuracy: 0.84228515625\n",
      "Batch: 9, Loss: 0.5003342032432556, Accuracy: 0.84423828125\n",
      "Batch: 10, Loss: 0.45525458455085754, Accuracy: 0.853515625\n",
      "Batch: 11, Loss: 0.5147654414176941, Accuracy: 0.83154296875\n",
      "Batch: 12, Loss: 0.4562276303768158, Accuracy: 0.85546875\n",
      "Batch: 13, Loss: 0.49441924691200256, Accuracy: 0.845703125\n",
      "Batch: 14, Loss: 0.5086801648139954, Accuracy: 0.841796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 15, Loss: 0.5090697407722473, Accuracy: 0.83203125\n",
      "Batch: 16, Loss: 0.5494050979614258, Accuracy: 0.8212890625\n",
      "Batch: 17, Loss: 0.4643881916999817, Accuracy: 0.84130859375\n",
      "Batch: 18, Loss: 0.4975437819957733, Accuracy: 0.83740234375\n",
      "Batch: 19, Loss: 0.5029350519180298, Accuracy: 0.8369140625\n",
      "Batch: 20, Loss: 0.4213029742240906, Accuracy: 0.8623046875\n",
      "Batch: 21, Loss: 0.5170503258705139, Accuracy: 0.8359375\n",
      "Batch: 22, Loss: 0.4624961018562317, Accuracy: 0.85498046875\n",
      "Batch: 23, Loss: 0.4563056230545044, Accuracy: 0.845703125\n",
      "Batch: 24, Loss: 0.49563711881637573, Accuracy: 0.841796875\n",
      "Batch: 25, Loss: 0.4826054871082306, Accuracy: 0.8427734375\n",
      "Batch: 26, Loss: 0.4804365634918213, Accuracy: 0.837890625\n",
      "Batch: 27, Loss: 0.5133273601531982, Accuracy: 0.8359375\n",
      "Batch: 28, Loss: 0.4872932434082031, Accuracy: 0.8349609375\n",
      "Batch: 29, Loss: 0.548811674118042, Accuracy: 0.828125\n",
      "Batch: 30, Loss: 0.5037789344787598, Accuracy: 0.8330078125\n",
      "Batch: 31, Loss: 0.5435583591461182, Accuracy: 0.82666015625\n",
      "Batch: 32, Loss: 0.5720468759536743, Accuracy: 0.81591796875\n",
      "Batch: 33, Loss: 0.5089854001998901, Accuracy: 0.83154296875\n",
      "Batch: 34, Loss: 0.5284354090690613, Accuracy: 0.8369140625\n",
      "Batch: 35, Loss: 0.5515198707580566, Accuracy: 0.826171875\n",
      "Batch: 36, Loss: 0.5179239511489868, Accuracy: 0.83544921875\n",
      "Batch: 37, Loss: 0.5592100620269775, Accuracy: 0.82275390625\n",
      "Batch: 38, Loss: 0.5470287799835205, Accuracy: 0.828125\n",
      "Batch: 39, Loss: 0.5099967122077942, Accuracy: 0.83251953125\n",
      "Batch: 40, Loss: 0.5243534445762634, Accuracy: 0.837890625\n",
      "Batch: 41, Loss: 0.5313109159469604, Accuracy: 0.82421875\n",
      "Batch: 42, Loss: 0.5187191963195801, Accuracy: 0.8271484375\n",
      "Batch: 43, Loss: 0.4708264172077179, Accuracy: 0.853515625\n",
      "Batch: 44, Loss: 0.4249762296676636, Accuracy: 0.86474609375\n",
      "Batch: 45, Loss: 0.5011672377586365, Accuracy: 0.8359375\n",
      "Batch: 46, Loss: 0.4536701440811157, Accuracy: 0.8427734375\n",
      "Batch: 47, Loss: 0.501733124256134, Accuracy: 0.83544921875\n",
      "Batch: 48, Loss: 0.4901147484779358, Accuracy: 0.83642578125\n",
      "Batch: 49, Loss: 0.4767906665802002, Accuracy: 0.849609375\n",
      "Batch: 50, Loss: 0.5108650922775269, Accuracy: 0.833984375\n",
      "Batch: 51, Loss: 0.4952300190925598, Accuracy: 0.83837890625\n",
      "Batch: 52, Loss: 0.504906415939331, Accuracy: 0.82421875\n",
      "Batch: 53, Loss: 0.48496633768081665, Accuracy: 0.84375\n",
      "Batch: 54, Loss: 0.520288348197937, Accuracy: 0.82958984375\n",
      "Batch: 55, Loss: 0.5128564834594727, Accuracy: 0.82958984375\n",
      "Batch: 56, Loss: 0.4860503673553467, Accuracy: 0.83349609375\n",
      "Batch: 57, Loss: 0.5314335823059082, Accuracy: 0.833984375\n",
      "Batch: 58, Loss: 0.5085910558700562, Accuracy: 0.83740234375\n",
      "Batch: 59, Loss: 0.5678424835205078, Accuracy: 0.814453125\n",
      "Batch: 60, Loss: 0.49390140175819397, Accuracy: 0.8408203125\n",
      "Batch: 61, Loss: 0.47612807154655457, Accuracy: 0.85107421875\n",
      "Batch: 62, Loss: 0.4911884665489197, Accuracy: 0.84375\n",
      "Batch: 63, Loss: 0.4920077919960022, Accuracy: 0.84521484375\n",
      "Batch: 64, Loss: 0.5060688853263855, Accuracy: 0.83154296875\n",
      "Batch: 65, Loss: 0.5340099334716797, Accuracy: 0.8251953125\n",
      "Batch: 66, Loss: 0.4860454499721527, Accuracy: 0.84521484375\n",
      "Batch: 67, Loss: 0.5309710502624512, Accuracy: 0.8271484375\n",
      "Batch: 68, Loss: 0.4488523602485657, Accuracy: 0.849609375\n",
      "Batch: 69, Loss: 0.4921472668647766, Accuracy: 0.83251953125\n",
      "Batch: 70, Loss: 0.4739716053009033, Accuracy: 0.84130859375\n",
      "Batch: 71, Loss: 0.489454984664917, Accuracy: 0.8466796875\n",
      "Batch: 72, Loss: 0.5303950309753418, Accuracy: 0.8251953125\n",
      "Batch: 73, Loss: 0.5110743641853333, Accuracy: 0.8349609375\n",
      "Batch: 74, Loss: 0.5219477415084839, Accuracy: 0.8310546875\n",
      "Batch: 75, Loss: 0.45727092027664185, Accuracy: 0.8505859375\n",
      "Batch: 76, Loss: 0.4655192792415619, Accuracy: 0.8505859375\n",
      "Batch: 77, Loss: 0.4624534249305725, Accuracy: 0.845703125\n",
      "Batch: 78, Loss: 0.5001144409179688, Accuracy: 0.83935546875\n",
      "Batch: 79, Loss: 0.48660144209861755, Accuracy: 0.84326171875\n",
      "Batch: 80, Loss: 0.5233302116394043, Accuracy: 0.83251953125\n",
      "Batch: 81, Loss: 0.5069797039031982, Accuracy: 0.83837890625\n",
      "Batch: 82, Loss: 0.49363940954208374, Accuracy: 0.83447265625\n",
      "Batch: 83, Loss: 0.4610200524330139, Accuracy: 0.845703125\n",
      "Batch: 84, Loss: 0.4632050395011902, Accuracy: 0.85400390625\n",
      "Batch: 85, Loss: 0.5229634046554565, Accuracy: 0.8232421875\n",
      "Batch: 86, Loss: 0.551476240158081, Accuracy: 0.82763671875\n",
      "Batch: 87, Loss: 0.47793418169021606, Accuracy: 0.83984375\n",
      "Batch: 88, Loss: 0.5165914297103882, Accuracy: 0.82958984375\n",
      "Batch: 89, Loss: 0.4725605547428131, Accuracy: 0.8408203125\n",
      "Batch: 90, Loss: 0.508338451385498, Accuracy: 0.83447265625\n",
      "Batch: 91, Loss: 0.49202796816825867, Accuracy: 0.84521484375\n",
      "Batch: 92, Loss: 0.5375955104827881, Accuracy: 0.82666015625\n",
      "Batch: 93, Loss: 0.5542110204696655, Accuracy: 0.818359375\n",
      "Batch: 94, Loss: 0.5831971168518066, Accuracy: 0.8154296875\n",
      "Batch: 95, Loss: 0.5915639400482178, Accuracy: 0.81005859375\n",
      "Batch: 96, Loss: 0.5195828080177307, Accuracy: 0.83154296875\n",
      "Batch: 97, Loss: 0.502436101436615, Accuracy: 0.8359375\n",
      "Batch: 98, Loss: 0.516118049621582, Accuracy: 0.83056640625\n",
      "Batch: 99, Loss: 0.4928547739982605, Accuracy: 0.84130859375\n",
      "Batch: 100, Loss: 0.539162278175354, Accuracy: 0.830078125\n",
      "Batch: 101, Loss: 0.521247148513794, Accuracy: 0.82275390625\n",
      "Batch: 102, Loss: 0.4606139063835144, Accuracy: 0.84228515625\n",
      "Batch: 103, Loss: 0.5039653778076172, Accuracy: 0.83740234375\n",
      "Batch: 104, Loss: 0.49402692914009094, Accuracy: 0.83984375\n",
      "Batch: 105, Loss: 0.5052839517593384, Accuracy: 0.84765625\n",
      "Batch: 106, Loss: 0.46100935339927673, Accuracy: 0.85205078125\n",
      "Batch: 107, Loss: 0.5022027492523193, Accuracy: 0.84033203125\n",
      "Batch: 108, Loss: 0.48176705837249756, Accuracy: 0.837890625\n",
      "Batch: 109, Loss: 0.4805021286010742, Accuracy: 0.849609375\n",
      "Batch: 110, Loss: 0.4729945957660675, Accuracy: 0.84033203125\n",
      "Batch: 111, Loss: 0.46123450994491577, Accuracy: 0.85205078125\n",
      "Batch: 112, Loss: 0.45080113410949707, Accuracy: 0.84912109375\n",
      "Batch: 113, Loss: 0.5107284784317017, Accuracy: 0.8330078125\n",
      "Batch: 114, Loss: 0.4998358190059662, Accuracy: 0.84326171875\n",
      "Batch: 115, Loss: 0.4928010404109955, Accuracy: 0.83349609375\n",
      "Batch: 116, Loss: 0.489627480506897, Accuracy: 0.84375\n",
      "Batch: 117, Loss: 0.4558601677417755, Accuracy: 0.84423828125\n",
      "Batch: 118, Loss: 0.4931487441062927, Accuracy: 0.8359375\n",
      "Batch: 119, Loss: 0.4787304997444153, Accuracy: 0.84375\n",
      "Batch: 120, Loss: 0.49093830585479736, Accuracy: 0.83740234375\n",
      "Batch: 121, Loss: 0.4717898666858673, Accuracy: 0.84228515625\n",
      "Batch: 122, Loss: 0.44695332646369934, Accuracy: 0.84912109375\n",
      "Batch: 123, Loss: 0.4697449803352356, Accuracy: 0.85205078125\n",
      "Batch: 124, Loss: 0.45865702629089355, Accuracy: 0.84375\n",
      "Batch: 125, Loss: 0.4856950044631958, Accuracy: 0.8447265625\n",
      "Batch: 126, Loss: 0.47788041830062866, Accuracy: 0.85205078125\n",
      "Batch: 127, Loss: 0.4572296142578125, Accuracy: 0.85107421875\n",
      "Batch: 128, Loss: 0.5277363061904907, Accuracy: 0.82177734375\n",
      "Batch: 129, Loss: 0.5207962989807129, Accuracy: 0.83935546875\n",
      "Batch: 130, Loss: 0.5564149022102356, Accuracy: 0.83203125\n",
      "Batch: 131, Loss: 0.510588526725769, Accuracy: 0.837890625\n",
      "Batch: 132, Loss: 0.4490494728088379, Accuracy: 0.861328125\n",
      "Batch: 133, Loss: 0.4698241949081421, Accuracy: 0.8447265625\n",
      "Batch: 134, Loss: 0.5041351914405823, Accuracy: 0.83251953125\n",
      "Batch: 135, Loss: 0.5057984590530396, Accuracy: 0.8291015625\n",
      "Batch: 136, Loss: 0.45579540729522705, Accuracy: 0.85107421875\n",
      "Batch: 137, Loss: 0.4987310767173767, Accuracy: 0.8330078125\n",
      "Batch: 138, Loss: 0.4461977481842041, Accuracy: 0.86083984375\n",
      "Batch: 139, Loss: 0.4757254123687744, Accuracy: 0.8447265625\n",
      "Batch: 140, Loss: 0.43721216917037964, Accuracy: 0.86083984375\n",
      "Batch: 141, Loss: 0.4962514042854309, Accuracy: 0.83984375\n",
      "Batch: 142, Loss: 0.4626692831516266, Accuracy: 0.84716796875\n",
      "Batch: 143, Loss: 0.4914722442626953, Accuracy: 0.837890625\n",
      "Batch: 144, Loss: 0.5308760404586792, Accuracy: 0.82373046875\n",
      "Batch: 145, Loss: 0.5181093215942383, Accuracy: 0.8369140625\n",
      "Batch: 146, Loss: 0.5169151425361633, Accuracy: 0.83642578125\n",
      "Batch: 147, Loss: 0.4899049997329712, Accuracy: 0.83984375\n",
      "Batch: 148, Loss: 0.5190010070800781, Accuracy: 0.83251953125\n",
      "Batch: 149, Loss: 0.49402064085006714, Accuracy: 0.8408203125\n",
      "Batch: 150, Loss: 0.45092931389808655, Accuracy: 0.85986328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 151, Loss: 0.4584595561027527, Accuracy: 0.85400390625\n",
      "Batch: 152, Loss: 0.4944148659706116, Accuracy: 0.83447265625\n",
      "Batch: 153, Loss: 0.4929809868335724, Accuracy: 0.84228515625\n",
      "Batch: 154, Loss: 0.502132773399353, Accuracy: 0.8359375\n",
      "Batch: 155, Loss: 0.5485502481460571, Accuracy: 0.81884765625\n",
      "Batch: 156, Loss: 0.4443942904472351, Accuracy: 0.84619140625\n",
      "Batch: 157, Loss: 0.43290019035339355, Accuracy: 0.85791015625\n",
      "Batch: 158, Loss: 0.4645301103591919, Accuracy: 0.85546875\n",
      "Batch: 159, Loss: 0.48549801111221313, Accuracy: 0.84765625\n",
      "Batch: 160, Loss: 0.4972568154335022, Accuracy: 0.83984375\n",
      "Batch: 161, Loss: 0.5099654197692871, Accuracy: 0.83642578125\n",
      "Batch: 162, Loss: 0.46766695380210876, Accuracy: 0.8525390625\n",
      "Batch: 163, Loss: 0.4924112558364868, Accuracy: 0.83349609375\n",
      "Batch: 164, Loss: 0.5429304242134094, Accuracy: 0.82666015625\n",
      "Batch: 165, Loss: 0.4940495491027832, Accuracy: 0.8486328125\n",
      "Batch: 166, Loss: 0.5111507177352905, Accuracy: 0.8359375\n",
      "Batch: 167, Loss: 0.4952521026134491, Accuracy: 0.8408203125\n",
      "Batch: 168, Loss: 0.4638935327529907, Accuracy: 0.8466796875\n",
      "Batch: 169, Loss: 0.4957592785358429, Accuracy: 0.8447265625\n",
      "Batch: 170, Loss: 0.5318292379379272, Accuracy: 0.8359375\n",
      "Batch: 171, Loss: 0.49051469564437866, Accuracy: 0.83642578125\n",
      "Batch: 172, Loss: 0.45049747824668884, Accuracy: 0.85107421875\n",
      "Batch: 173, Loss: 0.5561875104904175, Accuracy: 0.82177734375\n",
      "Batch: 174, Loss: 0.4499647617340088, Accuracy: 0.84521484375\n",
      "Batch: 175, Loss: 0.5154790878295898, Accuracy: 0.83642578125\n",
      "Batch: 176, Loss: 0.5355281829833984, Accuracy: 0.82275390625\n",
      "Batch: 177, Loss: 0.5100315809249878, Accuracy: 0.8349609375\n",
      "Batch: 178, Loss: 0.4908416271209717, Accuracy: 0.83740234375\n",
      "Batch: 179, Loss: 0.4881121814250946, Accuracy: 0.84375\n",
      "Batch: 180, Loss: 0.4982302784919739, Accuracy: 0.84716796875\n",
      "Epoch 95/200\n",
      "Batch: 1, Loss: 0.7445557117462158, Accuracy: 0.783203125\n",
      "Batch: 2, Loss: 0.49495628476142883, Accuracy: 0.841796875\n",
      "Batch: 3, Loss: 0.5184875130653381, Accuracy: 0.8349609375\n",
      "Batch: 4, Loss: 0.49950751662254333, Accuracy: 0.83642578125\n",
      "Batch: 5, Loss: 0.4915805459022522, Accuracy: 0.84423828125\n",
      "Batch: 6, Loss: 0.5022470355033875, Accuracy: 0.830078125\n",
      "Batch: 7, Loss: 0.495410680770874, Accuracy: 0.84130859375\n",
      "Batch: 8, Loss: 0.4842206537723541, Accuracy: 0.8408203125\n",
      "Batch: 9, Loss: 0.5187182426452637, Accuracy: 0.837890625\n",
      "Batch: 10, Loss: 0.46921783685684204, Accuracy: 0.84912109375\n",
      "Batch: 11, Loss: 0.4983600378036499, Accuracy: 0.83642578125\n",
      "Batch: 12, Loss: 0.4435853660106659, Accuracy: 0.857421875\n",
      "Batch: 13, Loss: 0.4951527416706085, Accuracy: 0.833984375\n",
      "Batch: 14, Loss: 0.47646355628967285, Accuracy: 0.84521484375\n",
      "Batch: 15, Loss: 0.49498647451400757, Accuracy: 0.84033203125\n",
      "Batch: 16, Loss: 0.5268773436546326, Accuracy: 0.8251953125\n",
      "Batch: 17, Loss: 0.4892231523990631, Accuracy: 0.84912109375\n",
      "Batch: 18, Loss: 0.5163034200668335, Accuracy: 0.83349609375\n",
      "Batch: 19, Loss: 0.5274102091789246, Accuracy: 0.833984375\n",
      "Batch: 20, Loss: 0.4225808084011078, Accuracy: 0.8623046875\n",
      "Batch: 21, Loss: 0.48497283458709717, Accuracy: 0.84716796875\n",
      "Batch: 22, Loss: 0.4700070321559906, Accuracy: 0.84130859375\n",
      "Batch: 23, Loss: 0.44801419973373413, Accuracy: 0.85498046875\n",
      "Batch: 24, Loss: 0.47498711943626404, Accuracy: 0.83935546875\n",
      "Batch: 25, Loss: 0.47539961338043213, Accuracy: 0.8525390625\n",
      "Batch: 26, Loss: 0.455814003944397, Accuracy: 0.84423828125\n",
      "Batch: 27, Loss: 0.504305362701416, Accuracy: 0.84130859375\n",
      "Batch: 28, Loss: 0.46901142597198486, Accuracy: 0.84814453125\n",
      "Batch: 29, Loss: 0.522895872592926, Accuracy: 0.83349609375\n",
      "Batch: 30, Loss: 0.49532508850097656, Accuracy: 0.84228515625\n",
      "Batch: 31, Loss: 0.5450514554977417, Accuracy: 0.82666015625\n",
      "Batch: 32, Loss: 0.5150346755981445, Accuracy: 0.83642578125\n",
      "Batch: 33, Loss: 0.5137695074081421, Accuracy: 0.8310546875\n",
      "Batch: 34, Loss: 0.5351418852806091, Accuracy: 0.82275390625\n",
      "Batch: 35, Loss: 0.5431735515594482, Accuracy: 0.82470703125\n",
      "Batch: 36, Loss: 0.5022386312484741, Accuracy: 0.83203125\n",
      "Batch: 37, Loss: 0.5207797288894653, Accuracy: 0.83154296875\n",
      "Batch: 38, Loss: 0.5141324996948242, Accuracy: 0.83203125\n",
      "Batch: 39, Loss: 0.48044872283935547, Accuracy: 0.8427734375\n",
      "Batch: 40, Loss: 0.5387675762176514, Accuracy: 0.833984375\n",
      "Batch: 41, Loss: 0.5253509283065796, Accuracy: 0.8310546875\n",
      "Batch: 42, Loss: 0.4886360466480255, Accuracy: 0.83154296875\n",
      "Batch: 43, Loss: 0.47629737854003906, Accuracy: 0.849609375\n",
      "Batch: 44, Loss: 0.4566863179206848, Accuracy: 0.84814453125\n",
      "Batch: 45, Loss: 0.4968007206916809, Accuracy: 0.83544921875\n",
      "Batch: 46, Loss: 0.45986947417259216, Accuracy: 0.83984375\n",
      "Batch: 47, Loss: 0.47780779004096985, Accuracy: 0.8359375\n",
      "Batch: 48, Loss: 0.5060260891914368, Accuracy: 0.83935546875\n",
      "Batch: 49, Loss: 0.4720081686973572, Accuracy: 0.84814453125\n",
      "Batch: 50, Loss: 0.518151044845581, Accuracy: 0.8271484375\n",
      "Batch: 51, Loss: 0.4898354411125183, Accuracy: 0.8408203125\n",
      "Batch: 52, Loss: 0.494579553604126, Accuracy: 0.8388671875\n",
      "Batch: 53, Loss: 0.5008895993232727, Accuracy: 0.8369140625\n",
      "Batch: 54, Loss: 0.5201176404953003, Accuracy: 0.82470703125\n",
      "Batch: 55, Loss: 0.5291740894317627, Accuracy: 0.828125\n",
      "Batch: 56, Loss: 0.45181652903556824, Accuracy: 0.85205078125\n",
      "Batch: 57, Loss: 0.5392246842384338, Accuracy: 0.82177734375\n",
      "Batch: 58, Loss: 0.5027978420257568, Accuracy: 0.84326171875\n",
      "Batch: 59, Loss: 0.5645735859870911, Accuracy: 0.8173828125\n",
      "Batch: 60, Loss: 0.49801212549209595, Accuracy: 0.841796875\n",
      "Batch: 61, Loss: 0.4725573658943176, Accuracy: 0.841796875\n",
      "Batch: 62, Loss: 0.458481103181839, Accuracy: 0.85009765625\n",
      "Batch: 63, Loss: 0.4873179495334625, Accuracy: 0.84033203125\n",
      "Batch: 64, Loss: 0.5021706223487854, Accuracy: 0.8388671875\n",
      "Batch: 65, Loss: 0.5163174271583557, Accuracy: 0.83935546875\n",
      "Batch: 66, Loss: 0.4974531829357147, Accuracy: 0.841796875\n",
      "Batch: 67, Loss: 0.5269696116447449, Accuracy: 0.83544921875\n",
      "Batch: 68, Loss: 0.45672884583473206, Accuracy: 0.84033203125\n",
      "Batch: 69, Loss: 0.4880771338939667, Accuracy: 0.8359375\n",
      "Batch: 70, Loss: 0.4715566635131836, Accuracy: 0.8388671875\n",
      "Batch: 71, Loss: 0.47184640169143677, Accuracy: 0.8447265625\n",
      "Batch: 72, Loss: 0.548296332359314, Accuracy: 0.81689453125\n",
      "Batch: 73, Loss: 0.48929744958877563, Accuracy: 0.8369140625\n",
      "Batch: 74, Loss: 0.5215499997138977, Accuracy: 0.82763671875\n",
      "Batch: 75, Loss: 0.445068359375, Accuracy: 0.853515625\n",
      "Batch: 76, Loss: 0.45093199610710144, Accuracy: 0.853515625\n",
      "Batch: 77, Loss: 0.46267321705818176, Accuracy: 0.8564453125\n",
      "Batch: 78, Loss: 0.48697829246520996, Accuracy: 0.845703125\n",
      "Batch: 79, Loss: 0.4834491014480591, Accuracy: 0.8349609375\n",
      "Batch: 80, Loss: 0.4726651906967163, Accuracy: 0.85205078125\n",
      "Batch: 81, Loss: 0.4734393358230591, Accuracy: 0.84619140625\n",
      "Batch: 82, Loss: 0.49953609704971313, Accuracy: 0.8359375\n",
      "Batch: 83, Loss: 0.4650992155075073, Accuracy: 0.84814453125\n",
      "Batch: 84, Loss: 0.4858723282814026, Accuracy: 0.837890625\n",
      "Batch: 85, Loss: 0.5202022194862366, Accuracy: 0.82568359375\n",
      "Batch: 86, Loss: 0.5560609102249146, Accuracy: 0.83154296875\n",
      "Batch: 87, Loss: 0.4663323760032654, Accuracy: 0.841796875\n",
      "Batch: 88, Loss: 0.5093163847923279, Accuracy: 0.83837890625\n",
      "Batch: 89, Loss: 0.4685018062591553, Accuracy: 0.845703125\n",
      "Batch: 90, Loss: 0.5095425844192505, Accuracy: 0.8330078125\n",
      "Batch: 91, Loss: 0.49517399072647095, Accuracy: 0.84130859375\n",
      "Batch: 92, Loss: 0.5625611543655396, Accuracy: 0.81298828125\n",
      "Batch: 93, Loss: 0.5644357204437256, Accuracy: 0.814453125\n",
      "Batch: 94, Loss: 0.5587957501411438, Accuracy: 0.83056640625\n",
      "Batch: 95, Loss: 0.5602914094924927, Accuracy: 0.8154296875\n",
      "Batch: 96, Loss: 0.4883994162082672, Accuracy: 0.84326171875\n",
      "Batch: 97, Loss: 0.49850013852119446, Accuracy: 0.8466796875\n",
      "Batch: 98, Loss: 0.4988197088241577, Accuracy: 0.84130859375\n",
      "Batch: 99, Loss: 0.480182409286499, Accuracy: 0.8388671875\n",
      "Batch: 100, Loss: 0.562516450881958, Accuracy: 0.82763671875\n",
      "Batch: 101, Loss: 0.550417423248291, Accuracy: 0.81689453125\n",
      "Batch: 102, Loss: 0.45782601833343506, Accuracy: 0.8515625\n",
      "Batch: 103, Loss: 0.48238706588745117, Accuracy: 0.8388671875\n",
      "Batch: 104, Loss: 0.5010709762573242, Accuracy: 0.83349609375\n",
      "Batch: 105, Loss: 0.5100748538970947, Accuracy: 0.83642578125\n",
      "Batch: 106, Loss: 0.4719015955924988, Accuracy: 0.84326171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 107, Loss: 0.5253471732139587, Accuracy: 0.83251953125\n",
      "Batch: 108, Loss: 0.4585372805595398, Accuracy: 0.859375\n",
      "Batch: 109, Loss: 0.47751808166503906, Accuracy: 0.84033203125\n",
      "Batch: 110, Loss: 0.47715580463409424, Accuracy: 0.8447265625\n",
      "Batch: 111, Loss: 0.465998113155365, Accuracy: 0.849609375\n",
      "Batch: 112, Loss: 0.48366057872772217, Accuracy: 0.84423828125\n",
      "Batch: 113, Loss: 0.4997120201587677, Accuracy: 0.82861328125\n",
      "Batch: 114, Loss: 0.499177485704422, Accuracy: 0.8349609375\n",
      "Batch: 115, Loss: 0.47635388374328613, Accuracy: 0.8359375\n",
      "Batch: 116, Loss: 0.5008593797683716, Accuracy: 0.84033203125\n",
      "Batch: 117, Loss: 0.44938212633132935, Accuracy: 0.857421875\n",
      "Batch: 118, Loss: 0.4831533432006836, Accuracy: 0.845703125\n",
      "Batch: 119, Loss: 0.47792261838912964, Accuracy: 0.84423828125\n",
      "Batch: 120, Loss: 0.4576624631881714, Accuracy: 0.8486328125\n",
      "Batch: 121, Loss: 0.47247856855392456, Accuracy: 0.84521484375\n",
      "Batch: 122, Loss: 0.4434719383716583, Accuracy: 0.85546875\n",
      "Batch: 123, Loss: 0.46816107630729675, Accuracy: 0.84521484375\n",
      "Batch: 124, Loss: 0.4577159285545349, Accuracy: 0.84912109375\n",
      "Batch: 125, Loss: 0.47807085514068604, Accuracy: 0.84033203125\n",
      "Batch: 126, Loss: 0.47038573026657104, Accuracy: 0.8515625\n",
      "Batch: 127, Loss: 0.44825607538223267, Accuracy: 0.85107421875\n",
      "Batch: 128, Loss: 0.5212063789367676, Accuracy: 0.833984375\n",
      "Batch: 129, Loss: 0.5457708835601807, Accuracy: 0.83251953125\n",
      "Batch: 130, Loss: 0.5284578800201416, Accuracy: 0.8359375\n",
      "Batch: 131, Loss: 0.47823309898376465, Accuracy: 0.8544921875\n",
      "Batch: 132, Loss: 0.48427924513816833, Accuracy: 0.8369140625\n",
      "Batch: 133, Loss: 0.4509495496749878, Accuracy: 0.85009765625\n",
      "Batch: 134, Loss: 0.5071244239807129, Accuracy: 0.8349609375\n",
      "Batch: 135, Loss: 0.4805748462677002, Accuracy: 0.841796875\n",
      "Batch: 136, Loss: 0.47492334246635437, Accuracy: 0.8427734375\n",
      "Batch: 137, Loss: 0.4910317063331604, Accuracy: 0.84423828125\n",
      "Batch: 138, Loss: 0.4564175605773926, Accuracy: 0.8466796875\n",
      "Batch: 139, Loss: 0.4729495942592621, Accuracy: 0.837890625\n",
      "Batch: 140, Loss: 0.4283037781715393, Accuracy: 0.85986328125\n",
      "Batch: 141, Loss: 0.4928041100502014, Accuracy: 0.83642578125\n",
      "Batch: 142, Loss: 0.44252386689186096, Accuracy: 0.859375\n",
      "Batch: 143, Loss: 0.4769933819770813, Accuracy: 0.8544921875\n",
      "Batch: 144, Loss: 0.522077739238739, Accuracy: 0.82958984375\n",
      "Batch: 145, Loss: 0.49297818541526794, Accuracy: 0.84228515625\n",
      "Batch: 146, Loss: 0.47598788142204285, Accuracy: 0.8447265625\n",
      "Batch: 147, Loss: 0.4699828028678894, Accuracy: 0.853515625\n",
      "Batch: 148, Loss: 0.5119733214378357, Accuracy: 0.8271484375\n",
      "Batch: 149, Loss: 0.4899853467941284, Accuracy: 0.84326171875\n",
      "Batch: 150, Loss: 0.45518046617507935, Accuracy: 0.8525390625\n",
      "Batch: 151, Loss: 0.465961754322052, Accuracy: 0.84765625\n",
      "Batch: 152, Loss: 0.4812731146812439, Accuracy: 0.84228515625\n",
      "Batch: 153, Loss: 0.5058972835540771, Accuracy: 0.8349609375\n",
      "Batch: 154, Loss: 0.4959366023540497, Accuracy: 0.833984375\n",
      "Batch: 155, Loss: 0.5461528897285461, Accuracy: 0.822265625\n",
      "Batch: 156, Loss: 0.44505757093429565, Accuracy: 0.8486328125\n",
      "Batch: 157, Loss: 0.4406839907169342, Accuracy: 0.8525390625\n",
      "Batch: 158, Loss: 0.4545919597148895, Accuracy: 0.85498046875\n",
      "Batch: 159, Loss: 0.48156774044036865, Accuracy: 0.8427734375\n",
      "Batch: 160, Loss: 0.49501267075538635, Accuracy: 0.8388671875\n",
      "Batch: 161, Loss: 0.49896809458732605, Accuracy: 0.84033203125\n",
      "Batch: 162, Loss: 0.47971540689468384, Accuracy: 0.8388671875\n",
      "Batch: 163, Loss: 0.5047124624252319, Accuracy: 0.83349609375\n",
      "Batch: 164, Loss: 0.5443766713142395, Accuracy: 0.8310546875\n",
      "Batch: 165, Loss: 0.4948224127292633, Accuracy: 0.8466796875\n",
      "Batch: 166, Loss: 0.5108916163444519, Accuracy: 0.83544921875\n",
      "Batch: 167, Loss: 0.4938022494316101, Accuracy: 0.84375\n",
      "Batch: 168, Loss: 0.4589315354824066, Accuracy: 0.8544921875\n",
      "Batch: 169, Loss: 0.49073758721351624, Accuracy: 0.8388671875\n",
      "Batch: 170, Loss: 0.5246995687484741, Accuracy: 0.8271484375\n",
      "Batch: 171, Loss: 0.49859702587127686, Accuracy: 0.83447265625\n",
      "Batch: 172, Loss: 0.44486746191978455, Accuracy: 0.85400390625\n",
      "Batch: 173, Loss: 0.5106139183044434, Accuracy: 0.8369140625\n",
      "Batch: 174, Loss: 0.4376029968261719, Accuracy: 0.85205078125\n",
      "Batch: 175, Loss: 0.5214523077011108, Accuracy: 0.830078125\n",
      "Batch: 176, Loss: 0.5354752540588379, Accuracy: 0.830078125\n",
      "Batch: 177, Loss: 0.5050169229507446, Accuracy: 0.8466796875\n",
      "Batch: 178, Loss: 0.48096054792404175, Accuracy: 0.84521484375\n",
      "Batch: 179, Loss: 0.49975359439849854, Accuracy: 0.83935546875\n",
      "Batch: 180, Loss: 0.49600374698638916, Accuracy: 0.8447265625\n",
      "Epoch 96/200\n",
      "Batch: 1, Loss: 0.723595917224884, Accuracy: 0.7841796875\n",
      "Batch: 2, Loss: 0.5032280683517456, Accuracy: 0.826171875\n",
      "Batch: 3, Loss: 0.5094387531280518, Accuracy: 0.83642578125\n",
      "Batch: 4, Loss: 0.5107589960098267, Accuracy: 0.8349609375\n",
      "Batch: 5, Loss: 0.4911919832229614, Accuracy: 0.8466796875\n",
      "Batch: 6, Loss: 0.4974004030227661, Accuracy: 0.837890625\n",
      "Batch: 7, Loss: 0.4809502065181732, Accuracy: 0.8466796875\n",
      "Batch: 8, Loss: 0.4770243167877197, Accuracy: 0.8466796875\n",
      "Batch: 9, Loss: 0.5222799181938171, Accuracy: 0.82666015625\n",
      "Batch: 10, Loss: 0.4678793251514435, Accuracy: 0.8544921875\n",
      "Batch: 11, Loss: 0.5309697985649109, Accuracy: 0.82568359375\n",
      "Batch: 12, Loss: 0.442863404750824, Accuracy: 0.85546875\n",
      "Batch: 13, Loss: 0.4921625554561615, Accuracy: 0.84130859375\n",
      "Batch: 14, Loss: 0.4823169708251953, Accuracy: 0.84521484375\n",
      "Batch: 15, Loss: 0.5102033019065857, Accuracy: 0.83349609375\n",
      "Batch: 16, Loss: 0.5188870429992676, Accuracy: 0.82470703125\n",
      "Batch: 17, Loss: 0.4522794783115387, Accuracy: 0.85693359375\n",
      "Batch: 18, Loss: 0.5385066270828247, Accuracy: 0.83203125\n",
      "Batch: 19, Loss: 0.5087084770202637, Accuracy: 0.8427734375\n",
      "Batch: 20, Loss: 0.4352871775627136, Accuracy: 0.86181640625\n",
      "Batch: 21, Loss: 0.5215795040130615, Accuracy: 0.8251953125\n",
      "Batch: 22, Loss: 0.4652593433856964, Accuracy: 0.85205078125\n",
      "Batch: 23, Loss: 0.4510129988193512, Accuracy: 0.849609375\n",
      "Batch: 24, Loss: 0.4834211766719818, Accuracy: 0.8427734375\n",
      "Batch: 25, Loss: 0.46613505482673645, Accuracy: 0.84423828125\n",
      "Batch: 26, Loss: 0.4846746027469635, Accuracy: 0.83935546875\n",
      "Batch: 27, Loss: 0.539581298828125, Accuracy: 0.828125\n",
      "Batch: 28, Loss: 0.47857528924942017, Accuracy: 0.8505859375\n",
      "Batch: 29, Loss: 0.5219351649284363, Accuracy: 0.83251953125\n",
      "Batch: 30, Loss: 0.492020845413208, Accuracy: 0.8466796875\n",
      "Batch: 31, Loss: 0.5260734558105469, Accuracy: 0.8330078125\n",
      "Batch: 32, Loss: 0.5319600701332092, Accuracy: 0.82568359375\n",
      "Batch: 33, Loss: 0.4983595609664917, Accuracy: 0.83740234375\n",
      "Batch: 34, Loss: 0.5116415619850159, Accuracy: 0.83642578125\n",
      "Batch: 35, Loss: 0.5271207094192505, Accuracy: 0.8291015625\n",
      "Batch: 36, Loss: 0.4970158338546753, Accuracy: 0.8388671875\n",
      "Batch: 37, Loss: 0.5251760482788086, Accuracy: 0.828125\n",
      "Batch: 38, Loss: 0.5388938188552856, Accuracy: 0.81884765625\n",
      "Batch: 39, Loss: 0.48628121614456177, Accuracy: 0.83984375\n",
      "Batch: 40, Loss: 0.5427117943763733, Accuracy: 0.82470703125\n",
      "Batch: 41, Loss: 0.5361658930778503, Accuracy: 0.8251953125\n",
      "Batch: 42, Loss: 0.5162442922592163, Accuracy: 0.83056640625\n",
      "Batch: 43, Loss: 0.4745943546295166, Accuracy: 0.83935546875\n",
      "Batch: 44, Loss: 0.437208890914917, Accuracy: 0.86328125\n",
      "Batch: 45, Loss: 0.48240262269973755, Accuracy: 0.83642578125\n",
      "Batch: 46, Loss: 0.48063820600509644, Accuracy: 0.83642578125\n",
      "Batch: 47, Loss: 0.4777444005012512, Accuracy: 0.841796875\n",
      "Batch: 48, Loss: 0.4971945881843567, Accuracy: 0.841796875\n",
      "Batch: 49, Loss: 0.4745185375213623, Accuracy: 0.84228515625\n",
      "Batch: 50, Loss: 0.5119504928588867, Accuracy: 0.82666015625\n",
      "Batch: 51, Loss: 0.4722145199775696, Accuracy: 0.84765625\n",
      "Batch: 52, Loss: 0.5001710057258606, Accuracy: 0.83740234375\n",
      "Batch: 53, Loss: 0.4906696081161499, Accuracy: 0.826171875\n",
      "Batch: 54, Loss: 0.5026730298995972, Accuracy: 0.837890625\n",
      "Batch: 55, Loss: 0.5069361329078674, Accuracy: 0.8388671875\n",
      "Batch: 56, Loss: 0.4741082191467285, Accuracy: 0.8447265625\n",
      "Batch: 57, Loss: 0.5481589436531067, Accuracy: 0.82861328125\n",
      "Batch: 58, Loss: 0.49941733479499817, Accuracy: 0.8427734375\n",
      "Batch: 59, Loss: 0.59619140625, Accuracy: 0.81005859375\n",
      "Batch: 60, Loss: 0.4760502576828003, Accuracy: 0.84326171875\n",
      "Batch: 61, Loss: 0.4895285367965698, Accuracy: 0.845703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 62, Loss: 0.49889832735061646, Accuracy: 0.84130859375\n",
      "Batch: 63, Loss: 0.4747300148010254, Accuracy: 0.83935546875\n",
      "Batch: 64, Loss: 0.516369640827179, Accuracy: 0.8369140625\n",
      "Batch: 65, Loss: 0.4895305037498474, Accuracy: 0.8486328125\n",
      "Batch: 66, Loss: 0.4865865409374237, Accuracy: 0.84814453125\n",
      "Batch: 67, Loss: 0.49876686930656433, Accuracy: 0.837890625\n",
      "Batch: 68, Loss: 0.4569424092769623, Accuracy: 0.8515625\n",
      "Batch: 69, Loss: 0.5000662803649902, Accuracy: 0.8359375\n",
      "Batch: 70, Loss: 0.4499408006668091, Accuracy: 0.85107421875\n",
      "Batch: 71, Loss: 0.47717055678367615, Accuracy: 0.8359375\n",
      "Batch: 72, Loss: 0.5356087684631348, Accuracy: 0.81787109375\n",
      "Batch: 73, Loss: 0.4772317409515381, Accuracy: 0.85009765625\n",
      "Batch: 74, Loss: 0.49537771940231323, Accuracy: 0.84375\n",
      "Batch: 75, Loss: 0.4815453290939331, Accuracy: 0.8369140625\n",
      "Batch: 76, Loss: 0.45240336656570435, Accuracy: 0.8505859375\n",
      "Batch: 77, Loss: 0.4525792598724365, Accuracy: 0.86279296875\n",
      "Batch: 78, Loss: 0.49264276027679443, Accuracy: 0.83935546875\n",
      "Batch: 79, Loss: 0.4781856834888458, Accuracy: 0.84375\n",
      "Batch: 80, Loss: 0.49719318747520447, Accuracy: 0.83837890625\n",
      "Batch: 81, Loss: 0.5009391903877258, Accuracy: 0.83984375\n",
      "Batch: 82, Loss: 0.49224478006362915, Accuracy: 0.84716796875\n",
      "Batch: 83, Loss: 0.4670712947845459, Accuracy: 0.8466796875\n",
      "Batch: 84, Loss: 0.48322594165802, Accuracy: 0.8447265625\n",
      "Batch: 85, Loss: 0.4971359670162201, Accuracy: 0.83154296875\n",
      "Batch: 86, Loss: 0.5479638576507568, Accuracy: 0.83154296875\n",
      "Batch: 87, Loss: 0.4837877154350281, Accuracy: 0.83837890625\n",
      "Batch: 88, Loss: 0.5156391263008118, Accuracy: 0.83935546875\n",
      "Batch: 89, Loss: 0.472503125667572, Accuracy: 0.8447265625\n",
      "Batch: 90, Loss: 0.4879409968852997, Accuracy: 0.8466796875\n",
      "Batch: 91, Loss: 0.48454713821411133, Accuracy: 0.8525390625\n",
      "Batch: 92, Loss: 0.5368069410324097, Accuracy: 0.8203125\n",
      "Batch: 93, Loss: 0.5427157878875732, Accuracy: 0.822265625\n",
      "Batch: 94, Loss: 0.5313930511474609, Accuracy: 0.82666015625\n",
      "Batch: 95, Loss: 0.5515570044517517, Accuracy: 0.8203125\n",
      "Batch: 96, Loss: 0.5075792074203491, Accuracy: 0.837890625\n",
      "Batch: 97, Loss: 0.49782902002334595, Accuracy: 0.83447265625\n",
      "Batch: 98, Loss: 0.48068711161613464, Accuracy: 0.85107421875\n",
      "Batch: 99, Loss: 0.48536166548728943, Accuracy: 0.84423828125\n",
      "Batch: 100, Loss: 0.5507400035858154, Accuracy: 0.82275390625\n",
      "Batch: 101, Loss: 0.5170198678970337, Accuracy: 0.83154296875\n",
      "Batch: 102, Loss: 0.47968220710754395, Accuracy: 0.83935546875\n",
      "Batch: 103, Loss: 0.4802846610546112, Accuracy: 0.85400390625\n",
      "Batch: 104, Loss: 0.48538658022880554, Accuracy: 0.83642578125\n",
      "Batch: 105, Loss: 0.5021882057189941, Accuracy: 0.83349609375\n",
      "Batch: 106, Loss: 0.47273990511894226, Accuracy: 0.84423828125\n",
      "Batch: 107, Loss: 0.5101348161697388, Accuracy: 0.83984375\n",
      "Batch: 108, Loss: 0.4745159149169922, Accuracy: 0.84423828125\n",
      "Batch: 109, Loss: 0.4824814200401306, Accuracy: 0.8486328125\n",
      "Batch: 110, Loss: 0.46783536672592163, Accuracy: 0.849609375\n",
      "Batch: 111, Loss: 0.43190687894821167, Accuracy: 0.86181640625\n",
      "Batch: 112, Loss: 0.4864598214626312, Accuracy: 0.845703125\n",
      "Batch: 113, Loss: 0.5095751881599426, Accuracy: 0.8271484375\n",
      "Batch: 114, Loss: 0.4975656270980835, Accuracy: 0.83935546875\n",
      "Batch: 115, Loss: 0.4705750346183777, Accuracy: 0.84619140625\n",
      "Batch: 116, Loss: 0.473466694355011, Accuracy: 0.84619140625\n",
      "Batch: 117, Loss: 0.4496994614601135, Accuracy: 0.8525390625\n",
      "Batch: 118, Loss: 0.4789655804634094, Accuracy: 0.84814453125\n",
      "Batch: 119, Loss: 0.47355806827545166, Accuracy: 0.84228515625\n",
      "Batch: 120, Loss: 0.465350478887558, Accuracy: 0.8447265625\n",
      "Batch: 121, Loss: 0.47228607535362244, Accuracy: 0.8408203125\n",
      "Batch: 122, Loss: 0.4392601251602173, Accuracy: 0.853515625\n",
      "Batch: 123, Loss: 0.43973496556282043, Accuracy: 0.8583984375\n",
      "Batch: 124, Loss: 0.4521004855632782, Accuracy: 0.85107421875\n",
      "Batch: 125, Loss: 0.4866011440753937, Accuracy: 0.84375\n",
      "Batch: 126, Loss: 0.46382060647010803, Accuracy: 0.845703125\n",
      "Batch: 127, Loss: 0.416617751121521, Accuracy: 0.86572265625\n",
      "Batch: 128, Loss: 0.5443390607833862, Accuracy: 0.8310546875\n",
      "Batch: 129, Loss: 0.5504612922668457, Accuracy: 0.81982421875\n",
      "Batch: 130, Loss: 0.5483543872833252, Accuracy: 0.82421875\n",
      "Batch: 131, Loss: 0.49847081303596497, Accuracy: 0.833984375\n",
      "Batch: 132, Loss: 0.48183465003967285, Accuracy: 0.84423828125\n",
      "Batch: 133, Loss: 0.46883624792099, Accuracy: 0.8486328125\n",
      "Batch: 134, Loss: 0.48393502831459045, Accuracy: 0.84619140625\n",
      "Batch: 135, Loss: 0.48523810505867004, Accuracy: 0.83837890625\n",
      "Batch: 136, Loss: 0.46841317415237427, Accuracy: 0.85009765625\n",
      "Batch: 137, Loss: 0.5002151131629944, Accuracy: 0.837890625\n",
      "Batch: 138, Loss: 0.4547352194786072, Accuracy: 0.8544921875\n",
      "Batch: 139, Loss: 0.4669520854949951, Accuracy: 0.841796875\n",
      "Batch: 140, Loss: 0.4222908616065979, Accuracy: 0.8603515625\n",
      "Batch: 141, Loss: 0.4879605174064636, Accuracy: 0.837890625\n",
      "Batch: 142, Loss: 0.44944578409194946, Accuracy: 0.8525390625\n",
      "Batch: 143, Loss: 0.45232540369033813, Accuracy: 0.849609375\n",
      "Batch: 144, Loss: 0.5294501185417175, Accuracy: 0.82861328125\n",
      "Batch: 145, Loss: 0.5006005764007568, Accuracy: 0.8349609375\n",
      "Batch: 146, Loss: 0.49852657318115234, Accuracy: 0.84228515625\n",
      "Batch: 147, Loss: 0.4817264974117279, Accuracy: 0.84228515625\n",
      "Batch: 148, Loss: 0.5061711072921753, Accuracy: 0.83251953125\n",
      "Batch: 149, Loss: 0.5034471750259399, Accuracy: 0.8369140625\n",
      "Batch: 150, Loss: 0.43603676557540894, Accuracy: 0.8564453125\n",
      "Batch: 151, Loss: 0.45999079942703247, Accuracy: 0.8544921875\n",
      "Batch: 152, Loss: 0.46879130601882935, Accuracy: 0.84521484375\n",
      "Batch: 153, Loss: 0.48646366596221924, Accuracy: 0.83837890625\n",
      "Batch: 154, Loss: 0.4910731315612793, Accuracy: 0.83984375\n",
      "Batch: 155, Loss: 0.5451122522354126, Accuracy: 0.8212890625\n",
      "Batch: 156, Loss: 0.46145179867744446, Accuracy: 0.84423828125\n",
      "Batch: 157, Loss: 0.42840781807899475, Accuracy: 0.86083984375\n",
      "Batch: 158, Loss: 0.45163846015930176, Accuracy: 0.86083984375\n",
      "Batch: 159, Loss: 0.4691479504108429, Accuracy: 0.8525390625\n",
      "Batch: 160, Loss: 0.4908497929573059, Accuracy: 0.84375\n",
      "Batch: 161, Loss: 0.5052286386489868, Accuracy: 0.833984375\n",
      "Batch: 162, Loss: 0.47138386964797974, Accuracy: 0.8466796875\n",
      "Batch: 163, Loss: 0.510280191898346, Accuracy: 0.83203125\n",
      "Batch: 164, Loss: 0.5394518375396729, Accuracy: 0.8359375\n",
      "Batch: 165, Loss: 0.4856910705566406, Accuracy: 0.8427734375\n",
      "Batch: 166, Loss: 0.4941903054714203, Accuracy: 0.8408203125\n",
      "Batch: 167, Loss: 0.49118539690971375, Accuracy: 0.837890625\n",
      "Batch: 168, Loss: 0.4429021179676056, Accuracy: 0.85400390625\n",
      "Batch: 169, Loss: 0.48349469900131226, Accuracy: 0.8369140625\n",
      "Batch: 170, Loss: 0.5197563171386719, Accuracy: 0.8388671875\n",
      "Batch: 171, Loss: 0.4904758334159851, Accuracy: 0.8349609375\n",
      "Batch: 172, Loss: 0.46817630529403687, Accuracy: 0.84765625\n",
      "Batch: 173, Loss: 0.5286214351654053, Accuracy: 0.82421875\n",
      "Batch: 174, Loss: 0.4202949106693268, Accuracy: 0.8583984375\n",
      "Batch: 175, Loss: 0.5030442476272583, Accuracy: 0.83447265625\n",
      "Batch: 176, Loss: 0.5396998524665833, Accuracy: 0.82177734375\n",
      "Batch: 177, Loss: 0.4825837016105652, Accuracy: 0.8525390625\n",
      "Batch: 178, Loss: 0.47139599919319153, Accuracy: 0.83740234375\n",
      "Batch: 179, Loss: 0.47634875774383545, Accuracy: 0.84814453125\n",
      "Batch: 180, Loss: 0.5127438306808472, Accuracy: 0.84423828125\n",
      "Epoch 97/200\n",
      "Batch: 1, Loss: 0.7442773580551147, Accuracy: 0.7900390625\n",
      "Batch: 2, Loss: 0.5236992835998535, Accuracy: 0.82421875\n",
      "Batch: 3, Loss: 0.5025880336761475, Accuracy: 0.83154296875\n",
      "Batch: 4, Loss: 0.4978368878364563, Accuracy: 0.837890625\n",
      "Batch: 5, Loss: 0.5087741613388062, Accuracy: 0.83740234375\n",
      "Batch: 6, Loss: 0.5196674466133118, Accuracy: 0.82763671875\n",
      "Batch: 7, Loss: 0.49359554052352905, Accuracy: 0.8408203125\n",
      "Batch: 8, Loss: 0.4762769341468811, Accuracy: 0.84326171875\n",
      "Batch: 9, Loss: 0.5046273469924927, Accuracy: 0.8388671875\n",
      "Batch: 10, Loss: 0.45077669620513916, Accuracy: 0.85791015625\n",
      "Batch: 11, Loss: 0.5070263147354126, Accuracy: 0.82861328125\n",
      "Batch: 12, Loss: 0.43578991293907166, Accuracy: 0.85302734375\n",
      "Batch: 13, Loss: 0.5011156797409058, Accuracy: 0.837890625\n",
      "Batch: 14, Loss: 0.4725184440612793, Accuracy: 0.8505859375\n",
      "Batch: 15, Loss: 0.502889096736908, Accuracy: 0.84228515625\n",
      "Batch: 16, Loss: 0.5237612724304199, Accuracy: 0.8291015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 17, Loss: 0.46270471811294556, Accuracy: 0.8505859375\n",
      "Batch: 18, Loss: 0.4861786663532257, Accuracy: 0.84375\n",
      "Batch: 19, Loss: 0.5090154409408569, Accuracy: 0.83935546875\n",
      "Batch: 20, Loss: 0.44144558906555176, Accuracy: 0.85693359375\n",
      "Batch: 21, Loss: 0.49414026737213135, Accuracy: 0.84326171875\n",
      "Batch: 22, Loss: 0.4467250108718872, Accuracy: 0.85107421875\n",
      "Batch: 23, Loss: 0.4323917627334595, Accuracy: 0.85400390625\n",
      "Batch: 24, Loss: 0.4777716398239136, Accuracy: 0.84130859375\n",
      "Batch: 25, Loss: 0.4774099886417389, Accuracy: 0.84326171875\n",
      "Batch: 26, Loss: 0.46107539534568787, Accuracy: 0.841796875\n",
      "Batch: 27, Loss: 0.519924521446228, Accuracy: 0.8388671875\n",
      "Batch: 28, Loss: 0.4679490625858307, Accuracy: 0.85107421875\n",
      "Batch: 29, Loss: 0.5043957233428955, Accuracy: 0.83544921875\n",
      "Batch: 30, Loss: 0.5014980435371399, Accuracy: 0.84130859375\n",
      "Batch: 31, Loss: 0.5265881419181824, Accuracy: 0.83056640625\n",
      "Batch: 32, Loss: 0.5308750867843628, Accuracy: 0.82275390625\n",
      "Batch: 33, Loss: 0.48178789019584656, Accuracy: 0.83837890625\n",
      "Batch: 34, Loss: 0.5001233816146851, Accuracy: 0.83837890625\n",
      "Batch: 35, Loss: 0.5262861847877502, Accuracy: 0.82421875\n",
      "Batch: 36, Loss: 0.5132839679718018, Accuracy: 0.82958984375\n",
      "Batch: 37, Loss: 0.5488113760948181, Accuracy: 0.8251953125\n",
      "Batch: 38, Loss: 0.5110870599746704, Accuracy: 0.828125\n",
      "Batch: 39, Loss: 0.5065712332725525, Accuracy: 0.841796875\n",
      "Batch: 40, Loss: 0.5620419979095459, Accuracy: 0.81298828125\n",
      "Batch: 41, Loss: 0.5110929012298584, Accuracy: 0.828125\n",
      "Batch: 42, Loss: 0.5001026391983032, Accuracy: 0.82958984375\n",
      "Batch: 43, Loss: 0.46892714500427246, Accuracy: 0.85009765625\n",
      "Batch: 44, Loss: 0.44363880157470703, Accuracy: 0.86083984375\n",
      "Batch: 45, Loss: 0.4897974133491516, Accuracy: 0.83154296875\n",
      "Batch: 46, Loss: 0.4574882984161377, Accuracy: 0.841796875\n",
      "Batch: 47, Loss: 0.48009613156318665, Accuracy: 0.84765625\n",
      "Batch: 48, Loss: 0.49819302558898926, Accuracy: 0.84521484375\n",
      "Batch: 49, Loss: 0.47607579827308655, Accuracy: 0.8486328125\n",
      "Batch: 50, Loss: 0.5126758217811584, Accuracy: 0.83837890625\n",
      "Batch: 51, Loss: 0.4634162187576294, Accuracy: 0.84716796875\n",
      "Batch: 52, Loss: 0.5023691654205322, Accuracy: 0.830078125\n",
      "Batch: 53, Loss: 0.497789204120636, Accuracy: 0.833984375\n",
      "Batch: 54, Loss: 0.5242219567298889, Accuracy: 0.83154296875\n",
      "Batch: 55, Loss: 0.5211528539657593, Accuracy: 0.83056640625\n",
      "Batch: 56, Loss: 0.4775651693344116, Accuracy: 0.845703125\n",
      "Batch: 57, Loss: 0.5371785759925842, Accuracy: 0.82763671875\n",
      "Batch: 58, Loss: 0.4972648620605469, Accuracy: 0.83447265625\n",
      "Batch: 59, Loss: 0.5755529403686523, Accuracy: 0.8134765625\n",
      "Batch: 60, Loss: 0.5052001476287842, Accuracy: 0.837890625\n",
      "Batch: 61, Loss: 0.46640780568122864, Accuracy: 0.84765625\n",
      "Batch: 62, Loss: 0.4940660297870636, Accuracy: 0.8388671875\n",
      "Batch: 63, Loss: 0.47333893179893494, Accuracy: 0.84130859375\n",
      "Batch: 64, Loss: 0.521734356880188, Accuracy: 0.82470703125\n",
      "Batch: 65, Loss: 0.5324443578720093, Accuracy: 0.82177734375\n",
      "Batch: 66, Loss: 0.5058717727661133, Accuracy: 0.8369140625\n",
      "Batch: 67, Loss: 0.5307981371879578, Accuracy: 0.8232421875\n",
      "Batch: 68, Loss: 0.45332902669906616, Accuracy: 0.85205078125\n",
      "Batch: 69, Loss: 0.4863433539867401, Accuracy: 0.837890625\n",
      "Batch: 70, Loss: 0.4599783420562744, Accuracy: 0.8466796875\n",
      "Batch: 71, Loss: 0.453497976064682, Accuracy: 0.85546875\n",
      "Batch: 72, Loss: 0.505753755569458, Accuracy: 0.83251953125\n",
      "Batch: 73, Loss: 0.4953833520412445, Accuracy: 0.8388671875\n",
      "Batch: 74, Loss: 0.4991507828235626, Accuracy: 0.84033203125\n",
      "Batch: 75, Loss: 0.45226001739501953, Accuracy: 0.85888671875\n",
      "Batch: 76, Loss: 0.45140498876571655, Accuracy: 0.853515625\n",
      "Batch: 77, Loss: 0.45786261558532715, Accuracy: 0.85400390625\n",
      "Batch: 78, Loss: 0.4950673580169678, Accuracy: 0.84716796875\n",
      "Batch: 79, Loss: 0.4818546772003174, Accuracy: 0.83935546875\n",
      "Batch: 80, Loss: 0.5165202021598816, Accuracy: 0.8369140625\n",
      "Batch: 81, Loss: 0.5311245918273926, Accuracy: 0.830078125\n",
      "Batch: 82, Loss: 0.4847954511642456, Accuracy: 0.84228515625\n",
      "Batch: 83, Loss: 0.4385506510734558, Accuracy: 0.861328125\n",
      "Batch: 84, Loss: 0.47122129797935486, Accuracy: 0.849609375\n",
      "Batch: 85, Loss: 0.4984276592731476, Accuracy: 0.8232421875\n",
      "Batch: 86, Loss: 0.5360604524612427, Accuracy: 0.83349609375\n",
      "Batch: 87, Loss: 0.4581645131111145, Accuracy: 0.8486328125\n",
      "Batch: 88, Loss: 0.49120911955833435, Accuracy: 0.84130859375\n",
      "Batch: 89, Loss: 0.4440789818763733, Accuracy: 0.8447265625\n",
      "Batch: 90, Loss: 0.511162281036377, Accuracy: 0.837890625\n",
      "Batch: 91, Loss: 0.47857099771499634, Accuracy: 0.8486328125\n",
      "Batch: 92, Loss: 0.5433512926101685, Accuracy: 0.81640625\n",
      "Batch: 93, Loss: 0.5478053092956543, Accuracy: 0.814453125\n",
      "Batch: 94, Loss: 0.4914175271987915, Accuracy: 0.84130859375\n",
      "Batch: 95, Loss: 0.5338153839111328, Accuracy: 0.82080078125\n",
      "Batch: 96, Loss: 0.48419490456581116, Accuracy: 0.84716796875\n",
      "Batch: 97, Loss: 0.5070556402206421, Accuracy: 0.83935546875\n",
      "Batch: 98, Loss: 0.4763979911804199, Accuracy: 0.8447265625\n",
      "Batch: 99, Loss: 0.5031806230545044, Accuracy: 0.83544921875\n",
      "Batch: 100, Loss: 0.5483042001724243, Accuracy: 0.822265625\n",
      "Batch: 101, Loss: 0.5600473880767822, Accuracy: 0.81396484375\n",
      "Batch: 102, Loss: 0.47289299964904785, Accuracy: 0.84326171875\n",
      "Batch: 103, Loss: 0.513708770275116, Accuracy: 0.83984375\n",
      "Batch: 104, Loss: 0.4878959357738495, Accuracy: 0.849609375\n",
      "Batch: 105, Loss: 0.5100950002670288, Accuracy: 0.83056640625\n",
      "Batch: 106, Loss: 0.4963979125022888, Accuracy: 0.83935546875\n",
      "Batch: 107, Loss: 0.5096275806427002, Accuracy: 0.84033203125\n",
      "Batch: 108, Loss: 0.46518850326538086, Accuracy: 0.84228515625\n",
      "Batch: 109, Loss: 0.4820345640182495, Accuracy: 0.84130859375\n",
      "Batch: 110, Loss: 0.47737255692481995, Accuracy: 0.84716796875\n",
      "Batch: 111, Loss: 0.4670082926750183, Accuracy: 0.84130859375\n",
      "Batch: 112, Loss: 0.49215298891067505, Accuracy: 0.8359375\n",
      "Batch: 113, Loss: 0.5046786665916443, Accuracy: 0.83642578125\n",
      "Batch: 114, Loss: 0.5010689496994019, Accuracy: 0.83154296875\n",
      "Batch: 115, Loss: 0.48235175013542175, Accuracy: 0.8388671875\n",
      "Batch: 116, Loss: 0.4837377071380615, Accuracy: 0.84033203125\n",
      "Batch: 117, Loss: 0.4586378335952759, Accuracy: 0.8447265625\n",
      "Batch: 118, Loss: 0.4857577383518219, Accuracy: 0.84375\n",
      "Batch: 119, Loss: 0.47256922721862793, Accuracy: 0.83837890625\n",
      "Batch: 120, Loss: 0.4656124711036682, Accuracy: 0.85107421875\n",
      "Batch: 121, Loss: 0.4725031554698944, Accuracy: 0.8505859375\n",
      "Batch: 122, Loss: 0.4542887806892395, Accuracy: 0.853515625\n",
      "Batch: 123, Loss: 0.46652528643608093, Accuracy: 0.853515625\n",
      "Batch: 124, Loss: 0.4521942734718323, Accuracy: 0.85107421875\n",
      "Batch: 125, Loss: 0.48207157850265503, Accuracy: 0.84814453125\n",
      "Batch: 126, Loss: 0.46593940258026123, Accuracy: 0.8486328125\n",
      "Batch: 127, Loss: 0.4608820080757141, Accuracy: 0.8525390625\n",
      "Batch: 128, Loss: 0.5379048585891724, Accuracy: 0.82470703125\n",
      "Batch: 129, Loss: 0.5740126371383667, Accuracy: 0.822265625\n",
      "Batch: 130, Loss: 0.5654293298721313, Accuracy: 0.81640625\n",
      "Batch: 131, Loss: 0.5009741187095642, Accuracy: 0.84228515625\n",
      "Batch: 132, Loss: 0.4509859085083008, Accuracy: 0.8515625\n",
      "Batch: 133, Loss: 0.4433251619338989, Accuracy: 0.85302734375\n",
      "Batch: 134, Loss: 0.5025925040245056, Accuracy: 0.83642578125\n",
      "Batch: 135, Loss: 0.47289568185806274, Accuracy: 0.841796875\n",
      "Batch: 136, Loss: 0.45570001006126404, Accuracy: 0.8525390625\n",
      "Batch: 137, Loss: 0.5118348002433777, Accuracy: 0.82666015625\n",
      "Batch: 138, Loss: 0.45304980874061584, Accuracy: 0.85986328125\n",
      "Batch: 139, Loss: 0.4648958146572113, Accuracy: 0.8466796875\n",
      "Batch: 140, Loss: 0.4242556095123291, Accuracy: 0.869140625\n",
      "Batch: 141, Loss: 0.4901985228061676, Accuracy: 0.8525390625\n",
      "Batch: 142, Loss: 0.4431886374950409, Accuracy: 0.85693359375\n",
      "Batch: 143, Loss: 0.47937121987342834, Accuracy: 0.845703125\n",
      "Batch: 144, Loss: 0.5399167537689209, Accuracy: 0.8203125\n",
      "Batch: 145, Loss: 0.47501832246780396, Accuracy: 0.85009765625\n",
      "Batch: 146, Loss: 0.48600471019744873, Accuracy: 0.84326171875\n",
      "Batch: 147, Loss: 0.4756917357444763, Accuracy: 0.8515625\n",
      "Batch: 148, Loss: 0.49943244457244873, Accuracy: 0.8359375\n",
      "Batch: 149, Loss: 0.5278408527374268, Accuracy: 0.822265625\n",
      "Batch: 150, Loss: 0.43202757835388184, Accuracy: 0.865234375\n",
      "Batch: 151, Loss: 0.4447370171546936, Accuracy: 0.86083984375\n",
      "Batch: 152, Loss: 0.4588612914085388, Accuracy: 0.85546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 153, Loss: 0.4852222204208374, Accuracy: 0.84423828125\n",
      "Batch: 154, Loss: 0.47185438871383667, Accuracy: 0.8427734375\n",
      "Batch: 155, Loss: 0.5355594158172607, Accuracy: 0.8271484375\n",
      "Batch: 156, Loss: 0.4467182755470276, Accuracy: 0.8544921875\n",
      "Batch: 157, Loss: 0.44302690029144287, Accuracy: 0.83984375\n",
      "Batch: 158, Loss: 0.45552295446395874, Accuracy: 0.85693359375\n",
      "Batch: 159, Loss: 0.4832078218460083, Accuracy: 0.83544921875\n",
      "Batch: 160, Loss: 0.46466612815856934, Accuracy: 0.8486328125\n",
      "Batch: 161, Loss: 0.504163384437561, Accuracy: 0.83642578125\n",
      "Batch: 162, Loss: 0.4903491139411926, Accuracy: 0.837890625\n",
      "Batch: 163, Loss: 0.480683296918869, Accuracy: 0.84375\n",
      "Batch: 164, Loss: 0.5273023843765259, Accuracy: 0.83056640625\n",
      "Batch: 165, Loss: 0.4844821095466614, Accuracy: 0.83740234375\n",
      "Batch: 166, Loss: 0.5061507225036621, Accuracy: 0.83837890625\n",
      "Batch: 167, Loss: 0.49291762709617615, Accuracy: 0.8447265625\n",
      "Batch: 168, Loss: 0.45250996947288513, Accuracy: 0.8447265625\n",
      "Batch: 169, Loss: 0.4844138026237488, Accuracy: 0.8388671875\n",
      "Batch: 170, Loss: 0.5147941708564758, Accuracy: 0.82958984375\n",
      "Batch: 171, Loss: 0.48486411571502686, Accuracy: 0.84326171875\n",
      "Batch: 172, Loss: 0.47694674134254456, Accuracy: 0.8486328125\n",
      "Batch: 173, Loss: 0.514545202255249, Accuracy: 0.82373046875\n",
      "Batch: 174, Loss: 0.4382169246673584, Accuracy: 0.8486328125\n",
      "Batch: 175, Loss: 0.5119181871414185, Accuracy: 0.82958984375\n",
      "Batch: 176, Loss: 0.5277254581451416, Accuracy: 0.82958984375\n",
      "Batch: 177, Loss: 0.4965427815914154, Accuracy: 0.84228515625\n",
      "Batch: 178, Loss: 0.4567956030368805, Accuracy: 0.8447265625\n",
      "Batch: 179, Loss: 0.49091750383377075, Accuracy: 0.85009765625\n",
      "Batch: 180, Loss: 0.5102022886276245, Accuracy: 0.83740234375\n",
      "Epoch 98/200\n",
      "Batch: 1, Loss: 0.751055121421814, Accuracy: 0.79443359375\n",
      "Batch: 2, Loss: 0.4830489158630371, Accuracy: 0.8359375\n",
      "Batch: 3, Loss: 0.518413245677948, Accuracy: 0.83203125\n",
      "Batch: 4, Loss: 0.5286325216293335, Accuracy: 0.82666015625\n",
      "Batch: 5, Loss: 0.5028994679450989, Accuracy: 0.84521484375\n",
      "Batch: 6, Loss: 0.5151065587997437, Accuracy: 0.83544921875\n",
      "Batch: 7, Loss: 0.49890783429145813, Accuracy: 0.8349609375\n",
      "Batch: 8, Loss: 0.46466344594955444, Accuracy: 0.84912109375\n",
      "Batch: 9, Loss: 0.5101773142814636, Accuracy: 0.8369140625\n",
      "Batch: 10, Loss: 0.4524161219596863, Accuracy: 0.85595703125\n",
      "Batch: 11, Loss: 0.49761074781417847, Accuracy: 0.8359375\n",
      "Batch: 12, Loss: 0.43301278352737427, Accuracy: 0.86083984375\n",
      "Batch: 13, Loss: 0.49021637439727783, Accuracy: 0.83837890625\n",
      "Batch: 14, Loss: 0.4707934260368347, Accuracy: 0.84716796875\n",
      "Batch: 15, Loss: 0.493934690952301, Accuracy: 0.837890625\n",
      "Batch: 16, Loss: 0.5463408827781677, Accuracy: 0.82080078125\n",
      "Batch: 17, Loss: 0.4873916208744049, Accuracy: 0.84326171875\n",
      "Batch: 18, Loss: 0.5129772424697876, Accuracy: 0.83740234375\n",
      "Batch: 19, Loss: 0.47582632303237915, Accuracy: 0.84375\n",
      "Batch: 20, Loss: 0.40939098596572876, Accuracy: 0.8681640625\n",
      "Batch: 21, Loss: 0.4780728220939636, Accuracy: 0.8466796875\n",
      "Batch: 22, Loss: 0.45871418714523315, Accuracy: 0.8515625\n",
      "Batch: 23, Loss: 0.4442884922027588, Accuracy: 0.84912109375\n",
      "Batch: 24, Loss: 0.4679048955440521, Accuracy: 0.849609375\n",
      "Batch: 25, Loss: 0.4829471707344055, Accuracy: 0.83935546875\n",
      "Batch: 26, Loss: 0.48016583919525146, Accuracy: 0.8408203125\n",
      "Batch: 27, Loss: 0.5027533769607544, Accuracy: 0.83203125\n",
      "Batch: 28, Loss: 0.4650520980358124, Accuracy: 0.857421875\n",
      "Batch: 29, Loss: 0.5108869075775146, Accuracy: 0.83447265625\n",
      "Batch: 30, Loss: 0.5022528767585754, Accuracy: 0.84375\n",
      "Batch: 31, Loss: 0.5280735492706299, Accuracy: 0.83056640625\n",
      "Batch: 32, Loss: 0.5061131715774536, Accuracy: 0.83349609375\n",
      "Batch: 33, Loss: 0.48413267731666565, Accuracy: 0.84375\n",
      "Batch: 34, Loss: 0.5217776298522949, Accuracy: 0.82763671875\n",
      "Batch: 35, Loss: 0.5093034505844116, Accuracy: 0.83251953125\n",
      "Batch: 36, Loss: 0.488764226436615, Accuracy: 0.837890625\n",
      "Batch: 37, Loss: 0.5405207872390747, Accuracy: 0.8310546875\n",
      "Batch: 38, Loss: 0.5119581818580627, Accuracy: 0.83740234375\n",
      "Batch: 39, Loss: 0.47576582431793213, Accuracy: 0.85302734375\n",
      "Batch: 40, Loss: 0.5263592600822449, Accuracy: 0.82275390625\n",
      "Batch: 41, Loss: 0.49610209465026855, Accuracy: 0.84375\n",
      "Batch: 42, Loss: 0.4775804579257965, Accuracy: 0.8369140625\n",
      "Batch: 43, Loss: 0.4779401123523712, Accuracy: 0.8427734375\n",
      "Batch: 44, Loss: 0.4492054581642151, Accuracy: 0.857421875\n",
      "Batch: 45, Loss: 0.4878793954849243, Accuracy: 0.84033203125\n",
      "Batch: 46, Loss: 0.4410252273082733, Accuracy: 0.85205078125\n",
      "Batch: 47, Loss: 0.48529040813446045, Accuracy: 0.84033203125\n",
      "Batch: 48, Loss: 0.4791010618209839, Accuracy: 0.84423828125\n",
      "Batch: 49, Loss: 0.49032002687454224, Accuracy: 0.84521484375\n",
      "Batch: 50, Loss: 0.4783812463283539, Accuracy: 0.841796875\n",
      "Batch: 51, Loss: 0.46602189540863037, Accuracy: 0.845703125\n",
      "Batch: 52, Loss: 0.46799659729003906, Accuracy: 0.84375\n",
      "Batch: 53, Loss: 0.46697700023651123, Accuracy: 0.8466796875\n",
      "Batch: 54, Loss: 0.5151829719543457, Accuracy: 0.83154296875\n",
      "Batch: 55, Loss: 0.5010213851928711, Accuracy: 0.841796875\n",
      "Batch: 56, Loss: 0.4591032862663269, Accuracy: 0.84619140625\n",
      "Batch: 57, Loss: 0.5445038080215454, Accuracy: 0.8154296875\n",
      "Batch: 58, Loss: 0.4967365860939026, Accuracy: 0.8369140625\n",
      "Batch: 59, Loss: 0.5408934950828552, Accuracy: 0.82470703125\n",
      "Batch: 60, Loss: 0.4667322039604187, Accuracy: 0.853515625\n",
      "Batch: 61, Loss: 0.45459383726119995, Accuracy: 0.85205078125\n",
      "Batch: 62, Loss: 0.48342958092689514, Accuracy: 0.83984375\n",
      "Batch: 63, Loss: 0.47115543484687805, Accuracy: 0.83935546875\n",
      "Batch: 64, Loss: 0.47613295912742615, Accuracy: 0.8505859375\n",
      "Batch: 65, Loss: 0.509985625743866, Accuracy: 0.8369140625\n",
      "Batch: 66, Loss: 0.4770950376987457, Accuracy: 0.845703125\n",
      "Batch: 67, Loss: 0.5145608186721802, Accuracy: 0.8369140625\n",
      "Batch: 68, Loss: 0.47357046604156494, Accuracy: 0.833984375\n",
      "Batch: 69, Loss: 0.48708754777908325, Accuracy: 0.84423828125\n",
      "Batch: 70, Loss: 0.4812847971916199, Accuracy: 0.841796875\n",
      "Batch: 71, Loss: 0.47579336166381836, Accuracy: 0.84619140625\n",
      "Batch: 72, Loss: 0.5204062461853027, Accuracy: 0.826171875\n",
      "Batch: 73, Loss: 0.49692630767822266, Accuracy: 0.8388671875\n",
      "Batch: 74, Loss: 0.49573850631713867, Accuracy: 0.8369140625\n",
      "Batch: 75, Loss: 0.45061007142066956, Accuracy: 0.849609375\n",
      "Batch: 76, Loss: 0.43442922830581665, Accuracy: 0.85986328125\n",
      "Batch: 77, Loss: 0.4571002125740051, Accuracy: 0.8515625\n",
      "Batch: 78, Loss: 0.4836649000644684, Accuracy: 0.84814453125\n",
      "Batch: 79, Loss: 0.47513720393180847, Accuracy: 0.85009765625\n",
      "Batch: 80, Loss: 0.4921748638153076, Accuracy: 0.84814453125\n",
      "Batch: 81, Loss: 0.461366206407547, Accuracy: 0.8525390625\n",
      "Batch: 82, Loss: 0.48033884167671204, Accuracy: 0.84375\n",
      "Batch: 83, Loss: 0.44648289680480957, Accuracy: 0.85498046875\n",
      "Batch: 84, Loss: 0.47086501121520996, Accuracy: 0.85205078125\n",
      "Batch: 85, Loss: 0.48824968934059143, Accuracy: 0.8388671875\n",
      "Batch: 86, Loss: 0.524004340171814, Accuracy: 0.83740234375\n",
      "Batch: 87, Loss: 0.48924872279167175, Accuracy: 0.84228515625\n",
      "Batch: 88, Loss: 0.5064576864242554, Accuracy: 0.83251953125\n",
      "Batch: 89, Loss: 0.45211246609687805, Accuracy: 0.84521484375\n",
      "Batch: 90, Loss: 0.4887983202934265, Accuracy: 0.8369140625\n",
      "Batch: 91, Loss: 0.49398353695869446, Accuracy: 0.84375\n",
      "Batch: 92, Loss: 0.5272746682167053, Accuracy: 0.81591796875\n",
      "Batch: 93, Loss: 0.5097582340240479, Accuracy: 0.83203125\n",
      "Batch: 94, Loss: 0.5227516293525696, Accuracy: 0.82861328125\n",
      "Batch: 95, Loss: 0.5331388711929321, Accuracy: 0.82080078125\n",
      "Batch: 96, Loss: 0.5153031349182129, Accuracy: 0.83642578125\n",
      "Batch: 97, Loss: 0.4701349139213562, Accuracy: 0.845703125\n",
      "Batch: 98, Loss: 0.4800368547439575, Accuracy: 0.849609375\n",
      "Batch: 99, Loss: 0.4785199463367462, Accuracy: 0.8388671875\n",
      "Batch: 100, Loss: 0.5299264192581177, Accuracy: 0.82568359375\n",
      "Batch: 101, Loss: 0.5470339059829712, Accuracy: 0.82421875\n",
      "Batch: 102, Loss: 0.4500146210193634, Accuracy: 0.86279296875\n",
      "Batch: 103, Loss: 0.4943038821220398, Accuracy: 0.84375\n",
      "Batch: 104, Loss: 0.49071818590164185, Accuracy: 0.845703125\n",
      "Batch: 105, Loss: 0.49411794543266296, Accuracy: 0.841796875\n",
      "Batch: 106, Loss: 0.4481602907180786, Accuracy: 0.85302734375\n",
      "Batch: 107, Loss: 0.5063151717185974, Accuracy: 0.837890625\n",
      "Batch: 108, Loss: 0.45861998200416565, Accuracy: 0.85595703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 109, Loss: 0.4742678999900818, Accuracy: 0.84130859375\n",
      "Batch: 110, Loss: 0.4773295521736145, Accuracy: 0.8466796875\n",
      "Batch: 111, Loss: 0.44087833166122437, Accuracy: 0.8515625\n",
      "Batch: 112, Loss: 0.46137502789497375, Accuracy: 0.8515625\n",
      "Batch: 113, Loss: 0.5065615177154541, Accuracy: 0.8251953125\n",
      "Batch: 114, Loss: 0.5075063705444336, Accuracy: 0.83935546875\n",
      "Batch: 115, Loss: 0.4759484827518463, Accuracy: 0.84326171875\n",
      "Batch: 116, Loss: 0.4425850510597229, Accuracy: 0.861328125\n",
      "Batch: 117, Loss: 0.44582200050354004, Accuracy: 0.84619140625\n",
      "Batch: 118, Loss: 0.49049532413482666, Accuracy: 0.8369140625\n",
      "Batch: 119, Loss: 0.48799529671669006, Accuracy: 0.837890625\n",
      "Batch: 120, Loss: 0.4680337607860565, Accuracy: 0.84716796875\n",
      "Batch: 121, Loss: 0.46164020895957947, Accuracy: 0.84765625\n",
      "Batch: 122, Loss: 0.4579319953918457, Accuracy: 0.841796875\n",
      "Batch: 123, Loss: 0.45053985714912415, Accuracy: 0.85693359375\n",
      "Batch: 124, Loss: 0.4325264096260071, Accuracy: 0.8564453125\n",
      "Batch: 125, Loss: 0.4775948226451874, Accuracy: 0.84423828125\n",
      "Batch: 126, Loss: 0.47969335317611694, Accuracy: 0.84033203125\n",
      "Batch: 127, Loss: 0.43550264835357666, Accuracy: 0.85986328125\n",
      "Batch: 128, Loss: 0.5060901045799255, Accuracy: 0.8369140625\n",
      "Batch: 129, Loss: 0.5498456954956055, Accuracy: 0.81787109375\n",
      "Batch: 130, Loss: 0.5655449032783508, Accuracy: 0.81591796875\n",
      "Batch: 131, Loss: 0.4804735779762268, Accuracy: 0.83935546875\n",
      "Batch: 132, Loss: 0.45548495650291443, Accuracy: 0.85009765625\n",
      "Batch: 133, Loss: 0.4629041254520416, Accuracy: 0.85107421875\n",
      "Batch: 134, Loss: 0.4960508942604065, Accuracy: 0.83935546875\n",
      "Batch: 135, Loss: 0.4713537395000458, Accuracy: 0.8466796875\n",
      "Batch: 136, Loss: 0.4704006016254425, Accuracy: 0.84423828125\n",
      "Batch: 137, Loss: 0.4972458779811859, Accuracy: 0.84423828125\n",
      "Batch: 138, Loss: 0.4480094909667969, Accuracy: 0.857421875\n",
      "Batch: 139, Loss: 0.45535823702812195, Accuracy: 0.85009765625\n",
      "Batch: 140, Loss: 0.42997491359710693, Accuracy: 0.85400390625\n",
      "Batch: 141, Loss: 0.48882919549942017, Accuracy: 0.83544921875\n",
      "Batch: 142, Loss: 0.44220855832099915, Accuracy: 0.8505859375\n",
      "Batch: 143, Loss: 0.44754624366760254, Accuracy: 0.86328125\n",
      "Batch: 144, Loss: 0.533349871635437, Accuracy: 0.83203125\n",
      "Batch: 145, Loss: 0.5135940313339233, Accuracy: 0.84033203125\n",
      "Batch: 146, Loss: 0.4973815679550171, Accuracy: 0.84326171875\n",
      "Batch: 147, Loss: 0.44861385226249695, Accuracy: 0.86083984375\n",
      "Batch: 148, Loss: 0.47111088037490845, Accuracy: 0.83935546875\n",
      "Batch: 149, Loss: 0.485340416431427, Accuracy: 0.83740234375\n",
      "Batch: 150, Loss: 0.44353675842285156, Accuracy: 0.86181640625\n",
      "Batch: 151, Loss: 0.45275232195854187, Accuracy: 0.8603515625\n",
      "Batch: 152, Loss: 0.4628470540046692, Accuracy: 0.84375\n",
      "Batch: 153, Loss: 0.46229976415634155, Accuracy: 0.8486328125\n",
      "Batch: 154, Loss: 0.4719303548336029, Accuracy: 0.84814453125\n",
      "Batch: 155, Loss: 0.5224565863609314, Accuracy: 0.82470703125\n",
      "Batch: 156, Loss: 0.4366110861301422, Accuracy: 0.85205078125\n",
      "Batch: 157, Loss: 0.42377060651779175, Accuracy: 0.859375\n",
      "Batch: 158, Loss: 0.45537781715393066, Accuracy: 0.85888671875\n",
      "Batch: 159, Loss: 0.4667593240737915, Accuracy: 0.83984375\n",
      "Batch: 160, Loss: 0.48508918285369873, Accuracy: 0.84619140625\n",
      "Batch: 161, Loss: 0.5107725262641907, Accuracy: 0.83447265625\n",
      "Batch: 162, Loss: 0.4677415192127228, Accuracy: 0.84814453125\n",
      "Batch: 163, Loss: 0.47697436809539795, Accuracy: 0.84326171875\n",
      "Batch: 164, Loss: 0.5429812669754028, Accuracy: 0.82421875\n",
      "Batch: 165, Loss: 0.49722039699554443, Accuracy: 0.84326171875\n",
      "Batch: 166, Loss: 0.4860658645629883, Accuracy: 0.8408203125\n",
      "Batch: 167, Loss: 0.47051066160202026, Accuracy: 0.84521484375\n",
      "Batch: 168, Loss: 0.4285571277141571, Accuracy: 0.86474609375\n",
      "Batch: 169, Loss: 0.49664542078971863, Accuracy: 0.8349609375\n",
      "Batch: 170, Loss: 0.5073046088218689, Accuracy: 0.84033203125\n",
      "Batch: 171, Loss: 0.48554080724716187, Accuracy: 0.841796875\n",
      "Batch: 172, Loss: 0.4647146761417389, Accuracy: 0.8349609375\n",
      "Batch: 173, Loss: 0.5001949667930603, Accuracy: 0.83154296875\n",
      "Batch: 174, Loss: 0.4337618947029114, Accuracy: 0.85302734375\n",
      "Batch: 175, Loss: 0.4964222311973572, Accuracy: 0.83837890625\n",
      "Batch: 176, Loss: 0.5354779362678528, Accuracy: 0.830078125\n",
      "Batch: 177, Loss: 0.4864809513092041, Accuracy: 0.84619140625\n",
      "Batch: 178, Loss: 0.45917177200317383, Accuracy: 0.86083984375\n",
      "Batch: 179, Loss: 0.5110491514205933, Accuracy: 0.83984375\n",
      "Batch: 180, Loss: 0.5162917375564575, Accuracy: 0.83251953125\n",
      "Epoch 99/200\n",
      "Batch: 1, Loss: 0.7581126689910889, Accuracy: 0.783203125\n",
      "Batch: 2, Loss: 0.47698935866355896, Accuracy: 0.83349609375\n",
      "Batch: 3, Loss: 0.4823146462440491, Accuracy: 0.84130859375\n",
      "Batch: 4, Loss: 0.48738014698028564, Accuracy: 0.8359375\n",
      "Batch: 5, Loss: 0.48831847310066223, Accuracy: 0.845703125\n",
      "Batch: 6, Loss: 0.4884161055088043, Accuracy: 0.8359375\n",
      "Batch: 7, Loss: 0.47488439083099365, Accuracy: 0.8447265625\n",
      "Batch: 8, Loss: 0.46660444140434265, Accuracy: 0.8505859375\n",
      "Batch: 9, Loss: 0.49956852197647095, Accuracy: 0.84130859375\n",
      "Batch: 10, Loss: 0.454658180475235, Accuracy: 0.853515625\n",
      "Batch: 11, Loss: 0.4944165050983429, Accuracy: 0.8408203125\n",
      "Batch: 12, Loss: 0.4383155107498169, Accuracy: 0.85107421875\n",
      "Batch: 13, Loss: 0.49304288625717163, Accuracy: 0.83544921875\n",
      "Batch: 14, Loss: 0.4695993661880493, Accuracy: 0.85009765625\n",
      "Batch: 15, Loss: 0.4999168813228607, Accuracy: 0.841796875\n",
      "Batch: 16, Loss: 0.5175067782402039, Accuracy: 0.81884765625\n",
      "Batch: 17, Loss: 0.4738231599330902, Accuracy: 0.841796875\n",
      "Batch: 18, Loss: 0.5089507699012756, Accuracy: 0.84228515625\n",
      "Batch: 19, Loss: 0.48290395736694336, Accuracy: 0.84765625\n",
      "Batch: 20, Loss: 0.4124169945716858, Accuracy: 0.85791015625\n",
      "Batch: 21, Loss: 0.5002574920654297, Accuracy: 0.8408203125\n",
      "Batch: 22, Loss: 0.4526815414428711, Accuracy: 0.857421875\n",
      "Batch: 23, Loss: 0.43718844652175903, Accuracy: 0.8544921875\n",
      "Batch: 24, Loss: 0.48191994428634644, Accuracy: 0.84375\n",
      "Batch: 25, Loss: 0.4631401002407074, Accuracy: 0.85107421875\n",
      "Batch: 26, Loss: 0.4804985821247101, Accuracy: 0.83984375\n",
      "Batch: 27, Loss: 0.5025565028190613, Accuracy: 0.83349609375\n",
      "Batch: 28, Loss: 0.47184064984321594, Accuracy: 0.85546875\n",
      "Batch: 29, Loss: 0.4940313696861267, Accuracy: 0.841796875\n",
      "Batch: 30, Loss: 0.502901017665863, Accuracy: 0.84326171875\n",
      "Batch: 31, Loss: 0.5381902456283569, Accuracy: 0.82958984375\n",
      "Batch: 32, Loss: 0.5346016883850098, Accuracy: 0.8251953125\n",
      "Batch: 33, Loss: 0.4898325800895691, Accuracy: 0.83935546875\n",
      "Batch: 34, Loss: 0.5045263767242432, Accuracy: 0.83154296875\n",
      "Batch: 35, Loss: 0.5358626842498779, Accuracy: 0.8291015625\n",
      "Batch: 36, Loss: 0.5145390629768372, Accuracy: 0.82861328125\n",
      "Batch: 37, Loss: 0.5229020118713379, Accuracy: 0.83203125\n",
      "Batch: 38, Loss: 0.5091248750686646, Accuracy: 0.8330078125\n",
      "Batch: 39, Loss: 0.4938651919364929, Accuracy: 0.83544921875\n",
      "Batch: 40, Loss: 0.5099291801452637, Accuracy: 0.837890625\n",
      "Batch: 41, Loss: 0.5223575830459595, Accuracy: 0.83203125\n",
      "Batch: 42, Loss: 0.4974277913570404, Accuracy: 0.83544921875\n",
      "Batch: 43, Loss: 0.47104647755622864, Accuracy: 0.84814453125\n",
      "Batch: 44, Loss: 0.4352644383907318, Accuracy: 0.8642578125\n",
      "Batch: 45, Loss: 0.47857359051704407, Accuracy: 0.84130859375\n",
      "Batch: 46, Loss: 0.4532712996006012, Accuracy: 0.8447265625\n",
      "Batch: 47, Loss: 0.47611403465270996, Accuracy: 0.8466796875\n",
      "Batch: 48, Loss: 0.5011087656021118, Accuracy: 0.83642578125\n",
      "Batch: 49, Loss: 0.4671314060688019, Accuracy: 0.84814453125\n",
      "Batch: 50, Loss: 0.4790598154067993, Accuracy: 0.83935546875\n",
      "Batch: 51, Loss: 0.4745400547981262, Accuracy: 0.85791015625\n",
      "Batch: 52, Loss: 0.4867646098136902, Accuracy: 0.82861328125\n",
      "Batch: 53, Loss: 0.47575920820236206, Accuracy: 0.84814453125\n",
      "Batch: 54, Loss: 0.5001091957092285, Accuracy: 0.833984375\n",
      "Batch: 55, Loss: 0.4912429749965668, Accuracy: 0.8486328125\n",
      "Batch: 56, Loss: 0.45885640382766724, Accuracy: 0.84228515625\n",
      "Batch: 57, Loss: 0.5273893475532532, Accuracy: 0.83349609375\n",
      "Batch: 58, Loss: 0.4772029519081116, Accuracy: 0.84716796875\n",
      "Batch: 59, Loss: 0.5657166242599487, Accuracy: 0.82177734375\n",
      "Batch: 60, Loss: 0.46826720237731934, Accuracy: 0.8505859375\n",
      "Batch: 61, Loss: 0.4382782578468323, Accuracy: 0.85888671875\n",
      "Batch: 62, Loss: 0.4830583333969116, Accuracy: 0.84521484375\n",
      "Batch: 63, Loss: 0.4635024070739746, Accuracy: 0.8447265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 64, Loss: 0.4957650303840637, Accuracy: 0.82958984375\n",
      "Batch: 65, Loss: 0.5179043412208557, Accuracy: 0.822265625\n",
      "Batch: 66, Loss: 0.48863834142684937, Accuracy: 0.84375\n",
      "Batch: 67, Loss: 0.5140656232833862, Accuracy: 0.8359375\n",
      "Batch: 68, Loss: 0.4264504313468933, Accuracy: 0.86083984375\n",
      "Batch: 69, Loss: 0.4708821177482605, Accuracy: 0.84619140625\n",
      "Batch: 70, Loss: 0.4409862160682678, Accuracy: 0.8505859375\n",
      "Batch: 71, Loss: 0.4662485718727112, Accuracy: 0.84814453125\n",
      "Batch: 72, Loss: 0.48853233456611633, Accuracy: 0.83349609375\n",
      "Batch: 73, Loss: 0.48572391271591187, Accuracy: 0.84375\n",
      "Batch: 74, Loss: 0.4791041314601898, Accuracy: 0.8466796875\n",
      "Batch: 75, Loss: 0.4498368203639984, Accuracy: 0.8466796875\n",
      "Batch: 76, Loss: 0.4274808466434479, Accuracy: 0.87255859375\n",
      "Batch: 77, Loss: 0.455777645111084, Accuracy: 0.8583984375\n",
      "Batch: 78, Loss: 0.49066802859306335, Accuracy: 0.8447265625\n",
      "Batch: 79, Loss: 0.4709770679473877, Accuracy: 0.8515625\n",
      "Batch: 80, Loss: 0.47901231050491333, Accuracy: 0.84326171875\n",
      "Batch: 81, Loss: 0.5009562969207764, Accuracy: 0.8427734375\n",
      "Batch: 82, Loss: 0.5014445185661316, Accuracy: 0.83740234375\n",
      "Batch: 83, Loss: 0.4416370987892151, Accuracy: 0.85791015625\n",
      "Batch: 84, Loss: 0.48611828684806824, Accuracy: 0.83935546875\n",
      "Batch: 85, Loss: 0.4922199249267578, Accuracy: 0.8349609375\n",
      "Batch: 86, Loss: 0.5066804885864258, Accuracy: 0.84033203125\n",
      "Batch: 87, Loss: 0.4650925397872925, Accuracy: 0.84033203125\n",
      "Batch: 88, Loss: 0.49730682373046875, Accuracy: 0.84130859375\n",
      "Batch: 89, Loss: 0.4662231206893921, Accuracy: 0.8388671875\n",
      "Batch: 90, Loss: 0.5106709599494934, Accuracy: 0.83203125\n",
      "Batch: 91, Loss: 0.4905151128768921, Accuracy: 0.84912109375\n",
      "Batch: 92, Loss: 0.5286296606063843, Accuracy: 0.8203125\n",
      "Batch: 93, Loss: 0.541654109954834, Accuracy: 0.82080078125\n",
      "Batch: 94, Loss: 0.5177756547927856, Accuracy: 0.830078125\n",
      "Batch: 95, Loss: 0.5494334697723389, Accuracy: 0.8271484375\n",
      "Batch: 96, Loss: 0.5087060332298279, Accuracy: 0.8447265625\n",
      "Batch: 97, Loss: 0.5065221190452576, Accuracy: 0.83984375\n",
      "Batch: 98, Loss: 0.4942362904548645, Accuracy: 0.83935546875\n",
      "Batch: 99, Loss: 0.49110147356987, Accuracy: 0.8486328125\n",
      "Batch: 100, Loss: 0.5330358147621155, Accuracy: 0.8349609375\n",
      "Batch: 101, Loss: 0.5412213802337646, Accuracy: 0.81591796875\n",
      "Batch: 102, Loss: 0.4743735194206238, Accuracy: 0.8388671875\n",
      "Batch: 103, Loss: 0.4953697919845581, Accuracy: 0.82958984375\n",
      "Batch: 104, Loss: 0.4754313826560974, Accuracy: 0.84423828125\n",
      "Batch: 105, Loss: 0.4852467179298401, Accuracy: 0.84814453125\n",
      "Batch: 106, Loss: 0.4822671413421631, Accuracy: 0.84765625\n",
      "Batch: 107, Loss: 0.4858900308609009, Accuracy: 0.84814453125\n",
      "Batch: 108, Loss: 0.47609269618988037, Accuracy: 0.84423828125\n",
      "Batch: 109, Loss: 0.4530654549598694, Accuracy: 0.849609375\n",
      "Batch: 110, Loss: 0.45980149507522583, Accuracy: 0.84716796875\n",
      "Batch: 111, Loss: 0.45467156171798706, Accuracy: 0.84619140625\n",
      "Batch: 112, Loss: 0.48310813307762146, Accuracy: 0.8359375\n",
      "Batch: 113, Loss: 0.4932982921600342, Accuracy: 0.83642578125\n",
      "Batch: 114, Loss: 0.4879668951034546, Accuracy: 0.8466796875\n",
      "Batch: 115, Loss: 0.462285578250885, Accuracy: 0.8447265625\n",
      "Batch: 116, Loss: 0.4676090478897095, Accuracy: 0.84130859375\n",
      "Batch: 117, Loss: 0.4469485282897949, Accuracy: 0.8564453125\n",
      "Batch: 118, Loss: 0.48400211334228516, Accuracy: 0.8388671875\n",
      "Batch: 119, Loss: 0.45699501037597656, Accuracy: 0.85009765625\n",
      "Batch: 120, Loss: 0.44317978620529175, Accuracy: 0.85888671875\n",
      "Batch: 121, Loss: 0.4550212621688843, Accuracy: 0.8515625\n",
      "Batch: 122, Loss: 0.4570709466934204, Accuracy: 0.84619140625\n",
      "Batch: 123, Loss: 0.45657777786254883, Accuracy: 0.859375\n",
      "Batch: 124, Loss: 0.44697141647338867, Accuracy: 0.85498046875\n",
      "Batch: 125, Loss: 0.4651137590408325, Accuracy: 0.85107421875\n",
      "Batch: 126, Loss: 0.4988042116165161, Accuracy: 0.83642578125\n",
      "Batch: 127, Loss: 0.42612481117248535, Accuracy: 0.869140625\n",
      "Batch: 128, Loss: 0.5018579363822937, Accuracy: 0.84033203125\n",
      "Batch: 129, Loss: 0.5403944253921509, Accuracy: 0.8310546875\n",
      "Batch: 130, Loss: 0.5289340019226074, Accuracy: 0.82275390625\n",
      "Batch: 131, Loss: 0.4699240028858185, Accuracy: 0.84423828125\n",
      "Batch: 132, Loss: 0.4700986444950104, Accuracy: 0.84716796875\n",
      "Batch: 133, Loss: 0.4554396867752075, Accuracy: 0.8544921875\n",
      "Batch: 134, Loss: 0.5185965299606323, Accuracy: 0.83154296875\n",
      "Batch: 135, Loss: 0.5173472762107849, Accuracy: 0.82861328125\n",
      "Batch: 136, Loss: 0.4448992609977722, Accuracy: 0.86181640625\n",
      "Batch: 137, Loss: 0.4771346151828766, Accuracy: 0.84033203125\n",
      "Batch: 138, Loss: 0.44159984588623047, Accuracy: 0.85498046875\n",
      "Batch: 139, Loss: 0.4736238718032837, Accuracy: 0.84326171875\n",
      "Batch: 140, Loss: 0.4210819602012634, Accuracy: 0.85986328125\n",
      "Batch: 141, Loss: 0.44506382942199707, Accuracy: 0.857421875\n",
      "Batch: 142, Loss: 0.43851155042648315, Accuracy: 0.85986328125\n",
      "Batch: 143, Loss: 0.44271641969680786, Accuracy: 0.8544921875\n",
      "Batch: 144, Loss: 0.5165505409240723, Accuracy: 0.8310546875\n",
      "Batch: 145, Loss: 0.4916316866874695, Accuracy: 0.84228515625\n",
      "Batch: 146, Loss: 0.5277840495109558, Accuracy: 0.830078125\n",
      "Batch: 147, Loss: 0.4621036648750305, Accuracy: 0.84716796875\n",
      "Batch: 148, Loss: 0.5174914598464966, Accuracy: 0.828125\n",
      "Batch: 149, Loss: 0.5009180307388306, Accuracy: 0.82861328125\n",
      "Batch: 150, Loss: 0.4319964051246643, Accuracy: 0.85888671875\n",
      "Batch: 151, Loss: 0.4522882401943207, Accuracy: 0.8525390625\n",
      "Batch: 152, Loss: 0.4439641833305359, Accuracy: 0.85009765625\n",
      "Batch: 153, Loss: 0.4867996275424957, Accuracy: 0.8427734375\n",
      "Batch: 154, Loss: 0.4801623821258545, Accuracy: 0.84521484375\n",
      "Batch: 155, Loss: 0.5148550271987915, Accuracy: 0.8330078125\n",
      "Batch: 156, Loss: 0.4537576735019684, Accuracy: 0.85595703125\n",
      "Batch: 157, Loss: 0.44750508666038513, Accuracy: 0.8505859375\n",
      "Batch: 158, Loss: 0.48120611906051636, Accuracy: 0.84521484375\n",
      "Batch: 159, Loss: 0.4757949709892273, Accuracy: 0.84423828125\n",
      "Batch: 160, Loss: 0.48743733763694763, Accuracy: 0.8466796875\n",
      "Batch: 161, Loss: 0.5047452449798584, Accuracy: 0.85107421875\n",
      "Batch: 162, Loss: 0.46869027614593506, Accuracy: 0.845703125\n",
      "Batch: 163, Loss: 0.5132420659065247, Accuracy: 0.82861328125\n",
      "Batch: 164, Loss: 0.5333265066146851, Accuracy: 0.82568359375\n",
      "Batch: 165, Loss: 0.4890909790992737, Accuracy: 0.8544921875\n",
      "Batch: 166, Loss: 0.49054524302482605, Accuracy: 0.84375\n",
      "Batch: 167, Loss: 0.4722699224948883, Accuracy: 0.85009765625\n",
      "Batch: 168, Loss: 0.43736252188682556, Accuracy: 0.8583984375\n",
      "Batch: 169, Loss: 0.4573848843574524, Accuracy: 0.85009765625\n",
      "Batch: 170, Loss: 0.4888197183609009, Accuracy: 0.8447265625\n",
      "Batch: 171, Loss: 0.4770362079143524, Accuracy: 0.845703125\n",
      "Batch: 172, Loss: 0.46215927600860596, Accuracy: 0.845703125\n",
      "Batch: 173, Loss: 0.4959430992603302, Accuracy: 0.84033203125\n",
      "Batch: 174, Loss: 0.4508410692214966, Accuracy: 0.8505859375\n",
      "Batch: 175, Loss: 0.4760061502456665, Accuracy: 0.84130859375\n",
      "Batch: 176, Loss: 0.5143418312072754, Accuracy: 0.8330078125\n",
      "Batch: 177, Loss: 0.49423307180404663, Accuracy: 0.8359375\n",
      "Batch: 178, Loss: 0.46195513010025024, Accuracy: 0.84423828125\n",
      "Batch: 179, Loss: 0.49522221088409424, Accuracy: 0.84765625\n",
      "Batch: 180, Loss: 0.4963388741016388, Accuracy: 0.8388671875\n",
      "Epoch 100/200\n",
      "Batch: 1, Loss: 0.7311811447143555, Accuracy: 0.79248046875\n"
     ]
    }
   ],
   "source": [
    "file = open(os.path.join(data_directory, data_file), mode = 'r')\n",
    "data = file.read()\n",
    "file.close()\n",
    "if __name__ == \"__main__\":\n",
    "    training_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-30T18:24:40.401842Z",
     "start_time": "2020-04-30T18:24:38.945920Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.510531</td>\n",
       "      <td>0.140137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.274780</td>\n",
       "      <td>0.162109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.968642</td>\n",
       "      <td>0.208496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2.448124</td>\n",
       "      <td>0.333984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.157264</td>\n",
       "      <td>0.395508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>156</td>\n",
       "      <td>0.343946</td>\n",
       "      <td>0.883301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>0.337188</td>\n",
       "      <td>0.896484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>158</td>\n",
       "      <td>0.338072</td>\n",
       "      <td>0.895508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>159</td>\n",
       "      <td>0.321451</td>\n",
       "      <td>0.891602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>160</td>\n",
       "      <td>0.330902</td>\n",
       "      <td>0.893066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Epoch      Loss  Accuracy\n",
       "0        1  3.510531  0.140137\n",
       "1        2  3.274780  0.162109\n",
       "2        3  2.968642  0.208496\n",
       "3        4  2.448124  0.333984\n",
       "4        5  2.157264  0.395508\n",
       "..     ...       ...       ...\n",
       "155    156  0.343946  0.883301\n",
       "156    157  0.337188  0.896484\n",
       "157    158  0.338072  0.895508\n",
       "158    159  0.321451  0.891602\n",
       "159    160  0.330902  0.893066\n",
       "\n",
       "[160 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv(os.path.join(data_directory, \"log.csv\"))\n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
